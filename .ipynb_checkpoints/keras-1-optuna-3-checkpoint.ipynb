{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f94e9fd3-99b1-438c-9ac0-6d5455c99af4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pdb;\n",
    "from grocery_ml_tensorflow import GroceryML\n",
    "from grocery_ml_core import GroceryMLCore\n",
    "from hidden_layer_param_builder import HiddenLayerParamSetBuilder\n",
    "import tensorflow as tf\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option(\"display.float_format\", lambda x: f\"{x:.6f}\")\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", 2000)\n",
    "\n",
    "print(os.getcwd())\n",
    "# print(\"GPUs Available:\", tf.config.list_physical_devices('GPU'))\n",
    "#tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# def run_all_experiments(df, model_param_sets, output_dir):\n",
    "#     total = len(model_param_sets)\n",
    "#     print(f\"run_all_experiments() when: {datetime.now()}  output_dir: {output_dir}\");\n",
    "#     for index, params in enumerate(model_param_sets, 1):\n",
    "#         print(f\"Running Exp {index}/{total}...\")\n",
    "#         groceryML.run_experiment(df,  params[\"buildParams\"], params[\"trainParams\"], output_dir)\n",
    "\n",
    "\n",
    "try:\n",
    "    groceryML = GroceryML();\n",
    "    groceryMLCore = GroceryMLCore();\n",
    "    groceryML.build_training_df()\n",
    "    if groceryML.training_df is None:\n",
    "        raise();\n",
    "    ts = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "    # groceryML.training_df.to_csv(f\"training_df-{ts}.csv\");\n",
    "except Exception as ex: \n",
    "    print(ex)\n",
    "    ts = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "    groceryML.training_df.to_csv(f\"training_df-{ts}-exception.csv\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4722275b-46b7-4fd3-8e11-4148a6f0fb4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-14 20:22:43,050] A new study created in RDB with name: grocery_ml_tuning_20260114_202239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e126_l64-64-64_ep50_sig_642\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e126_l64-64-64_ep50_sig_642  \n",
      "run_experiment()  when: 2026-01-14 20:22:43.278788 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 20:23:28.719061\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e126_l64-64-64_ep50_sig_642\\normalized_training_df-e126_l64-64-64_ep50_sig_642.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e126_l64-64-64_ep50_sig_642\\normalized_training_df-e126_l64-64-64_ep50_sig_642.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e126_l64-64-64_ep50_sig_642\\predictions-e126_l64-64-64_ep50_sig_642.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e126_l64-64-64_ep50_sig_642\\predictions-e126_l64-64-64_ep50_sig_642.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e126_l64-64-64_ep50_sig_642\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e126_l64-64-64_ep50_sig_642\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e126_l64-64-64_ep50_sig_642\\model\\assets\n",
      "[I 2026-01-14 20:25:28,197] Trial 0 finished with value: 0.8946261405944824 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 126, 'epochs': 50}. Best is trial 0 with value: 0.8946261405944824.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e126_l64-64-64_ep50_sig_642\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e126_l64-64-64_ep50_sig_642\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e441_l64-64-64_ep50_sig_524\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e441_l64-64-64_ep50_sig_524  \n",
      "run_experiment()  when: 2026-01-14 20:25:28.235347 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 20:25:42.284585\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 856us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e441_l64-64-64_ep50_sig_524\\normalized_training_df-e441_l64-64-64_ep50_sig_524.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e441_l64-64-64_ep50_sig_524\\normalized_training_df-e441_l64-64-64_ep50_sig_524.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e441_l64-64-64_ep50_sig_524\\predictions-e441_l64-64-64_ep50_sig_524.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e441_l64-64-64_ep50_sig_524\\predictions-e441_l64-64-64_ep50_sig_524.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e441_l64-64-64_ep50_sig_524\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e441_l64-64-64_ep50_sig_524\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e441_l64-64-64_ep50_sig_524\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e441_l64-64-64_ep50_sig_524\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e441_l64-64-64_ep50_sig_524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-14 20:27:44,176] Trial 1 finished with value: 0.8923182487487793 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 441, 'epochs': 50}. Best is trial 0 with value: 0.8946261405944824.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e277_l64-64-64_ep50_sig_711\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e277_l64-64-64_ep50_sig_711  \n",
      "run_experiment()  when: 2026-01-14 20:27:44.308617 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 20:28:27.961851\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e277_l64-64-64_ep50_sig_711\\normalized_training_df-e277_l64-64-64_ep50_sig_711.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e277_l64-64-64_ep50_sig_711\\normalized_training_df-e277_l64-64-64_ep50_sig_711.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e277_l64-64-64_ep50_sig_711\\predictions-e277_l64-64-64_ep50_sig_711.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e277_l64-64-64_ep50_sig_711\\predictions-e277_l64-64-64_ep50_sig_711.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e277_l64-64-64_ep50_sig_711\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e277_l64-64-64_ep50_sig_711\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e277_l64-64-64_ep50_sig_711\\model\\assets\n",
      "[I 2026-01-14 20:29:15,358] Trial 2 finished with value: 0.8772014379501343 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 277, 'epochs': 50}. Best is trial 0 with value: 0.8946261405944824.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e277_l64-64-64_ep50_sig_711\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e277_l64-64-64_ep50_sig_711\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e303_l64-64-64_ep50_sig_902\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e303_l64-64-64_ep50_sig_902  \n",
      "run_experiment()  when: 2026-01-14 20:29:15.391533 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 20:30:15.278635\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 6ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e303_l64-64-64_ep50_sig_902\\normalized_training_df-e303_l64-64-64_ep50_sig_902.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e303_l64-64-64_ep50_sig_902\\normalized_training_df-e303_l64-64-64_ep50_sig_902.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e303_l64-64-64_ep50_sig_902\\predictions-e303_l64-64-64_ep50_sig_902.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e303_l64-64-64_ep50_sig_902\\predictions-e303_l64-64-64_ep50_sig_902.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e303_l64-64-64_ep50_sig_902\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e303_l64-64-64_ep50_sig_902\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e303_l64-64-64_ep50_sig_902\\model\\assets\n",
      "[I 2026-01-14 20:33:53,418] Trial 3 finished with value: 0.8922256231307983 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 303, 'epochs': 50}. Best is trial 0 with value: 0.8946261405944824.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e303_l64-64-64_ep50_sig_902\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e303_l64-64-64_ep50_sig_902\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e113_l64-64-64_ep50_sig_101\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e113_l64-64-64_ep50_sig_101  \n",
      "run_experiment()  when: 2026-01-14 20:33:53.449872 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 20:34:50.363727\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e113_l64-64-64_ep50_sig_101\\normalized_training_df-e113_l64-64-64_ep50_sig_101.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e113_l64-64-64_ep50_sig_101\\normalized_training_df-e113_l64-64-64_ep50_sig_101.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e113_l64-64-64_ep50_sig_101\\predictions-e113_l64-64-64_ep50_sig_101.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e113_l64-64-64_ep50_sig_101\\predictions-e113_l64-64-64_ep50_sig_101.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e113_l64-64-64_ep50_sig_101\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e113_l64-64-64_ep50_sig_101\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e113_l64-64-64_ep50_sig_101\\model\\assets\n",
      "[I 2026-01-14 20:37:43,279] Trial 4 finished with value: 0.8924294710159302 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 113, 'epochs': 50}. Best is trial 0 with value: 0.8946261405944824.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e113_l64-64-64_ep50_sig_101\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e113_l64-64-64_ep50_sig_101\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e367_l64-64-64_ep50_sig_715\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e367_l64-64-64_ep50_sig_715  \n",
      "run_experiment()  when: 2026-01-14 20:37:43.310383 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 20:37:54.851433\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e367_l64-64-64_ep50_sig_715\\normalized_training_df-e367_l64-64-64_ep50_sig_715.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e367_l64-64-64_ep50_sig_715\\normalized_training_df-e367_l64-64-64_ep50_sig_715.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e367_l64-64-64_ep50_sig_715\\predictions-e367_l64-64-64_ep50_sig_715.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e367_l64-64-64_ep50_sig_715\\predictions-e367_l64-64-64_ep50_sig_715.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e367_l64-64-64_ep50_sig_715\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e367_l64-64-64_ep50_sig_715\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e367_l64-64-64_ep50_sig_715\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-14 20:40:05,428] Trial 5 finished with value: 0.8915025591850281 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 367, 'epochs': 50}. Best is trial 0 with value: 0.8946261405944824.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e367_l64-64-64_ep50_sig_715\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e367_l64-64-64_ep50_sig_715\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e150_l64-64-64_ep50_sig_153\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e150_l64-64-64_ep50_sig_153  \n",
      "run_experiment()  when: 2026-01-14 20:40:05.663654 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 20:41:02.980255\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 11ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e150_l64-64-64_ep50_sig_153\\normalized_training_df-e150_l64-64-64_ep50_sig_153.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e150_l64-64-64_ep50_sig_153\\normalized_training_df-e150_l64-64-64_ep50_sig_153.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e150_l64-64-64_ep50_sig_153\\predictions-e150_l64-64-64_ep50_sig_153.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e150_l64-64-64_ep50_sig_153\\predictions-e150_l64-64-64_ep50_sig_153.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e150_l64-64-64_ep50_sig_153\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e150_l64-64-64_ep50_sig_153\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e150_l64-64-64_ep50_sig_153\\model\\assets\n",
      "[I 2026-01-14 20:44:44,477] Trial 6 finished with value: 0.8860388994216919 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 150, 'epochs': 50}. Best is trial 0 with value: 0.8946261405944824.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e150_l64-64-64_ep50_sig_153\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e150_l64-64-64_ep50_sig_153\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e198_l64-64-64_ep50_sig_118\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e198_l64-64-64_ep50_sig_118  \n",
      "run_experiment()  when: 2026-01-14 20:44:44.514525 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 20:44:54.608978\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 0s/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e198_l64-64-64_ep50_sig_118\\normalized_training_df-e198_l64-64-64_ep50_sig_118.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e198_l64-64-64_ep50_sig_118\\normalized_training_df-e198_l64-64-64_ep50_sig_118.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e198_l64-64-64_ep50_sig_118\\predictions-e198_l64-64-64_ep50_sig_118.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e198_l64-64-64_ep50_sig_118\\predictions-e198_l64-64-64_ep50_sig_118.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e198_l64-64-64_ep50_sig_118\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e198_l64-64-64_ep50_sig_118\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e198_l64-64-64_ep50_sig_118\\model\\assets\n",
      "[I 2026-01-14 20:46:04,830] Trial 7 finished with value: 0.8879805207252502 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 198, 'epochs': 50}. Best is trial 0 with value: 0.8946261405944824.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e198_l64-64-64_ep50_sig_118\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e198_l64-64-64_ep50_sig_118\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e330_l64-64-64_ep50_sig_198\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e330_l64-64-64_ep50_sig_198  \n",
      "run_experiment()  when: 2026-01-14 20:46:04.861878 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 20:47:09.158399\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 0s/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e330_l64-64-64_ep50_sig_198\\normalized_training_df-e330_l64-64-64_ep50_sig_198.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e330_l64-64-64_ep50_sig_198\\normalized_training_df-e330_l64-64-64_ep50_sig_198.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e330_l64-64-64_ep50_sig_198\\predictions-e330_l64-64-64_ep50_sig_198.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e330_l64-64-64_ep50_sig_198\\predictions-e330_l64-64-64_ep50_sig_198.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e330_l64-64-64_ep50_sig_198\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e330_l64-64-64_ep50_sig_198\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e330_l64-64-64_ep50_sig_198\\model\\assets\n",
      "[I 2026-01-14 20:49:54,589] Trial 8 finished with value: 0.8809504508972168 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 330, 'epochs': 50}. Best is trial 0 with value: 0.8946261405944824.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e330_l64-64-64_ep50_sig_198\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e330_l64-64-64_ep50_sig_198\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e422_l64-64-64_ep50_sig_142\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e422_l64-64-64_ep50_sig_142  \n",
      "run_experiment()  when: 2026-01-14 20:49:54.619467 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 20:50:07.425113\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e422_l64-64-64_ep50_sig_142\\normalized_training_df-e422_l64-64-64_ep50_sig_142.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e422_l64-64-64_ep50_sig_142\\normalized_training_df-e422_l64-64-64_ep50_sig_142.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e422_l64-64-64_ep50_sig_142\\predictions-e422_l64-64-64_ep50_sig_142.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e422_l64-64-64_ep50_sig_142\\predictions-e422_l64-64-64_ep50_sig_142.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e422_l64-64-64_ep50_sig_142\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e422_l64-64-64_ep50_sig_142\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e422_l64-64-64_ep50_sig_142\\model\\assets\n",
      "[I 2026-01-14 20:51:41,399] Trial 9 finished with value: 0.8955066800117493 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 422, 'epochs': 50}. Best is trial 9 with value: 0.8955066800117493.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e422_l64-64-64_ep50_sig_142\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e422_l64-64-64_ep50_sig_142\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e496_l64-64-64_ep50_sig_990\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e496_l64-64-64_ep50_sig_990  \n",
      "run_experiment()  when: 2026-01-14 20:51:41.437733 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 20:52:00.487704\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 0s/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e496_l64-64-64_ep50_sig_990\\normalized_training_df-e496_l64-64-64_ep50_sig_990.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e496_l64-64-64_ep50_sig_990\\normalized_training_df-e496_l64-64-64_ep50_sig_990.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e496_l64-64-64_ep50_sig_990\\predictions-e496_l64-64-64_ep50_sig_990.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e496_l64-64-64_ep50_sig_990\\predictions-e496_l64-64-64_ep50_sig_990.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e496_l64-64-64_ep50_sig_990\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e496_l64-64-64_ep50_sig_990\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e496_l64-64-64_ep50_sig_990\\model\\assets\n",
      "[I 2026-01-14 20:53:42,225] Trial 10 finished with value: 0.8890371918678284 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 496, 'epochs': 50}. Best is trial 9 with value: 0.8955066800117493.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e496_l64-64-64_ep50_sig_990\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e496_l64-64-64_ep50_sig_990\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e45_l64-64-64_ep50_sig_902\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e45_l64-64-64_ep50_sig_902  \n",
      "run_experiment()  when: 2026-01-14 20:53:42.398362 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 20:55:00.532466\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e45_l64-64-64_ep50_sig_902\\normalized_training_df-e45_l64-64-64_ep50_sig_902.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e45_l64-64-64_ep50_sig_902\\normalized_training_df-e45_l64-64-64_ep50_sig_902.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e45_l64-64-64_ep50_sig_902\\predictions-e45_l64-64-64_ep50_sig_902.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e45_l64-64-64_ep50_sig_902\\predictions-e45_l64-64-64_ep50_sig_902.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e45_l64-64-64_ep50_sig_902\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e45_l64-64-64_ep50_sig_902\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e45_l64-64-64_ep50_sig_902\\model\\assets\n",
      "[I 2026-01-14 20:58:52,903] Trial 11 finished with value: 0.8958912491798401 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 45, 'epochs': 50}. Best is trial 11 with value: 0.8958912491798401.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e45_l64-64-64_ep50_sig_902\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e45_l64-64-64_ep50_sig_902\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e44_l64-64-64_ep50_sig_219\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e44_l64-64-64_ep50_sig_219  \n",
      "run_experiment()  when: 2026-01-14 20:58:52.952304 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 21:00:03.928014\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e44_l64-64-64_ep50_sig_219\\normalized_training_df-e44_l64-64-64_ep50_sig_219.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e44_l64-64-64_ep50_sig_219\\normalized_training_df-e44_l64-64-64_ep50_sig_219.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e44_l64-64-64_ep50_sig_219\\predictions-e44_l64-64-64_ep50_sig_219.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e44_l64-64-64_ep50_sig_219\\predictions-e44_l64-64-64_ep50_sig_219.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e44_l64-64-64_ep50_sig_219\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e44_l64-64-64_ep50_sig_219\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e44_l64-64-64_ep50_sig_219\\model\\assets\n",
      "[I 2026-01-14 21:01:02,596] Trial 12 finished with value: 0.8981621265411377 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 44, 'epochs': 50}. Best is trial 12 with value: 0.8981621265411377.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e44_l64-64-64_ep50_sig_219\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e44_l64-64-64_ep50_sig_219\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e40_l64-64-64_ep50_sig_207\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e40_l64-64-64_ep50_sig_207  \n",
      "run_experiment()  when: 2026-01-14 21:01:02.906936 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 21:02:27.530109\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e40_l64-64-64_ep50_sig_207\\normalized_training_df-e40_l64-64-64_ep50_sig_207.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e40_l64-64-64_ep50_sig_207\\normalized_training_df-e40_l64-64-64_ep50_sig_207.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e40_l64-64-64_ep50_sig_207\\predictions-e40_l64-64-64_ep50_sig_207.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e40_l64-64-64_ep50_sig_207\\predictions-e40_l64-64-64_ep50_sig_207.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e40_l64-64-64_ep50_sig_207\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e40_l64-64-64_ep50_sig_207\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e40_l64-64-64_ep50_sig_207\\model\\assets\n",
      "[I 2026-01-14 21:06:29,580] Trial 13 finished with value: 0.8905201554298401 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 40, 'epochs': 50}. Best is trial 12 with value: 0.8981621265411377.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e40_l64-64-64_ep50_sig_207\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e40_l64-64-64_ep50_sig_207\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e38_l64-64-64_ep50_sig_197\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e38_l64-64-64_ep50_sig_197  \n",
      "run_experiment()  when: 2026-01-14 21:06:29.859201 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 21:07:09.589011\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e38_l64-64-64_ep50_sig_197\\normalized_training_df-e38_l64-64-64_ep50_sig_197.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e38_l64-64-64_ep50_sig_197\\normalized_training_df-e38_l64-64-64_ep50_sig_197.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e38_l64-64-64_ep50_sig_197\\predictions-e38_l64-64-64_ep50_sig_197.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e38_l64-64-64_ep50_sig_197\\predictions-e38_l64-64-64_ep50_sig_197.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e38_l64-64-64_ep50_sig_197\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e38_l64-64-64_ep50_sig_197\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e38_l64-64-64_ep50_sig_197\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e38_l64-64-64_ep50_sig_197\\model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-14 21:08:18,184] Trial 14 finished with value: 0.8892874717712402 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 38, 'epochs': 50}. Best is trial 12 with value: 0.8981621265411377.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e38_l64-64-64_ep50_sig_197\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e200_l64-64-64_ep50_sig_789\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e200_l64-64-64_ep50_sig_789  \n",
      "run_experiment()  when: 2026-01-14 21:08:18.344584 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 21:09:06.831444\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e200_l64-64-64_ep50_sig_789\\normalized_training_df-e200_l64-64-64_ep50_sig_789.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e200_l64-64-64_ep50_sig_789\\normalized_training_df-e200_l64-64-64_ep50_sig_789.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e200_l64-64-64_ep50_sig_789\\predictions-e200_l64-64-64_ep50_sig_789.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e200_l64-64-64_ep50_sig_789\\predictions-e200_l64-64-64_ep50_sig_789.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e200_l64-64-64_ep50_sig_789\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e200_l64-64-64_ep50_sig_789\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e200_l64-64-64_ep50_sig_789\\model\\assets\n",
      "[I 2026-01-14 21:10:32,321] Trial 15 finished with value: 0.8959932923316956 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 200, 'epochs': 50}. Best is trial 12 with value: 0.8981621265411377.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e200_l64-64-64_ep50_sig_789\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e200_l64-64-64_ep50_sig_789\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e216_l64-64-64_ep50_sig_833\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e216_l64-64-64_ep50_sig_833  \n",
      "run_experiment()  when: 2026-01-14 21:10:32.362603 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 21:10:49.662495\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 9ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e216_l64-64-64_ep50_sig_833\\normalized_training_df-e216_l64-64-64_ep50_sig_833.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e216_l64-64-64_ep50_sig_833\\normalized_training_df-e216_l64-64-64_ep50_sig_833.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e216_l64-64-64_ep50_sig_833\\predictions-e216_l64-64-64_ep50_sig_833.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e216_l64-64-64_ep50_sig_833\\predictions-e216_l64-64-64_ep50_sig_833.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e216_l64-64-64_ep50_sig_833\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e216_l64-64-64_ep50_sig_833\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e216_l64-64-64_ep50_sig_833\\model\\assets\n",
      "[I 2026-01-14 21:14:54,120] Trial 16 finished with value: 0.9013226628303528 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 216, 'epochs': 50}. Best is trial 16 with value: 0.9013226628303528.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e216_l64-64-64_ep50_sig_833\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e216_l64-64-64_ep50_sig_833\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e215_l64-64-64_ep50_sig_373\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e215_l64-64-64_ep50_sig_373  \n",
      "run_experiment()  when: 2026-01-14 21:14:54.162777 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 21:16:04.853368\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 998us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e215_l64-64-64_ep50_sig_373\\normalized_training_df-e215_l64-64-64_ep50_sig_373.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e215_l64-64-64_ep50_sig_373\\normalized_training_df-e215_l64-64-64_ep50_sig_373.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e215_l64-64-64_ep50_sig_373\\predictions-e215_l64-64-64_ep50_sig_373.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e215_l64-64-64_ep50_sig_373\\predictions-e215_l64-64-64_ep50_sig_373.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e215_l64-64-64_ep50_sig_373\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e215_l64-64-64_ep50_sig_373\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e215_l64-64-64_ep50_sig_373\\model\\assets\n",
      "[I 2026-01-14 21:18:25,421] Trial 17 finished with value: 0.8902745246887207 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 215, 'epochs': 50}. Best is trial 16 with value: 0.9013226628303528.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e215_l64-64-64_ep50_sig_373\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e215_l64-64-64_ep50_sig_373\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e244_l64-64-64_ep50_sig_106\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e244_l64-64-64_ep50_sig_106  \n",
      "run_experiment()  when: 2026-01-14 21:18:25.463706 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 21:18:44.140909\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e244_l64-64-64_ep50_sig_106\\normalized_training_df-e244_l64-64-64_ep50_sig_106.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e244_l64-64-64_ep50_sig_106\\normalized_training_df-e244_l64-64-64_ep50_sig_106.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e244_l64-64-64_ep50_sig_106\\predictions-e244_l64-64-64_ep50_sig_106.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e244_l64-64-64_ep50_sig_106\\predictions-e244_l64-64-64_ep50_sig_106.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e244_l64-64-64_ep50_sig_106\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e244_l64-64-64_ep50_sig_106\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e244_l64-64-64_ep50_sig_106\\model\\assets\n",
      "[I 2026-01-14 21:19:40,537] Trial 18 finished with value: 0.8777481317520142 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 244, 'epochs': 50}. Best is trial 16 with value: 0.9013226628303528.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e244_l64-64-64_ep50_sig_106\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e244_l64-64-64_ep50_sig_106\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e107_l64-64-64_ep50_sig_133\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e107_l64-64-64_ep50_sig_133  \n",
      "run_experiment()  when: 2026-01-14 21:19:40.579978 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 21:19:53.079834\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e107_l64-64-64_ep50_sig_133\\normalized_training_df-e107_l64-64-64_ep50_sig_133.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e107_l64-64-64_ep50_sig_133\\normalized_training_df-e107_l64-64-64_ep50_sig_133.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e107_l64-64-64_ep50_sig_133\\predictions-e107_l64-64-64_ep50_sig_133.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e107_l64-64-64_ep50_sig_133\\predictions-e107_l64-64-64_ep50_sig_133.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e107_l64-64-64_ep50_sig_133\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e107_l64-64-64_ep50_sig_133\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e107_l64-64-64_ep50_sig_133\\model\\assets\n",
      "[I 2026-01-14 21:22:55,613] Trial 19 finished with value: 0.8960118293762207 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 107, 'epochs': 50}. Best is trial 16 with value: 0.9013226628303528.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e107_l64-64-64_ep50_sig_133\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e107_l64-64-64_ep50_sig_133\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e156_l64-64-64_ep50_sig_213\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e156_l64-64-64_ep50_sig_213  \n",
      "run_experiment()  when: 2026-01-14 21:22:55.934878 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 21:23:46.087152\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e156_l64-64-64_ep50_sig_213\\normalized_training_df-e156_l64-64-64_ep50_sig_213.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e156_l64-64-64_ep50_sig_213\\normalized_training_df-e156_l64-64-64_ep50_sig_213.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e156_l64-64-64_ep50_sig_213\\predictions-e156_l64-64-64_ep50_sig_213.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e156_l64-64-64_ep50_sig_213\\predictions-e156_l64-64-64_ep50_sig_213.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e156_l64-64-64_ep50_sig_213\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e156_l64-64-64_ep50_sig_213\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e156_l64-64-64_ep50_sig_213\\model\\assets\n",
      "[I 2026-01-14 21:27:24,731] Trial 20 finished with value: 0.8902375102043152 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 156, 'epochs': 50}. Best is trial 16 with value: 0.9013226628303528.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e156_l64-64-64_ep50_sig_213\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e156_l64-64-64_ep50_sig_213\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e92_l64-64-64_ep50_sig_178\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e92_l64-64-64_ep50_sig_178  \n",
      "run_experiment()  when: 2026-01-14 21:27:24.773625 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 21:27:37.557090\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e92_l64-64-64_ep50_sig_178\\normalized_training_df-e92_l64-64-64_ep50_sig_178.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e92_l64-64-64_ep50_sig_178\\normalized_training_df-e92_l64-64-64_ep50_sig_178.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e92_l64-64-64_ep50_sig_178\\predictions-e92_l64-64-64_ep50_sig_178.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e92_l64-64-64_ep50_sig_178\\predictions-e92_l64-64-64_ep50_sig_178.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e92_l64-64-64_ep50_sig_178\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e92_l64-64-64_ep50_sig_178\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e92_l64-64-64_ep50_sig_178\\model\\assets\n",
      "[I 2026-01-14 21:29:31,932] Trial 21 finished with value: 0.9005255699157715 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 92, 'epochs': 50}. Best is trial 16 with value: 0.9013226628303528.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e92_l64-64-64_ep50_sig_178\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e92_l64-64-64_ep50_sig_178\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e79_l64-64-64_ep50_sig_720\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e79_l64-64-64_ep50_sig_720  \n",
      "run_experiment()  when: 2026-01-14 21:29:32.032233 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 21:30:52.425514\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e79_l64-64-64_ep50_sig_720\\normalized_training_df-e79_l64-64-64_ep50_sig_720.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e79_l64-64-64_ep50_sig_720\\normalized_training_df-e79_l64-64-64_ep50_sig_720.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e79_l64-64-64_ep50_sig_720\\predictions-e79_l64-64-64_ep50_sig_720.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e79_l64-64-64_ep50_sig_720\\predictions-e79_l64-64-64_ep50_sig_720.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e79_l64-64-64_ep50_sig_720\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e79_l64-64-64_ep50_sig_720\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e79_l64-64-64_ep50_sig_720\\model\\assets\n",
      "[I 2026-01-14 21:33:47,555] Trial 22 finished with value: 0.8836337327957153 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 79, 'epochs': 50}. Best is trial 16 with value: 0.9013226628303528.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e79_l64-64-64_ep50_sig_720\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e79_l64-64-64_ep50_sig_720\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e78_l64-64-64_ep50_sig_140\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e78_l64-64-64_ep50_sig_140  \n",
      "run_experiment()  when: 2026-01-14 21:33:47.608459 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 21:34:01.655621\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1000us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e78_l64-64-64_ep50_sig_140\\normalized_training_df-e78_l64-64-64_ep50_sig_140.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e78_l64-64-64_ep50_sig_140\\normalized_training_df-e78_l64-64-64_ep50_sig_140.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e78_l64-64-64_ep50_sig_140\\predictions-e78_l64-64-64_ep50_sig_140.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e78_l64-64-64_ep50_sig_140\\predictions-e78_l64-64-64_ep50_sig_140.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e78_l64-64-64_ep50_sig_140\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e78_l64-64-64_ep50_sig_140\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e78_l64-64-64_ep50_sig_140\\model\\assets\n",
      "[I 2026-01-14 21:36:28,979] Trial 23 finished with value: 0.8884578943252563 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 78, 'epochs': 50}. Best is trial 16 with value: 0.9013226628303528.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e78_l64-64-64_ep50_sig_140\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e78_l64-64-64_ep50_sig_140\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e150_l64-64-64_ep50_sig_596\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e150_l64-64-64_ep50_sig_596  \n",
      "run_experiment()  when: 2026-01-14 21:36:29.259619 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 21:37:47.646221\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e150_l64-64-64_ep50_sig_596\\normalized_training_df-e150_l64-64-64_ep50_sig_596.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e150_l64-64-64_ep50_sig_596\\normalized_training_df-e150_l64-64-64_ep50_sig_596.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e150_l64-64-64_ep50_sig_596\\predictions-e150_l64-64-64_ep50_sig_596.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e150_l64-64-64_ep50_sig_596\\predictions-e150_l64-64-64_ep50_sig_596.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e150_l64-64-64_ep50_sig_596\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e150_l64-64-64_ep50_sig_596\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e150_l64-64-64_ep50_sig_596\\model\\assets\n",
      "[I 2026-01-14 21:41:31,636] Trial 24 finished with value: 0.8978145718574524 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 150, 'epochs': 50}. Best is trial 16 with value: 0.9013226628303528.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e150_l64-64-64_ep50_sig_596\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e150_l64-64-64_ep50_sig_596\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e78_l64-64-64_ep50_sig_201\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e78_l64-64-64_ep50_sig_201  \n",
      "run_experiment()  when: 2026-01-14 21:41:31.880628 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 21:42:45.243167\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e78_l64-64-64_ep50_sig_201\\normalized_training_df-e78_l64-64-64_ep50_sig_201.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e78_l64-64-64_ep50_sig_201\\normalized_training_df-e78_l64-64-64_ep50_sig_201.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e78_l64-64-64_ep50_sig_201\\predictions-e78_l64-64-64_ep50_sig_201.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e78_l64-64-64_ep50_sig_201\\predictions-e78_l64-64-64_ep50_sig_201.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e78_l64-64-64_ep50_sig_201\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e78_l64-64-64_ep50_sig_201\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e78_l64-64-64_ep50_sig_201\\model\\assets\n",
      "[I 2026-01-14 21:44:12,187] Trial 25 finished with value: 0.8934815526008606 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 78, 'epochs': 50}. Best is trial 16 with value: 0.9013226628303528.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e78_l64-64-64_ep50_sig_201\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e78_l64-64-64_ep50_sig_201\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e181_l64-64-64_ep50_sig_535\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e181_l64-64-64_ep50_sig_535  \n",
      "run_experiment()  when: 2026-01-14 21:44:12.232030 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 21:44:27.779529\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e181_l64-64-64_ep50_sig_535\\normalized_training_df-e181_l64-64-64_ep50_sig_535.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e181_l64-64-64_ep50_sig_535\\normalized_training_df-e181_l64-64-64_ep50_sig_535.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e181_l64-64-64_ep50_sig_535\\predictions-e181_l64-64-64_ep50_sig_535.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e181_l64-64-64_ep50_sig_535\\predictions-e181_l64-64-64_ep50_sig_535.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e181_l64-64-64_ep50_sig_535\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e181_l64-64-64_ep50_sig_535\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e181_l64-64-64_ep50_sig_535\\model\\assets\n",
      "[I 2026-01-14 21:45:27,017] Trial 26 finished with value: 0.894343376159668 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 181, 'epochs': 50}. Best is trial 16 with value: 0.9013226628303528.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e181_l64-64-64_ep50_sig_535\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e181_l64-64-64_ep50_sig_535\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e238_l64-64-64_ep50_sig_134\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e238_l64-64-64_ep50_sig_134  \n",
      "run_experiment()  when: 2026-01-14 21:45:27.059128 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 21:45:39.737981\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 3ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e238_l64-64-64_ep50_sig_134\\normalized_training_df-e238_l64-64-64_ep50_sig_134.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e238_l64-64-64_ep50_sig_134\\normalized_training_df-e238_l64-64-64_ep50_sig_134.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e238_l64-64-64_ep50_sig_134\\predictions-e238_l64-64-64_ep50_sig_134.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e238_l64-64-64_ep50_sig_134\\predictions-e238_l64-64-64_ep50_sig_134.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e238_l64-64-64_ep50_sig_134\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e238_l64-64-64_ep50_sig_134\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e238_l64-64-64_ep50_sig_134\\model\\assets\n",
      "[I 2026-01-14 21:49:27,537] Trial 27 finished with value: 0.8783506155014038 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 238, 'epochs': 50}. Best is trial 16 with value: 0.9013226628303528.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e238_l64-64-64_ep50_sig_134\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e238_l64-64-64_ep50_sig_134\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e94_l64-64-64_ep50_sig_133\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e94_l64-64-64_ep50_sig_133  \n",
      "run_experiment()  when: 2026-01-14 21:49:27.579326 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 21:50:37.504926\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e94_l64-64-64_ep50_sig_133\\normalized_training_df-e94_l64-64-64_ep50_sig_133.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e94_l64-64-64_ep50_sig_133\\normalized_training_df-e94_l64-64-64_ep50_sig_133.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e94_l64-64-64_ep50_sig_133\\predictions-e94_l64-64-64_ep50_sig_133.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e94_l64-64-64_ep50_sig_133\\predictions-e94_l64-64-64_ep50_sig_133.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e94_l64-64-64_ep50_sig_133\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e94_l64-64-64_ep50_sig_133\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e94_l64-64-64_ep50_sig_133\\model\\assets\n",
      "[I 2026-01-14 21:51:45,809] Trial 28 finished with value: 0.8958171606063843 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 94, 'epochs': 50}. Best is trial 16 with value: 0.9013226628303528.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e94_l64-64-64_ep50_sig_133\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e94_l64-64-64_ep50_sig_133\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e129_l64-64-64_ep50_sig_196\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e129_l64-64-64_ep50_sig_196  \n",
      "run_experiment()  when: 2026-01-14 21:51:45.852883 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 21:52:11.681999\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e129_l64-64-64_ep50_sig_196\\normalized_training_df-e129_l64-64-64_ep50_sig_196.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e129_l64-64-64_ep50_sig_196\\normalized_training_df-e129_l64-64-64_ep50_sig_196.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e129_l64-64-64_ep50_sig_196\\predictions-e129_l64-64-64_ep50_sig_196.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e129_l64-64-64_ep50_sig_196\\predictions-e129_l64-64-64_ep50_sig_196.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e129_l64-64-64_ep50_sig_196\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e129_l64-64-64_ep50_sig_196\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e129_l64-64-64_ep50_sig_196\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-14 21:55:39,372] Trial 29 finished with value: 0.9061376452445984 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 129, 'epochs': 50}. Best is trial 29 with value: 0.9061376452445984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e129_l64-64-64_ep50_sig_196\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e129_l64-64-64_ep50_sig_196\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e127_l64-64-64_ep50_sig_139\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e127_l64-64-64_ep50_sig_139  \n",
      "run_experiment()  when: 2026-01-14 21:55:39.606462 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 21:56:16.364733\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e127_l64-64-64_ep50_sig_139\\normalized_training_df-e127_l64-64-64_ep50_sig_139.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e127_l64-64-64_ep50_sig_139\\normalized_training_df-e127_l64-64-64_ep50_sig_139.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e127_l64-64-64_ep50_sig_139\\predictions-e127_l64-64-64_ep50_sig_139.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e127_l64-64-64_ep50_sig_139\\predictions-e127_l64-64-64_ep50_sig_139.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e127_l64-64-64_ep50_sig_139\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e127_l64-64-64_ep50_sig_139\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e127_l64-64-64_ep50_sig_139\\model\\assets\n",
      "[I 2026-01-14 21:57:50,423] Trial 30 finished with value: 0.8939356803894043 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 127, 'epochs': 50}. Best is trial 29 with value: 0.9061376452445984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e127_l64-64-64_ep50_sig_139\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e127_l64-64-64_ep50_sig_139\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e164_l64-64-64_ep50_sig_107\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e164_l64-64-64_ep50_sig_107  \n",
      "run_experiment()  when: 2026-01-14 21:57:50.466405 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 21:58:48.305862\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e164_l64-64-64_ep50_sig_107\\normalized_training_df-e164_l64-64-64_ep50_sig_107.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e164_l64-64-64_ep50_sig_107\\normalized_training_df-e164_l64-64-64_ep50_sig_107.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e164_l64-64-64_ep50_sig_107\\predictions-e164_l64-64-64_ep50_sig_107.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e164_l64-64-64_ep50_sig_107\\predictions-e164_l64-64-64_ep50_sig_107.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e164_l64-64-64_ep50_sig_107\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e164_l64-64-64_ep50_sig_107\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e164_l64-64-64_ep50_sig_107\\model\\assets\n",
      "[I 2026-01-14 22:02:47,259] Trial 31 finished with value: 0.9050253629684448 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 164, 'epochs': 50}. Best is trial 29 with value: 0.9061376452445984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e164_l64-64-64_ep50_sig_107\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e164_l64-64-64_ep50_sig_107\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e173_l64-64-64_ep50_sig_123\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e173_l64-64-64_ep50_sig_123  \n",
      "run_experiment()  when: 2026-01-14 22:02:47.538438 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 22:04:07.217594\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e173_l64-64-64_ep50_sig_123\\normalized_training_df-e173_l64-64-64_ep50_sig_123.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e173_l64-64-64_ep50_sig_123\\normalized_training_df-e173_l64-64-64_ep50_sig_123.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e173_l64-64-64_ep50_sig_123\\predictions-e173_l64-64-64_ep50_sig_123.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e173_l64-64-64_ep50_sig_123\\predictions-e173_l64-64-64_ep50_sig_123.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e173_l64-64-64_ep50_sig_123\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e173_l64-64-64_ep50_sig_123\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e173_l64-64-64_ep50_sig_123\\model\\assets\n",
      "[I 2026-01-14 22:05:42,936] Trial 32 finished with value: 0.8812146186828613 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 173, 'epochs': 50}. Best is trial 29 with value: 0.9061376452445984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e173_l64-64-64_ep50_sig_123\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e173_l64-64-64_ep50_sig_123\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e231_l64-64-64_ep50_sig_225\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e231_l64-64-64_ep50_sig_225  \n",
      "run_experiment()  when: 2026-01-14 22:05:42.979986 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 22:05:58.160918\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 6ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e231_l64-64-64_ep50_sig_225\\normalized_training_df-e231_l64-64-64_ep50_sig_225.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e231_l64-64-64_ep50_sig_225\\normalized_training_df-e231_l64-64-64_ep50_sig_225.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e231_l64-64-64_ep50_sig_225\\predictions-e231_l64-64-64_ep50_sig_225.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e231_l64-64-64_ep50_sig_225\\predictions-e231_l64-64-64_ep50_sig_225.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e231_l64-64-64_ep50_sig_225\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e231_l64-64-64_ep50_sig_225\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e231_l64-64-64_ep50_sig_225\\model\\assets\n",
      "[I 2026-01-14 22:09:37,178] Trial 33 finished with value: 0.8854687809944153 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 231, 'epochs': 50}. Best is trial 29 with value: 0.9061376452445984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e231_l64-64-64_ep50_sig_225\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e231_l64-64-64_ep50_sig_225\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e130_l64-64-64_ep50_sig_103\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e130_l64-64-64_ep50_sig_103  \n",
      "run_experiment()  when: 2026-01-14 22:09:37.452955 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 22:10:42.076473\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e130_l64-64-64_ep50_sig_103\\normalized_training_df-e130_l64-64-64_ep50_sig_103.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e130_l64-64-64_ep50_sig_103\\normalized_training_df-e130_l64-64-64_ep50_sig_103.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e130_l64-64-64_ep50_sig_103\\predictions-e130_l64-64-64_ep50_sig_103.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e130_l64-64-64_ep50_sig_103\\predictions-e130_l64-64-64_ep50_sig_103.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e130_l64-64-64_ep50_sig_103\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e130_l64-64-64_ep50_sig_103\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e130_l64-64-64_ep50_sig_103\\model\\assets\n",
      "[I 2026-01-14 22:11:39,139] Trial 34 finished with value: 0.8983242511749268 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 130, 'epochs': 50}. Best is trial 29 with value: 0.9061376452445984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e130_l64-64-64_ep50_sig_103\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e130_l64-64-64_ep50_sig_103\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e283_l64-64-64_ep50_sig_427\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e283_l64-64-64_ep50_sig_427  \n",
      "run_experiment()  when: 2026-01-14 22:11:39.186267 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 22:12:13.849988\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e283_l64-64-64_ep50_sig_427\\normalized_training_df-e283_l64-64-64_ep50_sig_427.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e283_l64-64-64_ep50_sig_427\\normalized_training_df-e283_l64-64-64_ep50_sig_427.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e283_l64-64-64_ep50_sig_427\\predictions-e283_l64-64-64_ep50_sig_427.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e283_l64-64-64_ep50_sig_427\\predictions-e283_l64-64-64_ep50_sig_427.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e283_l64-64-64_ep50_sig_427\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e283_l64-64-64_ep50_sig_427\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e283_l64-64-64_ep50_sig_427\\model\\assets\n",
      "[I 2026-01-14 22:13:11,393] Trial 35 finished with value: 0.8905664682388306 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 283, 'epochs': 50}. Best is trial 29 with value: 0.9061376452445984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e283_l64-64-64_ep50_sig_427\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e283_l64-64-64_ep50_sig_427\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e174_l64-64-64_ep50_sig_100\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e174_l64-64-64_ep50_sig_100  \n",
      "run_experiment()  when: 2026-01-14 22:13:11.435598 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 22:14:07.289554\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 8ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e174_l64-64-64_ep50_sig_100\\normalized_training_df-e174_l64-64-64_ep50_sig_100.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e174_l64-64-64_ep50_sig_100\\normalized_training_df-e174_l64-64-64_ep50_sig_100.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e174_l64-64-64_ep50_sig_100\\predictions-e174_l64-64-64_ep50_sig_100.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e174_l64-64-64_ep50_sig_100\\predictions-e174_l64-64-64_ep50_sig_100.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e174_l64-64-64_ep50_sig_100\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e174_l64-64-64_ep50_sig_100\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e174_l64-64-64_ep50_sig_100\\model\\assets\n",
      "[I 2026-01-14 22:17:50,950] Trial 36 finished with value: 0.8772245645523071 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 174, 'epochs': 50}. Best is trial 29 with value: 0.9061376452445984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e174_l64-64-64_ep50_sig_100\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e174_l64-64-64_ep50_sig_100\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e260_l64-64-64_ep50_sig_553\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e260_l64-64-64_ep50_sig_553  \n",
      "run_experiment()  when: 2026-01-14 22:17:51.243930 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 22:19:17.328309\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 10ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e260_l64-64-64_ep50_sig_553\\normalized_training_df-e260_l64-64-64_ep50_sig_553.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e260_l64-64-64_ep50_sig_553\\normalized_training_df-e260_l64-64-64_ep50_sig_553.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e260_l64-64-64_ep50_sig_553\\predictions-e260_l64-64-64_ep50_sig_553.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e260_l64-64-64_ep50_sig_553\\predictions-e260_l64-64-64_ep50_sig_553.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e260_l64-64-64_ep50_sig_553\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e260_l64-64-64_ep50_sig_553\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e260_l64-64-64_ep50_sig_553\\model\\assets\n",
      "[I 2026-01-14 22:23:07,663] Trial 37 finished with value: 0.8843657970428467 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 260, 'epochs': 50}. Best is trial 29 with value: 0.9061376452445984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e260_l64-64-64_ep50_sig_553\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e260_l64-64-64_ep50_sig_553\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e312_l64-64-64_ep50_sig_166\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e312_l64-64-64_ep50_sig_166  \n",
      "run_experiment()  when: 2026-01-14 22:23:07.722998 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 22:23:23.880158\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e312_l64-64-64_ep50_sig_166\\normalized_training_df-e312_l64-64-64_ep50_sig_166.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e312_l64-64-64_ep50_sig_166\\normalized_training_df-e312_l64-64-64_ep50_sig_166.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e312_l64-64-64_ep50_sig_166\\predictions-e312_l64-64-64_ep50_sig_166.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e312_l64-64-64_ep50_sig_166\\predictions-e312_l64-64-64_ep50_sig_166.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e312_l64-64-64_ep50_sig_166\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e312_l64-64-64_ep50_sig_166\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e312_l64-64-64_ep50_sig_166\\model\\assets\n",
      "[I 2026-01-14 22:24:50,925] Trial 38 finished with value: 0.8740407228469849 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 312, 'epochs': 50}. Best is trial 29 with value: 0.9061376452445984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e312_l64-64-64_ep50_sig_166\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e312_l64-64-64_ep50_sig_166\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e139_l64-64-64_ep50_sig_613\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e139_l64-64-64_ep50_sig_613  \n",
      "run_experiment()  when: 2026-01-14 22:24:51.271870 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 22:26:19.874287\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e139_l64-64-64_ep50_sig_613\\normalized_training_df-e139_l64-64-64_ep50_sig_613.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e139_l64-64-64_ep50_sig_613\\normalized_training_df-e139_l64-64-64_ep50_sig_613.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e139_l64-64-64_ep50_sig_613\\predictions-e139_l64-64-64_ep50_sig_613.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e139_l64-64-64_ep50_sig_613\\predictions-e139_l64-64-64_ep50_sig_613.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e139_l64-64-64_ep50_sig_613\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e139_l64-64-64_ep50_sig_613\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e139_l64-64-64_ep50_sig_613\\model\\assets\n",
      "[I 2026-01-14 22:30:07,866] Trial 39 finished with value: 0.8901309967041016 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 139, 'epochs': 50}. Best is trial 29 with value: 0.9061376452445984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e139_l64-64-64_ep50_sig_613\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e139_l64-64-64_ep50_sig_613\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e205_l64-64-64_ep50_sig_226\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e205_l64-64-64_ep50_sig_226  \n",
      "run_experiment()  when: 2026-01-14 22:30:08.102009 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 22:31:28.680198\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e205_l64-64-64_ep50_sig_226\\normalized_training_df-e205_l64-64-64_ep50_sig_226.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e205_l64-64-64_ep50_sig_226\\normalized_training_df-e205_l64-64-64_ep50_sig_226.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e205_l64-64-64_ep50_sig_226\\predictions-e205_l64-64-64_ep50_sig_226.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e205_l64-64-64_ep50_sig_226\\predictions-e205_l64-64-64_ep50_sig_226.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e205_l64-64-64_ep50_sig_226\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e205_l64-64-64_ep50_sig_226\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e205_l64-64-64_ep50_sig_226\\model\\assets\n",
      "[I 2026-01-14 22:35:21,730] Trial 40 finished with value: 0.8856216669082642 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 205, 'epochs': 50}. Best is trial 29 with value: 0.9061376452445984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e205_l64-64-64_ep50_sig_226\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e205_l64-64-64_ep50_sig_226\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e118_l64-64-64_ep50_sig_178\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e118_l64-64-64_ep50_sig_178  \n",
      "run_experiment()  when: 2026-01-14 22:35:21.777129 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 22:35:37.086719\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e118_l64-64-64_ep50_sig_178\\normalized_training_df-e118_l64-64-64_ep50_sig_178.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e118_l64-64-64_ep50_sig_178\\normalized_training_df-e118_l64-64-64_ep50_sig_178.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e118_l64-64-64_ep50_sig_178\\predictions-e118_l64-64-64_ep50_sig_178.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e118_l64-64-64_ep50_sig_178\\predictions-e118_l64-64-64_ep50_sig_178.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e118_l64-64-64_ep50_sig_178\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e118_l64-64-64_ep50_sig_178\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e118_l64-64-64_ep50_sig_178\\model\\assets\n",
      "[I 2026-01-14 22:37:22,950] Trial 41 finished with value: 0.8882724642753601 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 118, 'epochs': 50}. Best is trial 29 with value: 0.9061376452445984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e118_l64-64-64_ep50_sig_178\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e118_l64-64-64_ep50_sig_178\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e101_l64-64-64_ep50_sig_618\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e101_l64-64-64_ep50_sig_618  \n",
      "run_experiment()  when: 2026-01-14 22:37:23.269194 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 22:38:33.150706\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 13ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e101_l64-64-64_ep50_sig_618\\normalized_training_df-e101_l64-64-64_ep50_sig_618.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e101_l64-64-64_ep50_sig_618\\normalized_training_df-e101_l64-64-64_ep50_sig_618.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e101_l64-64-64_ep50_sig_618\\predictions-e101_l64-64-64_ep50_sig_618.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e101_l64-64-64_ep50_sig_618\\predictions-e101_l64-64-64_ep50_sig_618.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e101_l64-64-64_ep50_sig_618\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e101_l64-64-64_ep50_sig_618\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e101_l64-64-64_ep50_sig_618\\model\\assets\n",
      "[I 2026-01-14 22:42:48,710] Trial 42 finished with value: 0.9018509387969971 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 101, 'epochs': 50}. Best is trial 29 with value: 0.9061376452445984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e101_l64-64-64_ep50_sig_618\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e101_l64-64-64_ep50_sig_618\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e106_l64-64-64_ep50_sig_173\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e106_l64-64-64_ep50_sig_173  \n",
      "run_experiment()  when: 2026-01-14 22:42:48.751653 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 22:43:48.994373\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e106_l64-64-64_ep50_sig_173\\normalized_training_df-e106_l64-64-64_ep50_sig_173.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e106_l64-64-64_ep50_sig_173\\normalized_training_df-e106_l64-64-64_ep50_sig_173.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e106_l64-64-64_ep50_sig_173\\predictions-e106_l64-64-64_ep50_sig_173.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e106_l64-64-64_ep50_sig_173\\predictions-e106_l64-64-64_ep50_sig_173.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e106_l64-64-64_ep50_sig_173\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e106_l64-64-64_ep50_sig_173\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e106_l64-64-64_ep50_sig_173\\model\\assets\n",
      "[I 2026-01-14 22:45:26,400] Trial 43 finished with value: 0.8906545042991638 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 106, 'epochs': 50}. Best is trial 29 with value: 0.9061376452445984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e106_l64-64-64_ep50_sig_173\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e106_l64-64-64_ep50_sig_173\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e66_l64-64-64_ep50_sig_102\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e66_l64-64-64_ep50_sig_102  \n",
      "run_experiment()  when: 2026-01-14 22:45:26.443959 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 22:45:41.563003\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 10ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e66_l64-64-64_ep50_sig_102\\normalized_training_df-e66_l64-64-64_ep50_sig_102.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e66_l64-64-64_ep50_sig_102\\normalized_training_df-e66_l64-64-64_ep50_sig_102.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e66_l64-64-64_ep50_sig_102\\predictions-e66_l64-64-64_ep50_sig_102.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e66_l64-64-64_ep50_sig_102\\predictions-e66_l64-64-64_ep50_sig_102.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e66_l64-64-64_ep50_sig_102\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e66_l64-64-64_ep50_sig_102\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e66_l64-64-64_ep50_sig_102\\model\\assets\n",
      "[I 2026-01-14 22:49:41,403] Trial 44 finished with value: 0.8953027725219727 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 66, 'epochs': 50}. Best is trial 29 with value: 0.9061376452445984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e66_l64-64-64_ep50_sig_102\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e66_l64-64-64_ep50_sig_102\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e160_l64-64-64_ep50_sig_159\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e160_l64-64-64_ep50_sig_159  \n",
      "run_experiment()  when: 2026-01-14 22:49:41.693756 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 22:50:54.004869\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e160_l64-64-64_ep50_sig_159\\normalized_training_df-e160_l64-64-64_ep50_sig_159.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e160_l64-64-64_ep50_sig_159\\normalized_training_df-e160_l64-64-64_ep50_sig_159.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e160_l64-64-64_ep50_sig_159\\predictions-e160_l64-64-64_ep50_sig_159.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e160_l64-64-64_ep50_sig_159\\predictions-e160_l64-64-64_ep50_sig_159.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e160_l64-64-64_ep50_sig_159\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e160_l64-64-64_ep50_sig_159\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e160_l64-64-64_ep50_sig_159\\model\\assets\n",
      "[I 2026-01-14 22:52:41,025] Trial 45 finished with value: 0.886868417263031 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 160, 'epochs': 50}. Best is trial 29 with value: 0.9061376452445984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e160_l64-64-64_ep50_sig_159\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e160_l64-64-64_ep50_sig_159\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e190_l64-64-64_ep50_sig_158\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e190_l64-64-64_ep50_sig_158  \n",
      "run_experiment()  when: 2026-01-14 22:52:41.069877 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 22:52:53.566420\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e190_l64-64-64_ep50_sig_158\\normalized_training_df-e190_l64-64-64_ep50_sig_158.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e190_l64-64-64_ep50_sig_158\\normalized_training_df-e190_l64-64-64_ep50_sig_158.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e190_l64-64-64_ep50_sig_158\\predictions-e190_l64-64-64_ep50_sig_158.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e190_l64-64-64_ep50_sig_158\\predictions-e190_l64-64-64_ep50_sig_158.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e190_l64-64-64_ep50_sig_158\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e190_l64-64-64_ep50_sig_158\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e190_l64-64-64_ep50_sig_158\\model\\assets\n",
      "[I 2026-01-14 22:56:34,868] Trial 46 finished with value: 0.8847506046295166 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 190, 'epochs': 50}. Best is trial 29 with value: 0.9061376452445984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e190_l64-64-64_ep50_sig_158\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e190_l64-64-64_ep50_sig_158\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e91_l64-64-64_ep50_sig_422\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e91_l64-64-64_ep50_sig_422  \n",
      "run_experiment()  when: 2026-01-14 22:56:35.188048 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 22:57:50.156691\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e91_l64-64-64_ep50_sig_422\\normalized_training_df-e91_l64-64-64_ep50_sig_422.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e91_l64-64-64_ep50_sig_422\\normalized_training_df-e91_l64-64-64_ep50_sig_422.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e91_l64-64-64_ep50_sig_422\\predictions-e91_l64-64-64_ep50_sig_422.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e91_l64-64-64_ep50_sig_422\\predictions-e91_l64-64-64_ep50_sig_422.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e91_l64-64-64_ep50_sig_422\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e91_l64-64-64_ep50_sig_422\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e91_l64-64-64_ep50_sig_422\\model\\assets\n",
      "[I 2026-01-14 23:01:46,759] Trial 47 finished with value: 0.8987599015235901 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 91, 'epochs': 50}. Best is trial 29 with value: 0.9061376452445984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e91_l64-64-64_ep50_sig_422\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e91_l64-64-64_ep50_sig_422\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e65_l64-64-64_ep50_sig_184\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e65_l64-64-64_ep50_sig_184  \n",
      "run_experiment()  when: 2026-01-14 23:01:46.798719 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 23:01:58.870703\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1000us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e65_l64-64-64_ep50_sig_184\\normalized_training_df-e65_l64-64-64_ep50_sig_184.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e65_l64-64-64_ep50_sig_184\\normalized_training_df-e65_l64-64-64_ep50_sig_184.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e65_l64-64-64_ep50_sig_184\\predictions-e65_l64-64-64_ep50_sig_184.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e65_l64-64-64_ep50_sig_184\\predictions-e65_l64-64-64_ep50_sig_184.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e65_l64-64-64_ep50_sig_184\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e65_l64-64-64_ep50_sig_184\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e65_l64-64-64_ep50_sig_184\\model\\assets\n",
      "[I 2026-01-14 23:03:30,626] Trial 48 finished with value: 0.8995754718780518 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 65, 'epochs': 50}. Best is trial 29 with value: 0.9061376452445984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e65_l64-64-64_ep50_sig_184\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e65_l64-64-64_ep50_sig_184\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e395_l64-64-64_ep50_sig_205\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e395_l64-64-64_ep50_sig_205  \n",
      "run_experiment()  when: 2026-01-14 23:03:30.901149 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 23:04:35.450715\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e395_l64-64-64_ep50_sig_205\\normalized_training_df-e395_l64-64-64_ep50_sig_205.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e395_l64-64-64_ep50_sig_205\\normalized_training_df-e395_l64-64-64_ep50_sig_205.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e395_l64-64-64_ep50_sig_205\\predictions-e395_l64-64-64_ep50_sig_205.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e395_l64-64-64_ep50_sig_205\\predictions-e395_l64-64-64_ep50_sig_205.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e395_l64-64-64_ep50_sig_205\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e395_l64-64-64_ep50_sig_205\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e395_l64-64-64_ep50_sig_205\\model\\assets\n",
      "[I 2026-01-14 23:07:41,975] Trial 49 finished with value: 0.8830960988998413 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 395, 'epochs': 50}. Best is trial 29 with value: 0.9061376452445984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e395_l64-64-64_ep50_sig_205\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e395_l64-64-64_ep50_sig_205\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e134_l64-64-64_ep50_sig_663\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e134_l64-64-64_ep50_sig_663  \n",
      "run_experiment()  when: 2026-01-14 23:07:42.028753 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 23:07:55.712500\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e134_l64-64-64_ep50_sig_663\\normalized_training_df-e134_l64-64-64_ep50_sig_663.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e134_l64-64-64_ep50_sig_663\\normalized_training_df-e134_l64-64-64_ep50_sig_663.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e134_l64-64-64_ep50_sig_663\\predictions-e134_l64-64-64_ep50_sig_663.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e134_l64-64-64_ep50_sig_663\\predictions-e134_l64-64-64_ep50_sig_663.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e134_l64-64-64_ep50_sig_663\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e134_l64-64-64_ep50_sig_663\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e134_l64-64-64_ep50_sig_663\\model\\assets\n",
      "[I 2026-01-14 23:09:59,542] Trial 50 finished with value: 0.8948113918304443 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 134, 'epochs': 50}. Best is trial 29 with value: 0.9061376452445984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e134_l64-64-64_ep50_sig_663\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e134_l64-64-64_ep50_sig_663\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e56_l64-64-64_ep50_sig_183\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e56_l64-64-64_ep50_sig_183  \n",
      "run_experiment()  when: 2026-01-14 23:09:59.801997 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 23:11:02.450643\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e56_l64-64-64_ep50_sig_183\\normalized_training_df-e56_l64-64-64_ep50_sig_183.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e56_l64-64-64_ep50_sig_183\\normalized_training_df-e56_l64-64-64_ep50_sig_183.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e56_l64-64-64_ep50_sig_183\\predictions-e56_l64-64-64_ep50_sig_183.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e56_l64-64-64_ep50_sig_183\\predictions-e56_l64-64-64_ep50_sig_183.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e56_l64-64-64_ep50_sig_183\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e56_l64-64-64_ep50_sig_183\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e56_l64-64-64_ep50_sig_183\\model\\assets\n",
      "[I 2026-01-14 23:12:38,048] Trial 51 finished with value: 0.8942878246307373 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 56, 'epochs': 50}. Best is trial 29 with value: 0.9061376452445984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e56_l64-64-64_ep50_sig_183\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e56_l64-64-64_ep50_sig_183\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e104_l64-64-64_ep50_sig_230\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e104_l64-64-64_ep50_sig_230  \n",
      "run_experiment()  when: 2026-01-14 23:12:38.100747 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 23:12:51.669484\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e104_l64-64-64_ep50_sig_230\\normalized_training_df-e104_l64-64-64_ep50_sig_230.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e104_l64-64-64_ep50_sig_230\\normalized_training_df-e104_l64-64-64_ep50_sig_230.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e104_l64-64-64_ep50_sig_230\\predictions-e104_l64-64-64_ep50_sig_230.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e104_l64-64-64_ep50_sig_230\\predictions-e104_l64-64-64_ep50_sig_230.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e104_l64-64-64_ep50_sig_230\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e104_l64-64-64_ep50_sig_230\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e104_l64-64-64_ep50_sig_230\\model\\assets\n",
      "[I 2026-01-14 23:16:47,210] Trial 52 finished with value: 0.8952145576477051 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 104, 'epochs': 50}. Best is trial 29 with value: 0.9061376452445984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e104_l64-64-64_ep50_sig_230\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e104_l64-64-64_ep50_sig_230\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e31_l64-64-64_ep50_sig_114\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e31_l64-64-64_ep50_sig_114  \n",
      "run_experiment()  when: 2026-01-14 23:16:47.501373 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 23:18:01.753257\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e31_l64-64-64_ep50_sig_114\\normalized_training_df-e31_l64-64-64_ep50_sig_114.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e31_l64-64-64_ep50_sig_114\\normalized_training_df-e31_l64-64-64_ep50_sig_114.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e31_l64-64-64_ep50_sig_114\\predictions-e31_l64-64-64_ep50_sig_114.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e31_l64-64-64_ep50_sig_114\\predictions-e31_l64-64-64_ep50_sig_114.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e31_l64-64-64_ep50_sig_114\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e31_l64-64-64_ep50_sig_114\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e31_l64-64-64_ep50_sig_114\\model\\assets\n",
      "[I 2026-01-14 23:22:01,239] Trial 53 finished with value: 0.9096412062644958 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 31, 'epochs': 50}. Best is trial 53 with value: 0.9096412062644958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e31_l64-64-64_ep50_sig_114\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e31_l64-64-64_ep50_sig_114\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e55_l64-64-64_ep50_sig_643\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e55_l64-64-64_ep50_sig_643  \n",
      "run_experiment()  when: 2026-01-14 23:22:01.280166 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 23:22:15.677649\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e55_l64-64-64_ep50_sig_643\\normalized_training_df-e55_l64-64-64_ep50_sig_643.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e55_l64-64-64_ep50_sig_643\\normalized_training_df-e55_l64-64-64_ep50_sig_643.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e55_l64-64-64_ep50_sig_643\\predictions-e55_l64-64-64_ep50_sig_643.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e55_l64-64-64_ep50_sig_643\\predictions-e55_l64-64-64_ep50_sig_643.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e55_l64-64-64_ep50_sig_643\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e55_l64-64-64_ep50_sig_643\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e55_l64-64-64_ep50_sig_643\\model\\assets\n",
      "[I 2026-01-14 23:24:04,188] Trial 54 finished with value: 0.8905802965164185 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 55, 'epochs': 50}. Best is trial 53 with value: 0.9096412062644958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e55_l64-64-64_ep50_sig_643\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e55_l64-64-64_ep50_sig_643\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e149_l64-64-64_ep50_sig_112\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e149_l64-64-64_ep50_sig_112  \n",
      "run_experiment()  when: 2026-01-14 23:24:04.489744 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 23:25:20.323807\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 8ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e149_l64-64-64_ep50_sig_112\\normalized_training_df-e149_l64-64-64_ep50_sig_112.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e149_l64-64-64_ep50_sig_112\\normalized_training_df-e149_l64-64-64_ep50_sig_112.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e149_l64-64-64_ep50_sig_112\\predictions-e149_l64-64-64_ep50_sig_112.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e149_l64-64-64_ep50_sig_112\\predictions-e149_l64-64-64_ep50_sig_112.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e149_l64-64-64_ep50_sig_112\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e149_l64-64-64_ep50_sig_112\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e149_l64-64-64_ep50_sig_112\\model\\assets\n",
      "[I 2026-01-14 23:28:52,031] Trial 55 finished with value: 0.8861871957778931 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 149, 'epochs': 50}. Best is trial 53 with value: 0.9096412062644958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e149_l64-64-64_ep50_sig_112\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e149_l64-64-64_ep50_sig_112\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e30_l64-64-64_ep50_sig_178\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e30_l64-64-64_ep50_sig_178  \n",
      "run_experiment()  when: 2026-01-14 23:28:52.078594 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 23:29:07.655378\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e30_l64-64-64_ep50_sig_178\\normalized_training_df-e30_l64-64-64_ep50_sig_178.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e30_l64-64-64_ep50_sig_178\\normalized_training_df-e30_l64-64-64_ep50_sig_178.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e30_l64-64-64_ep50_sig_178\\predictions-e30_l64-64-64_ep50_sig_178.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e30_l64-64-64_ep50_sig_178\\predictions-e30_l64-64-64_ep50_sig_178.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e30_l64-64-64_ep50_sig_178\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e30_l64-64-64_ep50_sig_178\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e30_l64-64-64_ep50_sig_178\\model\\assets\n",
      "[I 2026-01-14 23:31:00,035] Trial 56 finished with value: 0.9076298475265503 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 30, 'epochs': 50}. Best is trial 53 with value: 0.9096412062644958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e30_l64-64-64_ep50_sig_178\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e30_l64-64-64_ep50_sig_178\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e492_l64-64-64_ep50_sig_168\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e492_l64-64-64_ep50_sig_168  \n",
      "run_experiment()  when: 2026-01-14 23:31:00.074073 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 23:32:06.660121\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e492_l64-64-64_ep50_sig_168\\normalized_training_df-e492_l64-64-64_ep50_sig_168.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e492_l64-64-64_ep50_sig_168\\normalized_training_df-e492_l64-64-64_ep50_sig_168.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e492_l64-64-64_ep50_sig_168\\predictions-e492_l64-64-64_ep50_sig_168.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e492_l64-64-64_ep50_sig_168\\predictions-e492_l64-64-64_ep50_sig_168.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e492_l64-64-64_ep50_sig_168\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e492_l64-64-64_ep50_sig_168\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e492_l64-64-64_ep50_sig_168\\model\\assets\n",
      "[I 2026-01-14 23:33:23,938] Trial 57 finished with value: 0.8800791501998901 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 492, 'epochs': 50}. Best is trial 53 with value: 0.9096412062644958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e492_l64-64-64_ep50_sig_168\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e492_l64-64-64_ep50_sig_168\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e39_l64-64-64_ep50_sig_225\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e39_l64-64-64_ep50_sig_225  \n",
      "run_experiment()  when: 2026-01-14 23:33:23.978433 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 23:33:35.559686\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 800us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e39_l64-64-64_ep50_sig_225\\normalized_training_df-e39_l64-64-64_ep50_sig_225.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e39_l64-64-64_ep50_sig_225\\normalized_training_df-e39_l64-64-64_ep50_sig_225.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e39_l64-64-64_ep50_sig_225\\predictions-e39_l64-64-64_ep50_sig_225.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e39_l64-64-64_ep50_sig_225\\predictions-e39_l64-64-64_ep50_sig_225.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e39_l64-64-64_ep50_sig_225\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e39_l64-64-64_ep50_sig_225\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e39_l64-64-64_ep50_sig_225\\model\\assets\n",
      "[I 2026-01-14 23:37:19,725] Trial 58 finished with value: 0.8767517805099487 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 39, 'epochs': 50}. Best is trial 53 with value: 0.9096412062644958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e39_l64-64-64_ep50_sig_225\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e39_l64-64-64_ep50_sig_225\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e224_l64-64-64_ep50_sig_258\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e224_l64-64-64_ep50_sig_258  \n",
      "run_experiment()  when: 2026-01-14 23:37:20.112258 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 23:37:54.852394\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 600us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e224_l64-64-64_ep50_sig_258\\normalized_training_df-e224_l64-64-64_ep50_sig_258.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e224_l64-64-64_ep50_sig_258\\normalized_training_df-e224_l64-64-64_ep50_sig_258.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e224_l64-64-64_ep50_sig_258\\predictions-e224_l64-64-64_ep50_sig_258.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e224_l64-64-64_ep50_sig_258\\predictions-e224_l64-64-64_ep50_sig_258.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e224_l64-64-64_ep50_sig_258\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e224_l64-64-64_ep50_sig_258\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e224_l64-64-64_ep50_sig_258\\model\\assets\n",
      "[I 2026-01-14 23:39:07,949] Trial 59 finished with value: 0.8944917321205139 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 224, 'epochs': 50}. Best is trial 53 with value: 0.9096412062644958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e224_l64-64-64_ep50_sig_258\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e224_l64-64-64_ep50_sig_258\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e35_l64-64-64_ep50_sig_299\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e35_l64-64-64_ep50_sig_299  \n",
      "run_experiment()  when: 2026-01-14 23:39:08.134397 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 23:40:32.576830\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 8ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e35_l64-64-64_ep50_sig_299\\normalized_training_df-e35_l64-64-64_ep50_sig_299.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e35_l64-64-64_ep50_sig_299\\normalized_training_df-e35_l64-64-64_ep50_sig_299.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e35_l64-64-64_ep50_sig_299\\predictions-e35_l64-64-64_ep50_sig_299.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e35_l64-64-64_ep50_sig_299\\predictions-e35_l64-64-64_ep50_sig_299.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e35_l64-64-64_ep50_sig_299\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e35_l64-64-64_ep50_sig_299\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e35_l64-64-64_ep50_sig_299\\model\\assets\n",
      "[I 2026-01-14 23:44:13,249] Trial 60 finished with value: 0.8950431942939758 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 35, 'epochs': 50}. Best is trial 53 with value: 0.9096412062644958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e35_l64-64-64_ep50_sig_299\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e35_l64-64-64_ep50_sig_299\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e83_l64-64-64_ep50_sig_913\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e83_l64-64-64_ep50_sig_913  \n",
      "run_experiment()  when: 2026-01-14 23:44:13.396250 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 23:45:24.229467\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 0s/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e83_l64-64-64_ep50_sig_913\\normalized_training_df-e83_l64-64-64_ep50_sig_913.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e83_l64-64-64_ep50_sig_913\\normalized_training_df-e83_l64-64-64_ep50_sig_913.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e83_l64-64-64_ep50_sig_913\\predictions-e83_l64-64-64_ep50_sig_913.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e83_l64-64-64_ep50_sig_913\\predictions-e83_l64-64-64_ep50_sig_913.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e83_l64-64-64_ep50_sig_913\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e83_l64-64-64_ep50_sig_913\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e83_l64-64-64_ep50_sig_913\\model\\assets\n",
      "[I 2026-01-14 23:47:26,361] Trial 61 finished with value: 0.8892829418182373 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 83, 'epochs': 50}. Best is trial 53 with value: 0.9096412062644958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e83_l64-64-64_ep50_sig_913\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e83_l64-64-64_ep50_sig_913\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e114_l64-64-64_ep50_sig_925\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e114_l64-64-64_ep50_sig_925  \n",
      "run_experiment()  when: 2026-01-14 23:47:26.401411 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 23:47:37.014068\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 0s/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e114_l64-64-64_ep50_sig_925\\normalized_training_df-e114_l64-64-64_ep50_sig_925.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e114_l64-64-64_ep50_sig_925\\normalized_training_df-e114_l64-64-64_ep50_sig_925.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e114_l64-64-64_ep50_sig_925\\predictions-e114_l64-64-64_ep50_sig_925.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e114_l64-64-64_ep50_sig_925\\predictions-e114_l64-64-64_ep50_sig_925.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e114_l64-64-64_ep50_sig_925\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e114_l64-64-64_ep50_sig_925\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e114_l64-64-64_ep50_sig_925\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e114_l64-64-64_ep50_sig_925\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e114_l64-64-64_ep50_sig_925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-14 23:51:16,939] Trial 62 finished with value: 0.8972305059432983 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 114, 'epochs': 50}. Best is trial 53 with value: 0.9096412062644958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e30_l64-64-64_ep50_sig_711\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e30_l64-64-64_ep50_sig_711  \n",
      "run_experiment()  when: 2026-01-14 23:51:17.319594 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 23:52:31.938112\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e30_l64-64-64_ep50_sig_711\\normalized_training_df-e30_l64-64-64_ep50_sig_711.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e30_l64-64-64_ep50_sig_711\\normalized_training_df-e30_l64-64-64_ep50_sig_711.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e30_l64-64-64_ep50_sig_711\\predictions-e30_l64-64-64_ep50_sig_711.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e30_l64-64-64_ep50_sig_711\\predictions-e30_l64-64-64_ep50_sig_711.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e30_l64-64-64_ep50_sig_711\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e30_l64-64-64_ep50_sig_711\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e30_l64-64-64_ep50_sig_711\\model\\assets\n",
      "[I 2026-01-14 23:56:09,802] Trial 63 finished with value: 0.8972305059432983 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 30, 'epochs': 50}. Best is trial 53 with value: 0.9096412062644958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e30_l64-64-64_ep50_sig_711\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e30_l64-64-64_ep50_sig_711\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e68_l64-64-64_ep50_sig_194\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e68_l64-64-64_ep50_sig_194  \n",
      "run_experiment()  when: 2026-01-14 23:56:09.842705 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 23:56:27.104307\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e68_l64-64-64_ep50_sig_194\\normalized_training_df-e68_l64-64-64_ep50_sig_194.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e68_l64-64-64_ep50_sig_194\\normalized_training_df-e68_l64-64-64_ep50_sig_194.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e68_l64-64-64_ep50_sig_194\\predictions-e68_l64-64-64_ep50_sig_194.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e68_l64-64-64_ep50_sig_194\\predictions-e68_l64-64-64_ep50_sig_194.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e68_l64-64-64_ep50_sig_194\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e68_l64-64-64_ep50_sig_194\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e68_l64-64-64_ep50_sig_194\\model\\assets\n",
      "[I 2026-01-14 23:58:22,572] Trial 64 finished with value: 0.8951868414878845 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 68, 'epochs': 50}. Best is trial 53 with value: 0.9096412062644958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e68_l64-64-64_ep50_sig_194\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e68_l64-64-64_ep50_sig_194\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e91_l64-64-64_ep50_sig_219\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e91_l64-64-64_ep50_sig_219  \n",
      "run_experiment()  when: 2026-01-14 23:58:22.969482 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 23:59:46.617857\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 6ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e91_l64-64-64_ep50_sig_219\\normalized_training_df-e91_l64-64-64_ep50_sig_219.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e91_l64-64-64_ep50_sig_219\\normalized_training_df-e91_l64-64-64_ep50_sig_219.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e91_l64-64-64_ep50_sig_219\\predictions-e91_l64-64-64_ep50_sig_219.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e91_l64-64-64_ep50_sig_219\\predictions-e91_l64-64-64_ep50_sig_219.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e91_l64-64-64_ep50_sig_219\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e91_l64-64-64_ep50_sig_219\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e91_l64-64-64_ep50_sig_219\\model\\assets\n",
      "[I 2026-01-15 00:03:47,137] Trial 65 finished with value: 0.9004282355308533 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 91, 'epochs': 50}. Best is trial 53 with value: 0.9096412062644958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e91_l64-64-64_ep50_sig_219\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e91_l64-64-64_ep50_sig_219\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e164_l64-64-64_ep50_sig_919\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e164_l64-64-64_ep50_sig_919  \n",
      "run_experiment()  when: 2026-01-15 00:03:47.398652 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 00:04:54.870742\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 408us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e164_l64-64-64_ep50_sig_919\\normalized_training_df-e164_l64-64-64_ep50_sig_919.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e164_l64-64-64_ep50_sig_919\\normalized_training_df-e164_l64-64-64_ep50_sig_919.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e164_l64-64-64_ep50_sig_919\\predictions-e164_l64-64-64_ep50_sig_919.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e164_l64-64-64_ep50_sig_919\\predictions-e164_l64-64-64_ep50_sig_919.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e164_l64-64-64_ep50_sig_919\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e164_l64-64-64_ep50_sig_919\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e164_l64-64-64_ep50_sig_919\\model\\assets\n",
      "[I 2026-01-15 00:06:45,505] Trial 66 finished with value: 0.9033571481704712 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 164, 'epochs': 50}. Best is trial 53 with value: 0.9096412062644958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e164_l64-64-64_ep50_sig_919\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e164_l64-64-64_ep50_sig_919\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e162_l64-64-64_ep50_sig_125\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e162_l64-64-64_ep50_sig_125  \n",
      "run_experiment()  when: 2026-01-15 00:06:45.545305 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 00:06:57.674324\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 0s/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e162_l64-64-64_ep50_sig_125\\normalized_training_df-e162_l64-64-64_ep50_sig_125.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e162_l64-64-64_ep50_sig_125\\normalized_training_df-e162_l64-64-64_ep50_sig_125.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e162_l64-64-64_ep50_sig_125\\predictions-e162_l64-64-64_ep50_sig_125.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e162_l64-64-64_ep50_sig_125\\predictions-e162_l64-64-64_ep50_sig_125.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e162_l64-64-64_ep50_sig_125\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e162_l64-64-64_ep50_sig_125\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e162_l64-64-64_ep50_sig_125\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-15 00:09:38,588] Trial 67 finished with value: 0.9086910486221313 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 162, 'epochs': 50}. Best is trial 53 with value: 0.9096412062644958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e162_l64-64-64_ep50_sig_125\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e162_l64-64-64_ep50_sig_125\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e161_l64-64-64_ep50_sig_186\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e161_l64-64-64_ep50_sig_186  \n",
      "run_experiment()  when: 2026-01-15 00:09:38.807435 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 00:10:36.898949\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 600us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e161_l64-64-64_ep50_sig_186\\normalized_training_df-e161_l64-64-64_ep50_sig_186.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e161_l64-64-64_ep50_sig_186\\normalized_training_df-e161_l64-64-64_ep50_sig_186.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e161_l64-64-64_ep50_sig_186\\predictions-e161_l64-64-64_ep50_sig_186.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e161_l64-64-64_ep50_sig_186\\predictions-e161_l64-64-64_ep50_sig_186.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e161_l64-64-64_ep50_sig_186\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e161_l64-64-64_ep50_sig_186\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e161_l64-64-64_ep50_sig_186\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-15 00:13:53,367] Trial 68 finished with value: 0.9019853472709656 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 161, 'epochs': 50}. Best is trial 53 with value: 0.9096412062644958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e161_l64-64-64_ep50_sig_186\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e161_l64-64-64_ep50_sig_186\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e170_l64-64-64_ep50_sig_140\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e170_l64-64-64_ep50_sig_140  \n",
      "run_experiment()  when: 2026-01-15 00:13:53.613358 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 00:14:16.283648\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 408us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e170_l64-64-64_ep50_sig_140\\normalized_training_df-e170_l64-64-64_ep50_sig_140.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e170_l64-64-64_ep50_sig_140\\normalized_training_df-e170_l64-64-64_ep50_sig_140.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e170_l64-64-64_ep50_sig_140\\predictions-e170_l64-64-64_ep50_sig_140.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e170_l64-64-64_ep50_sig_140\\predictions-e170_l64-64-64_ep50_sig_140.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e170_l64-64-64_ep50_sig_140\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e170_l64-64-64_ep50_sig_140\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e170_l64-64-64_ep50_sig_140\\model\\assets\n",
      "[I 2026-01-15 00:15:39,464] Trial 69 finished with value: 0.8952377438545227 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 170, 'epochs': 50}. Best is trial 53 with value: 0.9096412062644958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e170_l64-64-64_ep50_sig_140\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e170_l64-64-64_ep50_sig_140\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e196_l64-64-64_ep50_sig_172\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e196_l64-64-64_ep50_sig_172  \n",
      "run_experiment()  when: 2026-01-15 00:15:39.753516 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 00:16:33.052039\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 11ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e196_l64-64-64_ep50_sig_172\\normalized_training_df-e196_l64-64-64_ep50_sig_172.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e196_l64-64-64_ep50_sig_172\\normalized_training_df-e196_l64-64-64_ep50_sig_172.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e196_l64-64-64_ep50_sig_172\\predictions-e196_l64-64-64_ep50_sig_172.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e196_l64-64-64_ep50_sig_172\\predictions-e196_l64-64-64_ep50_sig_172.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e196_l64-64-64_ep50_sig_172\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e196_l64-64-64_ep50_sig_172\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e196_l64-64-64_ep50_sig_172\\model\\assets\n",
      "[I 2026-01-15 00:20:23,656] Trial 70 finished with value: 0.8909510374069214 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 196, 'epochs': 50}. Best is trial 53 with value: 0.9096412062644958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e196_l64-64-64_ep50_sig_172\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e196_l64-64-64_ep50_sig_172\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e146_l64-64-64_ep50_sig_212\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e146_l64-64-64_ep50_sig_212  \n",
      "run_experiment()  when: 2026-01-15 00:20:23.923083 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 00:21:33.139335\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 682us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e146_l64-64-64_ep50_sig_212\\normalized_training_df-e146_l64-64-64_ep50_sig_212.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e146_l64-64-64_ep50_sig_212\\normalized_training_df-e146_l64-64-64_ep50_sig_212.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e146_l64-64-64_ep50_sig_212\\predictions-e146_l64-64-64_ep50_sig_212.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e146_l64-64-64_ep50_sig_212\\predictions-e146_l64-64-64_ep50_sig_212.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e146_l64-64-64_ep50_sig_212\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e146_l64-64-64_ep50_sig_212\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e146_l64-64-64_ep50_sig_212\\model\\assets\n",
      "[I 2026-01-15 00:22:21,143] Trial 71 finished with value: 0.8832722306251526 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 146, 'epochs': 50}. Best is trial 53 with value: 0.9096412062644958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e146_l64-64-64_ep50_sig_212\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e146_l64-64-64_ep50_sig_212\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e162_l64-64-64_ep50_sig_422\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e162_l64-64-64_ep50_sig_422  \n",
      "run_experiment()  when: 2026-01-15 00:22:21.183015 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 00:23:26.549330\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e162_l64-64-64_ep50_sig_422\\normalized_training_df-e162_l64-64-64_ep50_sig_422.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e162_l64-64-64_ep50_sig_422\\normalized_training_df-e162_l64-64-64_ep50_sig_422.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e162_l64-64-64_ep50_sig_422\\predictions-e162_l64-64-64_ep50_sig_422.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e162_l64-64-64_ep50_sig_422\\predictions-e162_l64-64-64_ep50_sig_422.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e162_l64-64-64_ep50_sig_422\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e162_l64-64-64_ep50_sig_422\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e162_l64-64-64_ep50_sig_422\\model\\assets\n",
      "[I 2026-01-15 00:27:07,840] Trial 72 finished with value: 0.8899455070495605 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 162, 'epochs': 50}. Best is trial 53 with value: 0.9096412062644958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e162_l64-64-64_ep50_sig_422\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e162_l64-64-64_ep50_sig_422\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e184_l64-64-64_ep50_sig_372\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e184_l64-64-64_ep50_sig_372  \n",
      "run_experiment()  when: 2026-01-15 00:27:08.161588 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 00:28:10.177981\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 20ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e184_l64-64-64_ep50_sig_372\\normalized_training_df-e184_l64-64-64_ep50_sig_372.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e184_l64-64-64_ep50_sig_372\\normalized_training_df-e184_l64-64-64_ep50_sig_372.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e184_l64-64-64_ep50_sig_372\\predictions-e184_l64-64-64_ep50_sig_372.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e184_l64-64-64_ep50_sig_372\\predictions-e184_l64-64-64_ep50_sig_372.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e184_l64-64-64_ep50_sig_372\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e184_l64-64-64_ep50_sig_372\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e184_l64-64-64_ep50_sig_372\\model\\assets\n",
      "[I 2026-01-15 00:31:00,236] Trial 73 finished with value: 0.8902002573013306 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 184, 'epochs': 50}. Best is trial 53 with value: 0.9096412062644958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e184_l64-64-64_ep50_sig_372\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e184_l64-64-64_ep50_sig_372\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e119_l64-64-64_ep50_sig_629\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e119_l64-64-64_ep50_sig_629  \n",
      "run_experiment()  when: 2026-01-15 00:31:00.273951 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 00:31:10.597651\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e119_l64-64-64_ep50_sig_629\\normalized_training_df-e119_l64-64-64_ep50_sig_629.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e119_l64-64-64_ep50_sig_629\\normalized_training_df-e119_l64-64-64_ep50_sig_629.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e119_l64-64-64_ep50_sig_629\\predictions-e119_l64-64-64_ep50_sig_629.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e119_l64-64-64_ep50_sig_629\\predictions-e119_l64-64-64_ep50_sig_629.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e119_l64-64-64_ep50_sig_629\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e119_l64-64-64_ep50_sig_629\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e119_l64-64-64_ep50_sig_629\\model\\assets\n",
      "[I 2026-01-15 00:33:59,521] Trial 74 finished with value: 0.8949087858200073 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 119, 'epochs': 50}. Best is trial 53 with value: 0.9096412062644958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e119_l64-64-64_ep50_sig_629\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e119_l64-64-64_ep50_sig_629\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e52_l64-64-64_ep50_sig_131\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e52_l64-64-64_ep50_sig_131  \n",
      "run_experiment()  when: 2026-01-15 00:33:59.572152 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 00:35:16.208534\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e52_l64-64-64_ep50_sig_131\\normalized_training_df-e52_l64-64-64_ep50_sig_131.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e52_l64-64-64_ep50_sig_131\\normalized_training_df-e52_l64-64-64_ep50_sig_131.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e52_l64-64-64_ep50_sig_131\\predictions-e52_l64-64-64_ep50_sig_131.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e52_l64-64-64_ep50_sig_131\\predictions-e52_l64-64-64_ep50_sig_131.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e52_l64-64-64_ep50_sig_131\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e52_l64-64-64_ep50_sig_131\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e52_l64-64-64_ep50_sig_131\\model\\assets\n",
      "[I 2026-01-15 00:38:16,784] Trial 75 finished with value: 0.9052663445472717 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 52, 'epochs': 50}. Best is trial 53 with value: 0.9096412062644958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e52_l64-64-64_ep50_sig_131\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e52_l64-64-64_ep50_sig_131\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e45_l64-64-64_ep50_sig_189\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e45_l64-64-64_ep50_sig_189  \n",
      "run_experiment()  when: 2026-01-15 00:38:16.822714 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 00:38:30.125835\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 800us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e45_l64-64-64_ep50_sig_189\\normalized_training_df-e45_l64-64-64_ep50_sig_189.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e45_l64-64-64_ep50_sig_189\\normalized_training_df-e45_l64-64-64_ep50_sig_189.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e45_l64-64-64_ep50_sig_189\\predictions-e45_l64-64-64_ep50_sig_189.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e45_l64-64-64_ep50_sig_189\\predictions-e45_l64-64-64_ep50_sig_189.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e45_l64-64-64_ep50_sig_189\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e45_l64-64-64_ep50_sig_189\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e45_l64-64-64_ep50_sig_189\\model\\assets\n",
      "[I 2026-01-15 00:40:24,380] Trial 76 finished with value: 0.8883790969848633 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 45, 'epochs': 50}. Best is trial 53 with value: 0.9096412062644958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e45_l64-64-64_ep50_sig_189\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e45_l64-64-64_ep50_sig_189\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e55_l64-64-64_ep50_sig_949\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e55_l64-64-64_ep50_sig_949  \n",
      "run_experiment()  when: 2026-01-15 00:40:24.411698 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 00:41:04.329015\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e55_l64-64-64_ep50_sig_949\\normalized_training_df-e55_l64-64-64_ep50_sig_949.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e55_l64-64-64_ep50_sig_949\\normalized_training_df-e55_l64-64-64_ep50_sig_949.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e55_l64-64-64_ep50_sig_949\\predictions-e55_l64-64-64_ep50_sig_949.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e55_l64-64-64_ep50_sig_949\\predictions-e55_l64-64-64_ep50_sig_949.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e55_l64-64-64_ep50_sig_949\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e55_l64-64-64_ep50_sig_949\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e55_l64-64-64_ep50_sig_949\\model\\assets\n",
      "[I 2026-01-15 00:42:15,879] Trial 77 finished with value: 0.9018509387969971 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 55, 'epochs': 50}. Best is trial 53 with value: 0.9096412062644958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e55_l64-64-64_ep50_sig_949\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-3\\e55_l64-64-64_ep50_sig_949\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e259_l64-64-64_ep50_sig_211\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-3\\e259_l64-64-64_ep50_sig_211  \n",
      "run_experiment()  when: 2026-01-15 00:42:15.917504 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2026-01-15 00:42:18,327] Trial 78 failed with parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 259, 'epochs': 50} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\miniconda3\\envs\\grocery-ml-keras\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 205, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_12452\\3176630135.py\", line 34, in objective\n",
      "    groceryML.run_experiment(\n",
      "  File \"C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_tensorflow.py\", line 470, in run_experiment\n",
      "    print(f\"run_experiment()  when: {datetime.now()} params: {modelTrainParams}  \");\n",
      "  File \"C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_tensorflow.py\", line 357, in train_model\n",
      "    history = model.fit(\n",
      "  File \"C:\\ProgramData\\miniconda3\\envs\\grocery-ml-keras\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\miniconda3\\envs\\grocery-ml-keras\\lib\\site-packages\\keras\\engine\\training.py\", line 1712, in fit\n",
      "    callbacks.on_epoch_end(epoch, epoch_logs)\n",
      "  File \"C:\\ProgramData\\miniconda3\\envs\\grocery-ml-keras\\lib\\site-packages\\keras\\callbacks.py\", line 454, in on_epoch_end\n",
      "    callback.on_epoch_end(epoch, logs)\n",
      "  File \"C:\\ProgramData\\miniconda3\\envs\\grocery-ml-keras\\lib\\site-packages\\keras\\callbacks.py\", line 2755, in on_epoch_end\n",
      "    self._log_weights(epoch)\n",
      "  File \"C:\\ProgramData\\miniconda3\\envs\\grocery-ml-keras\\lib\\site-packages\\keras\\callbacks.py\", line 2836, in _log_weights\n",
      "    self._log_weight_as_image(\n",
      "  File \"C:\\ProgramData\\miniconda3\\envs\\grocery-ml-keras\\lib\\site-packages\\keras\\callbacks.py\", line 2863, in _log_weight_as_image\n",
      "    tf.summary.image(weight_name, w_img, step=epoch)\n",
      "  File \"C:\\ProgramData\\miniconda3\\envs\\grocery-ml-keras\\lib\\site-packages\\tensorboard\\plugins\\image\\summary_v2.py\", line 140, in image\n",
      "    return tf.summary.write(\n",
      "  File \"C:\\ProgramData\\miniconda3\\envs\\grocery-ml-keras\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py\", line 769, in write\n",
      "    op = smart_cond.smart_cond(\n",
      "  File \"C:\\ProgramData\\miniconda3\\envs\\grocery-ml-keras\\lib\\site-packages\\tensorflow\\python\\framework\\smart_cond.py\", line 52, in smart_cond\n",
      "    return true_fn()\n",
      "  File \"C:\\ProgramData\\miniconda3\\envs\\grocery-ml-keras\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py\", line 759, in record\n",
      "    write_summary_op = gen_summary_ops.write_summary(\n",
      "  File \"C:\\ProgramData\\miniconda3\\envs\\grocery-ml-keras\\lib\\site-packages\\tensorflow\\python\\ops\\gen_summary_ops.py\", line 701, in write_summary\n",
      "    return write_summary_eager_fallback(\n",
      "  File \"C:\\ProgramData\\miniconda3\\envs\\grocery-ml-keras\\lib\\site-packages\\tensorflow\\python\\ops\\gen_summary_ops.py\", line 721, in write_summary_eager_fallback\n",
      "    _result = _execute.execute(b\"WriteSummary\", 0, inputs=_inputs_flat,\n",
      "  File \"C:\\ProgramData\\miniconda3\\envs\\grocery-ml-keras\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 52, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "KeyboardInterrupt\n",
      "[W 2026-01-15 00:42:18,335] Trial 78 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 57\u001b[0m\n\u001b[0;32m     47\u001b[0m study_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrocery_ml_tuning_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     48\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(\n\u001b[0;32m     49\u001b[0m     study_name\u001b[38;5;241m=\u001b[39m study_name,\n\u001b[0;32m     50\u001b[0m     sampler\u001b[38;5;241m=\u001b[39msampler,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     53\u001b[0m     load_if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     54\u001b[0m )\n\u001b[1;32m---> 57\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m250\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\miniconda3\\envs\\grocery-ml-keras\\lib\\site-packages\\optuna\\study\\study.py:490\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    389\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    390\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    397\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    398\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    399\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    400\u001b[0m \n\u001b[0;32m    401\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    489\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 490\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\miniconda3\\envs\\grocery-ml-keras\\lib\\site-packages\\optuna\\study\\_optimize.py:67\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 67\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     80\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mC:\\ProgramData\\miniconda3\\envs\\grocery-ml-keras\\lib\\site-packages\\optuna\\study\\_optimize.py:164\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 164\u001b[0m     frozen_trial_id \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mC:\\ProgramData\\miniconda3\\envs\\grocery-ml-keras\\lib\\site-packages\\optuna\\study\\_optimize.py:262\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    258\u001b[0m     updated_state \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    261\u001b[0m ):\n\u001b[1;32m--> 262\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trial\u001b[38;5;241m.\u001b[39m_trial_id\n",
      "File \u001b[1;32mC:\\ProgramData\\miniconda3\\envs\\grocery-ml-keras\\lib\\site-packages\\optuna\\study\\_optimize.py:205\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    207\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    208\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[2], line 34\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     18\u001b[0m build_params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m: embedding_dim,\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayers\u001b[39m\u001b[38;5;124m\"\u001b[39m: layers_cfg,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetrics\u001b[39m\u001b[38;5;124m\"\u001b[39m: metrics\n\u001b[0;32m     26\u001b[0m }\n\u001b[0;32m     28\u001b[0m train_params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m: epochs,\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m32\u001b[39m,\n\u001b[0;32m     31\u001b[0m  \n\u001b[0;32m     32\u001b[0m }\n\u001b[1;32m---> 34\u001b[0m \u001b[43mgroceryML\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroceryML\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbuild_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mf:/exp/keras/optuna/no-itemPurchaseCount-3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     39\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m groceryML\u001b[38;5;241m.\u001b[39mlast_val_auc\n",
      "File \u001b[1;32m~\\source\\repos\\grocery-ml\\grocery_ml_tensorflow.py:470\u001b[0m, in \u001b[0;36mrun_experiment\u001b[1;34m(self, training_df, modelBuildParams, modelTrainParams, baseDir)\u001b[0m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensorboard \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_tensorboard(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexp_dir_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/tensorflow/logs/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_experiment()  exp_dir: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexp_dir_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m  \u001b[39m\u001b[38;5;124m\"\u001b[39m);\n\u001b[1;32m--> 470\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_experiment()  when: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m params: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodelTrainParams\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m  \u001b[39m\u001b[38;5;124m\"\u001b[39m);\n\u001b[0;32m    472\u001b[0m \u001b[38;5;66;03m#training_df = self.groceryMLCore.drop_raw_columns(training_df)\u001b[39;00m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;66;03m#######################################################\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;66;03m#### normalize training_df, build and train model #####\u001b[39;00m\n\u001b[0;32m    475\u001b[0m target_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_target_col(training_df);\n",
      "File \u001b[1;32m~\\source\\repos\\grocery-ml\\grocery_ml_tensorflow.py:357\u001b[0m, in \u001b[0;36mGroceryML.train_model\u001b[1;34m(self, model, df, feature_cols, target_col, train_params)\u001b[0m\n\u001b[0;32m    354\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping( monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m ))\n\u001b[0;32m    355\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensorboard)\n\u001b[1;32m--> 357\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_feat_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_item_tr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    362\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    363\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    364\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    365\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m history\n",
      "File \u001b[1;32mC:\\ProgramData\\miniconda3\\envs\\grocery-ml-keras\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mC:\\ProgramData\\miniconda3\\envs\\grocery-ml-keras\\lib\\site-packages\\keras\\engine\\training.py:1712\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1707\u001b[0m     val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   1708\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   1709\u001b[0m     }\n\u001b[0;32m   1710\u001b[0m     epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n\u001b[1;32m-> 1712\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_epoch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_logs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1713\u001b[0m training_logs \u001b[38;5;241m=\u001b[39m epoch_logs\n\u001b[0;32m   1714\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32mC:\\ProgramData\\miniconda3\\envs\\grocery-ml-keras\\lib\\site-packages\\keras\\callbacks.py:454\u001b[0m, in \u001b[0;36mCallbackList.on_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    452\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_logs(logs)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[1;32m--> 454\u001b[0m     \u001b[43mcallback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_epoch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\miniconda3\\envs\\grocery-ml-keras\\lib\\site-packages\\keras\\callbacks.py:2755\u001b[0m, in \u001b[0;36mTensorBoard.on_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m   2752\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_epoch_metrics(epoch, logs)\n\u001b[0;32m   2754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistogram_freq \u001b[38;5;129;01mand\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistogram_freq \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2755\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2757\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings_freq \u001b[38;5;129;01mand\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings_freq \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   2758\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_embeddings(epoch)\n",
      "File \u001b[1;32mC:\\ProgramData\\miniconda3\\envs\\grocery-ml-keras\\lib\\site-packages\\keras\\callbacks.py:2836\u001b[0m, in \u001b[0;36mTensorBoard._log_weights\u001b[1;34m(self, epoch)\u001b[0m\n\u001b[0;32m   2832\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_images:\n\u001b[0;32m   2833\u001b[0m             \u001b[38;5;66;03m# Add a suffix to prevent summary tag name\u001b[39;00m\n\u001b[0;32m   2834\u001b[0m             \u001b[38;5;66;03m# collision.\u001b[39;00m\n\u001b[0;32m   2835\u001b[0m             image_weight_name \u001b[38;5;241m=\u001b[39m weight_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/image\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 2836\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_weight_as_image\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2837\u001b[0m \u001b[43m                \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_weight_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\n\u001b[0;32m   2838\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2839\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_writer\u001b[38;5;241m.\u001b[39mflush()\n",
      "File \u001b[1;32mC:\\ProgramData\\miniconda3\\envs\\grocery-ml-keras\\lib\\site-packages\\keras\\callbacks.py:2863\u001b[0m, in \u001b[0;36mTensorBoard._log_weight_as_image\u001b[1;34m(self, weight, weight_name, epoch)\u001b[0m\n\u001b[0;32m   2861\u001b[0m \u001b[38;5;66;03m# Not possible to handle 3D convnets etc.\u001b[39;00m\n\u001b[0;32m   2862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(shape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m shape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m]:\n\u001b[1;32m-> 2863\u001b[0m     \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\miniconda3\\envs\\grocery-ml-keras\\lib\\site-packages\\tensorboard\\plugins\\image\\summary_v2.py:140\u001b[0m, in \u001b[0;36mimage\u001b[1;34m(name, data, step, max_outputs, description)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mconcat([dimensions, encoded_images], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    138\u001b[0m \u001b[38;5;66;03m# To ensure that image encoding logic is only executed when summaries\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;66;03m# are written, we pass callable to `tensor` parameter.\u001b[39;00m\n\u001b[1;32m--> 140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlazy_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msummary_metadata\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\miniconda3\\envs\\grocery-ml-keras\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:769\u001b[0m, in \u001b[0;36mwrite\u001b[1;34m(tag, tensor, step, metadata, name)\u001b[0m\n\u001b[0;32m    766\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcontrol_dependencies([write_summary_op]):\n\u001b[0;32m    767\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m constant_op\u001b[38;5;241m.\u001b[39mconstant(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 769\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43msmart_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msmart_cond\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshould_record_summaries\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_nothing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msummary_cond\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    771\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m    772\u001b[0m   ops\u001b[38;5;241m.\u001b[39madd_to_collection(ops\u001b[38;5;241m.\u001b[39mGraphKeys\u001b[38;5;241m.\u001b[39m_SUMMARY_COLLECTION, op)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\miniconda3\\envs\\grocery-ml-keras\\lib\\site-packages\\tensorflow\\python\\framework\\smart_cond.py:52\u001b[0m, in \u001b[0;36msmart_cond\u001b[1;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pred_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m pred_value:\n\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrue_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m false_fn()\n",
      "File \u001b[1;32mC:\\ProgramData\\miniconda3\\envs\\grocery-ml-keras\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:759\u001b[0m, in \u001b[0;36mwrite.<locals>.record\u001b[1;34m()\u001b[0m\n\u001b[0;32m    756\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu:0\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    757\u001b[0m   summary_tensor \u001b[38;5;241m=\u001b[39m tensor() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(tensor) \u001b[38;5;28;01melse\u001b[39;00m array_ops\u001b[38;5;241m.\u001b[39midentity(\n\u001b[0;32m    758\u001b[0m       tensor)\n\u001b[1;32m--> 759\u001b[0m   write_summary_op \u001b[38;5;241m=\u001b[39m \u001b[43mgen_summary_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_summary\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    760\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_summary_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    761\u001b[0m \u001b[43m      \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    762\u001b[0m \u001b[43m      \u001b[49m\u001b[43msummary_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    763\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    764\u001b[0m \u001b[43m      \u001b[49m\u001b[43mserialized_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    765\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    766\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcontrol_dependencies([write_summary_op]):\n\u001b[0;32m    767\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m constant_op\u001b[38;5;241m.\u001b[39mconstant(\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\ProgramData\\miniconda3\\envs\\grocery-ml-keras\\lib\\site-packages\\tensorflow\\python\\ops\\gen_summary_ops.py:701\u001b[0m, in \u001b[0;36mwrite_summary\u001b[1;34m(writer, step, tensor, tag, summary_metadata, name)\u001b[0m\n\u001b[0;32m    699\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    700\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 701\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrite_summary_eager_fallback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[43m      \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msummary_metadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_ctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_SymbolicException:\n\u001b[0;32m    704\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Add nodes to the TensorFlow graph.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\miniconda3\\envs\\grocery-ml-keras\\lib\\site-packages\\tensorflow\\python\\ops\\gen_summary_ops.py:721\u001b[0m, in \u001b[0;36mwrite_summary_eager_fallback\u001b[1;34m(writer, step, tensor, tag, summary_metadata, name, ctx)\u001b[0m\n\u001b[0;32m    719\u001b[0m _inputs_flat \u001b[38;5;241m=\u001b[39m [writer, step, tensor, tag, summary_metadata]\n\u001b[0;32m    720\u001b[0m _attrs \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m\"\u001b[39m, _attr_T)\n\u001b[1;32m--> 721\u001b[0m _result \u001b[38;5;241m=\u001b[39m \u001b[43m_execute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWriteSummary\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_inputs_flat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_attrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    723\u001b[0m _result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _result\n",
      "File \u001b[1;32mC:\\ProgramData\\miniconda3\\envs\\grocery-ml-keras\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import optuna \n",
    "def objective(trial):\n",
    "\n",
    "    lr = trial.suggest_float(\"learning_rate\", 0.0001, 0.0001)\n",
    "    depth = trial.suggest_int(\"depth\", 3, 3)\n",
    "    units = trial.suggest_int(\"units\", 64, 64)\n",
    "    embedding_dim = trial.suggest_int(\"embedding_dim\", 30, 500, step=5)\n",
    "    epochs = trial.suggest_int(\"epochs\", 50, 50)\n",
    "    # output_activation = trial.suggest_categorical(\"output_activation\", [\"sigmoid\", \"linear\"])\n",
    "    output_activation = \"sigmoid\"\n",
    "    metrics = [\"AUC\", \"Precision\", \"Recall\"]\n",
    "    # metrics = [\"Accuracy\", \"MAE\", \"MSE\", \"MAPE\", \"MSLE\", \"Precision\", \"Recall\", \"AUC\",  \"BinaryCrossentropy\", \"RootMeanSquaredError\"]\n",
    "    \n",
    "    layers_cfg = []\n",
    "    for _ in range(depth):\n",
    "        layers_cfg.append({ \"units\": units, \"activation\": \"relu\" })\n",
    "\n",
    "    build_params = {\n",
    "        \"embedding_dim\": embedding_dim,\n",
    "        \"layers\": layers_cfg,\n",
    "        \"output_activation\": output_activation,\n",
    "        \"optimizer\": \"adam\",\n",
    "        \"learning_rate\": lr,\n",
    "        \"loss\": \"binary_crossentropy\" if output_activation == \"sigmoid\" else \"mse\",\n",
    "        \"metrics\": metrics\n",
    "    }\n",
    "\n",
    "    train_params = {\n",
    "        \"epochs\": epochs,\n",
    "        \"batch_size\": 32,\n",
    "     \n",
    "    }\n",
    "\n",
    "    outputDir = f\"f:/exp/keras/optuna/{trial.study.study_name}/trial-{trial.number}\"        \n",
    "    groceryML.run_experiment(groceryML.training_df, build_params, train_params, outputDir)\n",
    "\n",
    "    return groceryML.last_val_auc\n",
    "############################################################################\n",
    "\n",
    "\n",
    "sampler = optuna.samplers.TPESampler()\n",
    "\n",
    "study_name = f\"grocery_ml_tuning_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "study = optuna.create_study(\n",
    "    study_name= study_name,\n",
    "    sampler=sampler,\n",
    "    direction=\"maximize\",   # or minimize — see note below\n",
    "    storage=\"sqlite:///optuna_grocery.db\",\n",
    "    load_if_exists=True\n",
    ")\n",
    "\n",
    "\n",
    "study.optimize(objective, n_trials=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cef528-5472-429d-9657-42dd746a184c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
