{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f94e9fd3-99b1-438c-9ac0-6d5455c99af4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pdb;\n",
    "from grocery_ml_tensorflow import GroceryML\n",
    "from grocery_ml_core import GroceryMLCore\n",
    "from hidden_layer_param_builder import HiddenLayerParamSetBuilder\n",
    "import tensorflow as tf\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option(\"display.float_format\", lambda x: f\"{x:.6f}\")\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", 2000)\n",
    "\n",
    "print(os.getcwd())\n",
    "# print(\"GPUs Available:\", tf.config.list_physical_devices('GPU'))\n",
    "#tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# def run_all_experiments(df, model_param_sets, output_dir):\n",
    "#     total = len(model_param_sets)\n",
    "#     print(f\"run_all_experiments() when: {datetime.now()}  output_dir: {output_dir}\");\n",
    "#     for index, params in enumerate(model_param_sets, 1):\n",
    "#         print(f\"Running Exp {index}/{total}...\")\n",
    "#         groceryML.run_experiment(df,  params[\"buildParams\"], params[\"trainParams\"], output_dir)\n",
    "\n",
    "\n",
    "try:\n",
    "    groceryML = GroceryML();\n",
    "    groceryMLCore = GroceryMLCore();\n",
    "    groceryML.build_training_df()\n",
    "    if groceryML.training_df is None:\n",
    "        raise();\n",
    "    ts = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "    # groceryML.training_df.to_csv(f\"training_df-{ts}.csv\");\n",
    "except Exception as ex: \n",
    "    print(ex)\n",
    "    ts = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "    groceryML.training_df.to_csv(f\"training_df-{ts}-exception.csv\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc5404e4-f977-40ab-8250-f34c86c037ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-13 10:51:18,712] A new study created in RDB with name: grocery_ml_tuning_20260113_105118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dir: f:/exp/keras/optuna\\e1846_l831-831-831_ep21_sig_174\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e1846_l831-831-831_ep21_sig_174  \n",
      "run_experiment()  when: 2026-01-13 10:51:18.757752 params: {'epochs': 21, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 10:55:21.588466\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e1846_l831-831-831_ep21_sig_174\\normalized_training_df-e1846_l831-831-831_ep21_sig_174.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e1846_l831-831-831_ep21_sig_174\\normalized_training_df-e1846_l831-831-831_ep21_sig_174.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e1846_l831-831-831_ep21_sig_174\\predictions-e1846_l831-831-831_ep21_sig_174.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e1846_l831-831-831_ep21_sig_174\\predictions-e1846_l831-831-831_ep21_sig_174.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e1846_l831-831-831_ep21_sig_174\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e1846_l831-831-831_ep21_sig_174\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e1846_l831-831-831_ep21_sig_174\\model\\assets\n",
      "[I 2026-01-13 10:56:24,733] Trial 0 finished with value: 0.8015961647033691 and parameters: {'learning_rate': 0.0023934641760048935, 'depth': 3, 'units': 831, 'embedding_dim': 1846, 'epochs': 21}. Best is trial 0 with value: 0.8015961647033691.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e1846_l831-831-831_ep21_sig_174\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e1846_l831-831-831_ep21_sig_174\n",
      "Creating dir: f:/exp/keras/optuna\\e910_l262-262-262-262-262-262-2\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e910_l262-262-262-262-262-262-2  \n",
      "run_experiment()  when: 2026-01-13 10:56:24.782795 params: {'epochs': 26, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 10:56:56.994924\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e910_l262-262-262-262-262-262-2\\normalized_training_df-e910_l262-262-262-262-262-262-2.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e910_l262-262-262-262-262-262-2\\normalized_training_df-e910_l262-262-262-262-262-262-2.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e910_l262-262-262-262-262-262-2\\predictions-e910_l262-262-262-262-262-262-2.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e910_l262-262-262-262-262-262-2\\predictions-e910_l262-262-262-262-262-262-2.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e910_l262-262-262-262-262-262-2\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e910_l262-262-262-262-262-262-2\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e910_l262-262-262-262-262-262-2\\model\\assets\n",
      "[I 2026-01-13 10:58:00,423] Trial 1 finished with value: 0.7354387044906616 and parameters: {'learning_rate': 0.006652626728264734, 'depth': 7, 'units': 262, 'embedding_dim': 910, 'epochs': 26}. Best is trial 0 with value: 0.8015961647033691.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e910_l262-262-262-262-262-262-2\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e910_l262-262-262-262-262-262-2\n",
      "Creating dir: f:/exp/keras/optuna\\e359_l379-379-379-379-379-379-3\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e359_l379-379-379-379-379-379-3  \n",
      "run_experiment()  when: 2026-01-13 10:58:00.458654 params: {'epochs': 29, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 10:58:32.062366\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e359_l379-379-379-379-379-379-3\\normalized_training_df-e359_l379-379-379-379-379-379-3.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e359_l379-379-379-379-379-379-3\\normalized_training_df-e359_l379-379-379-379-379-379-3.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e359_l379-379-379-379-379-379-3\\predictions-e359_l379-379-379-379-379-379-3.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e359_l379-379-379-379-379-379-3\\predictions-e359_l379-379-379-379-379-379-3.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e359_l379-379-379-379-379-379-3\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e359_l379-379-379-379-379-379-3\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e359_l379-379-379-379-379-379-3\\model\\assets\n",
      "[I 2026-01-13 10:59:35,277] Trial 2 finished with value: 0.7926124334335327 and parameters: {'learning_rate': 0.0016438106329834349, 'depth': 10, 'units': 379, 'embedding_dim': 359, 'epochs': 29}. Best is trial 0 with value: 0.8015961647033691.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e359_l379-379-379-379-379-379-3\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e359_l379-379-379-379-379-379-3\n",
      "Creating dir: f:/exp/keras/optuna\\e1495_l483-483-483-483-483-483-\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e1495_l483-483-483-483-483-483-  \n",
      "run_experiment()  when: 2026-01-13 10:59:35.311253 params: {'epochs': 117, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 11:01:31.435861\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e1495_l483-483-483-483-483-483-\\normalized_training_df-e1495_l483-483-483-483-483-483-.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e1495_l483-483-483-483-483-483-\\normalized_training_df-e1495_l483-483-483-483-483-483-.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e1495_l483-483-483-483-483-483-\\predictions-e1495_l483-483-483-483-483-483-.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e1495_l483-483-483-483-483-483-\\predictions-e1495_l483-483-483-483-483-483-.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e1495_l483-483-483-483-483-483-\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e1495_l483-483-483-483-483-483-\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e1495_l483-483-483-483-483-483-\\model\\assets\n",
      "[I 2026-01-13 11:02:39,337] Trial 3 finished with value: 0.7810553312301636 and parameters: {'learning_rate': 0.002592547317253208, 'depth': 8, 'units': 483, 'embedding_dim': 1495, 'epochs': 117}. Best is trial 0 with value: 0.8015961647033691.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e1495_l483-483-483-483-483-483-\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e1495_l483-483-483-483-483-483-\n",
      "Creating dir: f:/exp/keras/optuna\\e1932_l445-445-445-445-445-445-\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e1932_l445-445-445-445-445-445-  \n",
      "run_experiment()  when: 2026-01-13 11:02:39.373518 params: {'epochs': 99, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 11:04:48.148163\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e1932_l445-445-445-445-445-445-\\normalized_training_df-e1932_l445-445-445-445-445-445-.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e1932_l445-445-445-445-445-445-\\normalized_training_df-e1932_l445-445-445-445-445-445-.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e1932_l445-445-445-445-445-445-\\predictions-e1932_l445-445-445-445-445-445-.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e1932_l445-445-445-445-445-445-\\predictions-e1932_l445-445-445-445-445-445-.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e1932_l445-445-445-445-445-445-\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e1932_l445-445-445-445-445-445-\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e1932_l445-445-445-445-445-445-\\model\\assets\n",
      "[I 2026-01-13 11:05:52,480] Trial 4 finished with value: 0.5 and parameters: {'learning_rate': 0.009775530973398009, 'depth': 7, 'units': 445, 'embedding_dim': 1932, 'epochs': 99}. Best is trial 0 with value: 0.8015961647033691.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e1932_l445-445-445-445-445-445-\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e1932_l445-445-445-445-445-445-\n",
      "Creating dir: f:/exp/keras/optuna\\e506_l1161_ep97_sig_119\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e506_l1161_ep97_sig_119  \n",
      "run_experiment()  when: 2026-01-13 11:05:52.516981 params: {'epochs': 97, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 11:06:59.458442\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e506_l1161_ep97_sig_119\\normalized_training_df-e506_l1161_ep97_sig_119.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e506_l1161_ep97_sig_119\\normalized_training_df-e506_l1161_ep97_sig_119.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e506_l1161_ep97_sig_119\\predictions-e506_l1161_ep97_sig_119.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e506_l1161_ep97_sig_119\\predictions-e506_l1161_ep97_sig_119.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e506_l1161_ep97_sig_119\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e506_l1161_ep97_sig_119\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e506_l1161_ep97_sig_119\\model\\assets\n",
      "[I 2026-01-13 11:08:03,326] Trial 5 finished with value: 0.8316614627838135 and parameters: {'learning_rate': 0.005685729446556347, 'depth': 1, 'units': 1161, 'embedding_dim': 506, 'epochs': 97}. Best is trial 5 with value: 0.8316614627838135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e506_l1161_ep97_sig_119\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e506_l1161_ep97_sig_119\n",
      "Creating dir: f:/exp/keras/optuna\\e1837_l1500-1500-1500-1500-1500\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e1837_l1500-1500-1500-1500-1500  \n",
      "run_experiment()  when: 2026-01-13 11:08:03.362241 params: {'epochs': 63, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 11:26:32.950414\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 16ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e1837_l1500-1500-1500-1500-1500\\normalized_training_df-e1837_l1500-1500-1500-1500-1500.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e1837_l1500-1500-1500-1500-1500\\normalized_training_df-e1837_l1500-1500-1500-1500-1500.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e1837_l1500-1500-1500-1500-1500\\predictions-e1837_l1500-1500-1500-1500-1500.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e1837_l1500-1500-1500-1500-1500\\predictions-e1837_l1500-1500-1500-1500-1500.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e1837_l1500-1500-1500-1500-1500\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e1837_l1500-1500-1500-1500-1500\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e1837_l1500-1500-1500-1500-1500\\model\\assets\n",
      "[I 2026-01-13 11:27:41,633] Trial 6 finished with value: 0.7827411890029907 and parameters: {'learning_rate': 0.0016946219615099768, 'depth': 9, 'units': 1500, 'embedding_dim': 1837, 'epochs': 63}. Best is trial 5 with value: 0.8316614627838135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e1837_l1500-1500-1500-1500-1500\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e1837_l1500-1500-1500-1500-1500\n",
      "Creating dir: f:/exp/keras/optuna\\e1716_l808-808-808-808-808_ep43\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e1716_l808-808-808-808-808_ep43  \n",
      "run_experiment()  when: 2026-01-13 11:27:41.669957 params: {'epochs': 43, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 11:32:58.876347\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 6ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e1716_l808-808-808-808-808_ep43\\normalized_training_df-e1716_l808-808-808-808-808_ep43.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e1716_l808-808-808-808-808_ep43\\normalized_training_df-e1716_l808-808-808-808-808_ep43.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e1716_l808-808-808-808-808_ep43\\predictions-e1716_l808-808-808-808-808_ep43.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e1716_l808-808-808-808-808_ep43\\predictions-e1716_l808-808-808-808-808_ep43.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e1716_l808-808-808-808-808_ep43\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e1716_l808-808-808-808-808_ep43\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e1716_l808-808-808-808-808_ep43\\model\\assets\n",
      "[I 2026-01-13 11:34:07,475] Trial 7 finished with value: 0.5 and parameters: {'learning_rate': 0.006704018482798245, 'depth': 5, 'units': 808, 'embedding_dim': 1716, 'epochs': 43}. Best is trial 5 with value: 0.8316614627838135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e1716_l808-808-808-808-808_ep43\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e1716_l808-808-808-808-808_ep43\n",
      "Creating dir: f:/exp/keras/optuna\\e1316_l1638-1638-1638-1638-1638\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e1316_l1638-1638-1638-1638-1638  \n",
      "run_experiment()  when: 2026-01-13 11:34:07.515603 params: {'epochs': 16, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 11:51:24.389846\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 13ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e1316_l1638-1638-1638-1638-1638\\normalized_training_df-e1316_l1638-1638-1638-1638-1638.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e1316_l1638-1638-1638-1638-1638\\normalized_training_df-e1316_l1638-1638-1638-1638-1638.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e1316_l1638-1638-1638-1638-1638\\predictions-e1316_l1638-1638-1638-1638-1638.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e1316_l1638-1638-1638-1638-1638\\predictions-e1316_l1638-1638-1638-1638-1638.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e1316_l1638-1638-1638-1638-1638\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e1316_l1638-1638-1638-1638-1638\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e1316_l1638-1638-1638-1638-1638\\model\\assets\n",
      "[I 2026-01-13 11:52:33,827] Trial 8 finished with value: 0.5 and parameters: {'learning_rate': 0.006288838778002975, 'depth': 6, 'units': 1638, 'embedding_dim': 1316, 'epochs': 16}. Best is trial 5 with value: 0.8316614627838135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e1316_l1638-1638-1638-1638-1638\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e1316_l1638-1638-1638-1638-1638\n",
      "Creating dir: f:/exp/keras/optuna\\e1192_l595-595-595-595-595-595-\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e1192_l595-595-595-595-595-595-  \n",
      "run_experiment()  when: 2026-01-13 11:52:33.876135 params: {'epochs': 22, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 11:54:38.699791\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 6ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e1192_l595-595-595-595-595-595-\\normalized_training_df-e1192_l595-595-595-595-595-595-.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e1192_l595-595-595-595-595-595-\\normalized_training_df-e1192_l595-595-595-595-595-595-.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e1192_l595-595-595-595-595-595-\\predictions-e1192_l595-595-595-595-595-595-.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e1192_l595-595-595-595-595-595-\\predictions-e1192_l595-595-595-595-595-595-.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e1192_l595-595-595-595-595-595-\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e1192_l595-595-595-595-595-595-\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e1192_l595-595-595-595-595-595-\\model\\assets\n",
      "[I 2026-01-13 11:55:47,238] Trial 9 finished with value: 0.5 and parameters: {'learning_rate': 0.008685450397091215, 'depth': 7, 'units': 595, 'embedding_dim': 1192, 'epochs': 22}. Best is trial 5 with value: 0.8316614627838135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e1192_l595-595-595-595-595-595-\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e1192_l595-595-595-595-595-595-\n",
      "Creating dir: f:/exp/keras/optuna\\e315_l2032_ep150_sig_669\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e315_l2032_ep150_sig_669  \n",
      "run_experiment()  when: 2026-01-13 11:55:47.291298 params: {'epochs': 150, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 11:56:33.051691\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e315_l2032_ep150_sig_669\\normalized_training_df-e315_l2032_ep150_sig_669.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e315_l2032_ep150_sig_669\\normalized_training_df-e315_l2032_ep150_sig_669.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e315_l2032_ep150_sig_669\\predictions-e315_l2032_ep150_sig_669.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e315_l2032_ep150_sig_669\\predictions-e315_l2032_ep150_sig_669.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e315_l2032_ep150_sig_669\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e315_l2032_ep150_sig_669\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e315_l2032_ep150_sig_669\\model\\assets\n",
      "[I 2026-01-13 11:57:41,282] Trial 10 finished with value: 0.8068953156471252 and parameters: {'learning_rate': 0.004252481282396868, 'depth': 1, 'units': 2032, 'embedding_dim': 315, 'epochs': 150}. Best is trial 5 with value: 0.8316614627838135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e315_l2032_ep150_sig_669\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e315_l2032_ep150_sig_669\n",
      "Creating dir: f:/exp/keras/optuna\\e301_l2009_ep136_sig_757\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e301_l2009_ep136_sig_757  \n",
      "run_experiment()  when: 2026-01-13 11:57:41.330682 params: {'epochs': 136, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 11:58:27.757563\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e301_l2009_ep136_sig_757\\normalized_training_df-e301_l2009_ep136_sig_757.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e301_l2009_ep136_sig_757\\normalized_training_df-e301_l2009_ep136_sig_757.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e301_l2009_ep136_sig_757\\predictions-e301_l2009_ep136_sig_757.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e301_l2009_ep136_sig_757\\predictions-e301_l2009_ep136_sig_757.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e301_l2009_ep136_sig_757\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e301_l2009_ep136_sig_757\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e301_l2009_ep136_sig_757\\model\\assets\n",
      "[I 2026-01-13 11:59:35,582] Trial 11 finished with value: 0.8059343099594116 and parameters: {'learning_rate': 0.004297618573520741, 'depth': 1, 'units': 2009, 'embedding_dim': 301, 'epochs': 136}. Best is trial 5 with value: 0.8316614627838135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e301_l2009_ep136_sig_757\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e301_l2009_ep136_sig_757\n",
      "Creating dir: f:/exp/keras/optuna\\e694_l1350_ep138_sig_145\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e694_l1350_ep138_sig_145  \n",
      "run_experiment()  when: 2026-01-13 11:59:35.632050 params: {'epochs': 138, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 12:01:36.631238\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e694_l1350_ep138_sig_145\\normalized_training_df-e694_l1350_ep138_sig_145.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e694_l1350_ep138_sig_145\\normalized_training_df-e694_l1350_ep138_sig_145.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e694_l1350_ep138_sig_145\\predictions-e694_l1350_ep138_sig_145.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e694_l1350_ep138_sig_145\\predictions-e694_l1350_ep138_sig_145.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e694_l1350_ep138_sig_145\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e694_l1350_ep138_sig_145\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e694_l1350_ep138_sig_145\\model\\assets\n",
      "[I 2026-01-13 12:02:45,343] Trial 12 finished with value: 0.8210128545761108 and parameters: {'learning_rate': 0.0045748425701029735, 'depth': 1, 'units': 1350, 'embedding_dim': 694, 'epochs': 138}. Best is trial 5 with value: 0.8316614627838135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e694_l1350_ep138_sig_145\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e694_l1350_ep138_sig_145\n",
      "Creating dir: f:/exp/keras/optuna\\e877_l1227-1227-1227_ep89_sig_9\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e877_l1227-1227-1227_ep89_sig_9  \n",
      "run_experiment()  when: 2026-01-13 12:02:45.392140 params: {'epochs': 89, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 12:09:44.255584\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 6ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e877_l1227-1227-1227_ep89_sig_9\\normalized_training_df-e877_l1227-1227-1227_ep89_sig_9.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e877_l1227-1227-1227_ep89_sig_9\\normalized_training_df-e877_l1227-1227-1227_ep89_sig_9.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e877_l1227-1227-1227_ep89_sig_9\\predictions-e877_l1227-1227-1227_ep89_sig_9.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e877_l1227-1227-1227_ep89_sig_9\\predictions-e877_l1227-1227-1227_ep89_sig_9.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e877_l1227-1227-1227_ep89_sig_9\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e877_l1227-1227-1227_ep89_sig_9\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e877_l1227-1227-1227_ep89_sig_9\\model\\assets\n",
      "[I 2026-01-13 12:10:52,994] Trial 13 finished with value: 0.7999049425125122 and parameters: {'learning_rate': 0.004606289716834364, 'depth': 3, 'units': 1227, 'embedding_dim': 877, 'epochs': 89}. Best is trial 5 with value: 0.8316614627838135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e877_l1227-1227-1227_ep89_sig_9\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e877_l1227-1227-1227_ep89_sig_9\n",
      "Creating dir: f:/exp/keras/optuna\\e664_l1209-1209-1209_ep114_sig_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e664_l1209-1209-1209_ep114_sig_  \n",
      "run_experiment()  when: 2026-01-13 12:10:53.045349 params: {'epochs': 114, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 12:13:23.613395\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e664_l1209-1209-1209_ep114_sig_\\normalized_training_df-e664_l1209-1209-1209_ep114_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e664_l1209-1209-1209_ep114_sig_\\normalized_training_df-e664_l1209-1209-1209_ep114_sig_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e664_l1209-1209-1209_ep114_sig_\\predictions-e664_l1209-1209-1209_ep114_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e664_l1209-1209-1209_ep114_sig_\\predictions-e664_l1209-1209-1209_ep114_sig_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e664_l1209-1209-1209_ep114_sig_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e664_l1209-1209-1209_ep114_sig_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e664_l1209-1209-1209_ep114_sig_\\model\\assets\n",
      "[I 2026-01-13 12:14:32,922] Trial 14 finished with value: 0.5 and parameters: {'learning_rate': 0.00767642137305585, 'depth': 3, 'units': 1209, 'embedding_dim': 664, 'epochs': 114}. Best is trial 5 with value: 0.8316614627838135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e664_l1209-1209-1209_ep114_sig_\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e664_l1209-1209-1209_ep114_sig_\n",
      "Creating dir: f:/exp/keras/optuna\\e719_l1524-1524_ep65_sig_223\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e719_l1524-1524_ep65_sig_223  \n",
      "run_experiment()  when: 2026-01-13 12:14:32.972323 params: {'epochs': 65, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 12:18:52.425651\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e719_l1524-1524_ep65_sig_223\\normalized_training_df-e719_l1524-1524_ep65_sig_223.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e719_l1524-1524_ep65_sig_223\\normalized_training_df-e719_l1524-1524_ep65_sig_223.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e719_l1524-1524_ep65_sig_223\\predictions-e719_l1524-1524_ep65_sig_223.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e719_l1524-1524_ep65_sig_223\\predictions-e719_l1524-1524_ep65_sig_223.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e719_l1524-1524_ep65_sig_223\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e719_l1524-1524_ep65_sig_223\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e719_l1524-1524_ep65_sig_223\\model\\assets\n",
      "[I 2026-01-13 12:20:00,513] Trial 15 finished with value: 0.8188227415084839 and parameters: {'learning_rate': 0.005452368614359693, 'depth': 2, 'units': 1524, 'embedding_dim': 719, 'epochs': 65}. Best is trial 5 with value: 0.8316614627838135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e719_l1524-1524_ep65_sig_223\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e719_l1524-1524_ep65_sig_223\n",
      "Creating dir: f:/exp/keras/optuna\\e622_l1124-1124-1124-1124_ep124\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e622_l1124-1124-1124-1124_ep124  \n",
      "run_experiment()  when: 2026-01-13 12:20:00.563073 params: {'epochs': 124, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 12:23:26.555393\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 6ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e622_l1124-1124-1124-1124_ep124\\normalized_training_df-e622_l1124-1124-1124-1124_ep124.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e622_l1124-1124-1124-1124_ep124\\normalized_training_df-e622_l1124-1124-1124-1124_ep124.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e622_l1124-1124-1124-1124_ep124\\predictions-e622_l1124-1124-1124-1124_ep124.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e622_l1124-1124-1124-1124_ep124\\predictions-e622_l1124-1124-1124-1124_ep124.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e622_l1124-1124-1124-1124_ep124\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e622_l1124-1124-1124-1124_ep124\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e622_l1124-1124-1124-1124_ep124\\model\\assets\n",
      "[I 2026-01-13 12:24:35,002] Trial 16 finished with value: 0.8066590428352356 and parameters: {'learning_rate': 0.003213150206626464, 'depth': 4, 'units': 1124, 'embedding_dim': 622, 'epochs': 124}. Best is trial 5 with value: 0.8316614627838135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e622_l1124-1124-1124-1124_ep124\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e622_l1124-1124-1124-1124_ep124\n",
      "Creating dir: f:/exp/keras/optuna\\e966_l1358_ep101_sig_116\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e966_l1358_ep101_sig_116  \n",
      "run_experiment()  when: 2026-01-13 12:24:35.051438 params: {'epochs': 101, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 12:25:48.377720\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e966_l1358_ep101_sig_116\\normalized_training_df-e966_l1358_ep101_sig_116.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e966_l1358_ep101_sig_116\\normalized_training_df-e966_l1358_ep101_sig_116.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e966_l1358_ep101_sig_116\\predictions-e966_l1358_ep101_sig_116.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e966_l1358_ep101_sig_116\\predictions-e966_l1358_ep101_sig_116.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e966_l1358_ep101_sig_116\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e966_l1358_ep101_sig_116\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e966_l1358_ep101_sig_116\\model\\assets\n",
      "[I 2026-01-13 12:26:56,514] Trial 17 finished with value: 0.8011654019355774 and parameters: {'learning_rate': 0.0054798623919161535, 'depth': 1, 'units': 1358, 'embedding_dim': 966, 'epochs': 101}. Best is trial 5 with value: 0.8316614627838135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e966_l1358_ep101_sig_116\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e966_l1358_ep101_sig_116\n",
      "Creating dir: f:/exp/keras/optuna\\e551_l1725-1725_ep69_sig_130\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e551_l1725-1725_ep69_sig_130  \n",
      "run_experiment()  when: 2026-01-13 12:26:56.566165 params: {'epochs': 69, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 12:29:35.641799\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e551_l1725-1725_ep69_sig_130\\normalized_training_df-e551_l1725-1725_ep69_sig_130.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e551_l1725-1725_ep69_sig_130\\normalized_training_df-e551_l1725-1725_ep69_sig_130.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e551_l1725-1725_ep69_sig_130\\predictions-e551_l1725-1725_ep69_sig_130.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e551_l1725-1725_ep69_sig_130\\predictions-e551_l1725-1725_ep69_sig_130.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e551_l1725-1725_ep69_sig_130\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e551_l1725-1725_ep69_sig_130\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e551_l1725-1725_ep69_sig_130\\model\\assets\n",
      "[I 2026-01-13 12:30:45,903] Trial 18 finished with value: 0.8077961206436157 and parameters: {'learning_rate': 0.0035650764864399204, 'depth': 2, 'units': 1725, 'embedding_dim': 551, 'epochs': 69}. Best is trial 5 with value: 0.8316614627838135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e551_l1725-1725_ep69_sig_130\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e551_l1725-1725_ep69_sig_130\n",
      "Creating dir: f:/exp/keras/optuna\\e516_l948-948-948-948-948_ep148\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e516_l948-948-948-948-948_ep148  \n",
      "run_experiment()  when: 2026-01-13 12:30:45.953282 params: {'epochs': 148, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 12:33:24.444034\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 6ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e516_l948-948-948-948-948_ep148\\normalized_training_df-e516_l948-948-948-948-948_ep148.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e516_l948-948-948-948-948_ep148\\normalized_training_df-e516_l948-948-948-948-948_ep148.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e516_l948-948-948-948-948_ep148\\predictions-e516_l948-948-948-948-948_ep148.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e516_l948-948-948-948-948_ep148\\predictions-e516_l948-948-948-948-948_ep148.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e516_l948-948-948-948-948_ep148\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e516_l948-948-948-948-948_ep148\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e516_l948-948-948-948-948_ep148\\model\\assets\n",
      "[I 2026-01-13 12:34:32,808] Trial 19 finished with value: 0.5 and parameters: {'learning_rate': 0.00771328796420892, 'depth': 5, 'units': 948, 'embedding_dim': 516, 'epochs': 148}. Best is trial 5 with value: 0.8316614627838135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e516_l948-948-948-948-948_ep148\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e516_l948-948-948-948-948_ep148\n",
      "Creating dir: f:/exp/keras/optuna\\e811_l724-724_ep135_sig_198\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e811_l724-724_ep135_sig_198  \n",
      "run_experiment()  when: 2026-01-13 12:34:32.862001 params: {'epochs': 135, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 12:35:31.542315\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e811_l724-724_ep135_sig_198\\normalized_training_df-e811_l724-724_ep135_sig_198.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e811_l724-724_ep135_sig_198\\normalized_training_df-e811_l724-724_ep135_sig_198.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e811_l724-724_ep135_sig_198\\predictions-e811_l724-724_ep135_sig_198.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e811_l724-724_ep135_sig_198\\predictions-e811_l724-724_ep135_sig_198.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e811_l724-724_ep135_sig_198\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e811_l724-724_ep135_sig_198\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e811_l724-724_ep135_sig_198\\model\\assets\n",
      "[I 2026-01-13 12:36:40,130] Trial 20 finished with value: 0.7989805936813354 and parameters: {'learning_rate': 0.0052863653631451644, 'depth': 2, 'units': 724, 'embedding_dim': 811, 'epochs': 135}. Best is trial 5 with value: 0.8316614627838135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e811_l724-724_ep135_sig_198\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e811_l724-724_ep135_sig_198\n",
      "Creating dir: f:/exp/keras/optuna\\e747_l1410-1410_ep52_sig_430\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e747_l1410-1410_ep52_sig_430  \n",
      "run_experiment()  when: 2026-01-13 12:36:40.186789 params: {'epochs': 52, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 12:40:38.103875\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e747_l1410-1410_ep52_sig_430\\normalized_training_df-e747_l1410-1410_ep52_sig_430.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e747_l1410-1410_ep52_sig_430\\normalized_training_df-e747_l1410-1410_ep52_sig_430.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e747_l1410-1410_ep52_sig_430\\predictions-e747_l1410-1410_ep52_sig_430.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e747_l1410-1410_ep52_sig_430\\predictions-e747_l1410-1410_ep52_sig_430.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e747_l1410-1410_ep52_sig_430\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e747_l1410-1410_ep52_sig_430\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e747_l1410-1410_ep52_sig_430\\model\\assets\n",
      "[I 2026-01-13 12:41:47,190] Trial 21 finished with value: 0.7654329538345337 and parameters: {'learning_rate': 0.005572821994120146, 'depth': 2, 'units': 1410, 'embedding_dim': 747, 'epochs': 52}. Best is trial 5 with value: 0.8316614627838135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e747_l1410-1410_ep52_sig_430\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e747_l1410-1410_ep52_sig_430\n",
      "Creating dir: f:/exp/keras/optuna\\e1109_l1723_ep77_sig_559\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e1109_l1723_ep77_sig_559  \n",
      "run_experiment()  when: 2026-01-13 12:41:47.242656 params: {'epochs': 77, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 12:43:56.486855\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e1109_l1723_ep77_sig_559\\normalized_training_df-e1109_l1723_ep77_sig_559.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e1109_l1723_ep77_sig_559\\normalized_training_df-e1109_l1723_ep77_sig_559.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e1109_l1723_ep77_sig_559\\predictions-e1109_l1723_ep77_sig_559.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e1109_l1723_ep77_sig_559\\predictions-e1109_l1723_ep77_sig_559.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e1109_l1723_ep77_sig_559\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e1109_l1723_ep77_sig_559\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e1109_l1723_ep77_sig_559\\model\\assets\n",
      "[I 2026-01-13 12:45:04,745] Trial 22 finished with value: 0.8122656345367432 and parameters: {'learning_rate': 0.004927134128387647, 'depth': 1, 'units': 1723, 'embedding_dim': 1109, 'epochs': 77}. Best is trial 5 with value: 0.8316614627838135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e1109_l1723_ep77_sig_559\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e1109_l1723_ep77_sig_559\n",
      "Creating dir: f:/exp/keras/optuna\\e434_l1559-1559-1559-1559_ep89_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e434_l1559-1559-1559-1559_ep89_  \n",
      "run_experiment()  when: 2026-01-13 12:45:04.803237 params: {'epochs': 89, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 12:50:46.316157\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 8ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e434_l1559-1559-1559-1559_ep89_\\normalized_training_df-e434_l1559-1559-1559-1559_ep89_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e434_l1559-1559-1559-1559_ep89_\\normalized_training_df-e434_l1559-1559-1559-1559_ep89_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e434_l1559-1559-1559-1559_ep89_\\predictions-e434_l1559-1559-1559-1559_ep89_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e434_l1559-1559-1559-1559_ep89_\\predictions-e434_l1559-1559-1559-1559_ep89_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e434_l1559-1559-1559-1559_ep89_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e434_l1559-1559-1559-1559_ep89_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e434_l1559-1559-1559-1559_ep89_\\model\\assets\n",
      "[I 2026-01-13 12:51:54,737] Trial 23 finished with value: 0.5 and parameters: {'learning_rate': 0.006273834617423704, 'depth': 4, 'units': 1559, 'embedding_dim': 434, 'epochs': 89}. Best is trial 5 with value: 0.8316614627838135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e434_l1559-1559-1559-1559_ep89_\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e434_l1559-1559-1559-1559_ep89_\n",
      "Creating dir: f:/exp/keras/optuna\\e1040_l997-997_ep54_sig_181\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e1040_l997-997_ep54_sig_181  \n",
      "run_experiment()  when: 2026-01-13 12:51:54.789396 params: {'epochs': 54, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 12:54:01.934437\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e1040_l997-997_ep54_sig_181\\normalized_training_df-e1040_l997-997_ep54_sig_181.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e1040_l997-997_ep54_sig_181\\normalized_training_df-e1040_l997-997_ep54_sig_181.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e1040_l997-997_ep54_sig_181\\predictions-e1040_l997-997_ep54_sig_181.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e1040_l997-997_ep54_sig_181\\predictions-e1040_l997-997_ep54_sig_181.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e1040_l997-997_ep54_sig_181\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e1040_l997-997_ep54_sig_181\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e1040_l997-997_ep54_sig_181\\model\\assets\n",
      "[I 2026-01-13 12:55:10,543] Trial 24 finished with value: 0.8124730587005615 and parameters: {'learning_rate': 0.0035632003553178423, 'depth': 2, 'units': 997, 'embedding_dim': 1040, 'epochs': 54}. Best is trial 5 with value: 0.8316614627838135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e1040_l997-997_ep54_sig_181\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e1040_l997-997_ep54_sig_181\n",
      "Creating dir: f:/exp/keras/optuna\\e731_l1828-1828-1828-1828_ep104\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e731_l1828-1828-1828-1828_ep104  \n",
      "run_experiment()  when: 2026-01-13 12:55:10.596915 params: {'epochs': 104, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 13:07:49.199664\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 9ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e731_l1828-1828-1828-1828_ep104\\normalized_training_df-e731_l1828-1828-1828-1828_ep104.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e731_l1828-1828-1828-1828_ep104\\normalized_training_df-e731_l1828-1828-1828-1828_ep104.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e731_l1828-1828-1828-1828_ep104\\predictions-e731_l1828-1828-1828-1828_ep104.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e731_l1828-1828-1828-1828_ep104\\predictions-e731_l1828-1828-1828-1828_ep104.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e731_l1828-1828-1828-1828_ep104\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e731_l1828-1828-1828-1828_ep104\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e731_l1828-1828-1828-1828_ep104\\model\\assets\n",
      "[I 2026-01-13 13:08:58,757] Trial 25 finished with value: 0.5 and parameters: {'learning_rate': 0.00730573800464369, 'depth': 4, 'units': 1828, 'embedding_dim': 731, 'epochs': 104}. Best is trial 5 with value: 0.8316614627838135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e731_l1828-1828-1828-1828_ep104\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e731_l1828-1828-1828-1828_ep104\n",
      "Creating dir: f:/exp/keras/optuna\\e588_l1384_ep81_sig_186\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e588_l1384_ep81_sig_186  \n",
      "run_experiment()  when: 2026-01-13 13:08:58.810646 params: {'epochs': 81, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 13:10:50.142036\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e588_l1384_ep81_sig_186\\normalized_training_df-e588_l1384_ep81_sig_186.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e588_l1384_ep81_sig_186\\normalized_training_df-e588_l1384_ep81_sig_186.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e588_l1384_ep81_sig_186\\predictions-e588_l1384_ep81_sig_186.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e588_l1384_ep81_sig_186\\predictions-e588_l1384_ep81_sig_186.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e588_l1384_ep81_sig_186\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e588_l1384_ep81_sig_186\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e588_l1384_ep81_sig_186\\model\\assets\n",
      "[I 2026-01-13 13:11:59,343] Trial 26 finished with value: 0.7616412043571472 and parameters: {'learning_rate': 0.00577745675264098, 'depth': 1, 'units': 1384, 'embedding_dim': 588, 'epochs': 81}. Best is trial 5 with value: 0.8316614627838135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e588_l1384_ep81_sig_186\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e588_l1384_ep81_sig_186\n",
      "Creating dir: f:/exp/keras/optuna\\e471_l1260-1260-1260_ep131_sig_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e471_l1260-1260-1260_ep131_sig_  \n",
      "run_experiment()  when: 2026-01-13 13:11:59.393195 params: {'epochs': 131, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 13:16:57.743577\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e471_l1260-1260-1260_ep131_sig_\\normalized_training_df-e471_l1260-1260-1260_ep131_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e471_l1260-1260-1260_ep131_sig_\\normalized_training_df-e471_l1260-1260-1260_ep131_sig_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e471_l1260-1260-1260_ep131_sig_\\predictions-e471_l1260-1260-1260_ep131_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e471_l1260-1260-1260_ep131_sig_\\predictions-e471_l1260-1260-1260_ep131_sig_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e471_l1260-1260-1260_ep131_sig_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e471_l1260-1260-1260_ep131_sig_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e471_l1260-1260-1260_ep131_sig_\\model\\assets\n",
      "[I 2026-01-13 13:18:05,544] Trial 27 finished with value: 0.7566674947738647 and parameters: {'learning_rate': 0.0041851598259089445, 'depth': 3, 'units': 1260, 'embedding_dim': 471, 'epochs': 131}. Best is trial 5 with value: 0.8316614627838135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e471_l1260-1260-1260_ep131_sig_\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e471_l1260-1260-1260_ep131_sig_\n",
      "Creating dir: f:/exp/keras/optuna\\e1301_l1098-1098_ep44_sig_138\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e1301_l1098-1098_ep44_sig_138  \n",
      "run_experiment()  when: 2026-01-13 13:18:05.600924 params: {'epochs': 44, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 13:21:51.392613\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e1301_l1098-1098_ep44_sig_138\\normalized_training_df-e1301_l1098-1098_ep44_sig_138.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e1301_l1098-1098_ep44_sig_138\\normalized_training_df-e1301_l1098-1098_ep44_sig_138.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e1301_l1098-1098_ep44_sig_138\\predictions-e1301_l1098-1098_ep44_sig_138.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e1301_l1098-1098_ep44_sig_138\\predictions-e1301_l1098-1098_ep44_sig_138.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e1301_l1098-1098_ep44_sig_138\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e1301_l1098-1098_ep44_sig_138\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e1301_l1098-1098_ep44_sig_138\\model\\assets\n",
      "[I 2026-01-13 13:23:00,425] Trial 28 finished with value: 0.7843588590621948 and parameters: {'learning_rate': 0.004875866790503929, 'depth': 2, 'units': 1098, 'embedding_dim': 1301, 'epochs': 44}. Best is trial 5 with value: 0.8316614627838135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e1301_l1098-1098_ep44_sig_138\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e1301_l1098-1098_ep44_sig_138\n",
      "Creating dir: f:/exp/keras/optuna\\e803_l939-939-939_ep112_sig_110\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e803_l939-939-939_ep112_sig_110  \n",
      "run_experiment()  when: 2026-01-13 13:23:00.481037 params: {'epochs': 112, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 13:26:02.818313\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e803_l939-939-939_ep112_sig_110\\normalized_training_df-e803_l939-939-939_ep112_sig_110.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e803_l939-939-939_ep112_sig_110\\normalized_training_df-e803_l939-939-939_ep112_sig_110.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e803_l939-939-939_ep112_sig_110\\predictions-e803_l939-939-939_ep112_sig_110.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e803_l939-939-939_ep112_sig_110\\predictions-e803_l939-939-939_ep112_sig_110.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e803_l939-939-939_ep112_sig_110\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e803_l939-939-939_ep112_sig_110\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e803_l939-939-939_ep112_sig_110\\model\\assets\n",
      "[I 2026-01-13 13:27:11,599] Trial 29 finished with value: 0.5 and parameters: {'learning_rate': 0.008448826943801809, 'depth': 3, 'units': 939, 'embedding_dim': 803, 'epochs': 112}. Best is trial 5 with value: 0.8316614627838135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e803_l939-939-939_ep112_sig_110\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e803_l939-939-939_ep112_sig_110\n",
      "Creating dir: f:/exp/keras/optuna\\e674_l25-25_ep68_sig_151\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e674_l25-25_ep68_sig_151  \n",
      "run_experiment()  when: 2026-01-13 13:27:11.656211 params: {'epochs': 68, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 13:27:38.156780\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e674_l25-25_ep68_sig_151\\normalized_training_df-e674_l25-25_ep68_sig_151.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e674_l25-25_ep68_sig_151\\normalized_training_df-e674_l25-25_ep68_sig_151.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e674_l25-25_ep68_sig_151\\predictions-e674_l25-25_ep68_sig_151.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e674_l25-25_ep68_sig_151\\predictions-e674_l25-25_ep68_sig_151.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e674_l25-25_ep68_sig_151\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e674_l25-25_ep68_sig_151\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e674_l25-25_ep68_sig_151\\model\\assets\n",
      "[I 2026-01-13 13:28:46,265] Trial 30 finished with value: 0.8050388097763062 and parameters: {'learning_rate': 0.002872116167066764, 'depth': 2, 'units': 25, 'embedding_dim': 674, 'epochs': 68}. Best is trial 5 with value: 0.8316614627838135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e674_l25-25_ep68_sig_151\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e674_l25-25_ep68_sig_151\n",
      "Creating dir: f:/exp/keras/optuna\\e1035_l1034-1034_ep58_sig_732\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e1035_l1034-1034_ep58_sig_732  \n",
      "run_experiment()  when: 2026-01-13 13:28:46.318716 params: {'epochs': 58, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 13:31:16.876312\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e1035_l1034-1034_ep58_sig_732\\normalized_training_df-e1035_l1034-1034_ep58_sig_732.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e1035_l1034-1034_ep58_sig_732\\normalized_training_df-e1035_l1034-1034_ep58_sig_732.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e1035_l1034-1034_ep58_sig_732\\predictions-e1035_l1034-1034_ep58_sig_732.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e1035_l1034-1034_ep58_sig_732\\predictions-e1035_l1034-1034_ep58_sig_732.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e1035_l1034-1034_ep58_sig_732\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e1035_l1034-1034_ep58_sig_732\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e1035_l1034-1034_ep58_sig_732\\model\\assets\n",
      "[I 2026-01-13 13:32:25,382] Trial 31 finished with value: 0.8083187937736511 and parameters: {'learning_rate': 0.0037622656392782335, 'depth': 2, 'units': 1034, 'embedding_dim': 1035, 'epochs': 58}. Best is trial 5 with value: 0.8316614627838135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e1035_l1034-1034_ep58_sig_732\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e1035_l1034-1034_ep58_sig_732\n",
      "Creating dir: f:/exp/keras/optuna\\e976_l946_ep37_sig_100\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e976_l946_ep37_sig_100  \n",
      "run_experiment()  when: 2026-01-13 13:32:25.437203 params: {'epochs': 37, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 13:33:32.373316\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e976_l946_ep37_sig_100\\normalized_training_df-e976_l946_ep37_sig_100.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e976_l946_ep37_sig_100\\normalized_training_df-e976_l946_ep37_sig_100.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e976_l946_ep37_sig_100\\predictions-e976_l946_ep37_sig_100.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e976_l946_ep37_sig_100\\predictions-e976_l946_ep37_sig_100.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e976_l946_ep37_sig_100\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e976_l946_ep37_sig_100\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e976_l946_ep37_sig_100\\model\\assets\n",
      "[I 2026-01-13 13:34:40,767] Trial 32 finished with value: 0.8108422756195068 and parameters: {'learning_rate': 0.0036911350022768843, 'depth': 1, 'units': 946, 'embedding_dim': 976, 'epochs': 37}. Best is trial 5 with value: 0.8316614627838135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e976_l946_ep37_sig_100\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e976_l946_ep37_sig_100\n",
      "Creating dir: f:/exp/keras/optuna\\e873_l1330-1330-1330_ep52_sig_1\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e873_l1330-1330-1330_ep52_sig_1  \n",
      "run_experiment()  when: 2026-01-13 13:34:40.821582 params: {'epochs': 52, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 13:37:51.088952\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e873_l1330-1330-1330_ep52_sig_1\\normalized_training_df-e873_l1330-1330-1330_ep52_sig_1.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e873_l1330-1330-1330_ep52_sig_1\\normalized_training_df-e873_l1330-1330-1330_ep52_sig_1.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e873_l1330-1330-1330_ep52_sig_1\\predictions-e873_l1330-1330-1330_ep52_sig_1.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e873_l1330-1330-1330_ep52_sig_1\\predictions-e873_l1330-1330-1330_ep52_sig_1.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e873_l1330-1330-1330_ep52_sig_1\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e873_l1330-1330-1330_ep52_sig_1\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e873_l1330-1330-1330_ep52_sig_1\\model\\assets\n",
      "[I 2026-01-13 13:38:59,912] Trial 33 finished with value: 0.5 and parameters: {'learning_rate': 0.006199518105565093, 'depth': 3, 'units': 1330, 'embedding_dim': 873, 'epochs': 52}. Best is trial 5 with value: 0.8316614627838135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e873_l1330-1330-1330_ep52_sig_1\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e873_l1330-1330-1330_ep52_sig_1\n",
      "Creating dir: f:/exp/keras/optuna\\e442_l1521-1521_ep79_sig_223\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e442_l1521-1521_ep79_sig_223  \n",
      "run_experiment()  when: 2026-01-13 13:38:59.968716 params: {'epochs': 79, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 13:40:59.746524\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e442_l1521-1521_ep79_sig_223\\normalized_training_df-e442_l1521-1521_ep79_sig_223.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e442_l1521-1521_ep79_sig_223\\normalized_training_df-e442_l1521-1521_ep79_sig_223.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e442_l1521-1521_ep79_sig_223\\predictions-e442_l1521-1521_ep79_sig_223.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e442_l1521-1521_ep79_sig_223\\predictions-e442_l1521-1521_ep79_sig_223.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e442_l1521-1521_ep79_sig_223\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e442_l1521-1521_ep79_sig_223\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e442_l1521-1521_ep79_sig_223\\model\\assets\n",
      "[I 2026-01-13 13:42:08,667] Trial 34 finished with value: 0.8085629940032959 and parameters: {'learning_rate': 0.001983067552259951, 'depth': 2, 'units': 1521, 'embedding_dim': 442, 'epochs': 79}. Best is trial 5 with value: 0.8316614627838135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e442_l1521-1521_ep79_sig_223\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e442_l1521-1521_ep79_sig_223\n",
      "Creating dir: f:/exp/keras/optuna\\e1130_l823_ep30_sig_166\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e1130_l823_ep30_sig_166  \n",
      "run_experiment()  when: 2026-01-13 13:42:08.723658 params: {'epochs': 30, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 13:43:51.120102\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e1130_l823_ep30_sig_166\\normalized_training_df-e1130_l823_ep30_sig_166.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e1130_l823_ep30_sig_166\\normalized_training_df-e1130_l823_ep30_sig_166.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e1130_l823_ep30_sig_166\\predictions-e1130_l823_ep30_sig_166.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e1130_l823_ep30_sig_166\\predictions-e1130_l823_ep30_sig_166.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e1130_l823_ep30_sig_166\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e1130_l823_ep30_sig_166\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e1130_l823_ep30_sig_166\\model\\assets\n",
      "[I 2026-01-13 13:45:00,628] Trial 35 finished with value: 0.798865020275116 and parameters: {'learning_rate': 0.002198884018146526, 'depth': 1, 'units': 823, 'embedding_dim': 1130, 'epochs': 30}. Best is trial 5 with value: 0.8316614627838135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e1130_l823_ep30_sig_166\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e1130_l823_ep30_sig_166\n",
      "Creating dir: f:/exp/keras/optuna\\e1422_l657-657-657-657_ep71_sig\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e1422_l657-657-657-657_ep71_sig  \n",
      "run_experiment()  when: 2026-01-13 13:45:00.679073 params: {'epochs': 71, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 13:46:58.815376\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e1422_l657-657-657-657_ep71_sig\\normalized_training_df-e1422_l657-657-657-657_ep71_sig.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e1422_l657-657-657-657_ep71_sig\\normalized_training_df-e1422_l657-657-657-657_ep71_sig.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e1422_l657-657-657-657_ep71_sig\\predictions-e1422_l657-657-657-657_ep71_sig.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e1422_l657-657-657-657_ep71_sig\\predictions-e1422_l657-657-657-657_ep71_sig.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e1422_l657-657-657-657_ep71_sig\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e1422_l657-657-657-657_ep71_sig\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e1422_l657-657-657-657_ep71_sig\\model\\assets\n",
      "[I 2026-01-13 13:48:07,505] Trial 36 finished with value: 0.8050649762153625 and parameters: {'learning_rate': 0.0012781238040715393, 'depth': 4, 'units': 657, 'embedding_dim': 1422, 'epochs': 71}. Best is trial 5 with value: 0.8316614627838135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e1422_l657-657-657-657_ep71_sig\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e1422_l657-657-657-657_ep71_sig\n",
      "Creating dir: f:/exp/keras/optuna\\e748_l1094-1094-1094-1094-1094-\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e748_l1094-1094-1094-1094-1094-  \n",
      "run_experiment()  when: 2026-01-13 13:48:07.561459 params: {'epochs': 88, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 14:04:32.157648\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 12ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e748_l1094-1094-1094-1094-1094-\\normalized_training_df-e748_l1094-1094-1094-1094-1094-.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e748_l1094-1094-1094-1094-1094-\\normalized_training_df-e748_l1094-1094-1094-1094-1094-.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e748_l1094-1094-1094-1094-1094-\\predictions-e748_l1094-1094-1094-1094-1094-.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e748_l1094-1094-1094-1094-1094-\\predictions-e748_l1094-1094-1094-1094-1094-.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e748_l1094-1094-1094-1094-1094-\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e748_l1094-1094-1094-1094-1094-\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e748_l1094-1094-1094-1094-1094-\\model\\assets\n",
      "[I 2026-01-13 14:05:42,524] Trial 37 finished with value: 0.5 and parameters: {'learning_rate': 0.0069485572869005235, 'depth': 10, 'units': 1094, 'embedding_dim': 748, 'epochs': 88}. Best is trial 5 with value: 0.8316614627838135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e748_l1094-1094-1094-1094-1094-\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e748_l1094-1094-1094-1094-1094-\n",
      "Creating dir: f:/exp/keras/optuna\\e408_l1444-1444_ep59_sig_133\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e408_l1444-1444_ep59_sig_133  \n",
      "run_experiment()  when: 2026-01-13 14:05:42.580438 params: {'epochs': 59, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 14:07:31.875091\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e408_l1444-1444_ep59_sig_133\\normalized_training_df-e408_l1444-1444_ep59_sig_133.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e408_l1444-1444_ep59_sig_133\\normalized_training_df-e408_l1444-1444_ep59_sig_133.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e408_l1444-1444_ep59_sig_133\\predictions-e408_l1444-1444_ep59_sig_133.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e408_l1444-1444_ep59_sig_133\\predictions-e408_l1444-1444_ep59_sig_133.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e408_l1444-1444_ep59_sig_133\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e408_l1444-1444_ep59_sig_133\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e408_l1444-1444_ep59_sig_133\\model\\assets\n",
      "[I 2026-01-13 14:08:40,647] Trial 38 finished with value: 0.8060944080352783 and parameters: {'learning_rate': 0.0031444858501993916, 'depth': 2, 'units': 1444, 'embedding_dim': 408, 'epochs': 59}. Best is trial 5 with value: 0.8316614627838135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e408_l1444-1444_ep59_sig_133\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e408_l1444-1444_ep59_sig_133\n",
      "Creating dir: f:/exp/keras/optuna\\e1601_l1626-1626-1626-1626-1626\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e1601_l1626-1626-1626-1626-1626  \n",
      "run_experiment()  when: 2026-01-13 14:08:40.705285 params: {'epochs': 45, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 14:27:36.759026\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 18ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e1601_l1626-1626-1626-1626-1626\\normalized_training_df-e1601_l1626-1626-1626-1626-1626.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e1601_l1626-1626-1626-1626-1626\\normalized_training_df-e1601_l1626-1626-1626-1626-1626.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e1601_l1626-1626-1626-1626-1626\\predictions-e1601_l1626-1626-1626-1626-1626.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e1601_l1626-1626-1626-1626-1626\\predictions-e1601_l1626-1626-1626-1626-1626.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e1601_l1626-1626-1626-1626-1626\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e1601_l1626-1626-1626-1626-1626\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e1601_l1626-1626-1626-1626-1626\\model\\assets\n",
      "[I 2026-01-13 14:28:47,692] Trial 39 finished with value: 0.5 and parameters: {'learning_rate': 0.005094162067367119, 'depth': 9, 'units': 1626, 'embedding_dim': 1601, 'epochs': 45}. Best is trial 5 with value: 0.8316614627838135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e1601_l1626-1626-1626-1626-1626\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e1601_l1626-1626-1626-1626-1626\n",
      "Creating dir: f:/exp/keras/optuna\\e1249_l1162-1162-1162-1162-1162\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e1249_l1162-1162-1162-1162-1162  \n",
      "run_experiment()  when: 2026-01-13 14:28:47.751711 params: {'epochs': 142, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 14:38:30.747558\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 8ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e1249_l1162-1162-1162-1162-1162\\normalized_training_df-e1249_l1162-1162-1162-1162-1162.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e1249_l1162-1162-1162-1162-1162\\normalized_training_df-e1249_l1162-1162-1162-1162-1162.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e1249_l1162-1162-1162-1162-1162\\predictions-e1249_l1162-1162-1162-1162-1162.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e1249_l1162-1162-1162-1162-1162\\predictions-e1249_l1162-1162-1162-1162-1162.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e1249_l1162-1162-1162-1162-1162\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e1249_l1162-1162-1162-1162-1162\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e1249_l1162-1162-1162-1162-1162\\model\\assets\n",
      "[I 2026-01-13 14:39:39,927] Trial 40 finished with value: 0.5 and parameters: {'learning_rate': 0.005860905740513617, 'depth': 5, 'units': 1162, 'embedding_dim': 1249, 'epochs': 142}. Best is trial 5 with value: 0.8316614627838135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e1249_l1162-1162-1162-1162-1162\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e1249_l1162-1162-1162-1162-1162\n",
      "Creating dir: f:/exp/keras/optuna\\e1104_l1780_ep72_sig_226\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e1104_l1780_ep72_sig_226  \n",
      "run_experiment()  when: 2026-01-13 14:39:39.982812 params: {'epochs': 72, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 14:41:52.030433\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e1104_l1780_ep72_sig_226\\normalized_training_df-e1104_l1780_ep72_sig_226.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e1104_l1780_ep72_sig_226\\normalized_training_df-e1104_l1780_ep72_sig_226.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e1104_l1780_ep72_sig_226\\predictions-e1104_l1780_ep72_sig_226.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e1104_l1780_ep72_sig_226\\predictions-e1104_l1780_ep72_sig_226.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e1104_l1780_ep72_sig_226\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e1104_l1780_ep72_sig_226\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e1104_l1780_ep72_sig_226\\model\\assets\n",
      "[I 2026-01-13 14:43:01,261] Trial 41 finished with value: 0.7849812507629395 and parameters: {'learning_rate': 0.00473350291221599, 'depth': 1, 'units': 1780, 'embedding_dim': 1104, 'epochs': 72}. Best is trial 5 with value: 0.8316614627838135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e1104_l1780_ep72_sig_226\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e1104_l1780_ep72_sig_226\n",
      "Creating dir: f:/exp/keras/optuna\\e1023_l1656_ep79_sig_749\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e1023_l1656_ep79_sig_749  \n",
      "run_experiment()  when: 2026-01-13 14:43:01.326154 params: {'epochs': 79, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 14:45:57.885397\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e1023_l1656_ep79_sig_749\\normalized_training_df-e1023_l1656_ep79_sig_749.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e1023_l1656_ep79_sig_749\\normalized_training_df-e1023_l1656_ep79_sig_749.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e1023_l1656_ep79_sig_749\\predictions-e1023_l1656_ep79_sig_749.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e1023_l1656_ep79_sig_749\\predictions-e1023_l1656_ep79_sig_749.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e1023_l1656_ep79_sig_749\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e1023_l1656_ep79_sig_749\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e1023_l1656_ep79_sig_749\\model\\assets\n",
      "[I 2026-01-13 14:47:06,131] Trial 42 finished with value: 0.8200544118881226 and parameters: {'learning_rate': 0.004098660681053546, 'depth': 1, 'units': 1656, 'embedding_dim': 1023, 'epochs': 79}. Best is trial 5 with value: 0.8316614627838135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e1023_l1656_ep79_sig_749\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e1023_l1656_ep79_sig_749\n",
      "Creating dir: f:/exp/keras/optuna\\e1028_l1922_ep63_sig_433\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e1028_l1922_ep63_sig_433  \n",
      "run_experiment()  when: 2026-01-13 14:47:06.188980 params: {'epochs': 63, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 14:49:00.964721\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e1028_l1922_ep63_sig_433\\normalized_training_df-e1028_l1922_ep63_sig_433.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e1028_l1922_ep63_sig_433\\normalized_training_df-e1028_l1922_ep63_sig_433.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e1028_l1922_ep63_sig_433\\predictions-e1028_l1922_ep63_sig_433.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e1028_l1922_ep63_sig_433\\predictions-e1028_l1922_ep63_sig_433.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e1028_l1922_ep63_sig_433\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e1028_l1922_ep63_sig_433\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e1028_l1922_ep63_sig_433\\model\\assets\n",
      "[I 2026-01-13 14:50:09,970] Trial 43 finished with value: 0.8240537643432617 and parameters: {'learning_rate': 0.0040583066887537825, 'depth': 1, 'units': 1922, 'embedding_dim': 1028, 'epochs': 63}. Best is trial 5 with value: 0.8316614627838135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e1028_l1922_ep63_sig_433\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e1028_l1922_ep63_sig_433\n",
      "Creating dir: f:/exp/keras/optuna\\e913_l1957_ep97_sig_780\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e913_l1957_ep97_sig_780  \n",
      "run_experiment()  when: 2026-01-13 14:50:10.034847 params: {'epochs': 97, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 14:52:10.776059\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e913_l1957_ep97_sig_780\\normalized_training_df-e913_l1957_ep97_sig_780.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e913_l1957_ep97_sig_780\\normalized_training_df-e913_l1957_ep97_sig_780.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e913_l1957_ep97_sig_780\\predictions-e913_l1957_ep97_sig_780.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e913_l1957_ep97_sig_780\\predictions-e913_l1957_ep97_sig_780.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e913_l1957_ep97_sig_780\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e913_l1957_ep97_sig_780\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e913_l1957_ep97_sig_780\\model\\assets\n",
      "[I 2026-01-13 14:53:19,454] Trial 44 finished with value: 0.7931087017059326 and parameters: {'learning_rate': 0.004197068995480165, 'depth': 1, 'units': 1957, 'embedding_dim': 913, 'epochs': 97}. Best is trial 5 with value: 0.8316614627838135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e913_l1957_ep97_sig_780\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e913_l1957_ep97_sig_780\n",
      "Creating dir: f:/exp/keras/optuna\\e647_l1848_ep123_sig_116\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e647_l1848_ep123_sig_116  \n",
      "run_experiment()  when: 2026-01-13 14:53:19.508108 params: {'epochs': 123, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 14:54:43.305167\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e647_l1848_ep123_sig_116\\normalized_training_df-e647_l1848_ep123_sig_116.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e647_l1848_ep123_sig_116\\normalized_training_df-e647_l1848_ep123_sig_116.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e647_l1848_ep123_sig_116\\predictions-e647_l1848_ep123_sig_116.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e647_l1848_ep123_sig_116\\predictions-e647_l1848_ep123_sig_116.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e647_l1848_ep123_sig_116\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e647_l1848_ep123_sig_116\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e647_l1848_ep123_sig_116\\model\\assets\n",
      "[I 2026-01-13 14:55:52,806] Trial 45 finished with value: 0.8068219423294067 and parameters: {'learning_rate': 0.004382164631809196, 'depth': 1, 'units': 1848, 'embedding_dim': 647, 'epochs': 123}. Best is trial 5 with value: 0.8316614627838135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e647_l1848_ep123_sig_116\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e647_l1848_ep123_sig_116\n",
      "Creating dir: f:/exp/keras/optuna\\e834_l1605_ep64_sig_199\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e834_l1605_ep64_sig_199  \n",
      "run_experiment()  when: 2026-01-13 14:55:52.865583 params: {'epochs': 64, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 14:57:03.154287\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e834_l1605_ep64_sig_199\\normalized_training_df-e834_l1605_ep64_sig_199.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e834_l1605_ep64_sig_199\\normalized_training_df-e834_l1605_ep64_sig_199.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e834_l1605_ep64_sig_199\\predictions-e834_l1605_ep64_sig_199.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e834_l1605_ep64_sig_199\\predictions-e834_l1605_ep64_sig_199.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e834_l1605_ep64_sig_199\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e834_l1605_ep64_sig_199\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e834_l1605_ep64_sig_199\\model\\assets\n",
      "[I 2026-01-13 14:58:12,047] Trial 46 finished with value: 0.8136337995529175 and parameters: {'learning_rate': 0.005948473322792334, 'depth': 1, 'units': 1605, 'embedding_dim': 834, 'epochs': 64}. Best is trial 5 with value: 0.8316614627838135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e834_l1605_ep64_sig_199\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e834_l1605_ep64_sig_199\n",
      "Creating dir: f:/exp/keras/optuna\\e1203_l1938-1938-1938-1938-1938\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e1203_l1938-1938-1938-1938-1938  \n",
      "run_experiment()  when: 2026-01-13 14:58:12.107302 params: {'epochs': 87, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 15:18:57.928675\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 14ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e1203_l1938-1938-1938-1938-1938\\normalized_training_df-e1203_l1938-1938-1938-1938-1938.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e1203_l1938-1938-1938-1938-1938\\normalized_training_df-e1203_l1938-1938-1938-1938-1938.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e1203_l1938-1938-1938-1938-1938\\predictions-e1203_l1938-1938-1938-1938-1938.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e1203_l1938-1938-1938-1938-1938\\predictions-e1203_l1938-1938-1938-1938-1938.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e1203_l1938-1938-1938-1938-1938\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e1203_l1938-1938-1938-1938-1938\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e1203_l1938-1938-1938-1938-1938\\model\\assets\n",
      "[I 2026-01-13 15:20:07,584] Trial 47 finished with value: 0.7928856015205383 and parameters: {'learning_rate': 0.0027066093813071504, 'depth': 6, 'units': 1938, 'embedding_dim': 1203, 'epochs': 87}. Best is trial 5 with value: 0.8316614627838135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e1203_l1938-1938-1938-1938-1938\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e1203_l1938-1938-1938-1938-1938\n",
      "Creating dir: f:/exp/keras/optuna\\e1407_l1706-1706-1706_ep107_sig\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e1407_l1706-1706-1706_ep107_sig  \n",
      "run_experiment()  when: 2026-01-13 15:20:07.643913 params: {'epochs': 107, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 15:25:30.309735\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 8ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e1407_l1706-1706-1706_ep107_sig\\normalized_training_df-e1407_l1706-1706-1706_ep107_sig.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e1407_l1706-1706-1706_ep107_sig\\normalized_training_df-e1407_l1706-1706-1706_ep107_sig.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e1407_l1706-1706-1706_ep107_sig\\predictions-e1407_l1706-1706-1706_ep107_sig.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e1407_l1706-1706-1706_ep107_sig\\predictions-e1407_l1706-1706-1706_ep107_sig.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e1407_l1706-1706-1706_ep107_sig\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e1407_l1706-1706-1706_ep107_sig\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e1407_l1706-1706-1706_ep107_sig\\model\\assets\n",
      "[I 2026-01-13 15:26:40,187] Trial 48 finished with value: 0.505666971206665 and parameters: {'learning_rate': 0.0066341028639053945, 'depth': 3, 'units': 1706, 'embedding_dim': 1407, 'epochs': 107}. Best is trial 5 with value: 0.8316614627838135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e1407_l1706-1706-1706_ep107_sig\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e1407_l1706-1706-1706_ep107_sig\n",
      "Creating dir: f:/exp/keras/optuna\\e951_l1270_ep95_sig_566\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e951_l1270_ep95_sig_566  \n",
      "run_experiment()  when: 2026-01-13 15:26:40.246606 params: {'epochs': 95, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 15:28:00.535248\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e951_l1270_ep95_sig_566\\normalized_training_df-e951_l1270_ep95_sig_566.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e951_l1270_ep95_sig_566\\normalized_training_df-e951_l1270_ep95_sig_566.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e951_l1270_ep95_sig_566\\predictions-e951_l1270_ep95_sig_566.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e951_l1270_ep95_sig_566\\predictions-e951_l1270_ep95_sig_566.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e951_l1270_ep95_sig_566\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e951_l1270_ep95_sig_566\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e951_l1270_ep95_sig_566\\model\\assets\n",
      "[I 2026-01-13 15:29:09,529] Trial 49 finished with value: 0.7833032608032227 and parameters: {'learning_rate': 0.005315183081050883, 'depth': 1, 'units': 1270, 'embedding_dim': 951, 'epochs': 95}. Best is trial 5 with value: 0.8316614627838135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e951_l1270_ep95_sig_566\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e951_l1270_ep95_sig_566\n",
      "Creating dir: f:/exp/keras/optuna\\e367_l1482-1482_ep76_sig_135\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e367_l1482-1482_ep76_sig_135  \n",
      "run_experiment()  when: 2026-01-13 15:29:09.587843 params: {'epochs': 76, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 15:31:17.510969\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e367_l1482-1482_ep76_sig_135\\normalized_training_df-e367_l1482-1482_ep76_sig_135.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e367_l1482-1482_ep76_sig_135\\normalized_training_df-e367_l1482-1482_ep76_sig_135.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e367_l1482-1482_ep76_sig_135\\predictions-e367_l1482-1482_ep76_sig_135.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e367_l1482-1482_ep76_sig_135\\predictions-e367_l1482-1482_ep76_sig_135.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e367_l1482-1482_ep76_sig_135\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e367_l1482-1482_ep76_sig_135\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e367_l1482-1482_ep76_sig_135\\model\\assets\n",
      "[I 2026-01-13 15:32:26,986] Trial 50 finished with value: 0.816062867641449 and parameters: {'learning_rate': 0.003903993221143158, 'depth': 2, 'units': 1482, 'embedding_dim': 367, 'epochs': 76}. Best is trial 5 with value: 0.8316614627838135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e367_l1482-1482_ep76_sig_135\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e367_l1482-1482_ep76_sig_135\n",
      "Creating dir: f:/exp/keras/optuna\\e377_l1483-1483_ep82_sig_106\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e377_l1483-1483_ep82_sig_106  \n",
      "run_experiment()  when: 2026-01-13 15:32:27.047083 params: {'epochs': 82, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 15:34:56.253156\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e377_l1483-1483_ep82_sig_106\\normalized_training_df-e377_l1483-1483_ep82_sig_106.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e377_l1483-1483_ep82_sig_106\\normalized_training_df-e377_l1483-1483_ep82_sig_106.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e377_l1483-1483_ep82_sig_106\\predictions-e377_l1483-1483_ep82_sig_106.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e377_l1483-1483_ep82_sig_106\\predictions-e377_l1483-1483_ep82_sig_106.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e377_l1483-1483_ep82_sig_106\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e377_l1483-1483_ep82_sig_106\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e377_l1483-1483_ep82_sig_106\\model\\assets\n",
      "[I 2026-01-13 15:36:05,625] Trial 51 finished with value: 0.8371865749359131 and parameters: {'learning_rate': 0.0041256128656937605, 'depth': 2, 'units': 1483, 'embedding_dim': 377, 'epochs': 82}. Best is trial 51 with value: 0.8371865749359131.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e377_l1483-1483_ep82_sig_106\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e377_l1483-1483_ep82_sig_106\n",
      "Creating dir: f:/exp/keras/optuna\\e553_l1560_ep64_sig_158\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e553_l1560_ep64_sig_158  \n",
      "run_experiment()  when: 2026-01-13 15:36:05.686311 params: {'epochs': 64, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 15:36:53.903680\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e553_l1560_ep64_sig_158\\normalized_training_df-e553_l1560_ep64_sig_158.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e553_l1560_ep64_sig_158\\normalized_training_df-e553_l1560_ep64_sig_158.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e553_l1560_ep64_sig_158\\predictions-e553_l1560_ep64_sig_158.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e553_l1560_ep64_sig_158\\predictions-e553_l1560_ep64_sig_158.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e553_l1560_ep64_sig_158\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e553_l1560_ep64_sig_158\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e553_l1560_ep64_sig_158\\model\\assets\n",
      "[I 2026-01-13 15:38:03,231] Trial 52 finished with value: 0.7866250872612 and parameters: {'learning_rate': 0.004693056013805194, 'depth': 1, 'units': 1560, 'embedding_dim': 553, 'epochs': 64}. Best is trial 51 with value: 0.8371865749359131.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e553_l1560_ep64_sig_158\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e553_l1560_ep64_sig_158\n",
      "Creating dir: f:/exp/keras/optuna\\e509_l1856-1856_ep82_sig_680\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e509_l1856-1856_ep82_sig_680  \n",
      "run_experiment()  when: 2026-01-13 15:38:03.295305 params: {'epochs': 82, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 15:41:30.771519\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e509_l1856-1856_ep82_sig_680\\normalized_training_df-e509_l1856-1856_ep82_sig_680.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e509_l1856-1856_ep82_sig_680\\normalized_training_df-e509_l1856-1856_ep82_sig_680.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e509_l1856-1856_ep82_sig_680\\predictions-e509_l1856-1856_ep82_sig_680.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e509_l1856-1856_ep82_sig_680\\predictions-e509_l1856-1856_ep82_sig_680.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e509_l1856-1856_ep82_sig_680\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e509_l1856-1856_ep82_sig_680\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e509_l1856-1856_ep82_sig_680\\model\\assets\n",
      "[I 2026-01-13 15:42:39,727] Trial 53 finished with value: 0.7922001481056213 and parameters: {'learning_rate': 0.0031754846192840647, 'depth': 2, 'units': 1856, 'embedding_dim': 509, 'epochs': 82}. Best is trial 51 with value: 0.8371865749359131.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e509_l1856-1856_ep82_sig_680\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e509_l1856-1856_ep82_sig_680\n",
      "Creating dir: f:/exp/keras/optuna\\e308_l1331-1331-1331_ep91_sig_1\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e308_l1331-1331-1331_ep91_sig_1  \n",
      "run_experiment()  when: 2026-01-13 15:42:39.786871 params: {'epochs': 91, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 15:46:49.533864\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e308_l1331-1331-1331_ep91_sig_1\\normalized_training_df-e308_l1331-1331-1331_ep91_sig_1.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e308_l1331-1331-1331_ep91_sig_1\\normalized_training_df-e308_l1331-1331-1331_ep91_sig_1.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e308_l1331-1331-1331_ep91_sig_1\\predictions-e308_l1331-1331-1331_ep91_sig_1.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e308_l1331-1331-1331_ep91_sig_1\\predictions-e308_l1331-1331-1331_ep91_sig_1.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e308_l1331-1331-1331_ep91_sig_1\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e308_l1331-1331-1331_ep91_sig_1\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e308_l1331-1331-1331_ep91_sig_1\\model\\assets\n",
      "[I 2026-01-13 15:47:58,259] Trial 54 finished with value: 0.784172534942627 and parameters: {'learning_rate': 0.0045556058714904665, 'depth': 3, 'units': 1331, 'embedding_dim': 308, 'epochs': 91}. Best is trial 51 with value: 0.8371865749359131.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e308_l1331-1331-1331_ep91_sig_1\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e308_l1331-1331-1331_ep91_sig_1\n",
      "Creating dir: f:/exp/keras/optuna\\e2037_l1698_ep10_sig_729\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e2037_l1698_ep10_sig_729  \n",
      "run_experiment()  when: 2026-01-13 15:47:58.317474 params: {'epochs': 10, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 15:52:33.764832\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e2037_l1698_ep10_sig_729\\normalized_training_df-e2037_l1698_ep10_sig_729.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e2037_l1698_ep10_sig_729\\normalized_training_df-e2037_l1698_ep10_sig_729.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e2037_l1698_ep10_sig_729\\predictions-e2037_l1698_ep10_sig_729.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e2037_l1698_ep10_sig_729\\predictions-e2037_l1698_ep10_sig_729.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e2037_l1698_ep10_sig_729\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e2037_l1698_ep10_sig_729\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e2037_l1698_ep10_sig_729\\model\\assets\n",
      "[I 2026-01-13 15:53:38,430] Trial 55 finished with value: 0.7972132563591003 and parameters: {'learning_rate': 0.003949751223631058, 'depth': 1, 'units': 1698, 'embedding_dim': 2037, 'epochs': 10}. Best is trial 51 with value: 0.8371865749359131.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e2037_l1698_ep10_sig_729\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e2037_l1698_ep10_sig_729\n",
      "Creating dir: f:/exp/keras/optuna\\e720_l1426-1426_ep83_sig_109\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e720_l1426-1426_ep83_sig_109  \n",
      "run_experiment()  when: 2026-01-13 15:53:38.473963 params: {'epochs': 83, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 15:56:41.435326\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e720_l1426-1426_ep83_sig_109\\normalized_training_df-e720_l1426-1426_ep83_sig_109.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e720_l1426-1426_ep83_sig_109\\normalized_training_df-e720_l1426-1426_ep83_sig_109.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e720_l1426-1426_ep83_sig_109\\predictions-e720_l1426-1426_ep83_sig_109.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e720_l1426-1426_ep83_sig_109\\predictions-e720_l1426-1426_ep83_sig_109.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e720_l1426-1426_ep83_sig_109\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e720_l1426-1426_ep83_sig_109\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e720_l1426-1426_ep83_sig_109\\model\\assets\n",
      "[I 2026-01-13 15:57:45,852] Trial 56 finished with value: 0.7866067290306091 and parameters: {'learning_rate': 0.005322606079647043, 'depth': 2, 'units': 1426, 'embedding_dim': 720, 'epochs': 83}. Best is trial 51 with value: 0.8371865749359131.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e720_l1426-1426_ep83_sig_109\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e720_l1426-1426_ep83_sig_109\n",
      "Creating dir: f:/exp/keras/optuna\\e581_l1616-1616-1616-1616-1616-\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e581_l1616-1616-1616-1616-1616-  \n",
      "run_experiment()  when: 2026-01-13 15:57:45.922422 params: {'epochs': 75, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 16:21:18.621475\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 15ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e581_l1616-1616-1616-1616-1616-\\normalized_training_df-e581_l1616-1616-1616-1616-1616-.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e581_l1616-1616-1616-1616-1616-\\normalized_training_df-e581_l1616-1616-1616-1616-1616-.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e581_l1616-1616-1616-1616-1616-\\predictions-e581_l1616-1616-1616-1616-1616-.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e581_l1616-1616-1616-1616-1616-\\predictions-e581_l1616-1616-1616-1616-1616-.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e581_l1616-1616-1616-1616-1616-\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e581_l1616-1616-1616-1616-1616-\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e581_l1616-1616-1616-1616-1616-\\model\\assets\n",
      "[I 2026-01-13 16:22:40,417] Trial 57 finished with value: 0.5 and parameters: {'learning_rate': 0.0050607973034121805, 'depth': 8, 'units': 1616, 'embedding_dim': 581, 'epochs': 75}. Best is trial 51 with value: 0.8371865749359131.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e581_l1616-1616-1616-1616-1616-\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e581_l1616-1616-1616-1616-1616-\n",
      "Creating dir: f:/exp/keras/optuna\\e368_l2039_ep120_sig_111\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e368_l2039_ep120_sig_111  \n",
      "run_experiment()  when: 2026-01-13 16:22:40.485385 params: {'epochs': 120, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 16:23:41.266206\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e368_l2039_ep120_sig_111\\normalized_training_df-e368_l2039_ep120_sig_111.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e368_l2039_ep120_sig_111\\normalized_training_df-e368_l2039_ep120_sig_111.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e368_l2039_ep120_sig_111\\predictions-e368_l2039_ep120_sig_111.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e368_l2039_ep120_sig_111\\predictions-e368_l2039_ep120_sig_111.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e368_l2039_ep120_sig_111\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e368_l2039_ep120_sig_111\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e368_l2039_ep120_sig_111\\model\\assets\n",
      "[I 2026-01-13 16:25:04,123] Trial 58 finished with value: 0.7780117988586426 and parameters: {'learning_rate': 0.0033300119513919265, 'depth': 1, 'units': 2039, 'embedding_dim': 368, 'epochs': 120}. Best is trial 51 with value: 0.8371865749359131.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e368_l2039_ep120_sig_111\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e368_l2039_ep120_sig_111\n",
      "Creating dir: f:/exp/keras/optuna\\e494_l1186-1186_ep59_sig_439\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e494_l1186-1186_ep59_sig_439  \n",
      "run_experiment()  when: 2026-01-13 16:25:04.190694 params: {'epochs': 59, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 16:26:45.652220\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e494_l1186-1186_ep59_sig_439\\normalized_training_df-e494_l1186-1186_ep59_sig_439.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e494_l1186-1186_ep59_sig_439\\normalized_training_df-e494_l1186-1186_ep59_sig_439.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e494_l1186-1186_ep59_sig_439\\predictions-e494_l1186-1186_ep59_sig_439.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e494_l1186-1186_ep59_sig_439\\predictions-e494_l1186-1186_ep59_sig_439.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e494_l1186-1186_ep59_sig_439\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e494_l1186-1186_ep59_sig_439\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e494_l1186-1186_ep59_sig_439\\model\\assets\n",
      "[I 2026-01-13 16:28:11,857] Trial 59 finished with value: 0.8113123178482056 and parameters: {'learning_rate': 0.005573799359772881, 'depth': 2, 'units': 1186, 'embedding_dim': 494, 'epochs': 59}. Best is trial 51 with value: 0.8371865749359131.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e494_l1186-1186_ep59_sig_439\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e494_l1186-1186_ep59_sig_439\n",
      "Creating dir: f:/exp/keras/optuna\\e1024_l1929-1929-1929_ep68_sig_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e1024_l1929-1929-1929_ep68_sig_  \n",
      "run_experiment()  when: 2026-01-13 16:28:11.921937 params: {'epochs': 68, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 16:37:24.467622\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 14ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e1024_l1929-1929-1929_ep68_sig_\\normalized_training_df-e1024_l1929-1929-1929_ep68_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e1024_l1929-1929-1929_ep68_sig_\\normalized_training_df-e1024_l1929-1929-1929_ep68_sig_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e1024_l1929-1929-1929_ep68_sig_\\predictions-e1024_l1929-1929-1929_ep68_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e1024_l1929-1929-1929_ep68_sig_\\predictions-e1024_l1929-1929-1929_ep68_sig_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e1024_l1929-1929-1929_ep68_sig_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e1024_l1929-1929-1929_ep68_sig_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e1024_l1929-1929-1929_ep68_sig_\\model\\assets\n",
      "[I 2026-01-13 16:39:02,506] Trial 60 finished with value: 0.7993192672729492 and parameters: {'learning_rate': 0.004055503247274989, 'depth': 3, 'units': 1929, 'embedding_dim': 1024, 'epochs': 68}. Best is trial 51 with value: 0.8371865749359131.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e1024_l1929-1929-1929_ep68_sig_\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e1024_l1929-1929-1929_ep68_sig_\n",
      "Creating dir: f:/exp/keras/optuna\\e357_l1455-1455_ep76_sig_130\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e357_l1455-1455_ep76_sig_130  \n",
      "run_experiment()  when: 2026-01-13 16:39:02.569392 params: {'epochs': 76, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 16:42:17.010885\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e357_l1455-1455_ep76_sig_130\\normalized_training_df-e357_l1455-1455_ep76_sig_130.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e357_l1455-1455_ep76_sig_130\\normalized_training_df-e357_l1455-1455_ep76_sig_130.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e357_l1455-1455_ep76_sig_130\\predictions-e357_l1455-1455_ep76_sig_130.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e357_l1455-1455_ep76_sig_130\\predictions-e357_l1455-1455_ep76_sig_130.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e357_l1455-1455_ep76_sig_130\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e357_l1455-1455_ep76_sig_130\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e357_l1455-1455_ep76_sig_130\\model\\assets\n",
      "[I 2026-01-13 16:43:56,671] Trial 61 finished with value: 0.8044269680976868 and parameters: {'learning_rate': 0.0038566170560491615, 'depth': 2, 'units': 1455, 'embedding_dim': 357, 'epochs': 76}. Best is trial 51 with value: 0.8371865749359131.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e357_l1455-1455_ep76_sig_130\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e357_l1455-1455_ep76_sig_130\n",
      "Creating dir: f:/exp/keras/optuna\\e380_l1484-1484_ep94_sig_169\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e380_l1484-1484_ep94_sig_169  \n",
      "run_experiment()  when: 2026-01-13 16:43:56.734953 params: {'epochs': 94, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 16:46:08.072046\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e380_l1484-1484_ep94_sig_169\\normalized_training_df-e380_l1484-1484_ep94_sig_169.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e380_l1484-1484_ep94_sig_169\\normalized_training_df-e380_l1484-1484_ep94_sig_169.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e380_l1484-1484_ep94_sig_169\\predictions-e380_l1484-1484_ep94_sig_169.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e380_l1484-1484_ep94_sig_169\\predictions-e380_l1484-1484_ep94_sig_169.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e380_l1484-1484_ep94_sig_169\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e380_l1484-1484_ep94_sig_169\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e380_l1484-1484_ep94_sig_169\\model\\assets\n",
      "[I 2026-01-13 16:47:34,007] Trial 62 finished with value: 0.8041380643844604 and parameters: {'learning_rate': 0.004352608924623699, 'depth': 2, 'units': 1484, 'embedding_dim': 380, 'epochs': 94}. Best is trial 51 with value: 0.8371865749359131.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e380_l1484-1484_ep94_sig_169\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e380_l1484-1484_ep94_sig_169\n",
      "Creating dir: f:/exp/keras/optuna\\e637_l1306_ep84_sig_158\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e637_l1306_ep84_sig_158  \n",
      "run_experiment()  when: 2026-01-13 16:47:34.069660 params: {'epochs': 84, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 16:49:20.865781\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e637_l1306_ep84_sig_158\\normalized_training_df-e637_l1306_ep84_sig_158.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e637_l1306_ep84_sig_158\\normalized_training_df-e637_l1306_ep84_sig_158.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e637_l1306_ep84_sig_158\\predictions-e637_l1306_ep84_sig_158.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e637_l1306_ep84_sig_158\\predictions-e637_l1306_ep84_sig_158.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e637_l1306_ep84_sig_158\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e637_l1306_ep84_sig_158\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e637_l1306_ep84_sig_158\\model\\assets\n",
      "[I 2026-01-13 16:50:32,954] Trial 63 finished with value: 0.7809870839118958 and parameters: {'learning_rate': 0.00464820038488706, 'depth': 1, 'units': 1306, 'embedding_dim': 637, 'epochs': 84}. Best is trial 51 with value: 0.8371865749359131.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e637_l1306_ep84_sig_158\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e637_l1306_ep84_sig_158\n",
      "Creating dir: f:/exp/keras/optuna\\e457_l1536_ep129_sig_462\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e457_l1536_ep129_sig_462  \n",
      "run_experiment()  when: 2026-01-13 16:50:33.021078 params: {'epochs': 129, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 16:51:18.886765\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e457_l1536_ep129_sig_462\\normalized_training_df-e457_l1536_ep129_sig_462.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e457_l1536_ep129_sig_462\\normalized_training_df-e457_l1536_ep129_sig_462.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e457_l1536_ep129_sig_462\\predictions-e457_l1536_ep129_sig_462.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e457_l1536_ep129_sig_462\\predictions-e457_l1536_ep129_sig_462.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e457_l1536_ep129_sig_462\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e457_l1536_ep129_sig_462\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e457_l1536_ep129_sig_462\\model\\assets\n",
      "[I 2026-01-13 16:52:31,146] Trial 64 finished with value: 0.8140329718589783 and parameters: {'learning_rate': 0.009908525518377276, 'depth': 1, 'units': 1536, 'embedding_dim': 457, 'epochs': 129}. Best is trial 51 with value: 0.8371865749359131.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e457_l1536_ep129_sig_462\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e457_l1536_ep129_sig_462\n",
      "Creating dir: f:/exp/keras/optuna\\e787_l1770-1770_ep103_sig_481\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e787_l1770-1770_ep103_sig_481  \n",
      "run_experiment()  when: 2026-01-13 16:52:31.209823 params: {'epochs': 103, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 16:57:08.513932\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e787_l1770-1770_ep103_sig_481\\normalized_training_df-e787_l1770-1770_ep103_sig_481.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e787_l1770-1770_ep103_sig_481\\normalized_training_df-e787_l1770-1770_ep103_sig_481.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e787_l1770-1770_ep103_sig_481\\predictions-e787_l1770-1770_ep103_sig_481.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e787_l1770-1770_ep103_sig_481\\predictions-e787_l1770-1770_ep103_sig_481.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e787_l1770-1770_ep103_sig_481\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e787_l1770-1770_ep103_sig_481\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e787_l1770-1770_ep103_sig_481\\model\\assets\n",
      "[I 2026-01-13 16:58:18,350] Trial 65 finished with value: 0.8016144037246704 and parameters: {'learning_rate': 0.0034197405667998485, 'depth': 2, 'units': 1770, 'embedding_dim': 787, 'epochs': 103}. Best is trial 51 with value: 0.8371865749359131.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e787_l1770-1770_ep103_sig_481\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e787_l1770-1770_ep103_sig_481\n",
      "Creating dir: f:/exp/keras/optuna\\e679_l1379-1379_ep76_sig_977\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e679_l1379-1379_ep76_sig_977  \n",
      "run_experiment()  when: 2026-01-13 16:58:18.423982 params: {'epochs': 76, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 17:00:39.523684\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e679_l1379-1379_ep76_sig_977\\normalized_training_df-e679_l1379-1379_ep76_sig_977.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e679_l1379-1379_ep76_sig_977\\normalized_training_df-e679_l1379-1379_ep76_sig_977.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e679_l1379-1379_ep76_sig_977\\predictions-e679_l1379-1379_ep76_sig_977.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e679_l1379-1379_ep76_sig_977\\predictions-e679_l1379-1379_ep76_sig_977.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e679_l1379-1379_ep76_sig_977\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e679_l1379-1379_ep76_sig_977\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e679_l1379-1379_ep76_sig_977\\model\\assets\n",
      "[I 2026-01-13 17:01:49,758] Trial 66 finished with value: 0.8074310421943665 and parameters: {'learning_rate': 0.0029429495047078947, 'depth': 2, 'units': 1379, 'embedding_dim': 679, 'epochs': 76}. Best is trial 51 with value: 0.8371865749359131.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e679_l1379-1379_ep76_sig_977\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e679_l1379-1379_ep76_sig_977\n",
      "Creating dir: f:/exp/keras/optuna\\e557_l1669-1669-1669_ep49_sig_1\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e557_l1669-1669-1669_ep49_sig_1  \n",
      "run_experiment()  when: 2026-01-13 17:01:49.816732 params: {'epochs': 49, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 17:07:09.393834\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e557_l1669-1669-1669_ep49_sig_1\\normalized_training_df-e557_l1669-1669-1669_ep49_sig_1.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e557_l1669-1669-1669_ep49_sig_1\\normalized_training_df-e557_l1669-1669-1669_ep49_sig_1.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e557_l1669-1669-1669_ep49_sig_1\\predictions-e557_l1669-1669-1669_ep49_sig_1.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e557_l1669-1669-1669_ep49_sig_1\\predictions-e557_l1669-1669-1669_ep49_sig_1.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e557_l1669-1669-1669_ep49_sig_1\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e557_l1669-1669-1669_ep49_sig_1\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e557_l1669-1669-1669_ep49_sig_1\\model\\assets\n",
      "[I 2026-01-13 17:08:37,397] Trial 67 finished with value: 0.8016356229782104 and parameters: {'learning_rate': 0.002477455344187406, 'depth': 3, 'units': 1669, 'embedding_dim': 557, 'epochs': 49}. Best is trial 51 with value: 0.8371865749359131.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e557_l1669-1669-1669_ep49_sig_1\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e557_l1669-1669-1669_ep49_sig_1\n",
      "Creating dir: f:/exp/keras/optuna\\e864_l1246_ep64_sig_103\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e864_l1246_ep64_sig_103  \n",
      "run_experiment()  when: 2026-01-13 17:08:37.449205 params: {'epochs': 64, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 17:09:37.018511\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e864_l1246_ep64_sig_103\\normalized_training_df-e864_l1246_ep64_sig_103.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e864_l1246_ep64_sig_103\\normalized_training_df-e864_l1246_ep64_sig_103.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e864_l1246_ep64_sig_103\\predictions-e864_l1246_ep64_sig_103.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e864_l1246_ep64_sig_103\\predictions-e864_l1246_ep64_sig_103.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e864_l1246_ep64_sig_103\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e864_l1246_ep64_sig_103\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e864_l1246_ep64_sig_103\\model\\assets\n",
      "[I 2026-01-13 17:10:46,152] Trial 68 finished with value: 0.7863099575042725 and parameters: {'learning_rate': 0.0050169237894829586, 'depth': 1, 'units': 1246, 'embedding_dim': 864, 'epochs': 64}. Best is trial 51 with value: 0.8371865749359131.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e864_l1246_ep64_sig_103\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e864_l1246_ep64_sig_103\n",
      "Creating dir: f:/exp/keras/optuna\\e606_l1564-1564-1564-1564_ep110\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e606_l1564-1564-1564-1564_ep110  \n",
      "run_experiment()  when: 2026-01-13 17:10:46.202908 params: {'epochs': 110, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 17:20:02.234333\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 7ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e606_l1564-1564-1564-1564_ep110\\normalized_training_df-e606_l1564-1564-1564-1564_ep110.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e606_l1564-1564-1564-1564_ep110\\normalized_training_df-e606_l1564-1564-1564-1564_ep110.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e606_l1564-1564-1564-1564_ep110\\predictions-e606_l1564-1564-1564-1564_ep110.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e606_l1564-1564-1564-1564_ep110\\predictions-e606_l1564-1564-1564-1564_ep110.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e606_l1564-1564-1564-1564_ep110\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e606_l1564-1564-1564-1564_ep110\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e606_l1564-1564-1564-1564_ep110\\model\\assets\n",
      "[I 2026-01-13 17:21:08,858] Trial 69 finished with value: 0.7845321297645569 and parameters: {'learning_rate': 0.0036599584823792095, 'depth': 4, 'units': 1564, 'embedding_dim': 606, 'epochs': 110}. Best is trial 51 with value: 0.8371865749359131.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e606_l1564-1564-1564-1564_ep110\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e606_l1564-1564-1564-1564_ep110\n",
      "Creating dir: f:/exp/keras/optuna\\e420_l1490-1490_ep56_sig_210\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e420_l1490-1490_ep56_sig_210  \n",
      "run_experiment()  when: 2026-01-13 17:21:08.912996 params: {'epochs': 56, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 17:22:49.294277\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e420_l1490-1490_ep56_sig_210\\normalized_training_df-e420_l1490-1490_ep56_sig_210.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e420_l1490-1490_ep56_sig_210\\normalized_training_df-e420_l1490-1490_ep56_sig_210.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e420_l1490-1490_ep56_sig_210\\predictions-e420_l1490-1490_ep56_sig_210.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e420_l1490-1490_ep56_sig_210\\predictions-e420_l1490-1490_ep56_sig_210.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e420_l1490-1490_ep56_sig_210\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e420_l1490-1490_ep56_sig_210\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e420_l1490-1490_ep56_sig_210\\model\\assets\n",
      "[I 2026-01-13 17:23:54,223] Trial 70 finished with value: 0.8136600852012634 and parameters: {'learning_rate': 0.006486117154689042, 'depth': 2, 'units': 1490, 'embedding_dim': 420, 'epochs': 56}. Best is trial 51 with value: 0.8371865749359131.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e420_l1490-1490_ep56_sig_210\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e420_l1490-1490_ep56_sig_210\n",
      "Creating dir: f:/exp/keras/optuna\\e452_l1531_ep146_sig_647\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e452_l1531_ep146_sig_647  \n",
      "run_experiment()  when: 2026-01-13 17:23:54.280999 params: {'epochs': 146, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 17:24:34.318282\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e452_l1531_ep146_sig_647\\normalized_training_df-e452_l1531_ep146_sig_647.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e452_l1531_ep146_sig_647\\normalized_training_df-e452_l1531_ep146_sig_647.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e452_l1531_ep146_sig_647\\predictions-e452_l1531_ep146_sig_647.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e452_l1531_ep146_sig_647\\predictions-e452_l1531_ep146_sig_647.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e452_l1531_ep146_sig_647\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e452_l1531_ep146_sig_647\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e452_l1531_ep146_sig_647\\model\\assets\n",
      "[I 2026-01-13 17:25:40,011] Trial 71 finished with value: 0.8277565240859985 and parameters: {'learning_rate': 0.007584203952728273, 'depth': 1, 'units': 1531, 'embedding_dim': 452, 'epochs': 146}. Best is trial 51 with value: 0.8371865749359131.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e452_l1531_ep146_sig_647\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e452_l1531_ep146_sig_647\n",
      "Creating dir: f:/exp/keras/optuna\\e347_l1393_ep146_sig_164\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e347_l1393_ep146_sig_164  \n",
      "run_experiment()  when: 2026-01-13 17:25:40.071485 params: {'epochs': 146, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 17:26:11.210906\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e347_l1393_ep146_sig_164\\normalized_training_df-e347_l1393_ep146_sig_164.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e347_l1393_ep146_sig_164\\normalized_training_df-e347_l1393_ep146_sig_164.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e347_l1393_ep146_sig_164\\predictions-e347_l1393_ep146_sig_164.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e347_l1393_ep146_sig_164\\predictions-e347_l1393_ep146_sig_164.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e347_l1393_ep146_sig_164\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e347_l1393_ep146_sig_164\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e347_l1393_ep146_sig_164\\model\\assets\n",
      "[I 2026-01-13 17:27:16,029] Trial 72 finished with value: 0.7671269178390503 and parameters: {'learning_rate': 0.008963243932512587, 'depth': 1, 'units': 1393, 'embedding_dim': 347, 'epochs': 146}. Best is trial 51 with value: 0.8371865749359131.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e347_l1393_ep146_sig_164\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e347_l1393_ep146_sig_164\n",
      "Creating dir: f:/exp/keras/optuna\\e518_l1664_ep139_sig_200\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e518_l1664_ep139_sig_200  \n",
      "run_experiment()  when: 2026-01-13 17:27:16.087042 params: {'epochs': 139, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 17:29:03.820799\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna\\e518_l1664_ep139_sig_200\\normalized_training_df-e518_l1664_ep139_sig_200.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e518_l1664_ep139_sig_200\\normalized_training_df-e518_l1664_ep139_sig_200.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna\\e518_l1664_ep139_sig_200\\predictions-e518_l1664_ep139_sig_200.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna\\e518_l1664_ep139_sig_200\\predictions-e518_l1664_ep139_sig_200.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna\\e518_l1664_ep139_sig_200\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e518_l1664_ep139_sig_200\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna\\e518_l1664_ep139_sig_200\\model\\assets\n",
      "[I 2026-01-13 17:30:08,948] Trial 73 finished with value: 0.8130191564559937 and parameters: {'learning_rate': 0.007735382962462779, 'depth': 1, 'units': 1664, 'embedding_dim': 518, 'epochs': 139}. Best is trial 51 with value: 0.8371865749359131.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna\\e518_l1664_ep139_sig_200\\model\n",
      "Saved experiment → f:/exp/keras/optuna\\e518_l1664_ep139_sig_200\n",
      "Creating dir: f:/exp/keras/optuna\\e475_l1304-1304_ep144_sig_355\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna\\e475_l1304-1304_ep144_sig_355  \n",
      "run_experiment()  when: 2026-01-13 17:30:09.001541 params: {'epochs': 144, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-13 17:31:47.915074\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2026-01-13 17:32:15,149] Trial 74 failed with parameters: {'learning_rate': 0.004469493769101995, 'depth': 2, 'units': 1304, 'embedding_dim': 475, 'epochs': 144} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\miniconda3\\envs\\grocery-ml-keras\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 205, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_11072\\2073892872.py\", line 34, in objective\n",
      "    groceryML.run_experiment(\n",
      "  File \"C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_tensorflow.py\", line 394, in run_experiment\n",
      "    prediction_time_artifacts = self.build_prediction_input(pd.Timestamp.now(), norm_params)\n",
      "  File \"C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_tensorflow.py\", line 418, in build_prediction_input\n",
      "    self.build_live_df()\n",
      "  File \"C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_tensorflow.py\", line 76, in build_live_df\n",
      "    self.live_df = self._build_combined_df(self.liveSources)\n",
      "  File \"C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_tensorflow.py\", line 114, in _build_combined_df\n",
      "    self._combined_df = self._build_trip_level_feats(self._combined_df);\n",
      "  File \"C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_tensorflow.py\", line 139, in _build_trip_level_feats\n",
      "    df[\"isDayLightSavingsTime_feat\"] = TemporalFeatures.is_dst_series(df[\"date\"])\n",
      "  File \"C:\\Users\\steve\\source\\repos\\grocery-ml\\temporal_features_2.py\", line 208, in is_dst_series\n",
      "    return s.map(\n",
      "  File \"C:\\ProgramData\\miniconda3\\envs\\grocery-ml-keras\\lib\\site-packages\\pandas\\core\\series.py\", line 4719, in map\n",
      "    new_values = self._map_values(arg, na_action=na_action)\n",
      "  File \"C:\\ProgramData\\miniconda3\\envs\\grocery-ml-keras\\lib\\site-packages\\pandas\\core\\base.py\", line 923, in _map_values\n",
      "    return arr.map(mapper, na_action=na_action)\n",
      "  File \"C:\\ProgramData\\miniconda3\\envs\\grocery-ml-keras\\lib\\site-packages\\pandas\\core\\arrays\\_mixins.py\", line 81, in method\n",
      "    return meth(self, *args, **kwargs)\n",
      "  File \"C:\\ProgramData\\miniconda3\\envs\\grocery-ml-keras\\lib\\site-packages\\pandas\\core\\arrays\\datetimelike.py\", line 763, in map\n",
      "    result = map_array(self, mapper, na_action=na_action)\n",
      "  File \"C:\\ProgramData\\miniconda3\\envs\\grocery-ml-keras\\lib\\site-packages\\pandas\\core\\algorithms.py\", line 1743, in map_array\n",
      "    return lib.map_infer(values, mapper, convert=convert)\n",
      "  File \"pandas/_libs/lib.pyx\", line 2999, in pandas._libs.lib.map_infer\n",
      "  File \"C:\\Users\\steve\\source\\repos\\grocery-ml\\temporal_features_2.py\", line 209, in <lambda>\n",
      "    lambda d: 1 if pytz.timezone(tz).localize(d).dst() != pd.Timedelta(0) else 0\n",
      "  File \"C:\\ProgramData\\miniconda3\\envs\\grocery-ml-keras\\lib\\site-packages\\pytz\\tzinfo.py\", line 331, in localize\n",
      "    loc_dt = tzinfo.normalize(dt.replace(tzinfo=tzinfo))\n",
      "  File \"C:\\ProgramData\\miniconda3\\envs\\grocery-ml-keras\\lib\\site-packages\\pytz\\tzinfo.py\", line 259, in normalize\n",
      "    return self.fromutc(dt)\n",
      "KeyboardInterrupt\n",
      "[W 2026-01-13 17:32:15,180] Trial 74 failed with value None.\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import optuna \n",
    "def objective(trial):\n",
    "\n",
    "    lr = trial.suggest_float(\"learning_rate\", 0.001, 0.01)\n",
    "    depth = trial.suggest_int(\"depth\", 1, 10)\n",
    "    units = trial.suggest_int(\"units\", 5, 2048)\n",
    "    embedding_dim = trial.suggest_int(\"embedding_dim\", 300, 2048)\n",
    "    epochs = trial.suggest_int(\"epochs\", 10, 150)\n",
    "    # output_activation = trial.suggest_categorical(\"output_activation\", [\"sigmoid\", \"linear\"])\n",
    "    output_activation = \"sigmoid\"\n",
    "    metrics = [\"AUC\", \"Precision\", \"Recall\"]\n",
    "    # metrics = [\"Accuracy\", \"MAE\", \"MSE\", \"MAPE\", \"MSLE\", \"Precision\", \"Recall\", \"AUC\",  \"BinaryCrossentropy\", \"RootMeanSquaredError\"]\n",
    "    \n",
    "    layers_cfg = []\n",
    "    for _ in range(depth):\n",
    "        layers_cfg.append({ \"units\": units, \"activation\": \"relu\" })\n",
    "\n",
    "    build_params = {\n",
    "        \"embedding_dim\": embedding_dim,\n",
    "        \"layers\": layers_cfg,\n",
    "        \"output_activation\": output_activation,\n",
    "        \"optimizer\": \"adam\",\n",
    "        \"learning_rate\": lr,\n",
    "        \"loss\": \"binary_crossentropy\" if output_activation == \"sigmoid\" else \"mse\",\n",
    "        \"metrics\": metrics\n",
    "    }\n",
    "\n",
    "    train_params = {\n",
    "        \"epochs\": epochs,\n",
    "        \"batch_size\": 32,\n",
    "     \n",
    "    }\n",
    "\n",
    "    groceryML.run_experiment(\n",
    "        groceryML.training_df,\n",
    "        build_params,\n",
    "        train_params,\n",
    "        r\"f:/exp/keras/optuna/after_neg_sameple_fix\"\n",
    "    )\n",
    "\n",
    "    return groceryML.last_val_auc\n",
    "############################################################################\n",
    "\n",
    "\n",
    "sampler = optuna.samplers.TPESampler()\n",
    "\n",
    "study_name = f\"grocery_ml_tuning_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "study = optuna.create_study(\n",
    "    study_name= study_name,\n",
    "    sampler=sampler,\n",
    "    direction=\"maximize\",   # or minimize — see note below\n",
    "    storage=\"sqlite:///optuna_grocery.db\",\n",
    "    load_if_exists=True\n",
    ")\n",
    "\n",
    "\n",
    "study.optimize(objective, n_trials=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cef528-5472-429d-9657-42dd746a184c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
