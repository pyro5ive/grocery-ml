{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "548e477f-aa81-4d9e-bb31-2acece50cbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ============================================================\n",
    "# # ITEM-LEVEL HABIT FEATURES (TF-IDF ANALOG)\n",
    "# # ============================================================\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# def build_habit_features(df, tau_days=120):\n",
    "#     df = df.copy()\n",
    "#     df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "#     total_trips = df[\"date\"].nunique()\n",
    "#     timeline_days = (df[\"date\"].max() - df[\"date\"].min()).days or 1\n",
    "\n",
    "#     rows = []\n",
    "\n",
    "#     for itemId, g in df.groupby(\"itemId\"):\n",
    "#         buys = g[g[\"didBuy_target\"] == 1][\"date\"]\n",
    "\n",
    "#         if len(buys) == 0:\n",
    "#             rows.append({\n",
    "#                 \"itemId\": itemId,\n",
    "#                 \"habitFrequency_feat\": 0.0,\n",
    "#                 \"habitSpan_feat\": 0.0,\n",
    "#                 \"habitDecay_feat\": 0.0,\n",
    "#             })\n",
    "#             continue\n",
    "\n",
    "#         first = buys.min()\n",
    "#         last = buys.max()\n",
    "\n",
    "#         habitFrequency = len(buys) / total_trips\n",
    "#         habitSpan = (last - first).days / timeline_days\n",
    "#         days_since_last = (df[\"date\"].max() - last).days\n",
    "#         habitDecay = np.exp(-days_since_last / tau_days)\n",
    "\n",
    "#         rows.append({\n",
    "#             \"itemId\": itemId,\n",
    "#             \"habitFrequency_feat\": habitFrequency,\n",
    "#             \"habitSpan_feat\": habitSpan,\n",
    "#             \"habitDecay_feat\": habitDecay,\n",
    "#         })\n",
    "\n",
    "#     return pd.DataFrame(rows)\n",
    "# ###############################################################################\n",
    "\n",
    "\n",
    "# def compute_due_score(df,itemId=None,use_sigmoid=True,normalize=False, weights=None):\n",
    "#     \"\"\"\n",
    "#     \"\"\"\n",
    "\n",
    "#     if weights is None:\n",
    "#         weights = {\n",
    "#             \"daysSinceLastPurchase_feat\": 1.5,\n",
    "#             \"freq_30\": 1.0,\n",
    "#             \"freq_90\": 0.5\n",
    "#         }\n",
    "\n",
    "#     # --------------------------------------------------------\n",
    "#     # Optional itemId filter\n",
    "#     # --------------------------------------------------------\n",
    "#     if itemId is not None:\n",
    "#         df = df[df[\"itemId\"] == itemId].copy()\n",
    "#     else:\n",
    "#         df = df.copy()\n",
    "\n",
    "#     # --------------------------------------------------------\n",
    "#     # RAW linear score (pre-normalization)\n",
    "#     # --------------------------------------------------------\n",
    "#     df[\"due_score_raw\"] = (\n",
    "#         weights[\"daysSinceLastPurchase_feat\"] * df[\"daysSinceLastPurchase_feat\"]\n",
    "#       + weights[\"freq_30_feat\"]              * df[\"freq_30_feat\"]\n",
    "#       + weights[\"freq_90_feat\"]              * df[\"freq_90_feat\"]\n",
    "#     )\n",
    "\n",
    "#     # --------------------------------------------------------\n",
    "#     # Final due_score\n",
    "#     # --------------------------------------------------------\n",
    "#     if use_sigmoid:\n",
    "#         df[\"due_score_feat\"] = 1 / (1 + np.exp(-df[\"due_score_raw\"]))\n",
    "\n",
    "#     elif normalize:\n",
    "#         mean = df[\"due_score_raw\"].mean()\n",
    "#         std  = df[\"due_score_raw\"].std() or 1.0\n",
    "#         df[\"due_score\"] = (df[\"due_score_raw\"] - mean) / std\n",
    "\n",
    "#     else:\n",
    "#         df[\"due_score\"] = df[\"due_score_raw\"]\n",
    "\n",
    "#     return df\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# MERGE HABIT FEATURES\n",
    "# ============================================================\n",
    "#habit_df = build_habit_features(combined_df)\n",
    "\n",
    "#combined_df = combined_df.merge(habit_df, on=\"itemId\",how=\"left\")\n",
    "\n",
    "#combined_df[[\"habitFrequency_feat\", \"habitSpan_feat\", \"habitDecay_feat\"]] = (\n",
    "#    combined_df[[\"habitFrequency_feat\", \"habitSpan_feat\", \"habitDecay_feat\"]].fillna(0.0)\n",
    "#)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c53ab4d-52a4-4136-8830-ad464c457e43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#combined_df[\"purchaseToTripRatio\"] = combined_df[\"daysSinceLastPurchase\"] / combined_df[\"avgDaysBetweenPurchases\"]\n",
    "\n",
    "\n",
    "# encoded_df[\"due_score\"] = (\n",
    "#     1.5 * encoded_df[\"daysSinceLastPurchase_norm\"]\n",
    "#   + 1.0 * encoded_df[\"freq_30_norm\"]\n",
    "#   + 0.5 * encoded_df[\"freq_90_norm\"]\n",
    "# )\n",
    "\n",
    "#encoded_df[\"due_score\"] = 1 / (1 + np.exp(-encoded_df[\"due_score\"]))\n",
    "\n",
    "# df[\"bulkAdjustedUrgencyRatio\"] = df.apply(\n",
    "#     lambda row: BulkPurchaseFeatures.bulk_adjusted_urgency_ratio(\n",
    "#         row[\"daysSinceLastPurchase\"],\n",
    "#         row[\"avgDaysBetweenPurchases\"],\n",
    "#         row[\"bulkFlag\"],\n",
    "#         row[\"didBuy\"]          # this is already 1 or 0 per trip\n",
    "#     ),\n",
    "#     axis=1\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "192abc4e-1a90-416f-b168-9093c1493c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "from grocery_ml import GroceryML\n",
    "from hidden_layer_param_builder import HiddenLayerParamSetBuilder\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option(\"display.float_format\", lambda x: f\"{x:.6f}\")\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", 2000)\n",
    "\n",
    "print(os.getcwd())\n",
    "# print(\"GPUs Available:\", tf.config.list_physical_devices('GPU'))\n",
    "#tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f34cfead-8f52-48ce-ab5c-35d377598296",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "insert_negative_samples()\n",
      "build_habit_frequency_for_training()\n",
      "compute_habit_frequency_map()\n",
      "build_trip_level_features()\n",
      "build_purchase_item_freq_cols()\n",
      "Writing XLSX: groceryml-combined_df-2025_12_27_02_05_47.xlsx\n",
      "   XLSX Done: groceryml-combined_df-2025_12_27_02_05_47.xlsx\n"
     ]
    }
   ],
   "source": [
    "def run_all_experiments(training_df, model_param_sets, output_dir):\n",
    "    total = len(model_param_sets)\n",
    "    print(f\"run_all_experiments() when: {datetime.now()}  output_dir: {output_dir}\");\n",
    "    for index, params in enumerate(model_param_sets, 1):\n",
    "        print(f\"Running Exp {index}/{total}...\")\n",
    "        groceryML.run_experiment(training_df, params[\"buildParams\"], params[\"trainParams\"], output_dir)\n",
    "\n",
    "groceryML = GroceryML();\n",
    "groceryML.build_combined_df()\n",
    "ts = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "groceryML.export_df_to_excel_table(groceryML.combined_df, f\"groceryml-combined_df-{ts}\", \"combined_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1dc656a-7c04-4e61-a0a7-1cc1f819d406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_all_experiments() when: 2025-12-27 02:08:15.735239  output_dir: exp/keras/2025_12_27_02_08_15\n",
      "Running Exp 1/15...\n",
      "run_experiment()  baseDir: exp/keras/2025_12_27_02_08_15  \n",
      "run_experiment()  when: 2025-12-27 02:08:15.735239 params: {'epochs': 20}  \n",
      "normalize_features()\n",
      "train_model()\n",
      " build_prediction_input()   Prediction date: 2025-12-27\n",
      "recompute_habit_frequency_for_prediction_time()\n",
      "compute_habit_frequency_map()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "23/23 [==============================] - 0s 593us/step\n",
      "Creating dir: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__121444\n",
      "Exporting dataframes:\n",
      "Writing XLSX: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__121444\\predictions-e48__l128__ep20__oa_sigmoid__121444.xlsx\n",
      "   XLSX Done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__121444\\predictions-e48__l128__ep20__oa_sigmoid__121444.xlsx\n",
      "Writing CSV: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__121444\\predictions-e48__l128__ep20__oa_sigmoid__121444.csv\n",
      "  CSV done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__121444\\predictions-e48__l128__ep20__oa_sigmoid__121444.csv\n",
      "Writing XLSX: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__121444\\normalized_df-e48__l128__ep20__oa_sigmoid__121444.xlsx\n",
      "   XLSX Done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__121444\\normalized_df-e48__l128__ep20__oa_sigmoid__121444.xlsx\n",
      "Writing CSV: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__121444\\normalized_df-e48__l128__ep20__oa_sigmoid__121444.csv\n",
      "  CSV done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__121444\\normalized_df-e48__l128__ep20__oa_sigmoid__121444.csv\n",
      "Writing XLSX: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__121444\\combined_df-e48__l128__ep20__oa_sigmoid__121444.xlsx\n",
      "   XLSX Done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__121444\\combined_df-e48__l128__ep20__oa_sigmoid__121444.xlsx\n",
      "Writing CSV: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__121444\\combined_df-e48__l128__ep20__oa_sigmoid__121444.csv\n",
      "  CSV done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__121444\\combined_df-e48__l128__ep20__oa_sigmoid__121444.csv\n",
      "Creating model dir: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__121444\\model\n",
      "Saving Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__121444\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__121444\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved experiment → exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__121444\n",
      "Running Exp 2/15...\n",
      "run_experiment()  baseDir: exp/keras/2025_12_27_02_08_15  \n",
      "run_experiment()  when: 2025-12-27 02:14:22.218004 params: {'epochs': 20}  \n",
      "normalize_features()\n",
      "train_model()\n",
      " build_prediction_input()   Prediction date: 2025-12-27\n",
      "recompute_habit_frequency_for_prediction_time()\n",
      "compute_habit_frequency_map()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "23/23 [==============================] - 0s 773us/step\n",
      "Creating dir: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__202028\n",
      "Exporting dataframes:\n",
      "Writing XLSX: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__202028\\predictions-e48__l128__ep20__oa_sigmoid__202028.xlsx\n",
      "   XLSX Done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__202028\\predictions-e48__l128__ep20__oa_sigmoid__202028.xlsx\n",
      "Writing CSV: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__202028\\predictions-e48__l128__ep20__oa_sigmoid__202028.csv\n",
      "  CSV done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__202028\\predictions-e48__l128__ep20__oa_sigmoid__202028.csv\n",
      "Writing XLSX: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__202028\\normalized_df-e48__l128__ep20__oa_sigmoid__202028.xlsx\n",
      "   XLSX Done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__202028\\normalized_df-e48__l128__ep20__oa_sigmoid__202028.xlsx\n",
      "Writing CSV: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__202028\\normalized_df-e48__l128__ep20__oa_sigmoid__202028.csv\n",
      "  CSV done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__202028\\normalized_df-e48__l128__ep20__oa_sigmoid__202028.csv\n",
      "Writing XLSX: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__202028\\combined_df-e48__l128__ep20__oa_sigmoid__202028.xlsx\n",
      "   XLSX Done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__202028\\combined_df-e48__l128__ep20__oa_sigmoid__202028.xlsx\n",
      "Writing CSV: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__202028\\combined_df-e48__l128__ep20__oa_sigmoid__202028.csv\n",
      "  CSV done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__202028\\combined_df-e48__l128__ep20__oa_sigmoid__202028.csv\n",
      "Creating model dir: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__202028\\model\n",
      "Saving Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__202028\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__202028\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved experiment → exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__202028\n",
      "Running Exp 3/15...\n",
      "run_experiment()  baseDir: exp/keras/2025_12_27_02_08_15  \n",
      "run_experiment()  when: 2025-12-27 02:21:29.755672 params: {'epochs': 20}  \n",
      "normalize_features()\n",
      "train_model()\n",
      " build_prediction_input()   Prediction date: 2025-12-27\n",
      "recompute_habit_frequency_for_prediction_time()\n",
      "compute_habit_frequency_map()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "23/23 [==============================] - 0s 636us/step\n",
      "Creating dir: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__601729\n",
      "Exporting dataframes:\n",
      "Writing XLSX: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__601729\\predictions-e48__l128__ep20__oa_sigmoid__601729.xlsx\n",
      "   XLSX Done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__601729\\predictions-e48__l128__ep20__oa_sigmoid__601729.xlsx\n",
      "Writing CSV: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__601729\\predictions-e48__l128__ep20__oa_sigmoid__601729.csv\n",
      "  CSV done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__601729\\predictions-e48__l128__ep20__oa_sigmoid__601729.csv\n",
      "Writing XLSX: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__601729\\normalized_df-e48__l128__ep20__oa_sigmoid__601729.xlsx\n",
      "   XLSX Done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__601729\\normalized_df-e48__l128__ep20__oa_sigmoid__601729.xlsx\n",
      "Writing CSV: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__601729\\normalized_df-e48__l128__ep20__oa_sigmoid__601729.csv\n",
      "  CSV done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__601729\\normalized_df-e48__l128__ep20__oa_sigmoid__601729.csv\n",
      "Writing XLSX: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__601729\\combined_df-e48__l128__ep20__oa_sigmoid__601729.xlsx\n",
      "   XLSX Done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__601729\\combined_df-e48__l128__ep20__oa_sigmoid__601729.xlsx\n",
      "Writing CSV: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__601729\\combined_df-e48__l128__ep20__oa_sigmoid__601729.csv\n",
      "  CSV done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__601729\\combined_df-e48__l128__ep20__oa_sigmoid__601729.csv\n",
      "Creating model dir: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__601729\\model\n",
      "Saving Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__601729\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__601729\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved experiment → exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__601729\n",
      "Running Exp 4/15...\n",
      "run_experiment()  baseDir: exp/keras/2025_12_27_02_08_15  \n",
      "run_experiment()  when: 2025-12-27 02:28:43.063233 params: {'epochs': 20}  \n",
      "normalize_features()\n",
      "train_model()\n",
      " build_prediction_input()   Prediction date: 2025-12-27\n",
      "recompute_habit_frequency_for_prediction_time()\n",
      "compute_habit_frequency_map()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "23/23 [==============================] - 0s 777us/step\n",
      "Creating dir: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__415176\n",
      "Exporting dataframes:\n",
      "Writing XLSX: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__415176\\predictions-e48__l128__ep20__oa_sigmoid__415176.xlsx\n",
      "   XLSX Done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__415176\\predictions-e48__l128__ep20__oa_sigmoid__415176.xlsx\n",
      "Writing CSV: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__415176\\predictions-e48__l128__ep20__oa_sigmoid__415176.csv\n",
      "  CSV done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__415176\\predictions-e48__l128__ep20__oa_sigmoid__415176.csv\n",
      "Writing XLSX: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__415176\\normalized_df-e48__l128__ep20__oa_sigmoid__415176.xlsx\n",
      "   XLSX Done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__415176\\normalized_df-e48__l128__ep20__oa_sigmoid__415176.xlsx\n",
      "Writing CSV: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__415176\\normalized_df-e48__l128__ep20__oa_sigmoid__415176.csv\n",
      "  CSV done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__415176\\normalized_df-e48__l128__ep20__oa_sigmoid__415176.csv\n",
      "Writing XLSX: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__415176\\combined_df-e48__l128__ep20__oa_sigmoid__415176.xlsx\n",
      "   XLSX Done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__415176\\combined_df-e48__l128__ep20__oa_sigmoid__415176.xlsx\n",
      "Writing CSV: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__415176\\combined_df-e48__l128__ep20__oa_sigmoid__415176.csv\n",
      "  CSV done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__415176\\combined_df-e48__l128__ep20__oa_sigmoid__415176.csv\n",
      "Creating model dir: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__415176\\model\n",
      "Saving Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__415176\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__415176\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved experiment → exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__415176\n",
      "Running Exp 5/15...\n",
      "run_experiment()  baseDir: exp/keras/2025_12_27_02_08_15  \n",
      "run_experiment()  when: 2025-12-27 02:35:56.370205 params: {'epochs': 20}  \n",
      "normalize_features()\n",
      "train_model()\n",
      " build_prediction_input()   Prediction date: 2025-12-27\n",
      "recompute_habit_frequency_for_prediction_time()\n",
      "compute_habit_frequency_map()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "23/23 [==============================] - 0s 637us/step\n",
      "Creating dir: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__132039\n",
      "Exporting dataframes:\n",
      "Writing XLSX: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__132039\\predictions-e48__l128__ep20__oa_sigmoid__132039.xlsx\n",
      "   XLSX Done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__132039\\predictions-e48__l128__ep20__oa_sigmoid__132039.xlsx\n",
      "Writing CSV: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__132039\\predictions-e48__l128__ep20__oa_sigmoid__132039.csv\n",
      "  CSV done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__132039\\predictions-e48__l128__ep20__oa_sigmoid__132039.csv\n",
      "Writing XLSX: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__132039\\normalized_df-e48__l128__ep20__oa_sigmoid__132039.xlsx\n",
      "   XLSX Done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__132039\\normalized_df-e48__l128__ep20__oa_sigmoid__132039.xlsx\n",
      "Writing CSV: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__132039\\normalized_df-e48__l128__ep20__oa_sigmoid__132039.csv\n",
      "  CSV done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__132039\\normalized_df-e48__l128__ep20__oa_sigmoid__132039.csv\n",
      "Writing XLSX: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__132039\\combined_df-e48__l128__ep20__oa_sigmoid__132039.xlsx\n",
      "   XLSX Done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__132039\\combined_df-e48__l128__ep20__oa_sigmoid__132039.xlsx\n",
      "Writing CSV: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__132039\\combined_df-e48__l128__ep20__oa_sigmoid__132039.csv\n",
      "  CSV done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__132039\\combined_df-e48__l128__ep20__oa_sigmoid__132039.csv\n",
      "Creating model dir: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__132039\\model\n",
      "Saving Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__132039\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__132039\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved experiment → exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_sigmoid__132039\n",
      "Running Exp 6/15...\n",
      "run_experiment()  baseDir: exp/keras/2025_12_27_02_08_15  \n",
      "run_experiment()  when: 2025-12-27 02:43:09.434051 params: {'epochs': 20}  \n",
      "normalize_features()\n",
      "train_model()\n",
      " build_prediction_input()   Prediction date: 2025-12-27\n",
      "recompute_habit_frequency_for_prediction_time()\n",
      "compute_habit_frequency_map()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "23/23 [==============================] - 0s 727us/step\n",
      "Creating dir: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__111846\n",
      "Exporting dataframes:\n",
      "Writing XLSX: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__111846\\predictions-e48__l128__ep20__oa_linear__111846.xlsx\n",
      "   XLSX Done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__111846\\predictions-e48__l128__ep20__oa_linear__111846.xlsx\n",
      "Writing CSV: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__111846\\predictions-e48__l128__ep20__oa_linear__111846.csv\n",
      "  CSV done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__111846\\predictions-e48__l128__ep20__oa_linear__111846.csv\n",
      "Writing XLSX: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__111846\\normalized_df-e48__l128__ep20__oa_linear__111846.xlsx\n",
      "   XLSX Done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__111846\\normalized_df-e48__l128__ep20__oa_linear__111846.xlsx\n",
      "Writing CSV: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__111846\\normalized_df-e48__l128__ep20__oa_linear__111846.csv\n",
      "  CSV done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__111846\\normalized_df-e48__l128__ep20__oa_linear__111846.csv\n",
      "Writing XLSX: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__111846\\combined_df-e48__l128__ep20__oa_linear__111846.xlsx\n",
      "   XLSX Done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__111846\\combined_df-e48__l128__ep20__oa_linear__111846.xlsx\n",
      "Writing CSV: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__111846\\combined_df-e48__l128__ep20__oa_linear__111846.csv\n",
      "  CSV done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__111846\\combined_df-e48__l128__ep20__oa_linear__111846.csv\n",
      "Creating model dir: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__111846\\model\n",
      "Saving Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__111846\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__111846\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved experiment → exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__111846\n",
      "Running Exp 7/15...\n",
      "run_experiment()  baseDir: exp/keras/2025_12_27_02_08_15  \n",
      "run_experiment()  when: 2025-12-27 02:50:22.794015 params: {'epochs': 20}  \n",
      "normalize_features()\n",
      "train_model()\n",
      " build_prediction_input()   Prediction date: 2025-12-27\n",
      "recompute_habit_frequency_for_prediction_time()\n",
      "compute_habit_frequency_map()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "23/23 [==============================] - 0s 682us/step\n",
      "Creating dir: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__137748\n",
      "Exporting dataframes:\n",
      "Writing XLSX: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__137748\\predictions-e48__l128__ep20__oa_linear__137748.xlsx\n",
      "   XLSX Done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__137748\\predictions-e48__l128__ep20__oa_linear__137748.xlsx\n",
      "Writing CSV: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__137748\\predictions-e48__l128__ep20__oa_linear__137748.csv\n",
      "  CSV done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__137748\\predictions-e48__l128__ep20__oa_linear__137748.csv\n",
      "Writing XLSX: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__137748\\normalized_df-e48__l128__ep20__oa_linear__137748.xlsx\n",
      "   XLSX Done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__137748\\normalized_df-e48__l128__ep20__oa_linear__137748.xlsx\n",
      "Writing CSV: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__137748\\normalized_df-e48__l128__ep20__oa_linear__137748.csv\n",
      "  CSV done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__137748\\normalized_df-e48__l128__ep20__oa_linear__137748.csv\n",
      "Writing XLSX: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__137748\\combined_df-e48__l128__ep20__oa_linear__137748.xlsx\n",
      "   XLSX Done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__137748\\combined_df-e48__l128__ep20__oa_linear__137748.xlsx\n",
      "Writing CSV: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__137748\\combined_df-e48__l128__ep20__oa_linear__137748.csv\n",
      "  CSV done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__137748\\combined_df-e48__l128__ep20__oa_linear__137748.csv\n",
      "Creating model dir: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__137748\\model\n",
      "Saving Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__137748\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__137748\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved experiment → exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__137748\n",
      "Running Exp 8/15...\n",
      "run_experiment()  baseDir: exp/keras/2025_12_27_02_08_15  \n",
      "run_experiment()  when: 2025-12-27 02:57:39.470750 params: {'epochs': 20}  \n",
      "normalize_features()\n",
      "train_model()\n",
      " build_prediction_input()   Prediction date: 2025-12-27\n",
      "recompute_habit_frequency_for_prediction_time()\n",
      "compute_habit_frequency_map()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "23/23 [==============================] - 0s 660us/step\n",
      "Creating dir: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__914765\n",
      "Exporting dataframes:\n",
      "Writing XLSX: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__914765\\predictions-e48__l128__ep20__oa_linear__914765.xlsx\n",
      "   XLSX Done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__914765\\predictions-e48__l128__ep20__oa_linear__914765.xlsx\n",
      "Writing CSV: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__914765\\predictions-e48__l128__ep20__oa_linear__914765.csv\n",
      "  CSV done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__914765\\predictions-e48__l128__ep20__oa_linear__914765.csv\n",
      "Writing XLSX: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__914765\\normalized_df-e48__l128__ep20__oa_linear__914765.xlsx\n",
      "   XLSX Done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__914765\\normalized_df-e48__l128__ep20__oa_linear__914765.xlsx\n",
      "Writing CSV: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__914765\\normalized_df-e48__l128__ep20__oa_linear__914765.csv\n",
      "  CSV done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__914765\\normalized_df-e48__l128__ep20__oa_linear__914765.csv\n",
      "Writing XLSX: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__914765\\combined_df-e48__l128__ep20__oa_linear__914765.xlsx\n",
      "   XLSX Done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__914765\\combined_df-e48__l128__ep20__oa_linear__914765.xlsx\n",
      "Writing CSV: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__914765\\combined_df-e48__l128__ep20__oa_linear__914765.csv\n",
      "  CSV done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__914765\\combined_df-e48__l128__ep20__oa_linear__914765.csv\n",
      "Creating model dir: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__914765\\model\n",
      "Saving Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__914765\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__914765\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved experiment → exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__914765\n",
      "Running Exp 9/15...\n",
      "run_experiment()  baseDir: exp/keras/2025_12_27_02_08_15  \n",
      "run_experiment()  when: 2025-12-27 03:04:53.633748 params: {'epochs': 20}  \n",
      "normalize_features()\n",
      "train_model()\n",
      " build_prediction_input()   Prediction date: 2025-12-27\n",
      "recompute_habit_frequency_for_prediction_time()\n",
      "compute_habit_frequency_map()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "23/23 [==============================] - 0s 636us/step\n",
      "Creating dir: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__549771\n",
      "Exporting dataframes:\n",
      "Writing XLSX: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__549771\\predictions-e48__l128__ep20__oa_linear__549771.xlsx\n",
      "   XLSX Done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__549771\\predictions-e48__l128__ep20__oa_linear__549771.xlsx\n",
      "Writing CSV: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__549771\\predictions-e48__l128__ep20__oa_linear__549771.csv\n",
      "  CSV done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__549771\\predictions-e48__l128__ep20__oa_linear__549771.csv\n",
      "Writing XLSX: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__549771\\normalized_df-e48__l128__ep20__oa_linear__549771.xlsx\n",
      "   XLSX Done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__549771\\normalized_df-e48__l128__ep20__oa_linear__549771.xlsx\n",
      "Writing CSV: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__549771\\normalized_df-e48__l128__ep20__oa_linear__549771.csv\n",
      "  CSV done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__549771\\normalized_df-e48__l128__ep20__oa_linear__549771.csv\n",
      "Writing XLSX: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__549771\\combined_df-e48__l128__ep20__oa_linear__549771.xlsx\n",
      "   XLSX Done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__549771\\combined_df-e48__l128__ep20__oa_linear__549771.xlsx\n",
      "Writing CSV: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__549771\\combined_df-e48__l128__ep20__oa_linear__549771.csv\n",
      "  CSV done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__549771\\combined_df-e48__l128__ep20__oa_linear__549771.csv\n",
      "Creating model dir: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__549771\\model\n",
      "Saving Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__549771\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__549771\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved experiment → exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__549771\n",
      "Running Exp 10/15...\n",
      "run_experiment()  baseDir: exp/keras/2025_12_27_02_08_15  \n",
      "run_experiment()  when: 2025-12-27 03:12:12.594898 params: {'epochs': 20}  \n",
      "normalize_features()\n",
      "train_model()\n",
      " build_prediction_input()   Prediction date: 2025-12-27\n",
      "recompute_habit_frequency_for_prediction_time()\n",
      "compute_habit_frequency_map()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "23/23 [==============================] - 0s 591us/step\n",
      "Creating dir: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__809757\n",
      "Exporting dataframes:\n",
      "Writing XLSX: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__809757\\predictions-e48__l128__ep20__oa_linear__809757.xlsx\n",
      "   XLSX Done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__809757\\predictions-e48__l128__ep20__oa_linear__809757.xlsx\n",
      "Writing CSV: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__809757\\predictions-e48__l128__ep20__oa_linear__809757.csv\n",
      "  CSV done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__809757\\predictions-e48__l128__ep20__oa_linear__809757.csv\n",
      "Writing XLSX: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__809757\\normalized_df-e48__l128__ep20__oa_linear__809757.xlsx\n",
      "   XLSX Done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__809757\\normalized_df-e48__l128__ep20__oa_linear__809757.xlsx\n",
      "Writing CSV: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__809757\\normalized_df-e48__l128__ep20__oa_linear__809757.csv\n",
      "  CSV done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__809757\\normalized_df-e48__l128__ep20__oa_linear__809757.csv\n",
      "Writing XLSX: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__809757\\combined_df-e48__l128__ep20__oa_linear__809757.xlsx\n",
      "   XLSX Done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__809757\\combined_df-e48__l128__ep20__oa_linear__809757.xlsx\n",
      "Writing CSV: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__809757\\combined_df-e48__l128__ep20__oa_linear__809757.csv\n",
      "  CSV done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__809757\\combined_df-e48__l128__ep20__oa_linear__809757.csv\n",
      "Creating model dir: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__809757\\model\n",
      "Saving Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__809757\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__809757\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved experiment → exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_linear__809757\n",
      "Running Exp 11/15...\n",
      "run_experiment()  baseDir: exp/keras/2025_12_27_02_08_15  \n",
      "run_experiment()  when: 2025-12-27 03:19:30.810687 params: {'epochs': 20}  \n",
      "normalize_features()\n",
      "train_model()\n",
      " build_prediction_input()   Prediction date: 2025-12-27\n",
      "recompute_habit_frequency_for_prediction_time()\n",
      "compute_habit_frequency_map()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "23/23 [==============================] - 0s 682us/step\n",
      "Creating dir: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__202637\n",
      "Exporting dataframes:\n",
      "Writing XLSX: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__202637\\predictions-e48__l128__ep20__oa_tanh__202637.xlsx\n",
      "   XLSX Done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__202637\\predictions-e48__l128__ep20__oa_tanh__202637.xlsx\n",
      "Writing CSV: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__202637\\predictions-e48__l128__ep20__oa_tanh__202637.csv\n",
      "  CSV done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__202637\\predictions-e48__l128__ep20__oa_tanh__202637.csv\n",
      "Writing XLSX: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__202637\\normalized_df-e48__l128__ep20__oa_tanh__202637.xlsx\n",
      "   XLSX Done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__202637\\normalized_df-e48__l128__ep20__oa_tanh__202637.xlsx\n",
      "Writing CSV: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__202637\\normalized_df-e48__l128__ep20__oa_tanh__202637.csv\n",
      "  CSV done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__202637\\normalized_df-e48__l128__ep20__oa_tanh__202637.csv\n",
      "Writing XLSX: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__202637\\combined_df-e48__l128__ep20__oa_tanh__202637.xlsx\n",
      "   XLSX Done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__202637\\combined_df-e48__l128__ep20__oa_tanh__202637.xlsx\n",
      "Writing CSV: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__202637\\combined_df-e48__l128__ep20__oa_tanh__202637.csv\n",
      "  CSV done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__202637\\combined_df-e48__l128__ep20__oa_tanh__202637.csv\n",
      "Creating model dir: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__202637\\model\n",
      "Saving Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__202637\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__202637\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved experiment → exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__202637\n",
      "Running Exp 12/15...\n",
      "run_experiment()  baseDir: exp/keras/2025_12_27_02_08_15  \n",
      "run_experiment()  when: 2025-12-27 03:26:51.130910 params: {'epochs': 20}  \n",
      "normalize_features()\n",
      "train_model()\n",
      " build_prediction_input()   Prediction date: 2025-12-27\n",
      "recompute_habit_frequency_for_prediction_time()\n",
      "compute_habit_frequency_map()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "23/23 [==============================] - 0s 773us/step\n",
      "Creating dir: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__659667\n",
      "Exporting dataframes:\n",
      "Writing XLSX: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__659667\\predictions-e48__l128__ep20__oa_tanh__659667.xlsx\n",
      "   XLSX Done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__659667\\predictions-e48__l128__ep20__oa_tanh__659667.xlsx\n",
      "Writing CSV: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__659667\\predictions-e48__l128__ep20__oa_tanh__659667.csv\n",
      "  CSV done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__659667\\predictions-e48__l128__ep20__oa_tanh__659667.csv\n",
      "Writing XLSX: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__659667\\normalized_df-e48__l128__ep20__oa_tanh__659667.xlsx\n",
      "   XLSX Done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__659667\\normalized_df-e48__l128__ep20__oa_tanh__659667.xlsx\n",
      "Writing CSV: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__659667\\normalized_df-e48__l128__ep20__oa_tanh__659667.csv\n",
      "  CSV done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__659667\\normalized_df-e48__l128__ep20__oa_tanh__659667.csv\n",
      "Writing XLSX: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__659667\\combined_df-e48__l128__ep20__oa_tanh__659667.xlsx\n",
      "   XLSX Done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__659667\\combined_df-e48__l128__ep20__oa_tanh__659667.xlsx\n",
      "Writing CSV: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__659667\\combined_df-e48__l128__ep20__oa_tanh__659667.csv\n",
      "  CSV done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__659667\\combined_df-e48__l128__ep20__oa_tanh__659667.csv\n",
      "Creating model dir: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__659667\\model\n",
      "Saving Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__659667\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__659667\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved experiment → exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__659667\n",
      "Running Exp 13/15...\n",
      "run_experiment()  baseDir: exp/keras/2025_12_27_02_08_15  \n",
      "run_experiment()  when: 2025-12-27 03:34:07.279842 params: {'epochs': 20}  \n",
      "normalize_features()\n",
      "train_model()\n",
      " build_prediction_input()   Prediction date: 2025-12-27\n",
      "recompute_habit_frequency_for_prediction_time()\n",
      "compute_habit_frequency_map()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "23/23 [==============================] - 0s 682us/step\n",
      "Creating dir: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__213993\n",
      "Exporting dataframes:\n",
      "Writing XLSX: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__213993\\predictions-e48__l128__ep20__oa_tanh__213993.xlsx\n",
      "   XLSX Done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__213993\\predictions-e48__l128__ep20__oa_tanh__213993.xlsx\n",
      "Writing CSV: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__213993\\predictions-e48__l128__ep20__oa_tanh__213993.csv\n",
      "  CSV done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__213993\\predictions-e48__l128__ep20__oa_tanh__213993.csv\n",
      "Writing XLSX: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__213993\\normalized_df-e48__l128__ep20__oa_tanh__213993.xlsx\n",
      "   XLSX Done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__213993\\normalized_df-e48__l128__ep20__oa_tanh__213993.xlsx\n",
      "Writing CSV: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__213993\\normalized_df-e48__l128__ep20__oa_tanh__213993.csv\n",
      "  CSV done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__213993\\normalized_df-e48__l128__ep20__oa_tanh__213993.csv\n",
      "Writing XLSX: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__213993\\combined_df-e48__l128__ep20__oa_tanh__213993.xlsx\n",
      "   XLSX Done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__213993\\combined_df-e48__l128__ep20__oa_tanh__213993.xlsx\n",
      "Writing CSV: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__213993\\combined_df-e48__l128__ep20__oa_tanh__213993.csv\n",
      "  CSV done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__213993\\combined_df-e48__l128__ep20__oa_tanh__213993.csv\n",
      "Creating model dir: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__213993\\model\n",
      "Saving Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__213993\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__213993\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved experiment → exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__213993\n",
      "Running Exp 14/15...\n",
      "run_experiment()  baseDir: exp/keras/2025_12_27_02_08_15  \n",
      "run_experiment()  when: 2025-12-27 03:41:26.939062 params: {'epochs': 20}  \n",
      "normalize_features()\n",
      "train_model()\n",
      " build_prediction_input()   Prediction date: 2025-12-27\n",
      "recompute_habit_frequency_for_prediction_time()\n",
      "compute_habit_frequency_map()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "23/23 [==============================] - 0s 682us/step\n",
      "Creating dir: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__131251\n",
      "Exporting dataframes:\n",
      "Writing XLSX: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__131251\\predictions-e48__l128__ep20__oa_tanh__131251.xlsx\n",
      "   XLSX Done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__131251\\predictions-e48__l128__ep20__oa_tanh__131251.xlsx\n",
      "Writing CSV: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__131251\\predictions-e48__l128__ep20__oa_tanh__131251.csv\n",
      "  CSV done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__131251\\predictions-e48__l128__ep20__oa_tanh__131251.csv\n",
      "Writing XLSX: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__131251\\normalized_df-e48__l128__ep20__oa_tanh__131251.xlsx\n",
      "   XLSX Done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__131251\\normalized_df-e48__l128__ep20__oa_tanh__131251.xlsx\n",
      "Writing CSV: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__131251\\normalized_df-e48__l128__ep20__oa_tanh__131251.csv\n",
      "  CSV done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__131251\\normalized_df-e48__l128__ep20__oa_tanh__131251.csv\n",
      "Writing XLSX: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__131251\\combined_df-e48__l128__ep20__oa_tanh__131251.xlsx\n",
      "   XLSX Done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__131251\\combined_df-e48__l128__ep20__oa_tanh__131251.xlsx\n",
      "Writing CSV: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__131251\\combined_df-e48__l128__ep20__oa_tanh__131251.csv\n",
      "  CSV done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__131251\\combined_df-e48__l128__ep20__oa_tanh__131251.csv\n",
      "Creating model dir: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__131251\\model\n",
      "Saving Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__131251\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__131251\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved experiment → exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__131251\n",
      "Running Exp 15/15...\n",
      "run_experiment()  baseDir: exp/keras/2025_12_27_02_08_15  \n",
      "run_experiment()  when: 2025-12-27 03:48:46.446878 params: {'epochs': 20}  \n",
      "normalize_features()\n",
      "train_model()\n",
      " build_prediction_input()   Prediction date: 2025-12-27\n",
      "recompute_habit_frequency_for_prediction_time()\n",
      "compute_habit_frequency_map()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "23/23 [==============================] - 0s 682us/step\n",
      "Creating dir: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__107104\n",
      "Exporting dataframes:\n",
      "Writing XLSX: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__107104\\predictions-e48__l128__ep20__oa_tanh__107104.xlsx\n",
      "   XLSX Done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__107104\\predictions-e48__l128__ep20__oa_tanh__107104.xlsx\n",
      "Writing CSV: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__107104\\predictions-e48__l128__ep20__oa_tanh__107104.csv\n",
      "  CSV done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__107104\\predictions-e48__l128__ep20__oa_tanh__107104.csv\n",
      "Writing XLSX: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__107104\\normalized_df-e48__l128__ep20__oa_tanh__107104.xlsx\n",
      "   XLSX Done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__107104\\normalized_df-e48__l128__ep20__oa_tanh__107104.xlsx\n",
      "Writing CSV: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__107104\\normalized_df-e48__l128__ep20__oa_tanh__107104.csv\n",
      "  CSV done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__107104\\normalized_df-e48__l128__ep20__oa_tanh__107104.csv\n",
      "Writing XLSX: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__107104\\combined_df-e48__l128__ep20__oa_tanh__107104.xlsx\n",
      "   XLSX Done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__107104\\combined_df-e48__l128__ep20__oa_tanh__107104.xlsx\n",
      "Writing CSV: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__107104\\combined_df-e48__l128__ep20__oa_tanh__107104.csv\n",
      "  CSV done: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__107104\\combined_df-e48__l128__ep20__oa_tanh__107104.csv\n",
      "Creating model dir: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__107104\\model\n",
      "Saving Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__107104\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__107104\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved experiment → exp/keras/2025_12_27_02_08_15\\e48__l128__ep20__oa_tanh__107104\n"
     ]
    }
   ],
   "source": [
    "modelParamsList = []\n",
    "\n",
    "# activations to try (no softmax)\n",
    "output_activations = [\"sigmoid\", \"linear\", \"tanh\"]\n",
    "# output_activations = [\"sigmoid\", \"linear\", \"tanh\", \"elu\"]\n",
    "embDims = [48]\n",
    "          \n",
    "for act in output_activations:\n",
    "    for dim in embDims:\n",
    "        # accuracy\n",
    "        modelParamsList.append({\n",
    "            \"trainParams\": { \"epochs\": 20 },\n",
    "            \"buildParams\": {\n",
    "                \"embedding_dim\": dim,\n",
    "                \"layers\": [128],\n",
    "                \"activation\": \"relu\",\n",
    "                \"output_activation\": act,\n",
    "                \"optimizer\": \"adam\",\n",
    "                \"learning_rate\": 0.001,\n",
    "                \"loss\": \"binary_crossentropy\" if act == \"sigmoid\" else \"mse\",\n",
    "                \"metrics\": [\"accuracy\"]\n",
    "            }\n",
    "        })\n",
    "    \n",
    "        # auc\n",
    "        modelParamsList.append({\n",
    "            \"trainParams\": { \"epochs\": 20 },\n",
    "            \"buildParams\": {\n",
    "                \"embedding_dim\": dim,\n",
    "                \"layers\": [128],\n",
    "                \"activation\": \"relu\",\n",
    "                \"output_activation\": act,\n",
    "                \"optimizer\": \"adam\",\n",
    "                \"learning_rate\": 0.001,\n",
    "                \"loss\": \"binary_crossentropy\" if act == \"sigmoid\" else \"mse\",\n",
    "                \"metrics\": [\"AUC\"]\n",
    "            }\n",
    "        })\n",
    "    \n",
    "        # precision + recall\n",
    "        modelParamsList.append({\n",
    "            \"trainParams\": { \"epochs\": 20 },\n",
    "            \"buildParams\": {\n",
    "                \"embedding_dim\": dim,\n",
    "                \"layers\": [128],\n",
    "                \"activation\": \"relu\",\n",
    "                \"output_activation\": act,\n",
    "                \"optimizer\": \"adam\",\n",
    "                \"learning_rate\": 0.001,\n",
    "                \"loss\": \"binary_crossentropy\" if act == \"sigmoid\" else \"mse\",\n",
    "                \"metrics\": [\"Precision\", \"Recall\"]\n",
    "            }\n",
    "        })\n",
    "    \n",
    "        # auc + precision + recall\n",
    "        modelParamsList.append({\n",
    "            \"trainParams\": { \"epochs\": 20 },\n",
    "            \"buildParams\": {\n",
    "               \"embedding_dim\": dim,\n",
    "                \"layers\": [128],\n",
    "                \"activation\": \"relu\",\n",
    "                \"output_activation\": act,\n",
    "                \"optimizer\": \"adam\",\n",
    "                \"learning_rate\": 0.001,\n",
    "                \"loss\": \"binary_crossentropy\" if act == \"sigmoid\" else \"mse\",\n",
    "                \"metrics\": [\"AUC\", \"Precision\", \"Recall\"]\n",
    "            }\n",
    "        })\n",
    "    \n",
    "        # mae\n",
    "        modelParamsList.append({\n",
    "            \"trainParams\": { \"epochs\": 20 },\n",
    "            \"buildParams\": {\n",
    "                \"embedding_dim\": dim,\n",
    "                \"layers\": [128],\n",
    "                \"activation\": \"relu\",\n",
    "                \"output_activation\": act,\n",
    "                \"optimizer\": \"adam\",\n",
    "                \"learning_rate\": 0.001,\n",
    "                \"loss\": \"binary_crossentropy\" if act == \"sigmoid\" else \"mse\",\n",
    "                \"metrics\": [\"mae\"]\n",
    "            }\n",
    "    })\n",
    "\n",
    "ts = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "run_all_experiments(groceryML.combined_df, modelParamsList, f\"exp/keras/{ts}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
