{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f94e9fd3-99b1-438c-9ac0-6d5455c99af4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pdb;\n",
    "from grocery_ml_tensorflow import GroceryML\n",
    "from grocery_ml_core import GroceryMLCore\n",
    "from hidden_layer_param_builder import HiddenLayerParamSetBuilder\n",
    "import tensorflow as tf\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option(\"display.float_format\", lambda x: f\"{x:.6f}\")\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", 2000)\n",
    "\n",
    "print(os.getcwd())\n",
    "# print(\"GPUs Available:\", tf.config.list_physical_devices('GPU'))\n",
    "#tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# def run_all_experiments(df, model_param_sets, output_dir):\n",
    "#     total = len(model_param_sets)\n",
    "#     print(f\"run_all_experiments() when: {datetime.now()}  output_dir: {output_dir}\");\n",
    "#     for index, params in enumerate(model_param_sets, 1):\n",
    "#         print(f\"Running Exp {index}/{total}...\")\n",
    "#         groceryML.run_experiment(df,  params[\"buildParams\"], params[\"trainParams\"], output_dir)\n",
    "\n",
    "\n",
    "try:\n",
    "    groceryML = GroceryML();\n",
    "    groceryMLCore = GroceryMLCore();\n",
    "    groceryML.build_training_df()\n",
    "    if groceryML.training_df is None:\n",
    "        raise();\n",
    "    ts = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "    # groceryML.training_df.to_csv(f\"training_df-{ts}.csv\");\n",
    "except Exception as ex: \n",
    "    print(ex)\n",
    "    ts = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "    groceryML.training_df.to_csv(f\"training_df-{ts}-exception.csv\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5404e4-f977-40ab-8250-f34c86c037ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-14 20:22:14,002] A new study created in RDB with name: grocery_ml_tuning_20260114_202213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1053-1053-1053-1053-1053_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1053-1053-1053-1053-1053_  \n",
      "run_experiment()  when: 2026-01-14 20:22:14.061185 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 20:25:07.585078\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 7ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1053-1053-1053-1053-1053_\\normalized_training_df-e300_l1053-1053-1053-1053-1053_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1053-1053-1053-1053-1053_\\normalized_training_df-e300_l1053-1053-1053-1053-1053_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1053-1053-1053-1053-1053_\\predictions-e300_l1053-1053-1053-1053-1053_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1053-1053-1053-1053-1053_\\predictions-e300_l1053-1053-1053-1053-1053_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1053-1053-1053-1053-1053_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1053-1053-1053-1053-1053_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1053-1053-1053-1053-1053_\\model\\assets\n",
      "[I 2026-01-14 20:26:01,923] Trial 0 finished with value: 0.8679929971694946 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 1053, 'embedding_dim': 300, 'epochs': 50}. Best is trial 0 with value: 0.8679929971694946.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1053-1053-1053-1053-1053_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1053-1053-1053-1053-1053_\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1089-1089-1089-1089-1089_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1089-1089-1089-1089-1089_  \n",
      "run_experiment()  when: 2026-01-14 20:26:01.958881 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 20:28:29.266933\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1089-1089-1089-1089-1089_\\normalized_training_df-e300_l1089-1089-1089-1089-1089_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1089-1089-1089-1089-1089_\\normalized_training_df-e300_l1089-1089-1089-1089-1089_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1089-1089-1089-1089-1089_\\predictions-e300_l1089-1089-1089-1089-1089_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1089-1089-1089-1089-1089_\\predictions-e300_l1089-1089-1089-1089-1089_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1089-1089-1089-1089-1089_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1089-1089-1089-1089-1089_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1089-1089-1089-1089-1089_\\model\\assets\n",
      "[I 2026-01-14 20:29:18,209] Trial 1 finished with value: 0.8884116411209106 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 1089, 'embedding_dim': 300, 'epochs': 50}. Best is trial 1 with value: 0.8884116411209106.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1089-1089-1089-1089-1089_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1089-1089-1089-1089-1089_\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1926-1926-1926-1926-1926_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1926-1926-1926-1926-1926_  \n",
      "run_experiment()  when: 2026-01-14 20:29:18.257123 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 20:37:31.992019\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 8ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1926-1926-1926-1926-1926_\\normalized_training_df-e300_l1926-1926-1926-1926-1926_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1926-1926-1926-1926-1926_\\normalized_training_df-e300_l1926-1926-1926-1926-1926_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1926-1926-1926-1926-1926_\\predictions-e300_l1926-1926-1926-1926-1926_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1926-1926-1926-1926-1926_\\predictions-e300_l1926-1926-1926-1926-1926_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1926-1926-1926-1926-1926_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1926-1926-1926-1926-1926_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1926-1926-1926-1926-1926_\\model\\assets\n",
      "[I 2026-01-14 20:38:23,539] Trial 2 finished with value: 0.875180721282959 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 1926, 'embedding_dim': 300, 'epochs': 50}. Best is trial 1 with value: 0.8884116411209106.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1926-1926-1926-1926-1926_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1926-1926-1926-1926-1926_\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1901-1901-1901-1901-1901_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1901-1901-1901-1901-1901_  \n",
      "run_experiment()  when: 2026-01-14 20:38:23.568262 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 20:44:46.072568\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 9ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1901-1901-1901-1901-1901_\\normalized_training_df-e300_l1901-1901-1901-1901-1901_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1901-1901-1901-1901-1901_\\normalized_training_df-e300_l1901-1901-1901-1901-1901_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1901-1901-1901-1901-1901_\\predictions-e300_l1901-1901-1901-1901-1901_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1901-1901-1901-1901-1901_\\predictions-e300_l1901-1901-1901-1901-1901_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1901-1901-1901-1901-1901_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1901-1901-1901-1901-1901_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1901-1901-1901-1901-1901_\\model\\assets\n",
      "[I 2026-01-14 20:45:37,411] Trial 3 finished with value: 0.8986903429031372 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 1901, 'embedding_dim': 300, 'epochs': 50}. Best is trial 3 with value: 0.8986903429031372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1901-1901-1901-1901-1901_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1901-1901-1901-1901-1901_\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1326-1326-1326-1326-1326_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1326-1326-1326-1326-1326_  \n",
      "run_experiment()  when: 2026-01-14 20:45:37.449178 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 20:49:39.943164\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 6ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1326-1326-1326-1326-1326_\\normalized_training_df-e300_l1326-1326-1326-1326-1326_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1326-1326-1326-1326-1326_\\normalized_training_df-e300_l1326-1326-1326-1326-1326_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1326-1326-1326-1326-1326_\\predictions-e300_l1326-1326-1326-1326-1326_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1326-1326-1326-1326-1326_\\predictions-e300_l1326-1326-1326-1326-1326_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1326-1326-1326-1326-1326_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1326-1326-1326-1326-1326_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1326-1326-1326-1326-1326_\\model\\assets\n",
      "[I 2026-01-14 20:50:35,450] Trial 4 finished with value: 0.8791662454605103 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 1326, 'embedding_dim': 300, 'epochs': 50}. Best is trial 3 with value: 0.8986903429031372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1326-1326-1326-1326-1326_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1326-1326-1326-1326-1326_\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l723-723-723-723-723_ep50_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l723-723-723-723-723_ep50_  \n",
      "run_experiment()  when: 2026-01-14 20:50:35.487746 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 20:51:41.158353\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l723-723-723-723-723_ep50_\\normalized_training_df-e300_l723-723-723-723-723_ep50_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l723-723-723-723-723_ep50_\\normalized_training_df-e300_l723-723-723-723-723_ep50_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l723-723-723-723-723_ep50_\\predictions-e300_l723-723-723-723-723_ep50_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l723-723-723-723-723_ep50_\\predictions-e300_l723-723-723-723-723_ep50_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l723-723-723-723-723_ep50_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l723-723-723-723-723_ep50_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l723-723-723-723-723_ep50_\\model\\assets\n",
      "[I 2026-01-14 20:52:36,341] Trial 5 finished with value: 0.8762605786323547 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 723, 'embedding_dim': 300, 'epochs': 50}. Best is trial 3 with value: 0.8986903429031372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l723-723-723-723-723_ep50_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l723-723-723-723-723_ep50_\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l2025-2025-2025-2025-2025_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l2025-2025-2025-2025-2025_  \n",
      "run_experiment()  when: 2026-01-14 20:52:36.373221 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 21:00:00.331669\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 13ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l2025-2025-2025-2025-2025_\\normalized_training_df-e300_l2025-2025-2025-2025-2025_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l2025-2025-2025-2025-2025_\\normalized_training_df-e300_l2025-2025-2025-2025-2025_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l2025-2025-2025-2025-2025_\\predictions-e300_l2025-2025-2025-2025-2025_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l2025-2025-2025-2025-2025_\\predictions-e300_l2025-2025-2025-2025-2025_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l2025-2025-2025-2025-2025_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l2025-2025-2025-2025-2025_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l2025-2025-2025-2025-2025_\\model\\assets\n",
      "[I 2026-01-14 21:00:54,345] Trial 6 finished with value: 0.8914932608604431 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 2025, 'embedding_dim': 300, 'epochs': 50}. Best is trial 3 with value: 0.8986903429031372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l2025-2025-2025-2025-2025_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l2025-2025-2025-2025-2025_\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1777-1777-1777-1777-1777_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1777-1777-1777-1777-1777_  \n",
      "run_experiment()  when: 2026-01-14 21:00:54.380977 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 21:07:01.227816\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 12ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1777-1777-1777-1777-1777_\\normalized_training_df-e300_l1777-1777-1777-1777-1777_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1777-1777-1777-1777-1777_\\normalized_training_df-e300_l1777-1777-1777-1777-1777_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1777-1777-1777-1777-1777_\\predictions-e300_l1777-1777-1777-1777-1777_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1777-1777-1777-1777-1777_\\predictions-e300_l1777-1777-1777-1777-1777_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1777-1777-1777-1777-1777_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1777-1777-1777-1777-1777_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1777-1777-1777-1777-1777_\\model\\assets\n",
      "[I 2026-01-14 21:07:54,751] Trial 7 finished with value: 0.8770020008087158 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 1777, 'embedding_dim': 300, 'epochs': 50}. Best is trial 3 with value: 0.8986903429031372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1777-1777-1777-1777-1777_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1777-1777-1777-1777-1777_\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l837-837-837-837-837_ep50_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l837-837-837-837-837_ep50_  \n",
      "run_experiment()  when: 2026-01-14 21:07:54.787108 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 21:09:53.572431\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l837-837-837-837-837_ep50_\\normalized_training_df-e300_l837-837-837-837-837_ep50_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l837-837-837-837-837_ep50_\\normalized_training_df-e300_l837-837-837-837-837_ep50_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l837-837-837-837-837_ep50_\\predictions-e300_l837-837-837-837-837_ep50_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l837-837-837-837-837_ep50_\\predictions-e300_l837-837-837-837-837_ep50_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l837-837-837-837-837_ep50_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l837-837-837-837-837_ep50_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l837-837-837-837-837_ep50_\\model\\assets\n",
      "[I 2026-01-14 21:10:50,661] Trial 8 finished with value: 0.8753893971443176 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 837, 'embedding_dim': 300, 'epochs': 50}. Best is trial 3 with value: 0.8986903429031372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l837-837-837-837-837_ep50_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l837-837-837-837-837_ep50_\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1944-1944-1944-1944-1944_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1944-1944-1944-1944-1944_  \n",
      "run_experiment()  when: 2026-01-14 21:10:50.696727 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 21:17:59.731870\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 13ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1944-1944-1944-1944-1944_\\normalized_training_df-e300_l1944-1944-1944-1944-1944_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1944-1944-1944-1944-1944_\\normalized_training_df-e300_l1944-1944-1944-1944-1944_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1944-1944-1944-1944-1944_\\predictions-e300_l1944-1944-1944-1944-1944_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1944-1944-1944-1944-1944_\\predictions-e300_l1944-1944-1944-1944-1944_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1944-1944-1944-1944-1944_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1944-1944-1944-1944-1944_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1944-1944-1944-1944-1944_\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1944-1944-1944-1944-1944_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1944-1944-1944-1944-1944_\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-14 21:18:56,943] Trial 9 finished with value: 0.8958726525306702 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 1944, 'embedding_dim': 300, 'epochs': 50}. Best is trial 3 with value: 0.8986903429031372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l26-26-26-26-26_ep50_sig_1\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l26-26-26-26-26_ep50_sig_1  \n",
      "run_experiment()  when: 2026-01-14 21:18:57.461001 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 21:19:15.088967\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l26-26-26-26-26_ep50_sig_1\\normalized_training_df-e300_l26-26-26-26-26_ep50_sig_1.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l26-26-26-26-26_ep50_sig_1\\normalized_training_df-e300_l26-26-26-26-26_ep50_sig_1.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l26-26-26-26-26_ep50_sig_1\\predictions-e300_l26-26-26-26-26_ep50_sig_1.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l26-26-26-26-26_ep50_sig_1\\predictions-e300_l26-26-26-26-26_ep50_sig_1.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l26-26-26-26-26_ep50_sig_1\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l26-26-26-26-26_ep50_sig_1\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l26-26-26-26-26_ep50_sig_1\\model\\assets\n",
      "[I 2026-01-14 21:20:08,921] Trial 10 finished with value: 0.8658797144889832 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 26, 'embedding_dim': 300, 'epochs': 50}. Best is trial 3 with value: 0.8986903429031372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l26-26-26-26-26_ep50_sig_1\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l26-26-26-26-26_ep50_sig_1\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1593-1593-1593-1593-1593_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1593-1593-1593-1593-1593_  \n",
      "run_experiment()  when: 2026-01-14 21:20:08.960509 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 21:27:19.849113\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 9ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1593-1593-1593-1593-1593_\\normalized_training_df-e300_l1593-1593-1593-1593-1593_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1593-1593-1593-1593-1593_\\normalized_training_df-e300_l1593-1593-1593-1593-1593_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1593-1593-1593-1593-1593_\\predictions-e300_l1593-1593-1593-1593-1593_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1593-1593-1593-1593-1593_\\predictions-e300_l1593-1593-1593-1593-1593_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1593-1593-1593-1593-1593_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1593-1593-1593-1593-1593_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1593-1593-1593-1593-1593_\\model\\assets\n",
      "[I 2026-01-14 21:28:13,290] Trial 11 finished with value: 0.8633910417556763 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 1593, 'embedding_dim': 300, 'epochs': 50}. Best is trial 3 with value: 0.8986903429031372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1593-1593-1593-1593-1593_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1593-1593-1593-1593-1593_\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1544-1544-1544-1544-1544_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1544-1544-1544-1544-1544_  \n",
      "run_experiment()  when: 2026-01-14 21:28:13.333017 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 21:33:34.203830\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 9ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1544-1544-1544-1544-1544_\\normalized_training_df-e300_l1544-1544-1544-1544-1544_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1544-1544-1544-1544-1544_\\normalized_training_df-e300_l1544-1544-1544-1544-1544_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1544-1544-1544-1544-1544_\\predictions-e300_l1544-1544-1544-1544-1544_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1544-1544-1544-1544-1544_\\predictions-e300_l1544-1544-1544-1544-1544_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1544-1544-1544-1544-1544_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1544-1544-1544-1544-1544_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1544-1544-1544-1544-1544_\\model\\assets\n",
      "[I 2026-01-14 21:34:28,316] Trial 12 finished with value: 0.886548638343811 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 1544, 'embedding_dim': 300, 'epochs': 50}. Best is trial 3 with value: 0.8986903429031372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1544-1544-1544-1544-1544_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1544-1544-1544-1544-1544_\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l2043-2043-2043-2043-2043_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l2043-2043-2043-2043-2043_  \n",
      "run_experiment()  when: 2026-01-14 21:34:28.356935 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 21:43:29.791781\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 13ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l2043-2043-2043-2043-2043_\\normalized_training_df-e300_l2043-2043-2043-2043-2043_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l2043-2043-2043-2043-2043_\\normalized_training_df-e300_l2043-2043-2043-2043-2043_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l2043-2043-2043-2043-2043_\\predictions-e300_l2043-2043-2043-2043-2043_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l2043-2043-2043-2043-2043_\\predictions-e300_l2043-2043-2043-2043-2043_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l2043-2043-2043-2043-2043_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l2043-2043-2043-2043-2043_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l2043-2043-2043-2043-2043_\\model\\assets\n",
      "[I 2026-01-14 21:44:24,285] Trial 13 finished with value: 0.86519855260849 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 2043, 'embedding_dim': 300, 'epochs': 50}. Best is trial 3 with value: 0.8986903429031372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l2043-2043-2043-2043-2043_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l2043-2043-2043-2043-2043_\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l287-287-287-287-287_ep50_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l287-287-287-287-287_ep50_  \n",
      "run_experiment()  when: 2026-01-14 21:44:24.350757 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 21:44:46.700648\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l287-287-287-287-287_ep50_\\normalized_training_df-e300_l287-287-287-287-287_ep50_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l287-287-287-287-287_ep50_\\normalized_training_df-e300_l287-287-287-287-287_ep50_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l287-287-287-287-287_ep50_\\predictions-e300_l287-287-287-287-287_ep50_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l287-287-287-287-287_ep50_\\predictions-e300_l287-287-287-287-287_ep50_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l287-287-287-287-287_ep50_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l287-287-287-287-287_ep50_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l287-287-287-287-287_ep50_\\model\\assets\n",
      "[I 2026-01-14 21:45:40,936] Trial 14 finished with value: 0.8720062971115112 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 287, 'embedding_dim': 300, 'epochs': 50}. Best is trial 3 with value: 0.8986903429031372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l287-287-287-287-287_ep50_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l287-287-287-287-287_ep50_\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1647-1647-1647-1647-1647_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1647-1647-1647-1647-1647_  \n",
      "run_experiment()  when: 2026-01-14 21:45:40.981384 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 21:50:59.618900\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 10ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1647-1647-1647-1647-1647_\\normalized_training_df-e300_l1647-1647-1647-1647-1647_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1647-1647-1647-1647-1647_\\normalized_training_df-e300_l1647-1647-1647-1647-1647_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1647-1647-1647-1647-1647_\\predictions-e300_l1647-1647-1647-1647-1647_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1647-1647-1647-1647-1647_\\predictions-e300_l1647-1647-1647-1647-1647_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1647-1647-1647-1647-1647_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1647-1647-1647-1647-1647_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1647-1647-1647-1647-1647_\\model\\assets\n",
      "[I 2026-01-14 21:51:53,103] Trial 15 finished with value: 0.8836615085601807 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 1647, 'embedding_dim': 300, 'epochs': 50}. Best is trial 3 with value: 0.8986903429031372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1647-1647-1647-1647-1647_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1647-1647-1647-1647-1647_\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1264-1264-1264-1264-1264_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1264-1264-1264-1264-1264_  \n",
      "run_experiment()  when: 2026-01-14 21:51:53.162528 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 21:56:06.061415\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 7ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1264-1264-1264-1264-1264_\\normalized_training_df-e300_l1264-1264-1264-1264-1264_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1264-1264-1264-1264-1264_\\normalized_training_df-e300_l1264-1264-1264-1264-1264_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1264-1264-1264-1264-1264_\\predictions-e300_l1264-1264-1264-1264-1264_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1264-1264-1264-1264-1264_\\predictions-e300_l1264-1264-1264-1264-1264_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1264-1264-1264-1264-1264_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1264-1264-1264-1264-1264_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1264-1264-1264-1264-1264_\\model\\assets\n",
      "[I 2026-01-14 21:57:00,269] Trial 16 finished with value: 0.8602027297019958 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 1264, 'embedding_dim': 300, 'epochs': 50}. Best is trial 3 with value: 0.8986903429031372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1264-1264-1264-1264-1264_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1264-1264-1264-1264-1264_\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1793-1793-1793-1793-1793_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1793-1793-1793-1793-1793_  \n",
      "run_experiment()  when: 2026-01-14 21:57:00.309966 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 22:05:04.725895\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 11ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1793-1793-1793-1793-1793_\\normalized_training_df-e300_l1793-1793-1793-1793-1793_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1793-1793-1793-1793-1793_\\normalized_training_df-e300_l1793-1793-1793-1793-1793_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1793-1793-1793-1793-1793_\\predictions-e300_l1793-1793-1793-1793-1793_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1793-1793-1793-1793-1793_\\predictions-e300_l1793-1793-1793-1793-1793_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1793-1793-1793-1793-1793_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1793-1793-1793-1793-1793_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1793-1793-1793-1793-1793_\\model\\assets\n",
      "[I 2026-01-14 22:06:00,641] Trial 17 finished with value: 0.8531540036201477 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 1793, 'embedding_dim': 300, 'epochs': 50}. Best is trial 3 with value: 0.8986903429031372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1793-1793-1793-1793-1793_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1793-1793-1793-1793-1793_\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1435-1435-1435-1435-1435_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1435-1435-1435-1435-1435_  \n",
      "run_experiment()  when: 2026-01-14 22:06:00.682486 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 22:10:39.465779\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 9ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1435-1435-1435-1435-1435_\\normalized_training_df-e300_l1435-1435-1435-1435-1435_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1435-1435-1435-1435-1435_\\normalized_training_df-e300_l1435-1435-1435-1435-1435_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1435-1435-1435-1435-1435_\\predictions-e300_l1435-1435-1435-1435-1435_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1435-1435-1435-1435-1435_\\predictions-e300_l1435-1435-1435-1435-1435_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1435-1435-1435-1435-1435_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1435-1435-1435-1435-1435_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1435-1435-1435-1435-1435_\\model\\assets\n",
      "[I 2026-01-14 22:11:33,047] Trial 18 finished with value: 0.8849451541900635 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 1435, 'embedding_dim': 300, 'epochs': 50}. Best is trial 3 with value: 0.8986903429031372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1435-1435-1435-1435-1435_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1435-1435-1435-1435-1435_\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l540-540-540-540-540_ep50_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l540-540-540-540-540_ep50_  \n",
      "run_experiment()  when: 2026-01-14 22:11:33.085719 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 22:12:20.600507\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l540-540-540-540-540_ep50_\\normalized_training_df-e300_l540-540-540-540-540_ep50_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l540-540-540-540-540_ep50_\\normalized_training_df-e300_l540-540-540-540-540_ep50_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l540-540-540-540-540_ep50_\\predictions-e300_l540-540-540-540-540_ep50_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l540-540-540-540-540_ep50_\\predictions-e300_l540-540-540-540-540_ep50_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l540-540-540-540-540_ep50_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l540-540-540-540-540_ep50_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l540-540-540-540-540_ep50_\\model\\assets\n",
      "[I 2026-01-14 22:13:14,819] Trial 19 finished with value: 0.87024986743927 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 540, 'embedding_dim': 300, 'epochs': 50}. Best is trial 3 with value: 0.8986903429031372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l540-540-540-540-540_ep50_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l540-540-540-540-540_ep50_\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1809-1809-1809-1809-1809_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1809-1809-1809-1809-1809_  \n",
      "run_experiment()  when: 2026-01-14 22:13:14.886374 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 22:23:10.454138\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 11ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1809-1809-1809-1809-1809_\\normalized_training_df-e300_l1809-1809-1809-1809-1809_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1809-1809-1809-1809-1809_\\normalized_training_df-e300_l1809-1809-1809-1809-1809_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1809-1809-1809-1809-1809_\\predictions-e300_l1809-1809-1809-1809-1809_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1809-1809-1809-1809-1809_\\predictions-e300_l1809-1809-1809-1809-1809_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1809-1809-1809-1809-1809_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1809-1809-1809-1809-1809_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1809-1809-1809-1809-1809_\\model\\assets\n",
      "[I 2026-01-14 22:24:06,269] Trial 20 finished with value: 0.853524923324585 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 1809, 'embedding_dim': 300, 'epochs': 50}. Best is trial 3 with value: 0.8986903429031372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1809-1809-1809-1809-1809_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1809-1809-1809-1809-1809_\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l2038-2038-2038-2038-2038_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l2038-2038-2038-2038-2038_  \n",
      "run_experiment()  when: 2026-01-14 22:24:06.313753 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 22:35:21.307024\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 13ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l2038-2038-2038-2038-2038_\\normalized_training_df-e300_l2038-2038-2038-2038-2038_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l2038-2038-2038-2038-2038_\\normalized_training_df-e300_l2038-2038-2038-2038-2038_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l2038-2038-2038-2038-2038_\\predictions-e300_l2038-2038-2038-2038-2038_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l2038-2038-2038-2038-2038_\\predictions-e300_l2038-2038-2038-2038-2038_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l2038-2038-2038-2038-2038_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l2038-2038-2038-2038-2038_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l2038-2038-2038-2038-2038_\\model\\assets\n",
      "[I 2026-01-14 22:36:15,516] Trial 21 finished with value: 0.8313359618186951 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 2038, 'embedding_dim': 300, 'epochs': 50}. Best is trial 3 with value: 0.8986903429031372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l2038-2038-2038-2038-2038_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l2038-2038-2038-2038-2038_\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1856-1856-1856-1856-1856_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1856-1856-1856-1856-1856_  \n",
      "run_experiment()  when: 2026-01-14 22:36:15.562888 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 22:44:45.920249\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 12ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1856-1856-1856-1856-1856_\\normalized_training_df-e300_l1856-1856-1856-1856-1856_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1856-1856-1856-1856-1856_\\normalized_training_df-e300_l1856-1856-1856-1856-1856_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1856-1856-1856-1856-1856_\\predictions-e300_l1856-1856-1856-1856-1856_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1856-1856-1856-1856-1856_\\predictions-e300_l1856-1856-1856-1856-1856_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1856-1856-1856-1856-1856_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1856-1856-1856-1856-1856_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1856-1856-1856-1856-1856_\\model\\assets\n",
      "[I 2026-01-14 22:45:40,505] Trial 22 finished with value: 0.8546093106269836 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 1856, 'embedding_dim': 300, 'epochs': 50}. Best is trial 3 with value: 0.8986903429031372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1856-1856-1856-1856-1856_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1856-1856-1856-1856-1856_\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1690-1690-1690-1690-1690_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1690-1690-1690-1690-1690_  \n",
      "run_experiment()  when: 2026-01-14 22:45:40.564778 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 22:52:03.506088\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 10ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1690-1690-1690-1690-1690_\\normalized_training_df-e300_l1690-1690-1690-1690-1690_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1690-1690-1690-1690-1690_\\normalized_training_df-e300_l1690-1690-1690-1690-1690_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1690-1690-1690-1690-1690_\\predictions-e300_l1690-1690-1690-1690-1690_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1690-1690-1690-1690-1690_\\predictions-e300_l1690-1690-1690-1690-1690_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1690-1690-1690-1690-1690_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1690-1690-1690-1690-1690_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1690-1690-1690-1690-1690_\\model\\assets\n",
      "[I 2026-01-14 22:52:59,588] Trial 23 finished with value: 0.889519214630127 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 1690, 'embedding_dim': 300, 'epochs': 50}. Best is trial 3 with value: 0.8986903429031372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1690-1690-1690-1690-1690_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1690-1690-1690-1690-1690_\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l2011-2011-2011-2011-2011_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l2011-2011-2011-2011-2011_  \n",
      "run_experiment()  when: 2026-01-14 22:52:59.628787 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 23:01:46.166553\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 13ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l2011-2011-2011-2011-2011_\\normalized_training_df-e300_l2011-2011-2011-2011-2011_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l2011-2011-2011-2011-2011_\\normalized_training_df-e300_l2011-2011-2011-2011-2011_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l2011-2011-2011-2011-2011_\\predictions-e300_l2011-2011-2011-2011-2011_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l2011-2011-2011-2011-2011_\\predictions-e300_l2011-2011-2011-2011-2011_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l2011-2011-2011-2011-2011_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l2011-2011-2011-2011-2011_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l2011-2011-2011-2011-2011_\\model\\assets\n",
      "[I 2026-01-14 23:02:38,792] Trial 24 finished with value: 0.8625569939613342 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 2011, 'embedding_dim': 300, 'epochs': 50}. Best is trial 3 with value: 0.8986903429031372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l2011-2011-2011-2011-2011_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l2011-2011-2011-2011-2011_\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1452-1452-1452-1452-1452_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1452-1452-1452-1452-1452_  \n",
      "run_experiment()  when: 2026-01-14 23:02:38.834880 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 23:07:30.695225\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 10ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1452-1452-1452-1452-1452_\\normalized_training_df-e300_l1452-1452-1452-1452-1452_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1452-1452-1452-1452-1452_\\normalized_training_df-e300_l1452-1452-1452-1452-1452_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1452-1452-1452-1452-1452_\\predictions-e300_l1452-1452-1452-1452-1452_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1452-1452-1452-1452-1452_\\predictions-e300_l1452-1452-1452-1452-1452_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1452-1452-1452-1452-1452_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1452-1452-1452-1452-1452_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1452-1452-1452-1452-1452_\\model\\assets\n",
      "[I 2026-01-14 23:08:24,699] Trial 25 finished with value: 0.8774375319480896 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 1452, 'embedding_dim': 300, 'epochs': 50}. Best is trial 3 with value: 0.8986903429031372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1452-1452-1452-1452-1452_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1452-1452-1452-1452-1452_\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1246-1246-1246-1246-1246_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1246-1246-1246-1246-1246_  \n",
      "run_experiment()  when: 2026-01-14 23:08:24.737837 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 23:12:02.097562\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 8ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1246-1246-1246-1246-1246_\\normalized_training_df-e300_l1246-1246-1246-1246-1246_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1246-1246-1246-1246-1246_\\normalized_training_df-e300_l1246-1246-1246-1246-1246_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1246-1246-1246-1246-1246_\\predictions-e300_l1246-1246-1246-1246-1246_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1246-1246-1246-1246-1246_\\predictions-e300_l1246-1246-1246-1246-1246_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1246-1246-1246-1246-1246_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1246-1246-1246-1246-1246_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1246-1246-1246-1246-1246_\\model\\assets\n",
      "[I 2026-01-14 23:12:56,336] Trial 26 finished with value: 0.8605040907859802 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 1246, 'embedding_dim': 300, 'epochs': 50}. Best is trial 3 with value: 0.8986903429031372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1246-1246-1246-1246-1246_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1246-1246-1246-1246-1246_\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1938-1938-1938-1938-1938_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1938-1938-1938-1938-1938_  \n",
      "run_experiment()  when: 2026-01-14 23:12:56.376233 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 23:21:58.125569\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 12ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1938-1938-1938-1938-1938_\\normalized_training_df-e300_l1938-1938-1938-1938-1938_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1938-1938-1938-1938-1938_\\normalized_training_df-e300_l1938-1938-1938-1938-1938_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1938-1938-1938-1938-1938_\\predictions-e300_l1938-1938-1938-1938-1938_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1938-1938-1938-1938-1938_\\predictions-e300_l1938-1938-1938-1938-1938_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1938-1938-1938-1938-1938_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1938-1938-1938-1938-1938_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1938-1938-1938-1938-1938_\\model\\assets\n",
      "[I 2026-01-14 23:22:52,677] Trial 27 finished with value: 0.8907982110977173 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 1938, 'embedding_dim': 300, 'epochs': 50}. Best is trial 3 with value: 0.8986903429031372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1938-1938-1938-1938-1938_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1938-1938-1938-1938-1938_\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1723-1723-1723-1723-1723_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1723-1723-1723-1723-1723_  \n",
      "run_experiment()  when: 2026-01-14 23:22:52.715853 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 23:28:37.915717\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 11ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1723-1723-1723-1723-1723_\\normalized_training_df-e300_l1723-1723-1723-1723-1723_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1723-1723-1723-1723-1723_\\normalized_training_df-e300_l1723-1723-1723-1723-1723_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1723-1723-1723-1723-1723_\\predictions-e300_l1723-1723-1723-1723-1723_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1723-1723-1723-1723-1723_\\predictions-e300_l1723-1723-1723-1723-1723_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1723-1723-1723-1723-1723_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1723-1723-1723-1723-1723_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1723-1723-1723-1723-1723_\\model\\assets\n",
      "[I 2026-01-14 23:29:33,763] Trial 28 finished with value: 0.8831980228424072 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 1723, 'embedding_dim': 300, 'epochs': 50}. Best is trial 3 with value: 0.8986903429031372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1723-1723-1723-1723-1723_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1723-1723-1723-1723-1723_\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1023-1023-1023-1023-1023_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1023-1023-1023-1023-1023_  \n",
      "run_experiment()  when: 2026-01-14 23:29:33.804846 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 23:32:43.859617\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1023-1023-1023-1023-1023_\\normalized_training_df-e300_l1023-1023-1023-1023-1023_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1023-1023-1023-1023-1023_\\normalized_training_df-e300_l1023-1023-1023-1023-1023_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1023-1023-1023-1023-1023_\\predictions-e300_l1023-1023-1023-1023-1023_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1023-1023-1023-1023-1023_\\predictions-e300_l1023-1023-1023-1023-1023_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1023-1023-1023-1023-1023_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1023-1023-1023-1023-1023_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1023-1023-1023-1023-1023_\\model\\assets\n",
      "[I 2026-01-14 23:33:35,066] Trial 29 finished with value: 0.8622187972068787 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 1023, 'embedding_dim': 300, 'epochs': 50}. Best is trial 3 with value: 0.8986903429031372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1023-1023-1023-1023-1023_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1023-1023-1023-1023-1023_\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1538-1538-1538-1538-1538_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1538-1538-1538-1538-1538_  \n",
      "run_experiment()  when: 2026-01-14 23:33:35.097017 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 23:37:49.520753\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 7ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1538-1538-1538-1538-1538_\\normalized_training_df-e300_l1538-1538-1538-1538-1538_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1538-1538-1538-1538-1538_\\normalized_training_df-e300_l1538-1538-1538-1538-1538_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1538-1538-1538-1538-1538_\\predictions-e300_l1538-1538-1538-1538-1538_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1538-1538-1538-1538-1538_\\predictions-e300_l1538-1538-1538-1538-1538_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1538-1538-1538-1538-1538_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1538-1538-1538-1538-1538_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1538-1538-1538-1538-1538_\\model\\assets\n",
      "[I 2026-01-14 23:38:41,805] Trial 30 finished with value: 0.8389546871185303 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 1538, 'embedding_dim': 300, 'epochs': 50}. Best is trial 3 with value: 0.8986903429031372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1538-1538-1538-1538-1538_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1538-1538-1538-1538-1538_\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1914-1914-1914-1914-1914_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1914-1914-1914-1914-1914_  \n",
      "run_experiment()  when: 2026-01-14 23:38:41.845908 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 23:46:56.961955\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 10ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1914-1914-1914-1914-1914_\\normalized_training_df-e300_l1914-1914-1914-1914-1914_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1914-1914-1914-1914-1914_\\normalized_training_df-e300_l1914-1914-1914-1914-1914_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1914-1914-1914-1914-1914_\\predictions-e300_l1914-1914-1914-1914-1914_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1914-1914-1914-1914-1914_\\predictions-e300_l1914-1914-1914-1914-1914_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1914-1914-1914-1914-1914_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1914-1914-1914-1914-1914_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1914-1914-1914-1914-1914_\\model\\assets\n",
      "[I 2026-01-14 23:47:45,130] Trial 31 finished with value: 0.8874568939208984 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 1914, 'embedding_dim': 300, 'epochs': 50}. Best is trial 3 with value: 0.8986903429031372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1914-1914-1914-1914-1914_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1914-1914-1914-1914-1914_\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1927-1927-1927-1927-1927_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1927-1927-1927-1927-1927_  \n",
      "run_experiment()  when: 2026-01-14 23:47:45.162389 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-14 23:56:09.827079\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 8ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1927-1927-1927-1927-1927_\\normalized_training_df-e300_l1927-1927-1927-1927-1927_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1927-1927-1927-1927-1927_\\normalized_training_df-e300_l1927-1927-1927-1927-1927_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1927-1927-1927-1927-1927_\\predictions-e300_l1927-1927-1927-1927-1927_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1927-1927-1927-1927-1927_\\predictions-e300_l1927-1927-1927-1927-1927_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1927-1927-1927-1927-1927_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1927-1927-1927-1927-1927_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1927-1927-1927-1927-1927_\\model\\assets\n",
      "[I 2026-01-14 23:57:17,069] Trial 32 finished with value: 0.8770482540130615 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 1927, 'embedding_dim': 300, 'epochs': 50}. Best is trial 3 with value: 0.8986903429031372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1927-1927-1927-1927-1927_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1927-1927-1927-1927-1927_\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1904-1904-1904-1904-1904_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1904-1904-1904-1904-1904_  \n",
      "run_experiment()  when: 2026-01-14 23:57:17.109650 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 00:06:20.448340\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 9ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1904-1904-1904-1904-1904_\\normalized_training_df-e300_l1904-1904-1904-1904-1904_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1904-1904-1904-1904-1904_\\normalized_training_df-e300_l1904-1904-1904-1904-1904_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1904-1904-1904-1904-1904_\\predictions-e300_l1904-1904-1904-1904-1904_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1904-1904-1904-1904-1904_\\predictions-e300_l1904-1904-1904-1904-1904_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1904-1904-1904-1904-1904_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1904-1904-1904-1904-1904_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1904-1904-1904-1904-1904_\\model\\assets\n",
      "[I 2026-01-15 00:07:09,491] Trial 33 finished with value: 0.8678261637687683 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 1904, 'embedding_dim': 300, 'epochs': 50}. Best is trial 3 with value: 0.8986903429031372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1904-1904-1904-1904-1904_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1904-1904-1904-1904-1904_\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1685-1685-1685-1685-1685_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1685-1685-1685-1685-1685_  \n",
      "run_experiment()  when: 2026-01-15 00:07:09.529420 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 00:14:07.993002\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 6ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1685-1685-1685-1685-1685_\\normalized_training_df-e300_l1685-1685-1685-1685-1685_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1685-1685-1685-1685-1685_\\normalized_training_df-e300_l1685-1685-1685-1685-1685_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1685-1685-1685-1685-1685_\\predictions-e300_l1685-1685-1685-1685-1685_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1685-1685-1685-1685-1685_\\predictions-e300_l1685-1685-1685-1685-1685_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1685-1685-1685-1685-1685_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1685-1685-1685-1685-1685_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1685-1685-1685-1685-1685_\\model\\assets\n",
      "[I 2026-01-15 00:14:55,987] Trial 34 finished with value: 0.8358033299446106 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 1685, 'embedding_dim': 300, 'epochs': 50}. Best is trial 3 with value: 0.8986903429031372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1685-1685-1685-1685-1685_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1685-1685-1685-1685-1685_\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1958-1958-1958-1958-1958_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1958-1958-1958-1958-1958_  \n",
      "run_experiment()  when: 2026-01-15 00:14:56.023155 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 00:21:36.897651\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 6ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1958-1958-1958-1958-1958_\\normalized_training_df-e300_l1958-1958-1958-1958-1958_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1958-1958-1958-1958-1958_\\normalized_training_df-e300_l1958-1958-1958-1958-1958_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1958-1958-1958-1958-1958_\\predictions-e300_l1958-1958-1958-1958-1958_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1958-1958-1958-1958-1958_\\predictions-e300_l1958-1958-1958-1958-1958_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1958-1958-1958-1958-1958_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1958-1958-1958-1958-1958_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1958-1958-1958-1958-1958_\\model\\assets\n",
      "[I 2026-01-15 00:22:25,259] Trial 35 finished with value: 0.9003447890281677 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 1958, 'embedding_dim': 300, 'epochs': 50}. Best is trial 35 with value: 0.9003447890281677.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1958-1958-1958-1958-1958_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1958-1958-1958-1958-1958_\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l2046-2046-2046-2046-2046_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l2046-2046-2046-2046-2046_  \n",
      "run_experiment()  when: 2026-01-15 00:22:25.313188 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 00:30:41.237468\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 10ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l2046-2046-2046-2046-2046_\\normalized_training_df-e300_l2046-2046-2046-2046-2046_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l2046-2046-2046-2046-2046_\\normalized_training_df-e300_l2046-2046-2046-2046-2046_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l2046-2046-2046-2046-2046_\\predictions-e300_l2046-2046-2046-2046-2046_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l2046-2046-2046-2046-2046_\\predictions-e300_l2046-2046-2046-2046-2046_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l2046-2046-2046-2046-2046_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l2046-2046-2046-2046-2046_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l2046-2046-2046-2046-2046_\\model\\assets\n",
      "[I 2026-01-15 00:31:32,053] Trial 36 finished with value: 0.8638129830360413 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 2046, 'embedding_dim': 300, 'epochs': 50}. Best is trial 35 with value: 0.9003447890281677.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l2046-2046-2046-2046-2046_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l2046-2046-2046-2046-2046_\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1814-1814-1814-1814-1814_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1814-1814-1814-1814-1814_  \n",
      "run_experiment()  when: 2026-01-15 00:31:32.100951 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 00:38:05.355632\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1814-1814-1814-1814-1814_\\normalized_training_df-e300_l1814-1814-1814-1814-1814_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1814-1814-1814-1814-1814_\\normalized_training_df-e300_l1814-1814-1814-1814-1814_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1814-1814-1814-1814-1814_\\predictions-e300_l1814-1814-1814-1814-1814_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1814-1814-1814-1814-1814_\\predictions-e300_l1814-1814-1814-1814-1814_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1814-1814-1814-1814-1814_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1814-1814-1814-1814-1814_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1814-1814-1814-1814-1814_\\model\\assets\n",
      "[I 2026-01-15 00:38:54,918] Trial 37 finished with value: 0.8882401585578918 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 1814, 'embedding_dim': 300, 'epochs': 50}. Best is trial 35 with value: 0.9003447890281677.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1814-1814-1814-1814-1814_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1814-1814-1814-1814-1814_\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1075-1075-1075-1075-1075_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1075-1075-1075-1075-1075_  \n",
      "run_experiment()  when: 2026-01-15 00:38:54.959360 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 00:41:35.037451\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1075-1075-1075-1075-1075_\\normalized_training_df-e300_l1075-1075-1075-1075-1075_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1075-1075-1075-1075-1075_\\normalized_training_df-e300_l1075-1075-1075-1075-1075_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1075-1075-1075-1075-1075_\\predictions-e300_l1075-1075-1075-1075-1075_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1075-1075-1075-1075-1075_\\predictions-e300_l1075-1075-1075-1075-1075_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1075-1075-1075-1075-1075_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1075-1075-1075-1075-1075_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1075-1075-1075-1075-1075_\\model\\assets\n",
      "[I 2026-01-15 00:42:25,339] Trial 38 finished with value: 0.8876978754997253 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 1075, 'embedding_dim': 300, 'epochs': 50}. Best is trial 35 with value: 0.9003447890281677.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1075-1075-1075-1075-1075_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1075-1075-1075-1075-1075_\n",
      "Creating dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1419-1419-1419-1419-1419_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/no-itemPurchaseCount-1\\e300_l1419-1419-1419-1419-1419_  \n",
      "run_experiment()  when: 2026-01-15 00:42:25.372529 params: {'epochs': 50, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n"
     ]
    }
   ],
   "source": [
    "import optuna \n",
    "def objective(trial):\n",
    "\n",
    "    lr = trial.suggest_float(\"learning_rate\", 0.0001, 0.0001)\n",
    "    depth = trial.suggest_int(\"depth\", 5, 5)\n",
    "    units = trial.suggest_int(\"units\", 5, 2048, step = 5)\n",
    "    embedding_dim = trial.suggest_int(\"embedding_dim\", 300, 300)\n",
    "    epochs = trial.suggest_int(\"epochs\", 50, 50)\n",
    "    # output_activation = trial.suggest_categorical(\"output_activation\", [\"sigmoid\", \"linear\"])\n",
    "    output_activation = \"sigmoid\"\n",
    "    metrics = [\"AUC\", \"Precision\", \"Recall\"]\n",
    "    # metrics = [\"Accuracy\", \"MAE\", \"MSE\", \"MAPE\", \"MSLE\", \"Precision\", \"Recall\", \"AUC\",  \"BinaryCrossentropy\", \"RootMeanSquaredError\"]\n",
    "    \n",
    "    layers_cfg = []\n",
    "    for _ in range(depth):\n",
    "        layers_cfg.append({ \"units\": units, \"activation\": \"relu\" })\n",
    "\n",
    "    build_params = {\n",
    "        \"embedding_dim\": embedding_dim,\n",
    "        \"layers\": layers_cfg,\n",
    "        \"output_activation\": output_activation,\n",
    "        \"optimizer\": \"adam\",\n",
    "        \"learning_rate\": lr,\n",
    "        \"loss\": \"binary_crossentropy\" if output_activation == \"sigmoid\" else \"mse\",\n",
    "        \"metrics\": metrics\n",
    "    }\n",
    "\n",
    "    train_params = {\n",
    "        \"epochs\": epochs,\n",
    "        \"batch_size\": 32,\n",
    "     \n",
    "    }\n",
    "\n",
    "    outputDir = f\"f:/exp/keras/optuna/{trial.study.study_name}/trial-{trial.number}\"\n",
    "            \n",
    "    groceryML.run_experiment(groceryML.training_df, build_params, train_params, outputDir)\n",
    "\n",
    "\n",
    "    return groceryML.last_val_auc\n",
    "############################################################################\n",
    "\n",
    "\n",
    "sampler = optuna.samplers.TPESampler()\n",
    "\n",
    "study_name = f\"grocery_ml_tuning_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "study = optuna.create_study(\n",
    "    study_name= study_name,\n",
    "    sampler=sampler,\n",
    "    direction=\"maximize\",   # or minimize — see note below\n",
    "    storage=\"sqlite:///optuna_grocery.db\",\n",
    "    load_if_exists=True\n",
    ")\n",
    "\n",
    "\n",
    "study.optimize(objective, n_trials=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac22bf7-3b17-471e-8ae8-365617bd9ec6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
