{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "192abc4e-1a90-416f-b168-9093c1493c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\OneDrive - NOLA Business IT\\source\\repos\\grocery-ml\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from winn_dixie_recpt_parser import WinnDixieRecptParser \n",
    "\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01e514d2-7c8e-45ea-a1bd-88d5d4e6ce68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_grouped(grouped, rows=10):\n",
    "    # collect only the daysSinceLastPurchase_* columns\n",
    "    feature_cols = [c for c in grouped.columns if c.startswith(\"daysSinceLastPurchase_\")]\n",
    "\n",
    "    for i in range(min(rows, len(grouped))):\n",
    "        print(\"Row:\", i)\n",
    "        print(\"Date:\", grouped.iloc[i][\"date\"])\n",
    "        print(\"Time:\", grouped.iloc[i][\"time\"])\n",
    "        print(\"Items:\", grouped.iloc[i][\"item\"])\n",
    "        print(\"------ daysSinceLastPurchase ------\")\n",
    "\n",
    "        for col in feature_cols:\n",
    "            print(f\"{col}: {grouped.iloc[i][col]}\")\n",
    "\n",
    "        print(\"-----------------------------------\")\n",
    "\n",
    "\n",
    "def show_encoded(encoded_df, rows=10):\n",
    "    # Identify columns\n",
    "    days_cols = [c for c in encoded_df.columns if c.startswith(\"daysSinceLastPurchase_\")]\n",
    "    item_cols = [c for c in encoded_df.columns if c not in days_cols and c not in [\"date\", \"time\"]]\n",
    "\n",
    "    for i in range(min(rows, len(encoded_df))):\n",
    "        print(\"Row:\", i)\n",
    "        print(\"Date:\", encoded_df.iloc[i][\"date\"])\n",
    "        print(\"Time:\", encoded_df.iloc[i][\"time\"])\n",
    "\n",
    "        # Show the items purchased (reverse one-hot)\n",
    "        purchased_items = []\n",
    "        row_vals = encoded_df.iloc[i]\n",
    "\n",
    "        for item in item_cols:\n",
    "            if row_vals[item] == 1:\n",
    "                purchased_items.append(item)\n",
    "\n",
    "        print(\"Items:\", purchased_items)\n",
    "\n",
    "        print(\"------ daysSinceLastPurchase ------\")\n",
    "        for col in days_cols:\n",
    "            print(f\"{col}: {encoded_df.iloc[i][col]}\")\n",
    "\n",
    "        print(\"-----------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94fc3103-8878-4ae3-bb2f-f13bdf094e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rows = []\n",
    "\n",
    "recptParser  = WinnDixieRecptParser();\n",
    "\n",
    "for p in Path(\"StevePhone2/pdf/text\").glob(\"*.txt\"):\n",
    "    result = recptParser.parse(p.read_text(encoding=\"utf-8\", errors=\"ignore\"))\n",
    "    for r in result[\"items\"]:\n",
    "        rows.append({\n",
    "            \"source\": p.name,\n",
    "            \"date\": result[\"date\"],\n",
    "            \"time\": result[\"time\"],\n",
    "            \"manager\": result[\"manager\"],\n",
    "            \"cashier\": result[\"cashier\"],\n",
    "            \"item\": r[\"item\"],\n",
    "            \"qty\": r[\"qty\"],\n",
    "            \"reg\": r[\"reg\"],\n",
    "            \"youPay\": r[\"youPay\"],\n",
    "            \"reportedItemsSold\": result[\"reported\"],\n",
    "            #\"rowsMatchReported\": result[\"validation\"][\"rowsMatchReported\"],\n",
    "            \"qtyMatchReported\": result[\"validation\"][\"qtyMatchReported\"],\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93282d34-6c3d-42b7-952d-ee9c10ab3757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Item list\n",
    "\n",
    "df[\"item\"] = (\n",
    "    df[\"item\"]\n",
    "        .astype(str)\n",
    "        .str.strip()      \n",
    "        .str.replace(r\"\\s+\", \"-\", regex=True)     # collapse ANY whitespace into ONE hyphen\n",
    "        .str.replace(\"[^A-Za-z0-9-]\", \"\", regex=True)  # keep A-Z, a-z, 0-9 and hyphens\n",
    "        .str.lower()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23ce1382-e07f-4b91-984b-b1f9c1aec22c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\2973701663.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped[\"daysSinceLastPurchase_\" + item] = 0\n"
     ]
    }
   ],
   "source": [
    "# Transpose / group\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df[\"time\"] = df[\"time\"].astype(str)\n",
    "df = df.sort_values([\"date\", \"time\"])\n",
    "grouped = (df.groupby([\"date\", \"time\"])[\"item\"].apply(list).reset_index())\n",
    "\n",
    "# unique items\n",
    "unique_items = set()\n",
    "for item_list in grouped[\"item\"]:\n",
    "    for item in item_list:\n",
    "        unique_items.add(item)\n",
    "unique_items = sorted(unique_items)\n",
    "\n",
    "# create empty daysSince columns (all zero for now)\n",
    "for item in unique_items:\n",
    "    grouped[\"daysSinceLastPurchase_\" + item] = 0\n",
    "\n",
    "# ------------ NEW CODE YOU NEED HERE ------------\n",
    "# Fill the daysSinceLastPurchase columns\n",
    "for item in unique_items:\n",
    "    last_date_seen = None\n",
    "    values = []\n",
    "\n",
    "    for idx in range(len(grouped)):\n",
    "        current_date = grouped.iloc[idx][\"date\"]\n",
    "        items_this_trip = grouped.iloc[idx][\"item\"]\n",
    "\n",
    "        # If item purchased today  update last seen\n",
    "        if item in items_this_trip:\n",
    "            last_date_seen = current_date\n",
    "\n",
    "        # Compute days difference\n",
    "        if last_date_seen is None:\n",
    "            values.append(0)   # first occurrence  okay to use 0 as you decided\n",
    "        else:\n",
    "            days = (current_date - last_date_seen).days\n",
    "            values.append(days)\n",
    "\n",
    "    grouped[\"daysSinceLastPurchase_\" + item] = values\n",
    "# -------------------------------------------------\n",
    "\n",
    "# build index mapping\n",
    "item_to_index = {}\n",
    "for i in range(len(unique_items)):\n",
    "    item_to_index[unique_items[i]] = i\n",
    "\n",
    "##print(grouped.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "799584a6-c5d4-48cd-b2ed-c19fe88b291d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_items = len(unique_items)\n",
    "vectors = []\n",
    "\n",
    "for item_list in grouped[\"item\"]:\n",
    "    vector = np.zeros(num_items, dtype=np.int32)\n",
    "\n",
    "    for name in item_list:\n",
    "        index = item_to_index[name]\n",
    "        vector[index] = 1\n",
    "\n",
    "    vectors.append(vector)\n",
    "\n",
    "encoded_df = pd.DataFrame(vectors, columns=unique_items)\n",
    "days_cols = [c for c in grouped.columns if c.startswith(\"daysSinceLastPurchase_\")]\n",
    "\n",
    "encoded_df = pd.concat(\n",
    "    [grouped[[\"date\", \"time\"]], grouped[days_cols], encoded_df],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "#show_encoded(encoded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c662ca8e-a2ca-4d4b-87ca-11b282090299",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_20052\\822516727.py:3: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  encoded_df[\"dateTime\"] = pd.to_datetime(\n"
     ]
    }
   ],
   "source": [
    "# fix time date\n",
    "\n",
    "encoded_df[\"dateTime\"] = pd.to_datetime(\n",
    "    encoded_df[\"date\"].astype(str) + \" \" + encoded_df[\"time\"].astype(str),\n",
    "    errors=\"coerce\"\n",
    ")\n",
    "\n",
    "encoded_df = encoded_df.drop(columns=[\"date\", \"time\"])\n",
    "\n",
    "dt = encoded_df[\"dateTime\"]\n",
    "\n",
    "encoded_df[\"year\"]    = dt.dt.year\n",
    "encoded_df[\"month\"]   = dt.dt.month\n",
    "encoded_df[\"day\"]     = dt.dt.day\n",
    "encoded_df[\"hour\"]    = dt.dt.hour\n",
    "encoded_df[\"minute\"]  = dt.dt.minute\n",
    "encoded_df[\"dow\"]     = dt.dt.dayofweek\n",
    "encoded_df[\"doy\"]     = dt.dt.dayofyear\n",
    "encoded_df[\"quarter\"] = dt.dt.quarter\n",
    "\n",
    "\n",
    "encoded_df[\"hour_sin\"] = np.sin(2 * np.pi * encoded_df[\"hour\"] / 24.0)\n",
    "encoded_df[\"hour_cos\"] = np.cos(2 * np.pi * encoded_df[\"hour\"] / 24.0)\n",
    "\n",
    "encoded_df[\"minute_sin\"] = np.sin(2 * np.pi * encoded_df[\"minute\"] / 60.0)\n",
    "encoded_df[\"minute_cos\"] = np.cos(2 * np.pi * encoded_df[\"minute\"] / 60.0)\n",
    "\n",
    "encoded_df[\"dow_sin\"] = np.sin(2 * np.pi * encoded_df[\"dow\"] / 7.0)\n",
    "encoded_df[\"dow_cos\"] = np.cos(2 * np.pi * encoded_df[\"dow\"] / 7.0)\n",
    "encoded_df[\"month_sin\"] = np.sin(2 * np.pi * encoded_df[\"month\"] / 12.0)\n",
    "encoded_df[\"month_cos\"] = np.cos(2 * np.pi * encoded_df[\"month\"] / 12.0)\n",
    "\n",
    "encoded_df[\"doy_sin\"] = np.sin(2 * np.pi * encoded_df[\"doy\"] / 365.0)\n",
    "encoded_df[\"doy_cos\"] = np.cos(2 * np.pi * encoded_df[\"doy\"] / 365.0)\n",
    "\n",
    "cols_to_drop = [\"month\", \"hour\", \"minute\", \"dow\", \"doy\"]\n",
    "encoded_df = encoded_df.drop(columns=cols_to_drop)\n",
    "\n",
    "noncyc_cols = [\"year\", \"day\", \"quarter\"]\n",
    "\n",
    "for col in noncyc_cols:\n",
    "    mean = encoded_df[col].mean()\n",
    "    std = encoded_df[col].std()\n",
    "\n",
    "    if std == 0:\n",
    "        std = 1.0\n",
    "\n",
    "    encoded_df[col + \"_norm\"] = (encoded_df[col] - mean) / std\n",
    "\n",
    "encoded_df = encoded_df.drop(columns=[\"year\", \"day\", \"quarter\"])\n",
    "encoded_df = encoded_df.drop(columns=[\"dateTime\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099e75d1-6cb4-4e1c-939d-d9f79c9ee51e",
   "metadata": {},
   "source": [
    "# TRAIN !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7672fca-abf7-440c-a26e-6183edce256a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\.conda\\envs\\intercard-ml\\python.exe\n",
      "Epoch 1/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 163ms/step - auc: 0.5453 - bin_acc: 0.3700 - loss: 0.1975 - precision: 0.3308 - recall: 0.5494 - val_auc: 0.6463 - val_bin_acc: 0.3746 - val_loss: -1.1580 - val_precision: 0.4598 - val_recall: 0.6261\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.6603 - bin_acc: 0.4067 - loss: -0.9935 - precision: 0.4016 - recall: 0.6621 - val_auc: 0.7512 - val_bin_acc: 0.4155 - val_loss: -2.8593 - val_precision: 0.5390 - val_recall: 0.7278\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.7511 - bin_acc: 0.4376 - loss: -2.3324 - precision: 0.4622 - recall: 0.7584 - val_auc: 0.8265 - val_bin_acc: 0.4504 - val_loss: -4.9720 - val_precision: 0.6088 - val_recall: 0.8153\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.8162 - bin_acc: 0.4664 - loss: -4.0833 - precision: 0.5157 - recall: 0.8352 - val_auc: 0.8726 - val_bin_acc: 0.4742 - val_loss: -7.6049 - val_precision: 0.6565 - val_recall: 0.8742\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.8547 - bin_acc: 0.4899 - loss: -6.2097 - precision: 0.5594 - recall: 0.8939 - val_auc: 0.8971 - val_bin_acc: 0.4922 - val_loss: -10.9254 - val_precision: 0.6930 - val_recall: 0.9134\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.8716 - bin_acc: 0.5055 - loss: -8.7119 - precision: 0.5879 - recall: 0.9288 - val_auc: 0.9097 - val_bin_acc: 0.5037 - val_loss: -15.0716 - val_precision: 0.7156 - val_recall: 0.9353\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.8839 - bin_acc: 0.5118 - loss: -12.0055 - precision: 0.6007 - recall: 0.9469 - val_auc: 0.9172 - val_bin_acc: 0.5070 - val_loss: -20.2029 - val_precision: 0.7229 - val_recall: 0.9465\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.8905 - bin_acc: 0.5132 - loss: -16.0368 - precision: 0.6053 - recall: 0.9579 - val_auc: 0.9228 - val_bin_acc: 0.5078 - val_loss: -26.5995 - val_precision: 0.7259 - val_recall: 0.9549\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.8935 - bin_acc: 0.5137 - loss: -20.6588 - precision: 0.6073 - recall: 0.9630 - val_auc: 0.9275 - val_bin_acc: 0.5078 - val_loss: -34.4461 - val_precision: 0.7265 - val_recall: 0.9576\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.9024 - bin_acc: 0.5141 - loss: -27.0428 - precision: 0.6081 - recall: 0.9644 - val_auc: 0.9317 - val_bin_acc: 0.5081 - val_loss: -43.9298 - val_precision: 0.7270 - val_recall: 0.9576\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.9058 - bin_acc: 0.5142 - loss: -34.1670 - precision: 0.6084 - recall: 0.9647 - val_auc: 0.9354 - val_bin_acc: 0.5084 - val_loss: -55.4622 - val_precision: 0.7275 - val_recall: 0.9576\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.9114 - bin_acc: 0.5145 - loss: -43.1380 - precision: 0.6087 - recall: 0.9647 - val_auc: 0.9385 - val_bin_acc: 0.5084 - val_loss: -69.2200 - val_precision: 0.7275 - val_recall: 0.9576\n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - auc: 0.9136 - bin_acc: 0.5145 - loss: -53.3465 - precision: 0.6087 - recall: 0.9647 - val_auc: 0.9414 - val_bin_acc: 0.5083 - val_loss: -86.0826 - val_precision: 0.7272 - val_recall: 0.9576\n",
      "Epoch 14/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - auc: 0.9183 - bin_acc: 0.5143 - loss: -66.3462 - precision: 0.6085 - recall: 0.9647 - val_auc: 0.9437 - val_bin_acc: 0.5081 - val_loss: -106.4061 - val_precision: 0.7270 - val_recall: 0.9576\n",
      "Epoch 15/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.9218 - bin_acc: 0.5141 - loss: -81.3394 - precision: 0.6082 - recall: 0.9647 - val_auc: 0.9458 - val_bin_acc: 0.5081 - val_loss: -130.7813 - val_precision: 0.7270 - val_recall: 0.9576\n",
      "Epoch 16/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.9242 - bin_acc: 0.5140 - loss: -98.9847 - precision: 0.6082 - recall: 0.9648 - val_auc: 0.9476 - val_bin_acc: 0.5079 - val_loss: -159.6468 - val_precision: 0.7267 - val_recall: 0.9576\n",
      "Epoch 17/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.9281 - bin_acc: 0.5141 - loss: -120.4593 - precision: 0.6082 - recall: 0.9648 - val_auc: 0.9488 - val_bin_acc: 0.5079 - val_loss: -193.3659 - val_precision: 0.7267 - val_recall: 0.9576\n",
      "Epoch 18/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.9294 - bin_acc: 0.5142 - loss: -145.2665 - precision: 0.6084 - recall: 0.9648 - val_auc: 0.9491 - val_bin_acc: 0.5083 - val_loss: -232.3610 - val_precision: 0.7272 - val_recall: 0.9576\n",
      "Epoch 19/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.9285 - bin_acc: 0.5142 - loss: -174.5993 - precision: 0.6084 - recall: 0.9648 - val_auc: 0.9477 - val_bin_acc: 0.5083 - val_loss: -278.0775 - val_precision: 0.7272 - val_recall: 0.9576\n",
      "Epoch 20/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.9256 - bin_acc: 0.5143 - loss: -207.7789 - precision: 0.6085 - recall: 0.9648 - val_auc: 0.9423 - val_bin_acc: 0.5086 - val_loss: -331.7244 - val_precision: 0.7277 - val_recall: 0.9576\n",
      "Epoch 21/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.9203 - bin_acc: 0.5145 - loss: -245.1407 - precision: 0.6088 - recall: 0.9648 - val_auc: 0.9296 - val_bin_acc: 0.5087 - val_loss: -393.0916 - val_precision: 0.7280 - val_recall: 0.9576\n",
      "Epoch 22/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.9115 - bin_acc: 0.5146 - loss: -290.1271 - precision: 0.6088 - recall: 0.9648 - val_auc: 0.9168 - val_bin_acc: 0.5089 - val_loss: -461.6953 - val_precision: 0.7282 - val_recall: 0.9576\n",
      "Epoch 23/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.9029 - bin_acc: 0.5145 - loss: -342.6369 - precision: 0.6088 - recall: 0.9648 - val_auc: 0.9121 - val_bin_acc: 0.5087 - val_loss: -540.0090 - val_precision: 0.7280 - val_recall: 0.9576\n",
      "Epoch 24/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.8919 - bin_acc: 0.5144 - loss: -396.0545 - precision: 0.6086 - recall: 0.9648 - val_auc: 0.9106 - val_bin_acc: 0.5086 - val_loss: -630.0306 - val_precision: 0.7277 - val_recall: 0.9576\n",
      "Epoch 25/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.8795 - bin_acc: 0.5142 - loss: -460.0358 - precision: 0.6083 - recall: 0.9648 - val_auc: 0.9092 - val_bin_acc: 0.5079 - val_loss: -730.5240 - val_precision: 0.7267 - val_recall: 0.9576\n",
      "Epoch 26/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.8697 - bin_acc: 0.5140 - loss: -534.5234 - precision: 0.6081 - recall: 0.9648 - val_auc: 0.9051 - val_bin_acc: 0.5078 - val_loss: -842.6428 - val_precision: 0.7265 - val_recall: 0.9576\n",
      "Epoch 27/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.8628 - bin_acc: 0.5135 - loss: -616.9808 - precision: 0.6075 - recall: 0.9649 - val_auc: 0.8969 - val_bin_acc: 0.5070 - val_loss: -968.2302 - val_precision: 0.7253 - val_recall: 0.9581\n",
      "Epoch 28/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - auc: 0.8590 - bin_acc: 0.5129 - loss: -704.1377 - precision: 0.6068 - recall: 0.9651 - val_auc: 0.8892 - val_bin_acc: 0.5066 - val_loss: -1108.0339 - val_precision: 0.7248 - val_recall: 0.9581\n",
      "Epoch 29/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.8566 - bin_acc: 0.5125 - loss: -801.9634 - precision: 0.6062 - recall: 0.9651 - val_auc: 0.8850 - val_bin_acc: 0.5063 - val_loss: -1262.4200 - val_precision: 0.7244 - val_recall: 0.9581\n",
      "Epoch 30/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - auc: 0.8551 - bin_acc: 0.5124 - loss: -911.4509 - precision: 0.6061 - recall: 0.9651 - val_auc: 0.8838 - val_bin_acc: 0.5063 - val_loss: -1433.1115 - val_precision: 0.7245 - val_recall: 0.9585\n",
      "Epoch 31/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.8546 - bin_acc: 0.5124 - loss: -1030.8044 - precision: 0.6062 - recall: 0.9653 - val_auc: 0.8838 - val_bin_acc: 0.5068 - val_loss: -1620.2029 - val_precision: 0.7254 - val_recall: 0.9594\n",
      "Epoch 32/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - auc: 0.8545 - bin_acc: 0.5130 - loss: -1164.4847 - precision: 0.6070 - recall: 0.9653 - val_auc: 0.8836 - val_bin_acc: 0.5078 - val_loss: -1824.6588 - val_precision: 0.7267 - val_recall: 0.9585\n",
      "Epoch 33/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.8544 - bin_acc: 0.5135 - loss: -1305.1642 - precision: 0.6076 - recall: 0.9651 - val_auc: 0.8838 - val_bin_acc: 0.5086 - val_loss: -2045.7441 - val_precision: 0.7278 - val_recall: 0.9581\n",
      "Epoch 34/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - auc: 0.8543 - bin_acc: 0.5142 - loss: -1464.3312 - precision: 0.6084 - recall: 0.9649 - val_auc: 0.8838 - val_bin_acc: 0.5089 - val_loss: -2285.2466 - val_precision: 0.7282 - val_recall: 0.9576\n",
      "Epoch 35/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.8543 - bin_acc: 0.5148 - loss: -1640.5551 - precision: 0.6091 - recall: 0.9649 - val_auc: 0.8839 - val_bin_acc: 0.5087 - val_loss: -2548.8779 - val_precision: 0.7280 - val_recall: 0.9576\n",
      "Epoch 36/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.8543 - bin_acc: 0.5142 - loss: -1833.6537 - precision: 0.6084 - recall: 0.9649 - val_auc: 0.8839 - val_bin_acc: 0.5078 - val_loss: -2838.4680 - val_precision: 0.7266 - val_recall: 0.9581\n",
      "Epoch 37/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - auc: 0.8541 - bin_acc: 0.5135 - loss: -2022.3522 - precision: 0.6076 - recall: 0.9651 - val_auc: 0.8839 - val_bin_acc: 0.5071 - val_loss: -3158.3840 - val_precision: 0.7256 - val_recall: 0.9581\n",
      "Epoch 38/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - auc: 0.8540 - bin_acc: 0.5131 - loss: -2243.0645 - precision: 0.6071 - recall: 0.9651 - val_auc: 0.8839 - val_bin_acc: 0.5070 - val_loss: -3500.1533 - val_precision: 0.7253 - val_recall: 0.9581\n",
      "Epoch 39/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - auc: 0.8539 - bin_acc: 0.5131 - loss: -2486.1550 - precision: 0.6070 - recall: 0.9651 - val_auc: 0.8838 - val_bin_acc: 0.5066 - val_loss: -3861.4392 - val_precision: 0.7249 - val_recall: 0.9585\n",
      "Epoch 40/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - auc: 0.8538 - bin_acc: 0.5115 - loss: -2740.7563 - precision: 0.6051 - recall: 0.9653 - val_auc: 0.8835 - val_bin_acc: 0.5023 - val_loss: -4252.4053 - val_precision: 0.7189 - val_recall: 0.9607\n",
      "Epoch 41/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.8537 - bin_acc: 0.5077 - loss: -3007.4663 - precision: 0.6006 - recall: 0.9665 - val_auc: 0.8833 - val_bin_acc: 0.5003 - val_loss: -4674.2959 - val_precision: 0.7161 - val_recall: 0.9612\n",
      "Epoch 42/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - auc: 0.8537 - bin_acc: 0.5074 - loss: -3317.1460 - precision: 0.6003 - recall: 0.9665 - val_auc: 0.8828 - val_bin_acc: 0.5029 - val_loss: -5120.6191 - val_precision: 0.7198 - val_recall: 0.9607\n",
      "Epoch 43/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.8538 - bin_acc: 0.5102 - loss: -3622.1880 - precision: 0.6036 - recall: 0.9663 - val_auc: 0.8828 - val_bin_acc: 0.5062 - val_loss: -5601.2109 - val_precision: 0.7245 - val_recall: 0.9598\n",
      "Epoch 44/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.8538 - bin_acc: 0.5127 - loss: -3955.7581 - precision: 0.6066 - recall: 0.9650 - val_auc: 0.8826 - val_bin_acc: 0.5078 - val_loss: -6111.1060 - val_precision: 0.7266 - val_recall: 0.9581\n",
      "Epoch 45/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.8538 - bin_acc: 0.5129 - loss: -4312.8330 - precision: 0.6068 - recall: 0.9653 - val_auc: 0.8822 - val_bin_acc: 0.5039 - val_loss: -6653.9053 - val_precision: 0.7213 - val_recall: 0.9607\n",
      "Epoch 46/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - auc: 0.8536 - bin_acc: 0.5096 - loss: -4682.1704 - precision: 0.6029 - recall: 0.9665 - val_auc: 0.8817 - val_bin_acc: 0.5002 - val_loss: -7234.9839 - val_precision: 0.7159 - val_recall: 0.9616\n",
      "Epoch 47/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - auc: 0.8532 - bin_acc: 0.5063 - loss: -5093.3174 - precision: 0.5990 - recall: 0.9668 - val_auc: 0.8817 - val_bin_acc: 0.5011 - val_loss: -7846.2725 - val_precision: 0.7174 - val_recall: 0.9616\n",
      "Epoch 48/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - auc: 0.8532 - bin_acc: 0.5086 - loss: -5517.3262 - precision: 0.6017 - recall: 0.9664 - val_auc: 0.8818 - val_bin_acc: 0.5053 - val_loss: -8496.2871 - val_precision: 0.7232 - val_recall: 0.9616\n",
      "Epoch 49/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.8531 - bin_acc: 0.5108 - loss: -5976.1353 - precision: 0.6042 - recall: 0.9662 - val_auc: 0.8818 - val_bin_acc: 0.5049 - val_loss: -9178.7383 - val_precision: 0.7227 - val_recall: 0.9607\n",
      "Epoch 50/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - auc: 0.8530 - bin_acc: 0.5099 - loss: -6458.4385 - precision: 0.6033 - recall: 0.9660 - val_auc: 0.8816 - val_bin_acc: 0.5036 - val_loss: -9898.6230 - val_precision: 0.7208 - val_recall: 0.9607\n"
     ]
    }
   ],
   "source": [
    "time_feature_cols = [\n",
    "    \"hour_sin\", \"hour_cos\",\n",
    "    \"minute_sin\", \"minute_cos\",\n",
    "    \"dow_sin\", \"dow_cos\",\n",
    "    \"month_sin\", \"month_cos\",\n",
    "    \"doy_sin\", \"doy_cos\",\n",
    "    \"year_norm\", \"day_norm\", \"quarter_norm\",\n",
    "]\n",
    "\n",
    "exclude = set(time_feature_cols + [\"date\", \"time\", \"dateTime\"])  # whatever time/meta cols still exist\n",
    "item_cols = [c for c in encoded_df.columns if c not in exclude]\n",
    "\n",
    "X = encoded_df[time_feature_cols].to_numpy(dtype=np.float32)   # shape: (num_trips, num_time_features)\n",
    "y = encoded_df[item_cols].to_numpy(dtype=np.float32)          # shape: (num_trips, num_items)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,       # 20% test set\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "import sys\n",
    "print(sys.executable)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "input_dim = X_train.shape[1]     # number of time features ( 13)\n",
    "output_dim = y_train.shape[1]    # number of items\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(input_dim,)),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(output_dim, activation=\"sigmoid\")  \n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\n",
    "        tf.keras.metrics.BinaryAccuracy(threshold=0.5, name=\"bin_acc\"),\n",
    "        tf.keras.metrics.AUC(curve=\"ROC\", name=\"auc\"),\n",
    "        tf.keras.metrics.Precision(name=\"precision\"),\n",
    "        tf.keras.metrics.Recall(name=\"recall\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3fd429-c69f-4a7b-a455-6235a92ab9c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
