{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f94e9fd3-99b1-438c-9ac0-6d5455c99af4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pdb;\n",
    "from grocery_ml_tensorflow import GroceryML\n",
    "from grocery_ml_core import GroceryMLCore\n",
    "from hidden_layer_param_builder import HiddenLayerParamSetBuilder\n",
    "import tensorflow as tf\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option(\"display.float_format\", lambda x: f\"{x:.6f}\")\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", 2000)\n",
    "\n",
    "print(os.getcwd())\n",
    "# print(\"GPUs Available:\", tf.config.list_physical_devices('GPU'))\n",
    "#tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# def run_all_experiments(df, model_param_sets, output_dir):\n",
    "#     total = len(model_param_sets)\n",
    "#     print(f\"run_all_experiments() when: {datetime.now()}  output_dir: {output_dir}\");\n",
    "#     for index, params in enumerate(model_param_sets, 1):\n",
    "#         print(f\"Running Exp {index}/{total}...\")\n",
    "#         groceryML.run_experiment(df,  params[\"buildParams\"], params[\"trainParams\"], output_dir)\n",
    "\n",
    "\n",
    "try:\n",
    "    groceryML = GroceryML();\n",
    "    groceryMLCore = GroceryMLCore();\n",
    "    groceryML.build_training_df()\n",
    "    if groceryML.training_df is None:\n",
    "        raise();\n",
    "    ts = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "    # groceryML.training_df.to_csv(f\"training_df-{ts}.csv\");\n",
    "except Exception as ex: \n",
    "    print(ex)\n",
    "    ts = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "    groceryML.training_df.to_csv(f\"training_df-{ts}-exception.csv\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4722275b-46b7-4fd3-8e11-4148a6f0fb4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-15 00:37:35,993] A new study created in RDB with name: study-no-itemPurchaseCount-20260115_003731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-0\\e100_l64-64-64-64-64_ep380_sig_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-0\\e100_l64-64-64-64-64_ep380_sig_  \n",
      "run_experiment()  when: 2026-01-15 00:37:36.339264 params: {'epochs': 380, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 00:38:09.573974\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-0\\e100_l64-64-64-64-64_ep380_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep380_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-0\\e100_l64-64-64-64-64_ep380_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep380_sig_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-0\\e100_l64-64-64-64-64_ep380_sig_\\predictions-e100_l64-64-64-64-64_ep380_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-0\\e100_l64-64-64-64-64_ep380_sig_\\predictions-e100_l64-64-64-64-64_ep380_sig_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-0\\e100_l64-64-64-64-64_ep380_sig_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-0\\e100_l64-64-64-64-64_ep380_sig_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-0\\e100_l64-64-64-64-64_ep380_sig_\\model\\assets\n",
      "[I 2026-01-15 00:39:03,020] Trial 0 finished with value: 0.8961786031723022 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 64, 'embedding_dim': 100, 'epochs': 380}. Best is trial 0 with value: 0.8961786031723022.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-0\\e100_l64-64-64-64-64_ep380_sig_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-0\\e100_l64-64-64-64-64_ep380_sig_\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-1\\e100_l64-64-64_ep290_sig_402\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-1\\e100_l64-64-64_ep290_sig_402  \n",
      "run_experiment()  when: 2026-01-15 00:39:03.178130 params: {'epochs': 290, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 00:39:47.328512\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-1\\e100_l64-64-64_ep290_sig_402\\normalized_training_df-e100_l64-64-64_ep290_sig_402.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-1\\e100_l64-64-64_ep290_sig_402\\normalized_training_df-e100_l64-64-64_ep290_sig_402.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-1\\e100_l64-64-64_ep290_sig_402\\predictions-e100_l64-64-64_ep290_sig_402.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-1\\e100_l64-64-64_ep290_sig_402\\predictions-e100_l64-64-64_ep290_sig_402.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-1\\e100_l64-64-64_ep290_sig_402\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-1\\e100_l64-64-64_ep290_sig_402\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-1\\e100_l64-64-64_ep290_sig_402\\model\\assets\n",
      "[I 2026-01-15 00:41:49,749] Trial 1 finished with value: 0.8897231221199036 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 100, 'epochs': 290}. Best is trial 0 with value: 0.8961786031723022.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-1\\e100_l64-64-64_ep290_sig_402\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-1\\e100_l64-64-64_ep290_sig_402\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-2\\e100_l64-64-64-64-64_ep190_sig_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-2\\e100_l64-64-64-64-64_ep190_sig_  \n",
      "run_experiment()  when: 2026-01-15 00:41:49.788289 params: {'epochs': 190, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 00:41:59.823047\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 800us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-2\\e100_l64-64-64-64-64_ep190_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep190_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-2\\e100_l64-64-64-64-64_ep190_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep190_sig_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-2\\e100_l64-64-64-64-64_ep190_sig_\\predictions-e100_l64-64-64-64-64_ep190_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-2\\e100_l64-64-64-64-64_ep190_sig_\\predictions-e100_l64-64-64-64-64_ep190_sig_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-2\\e100_l64-64-64-64-64_ep190_sig_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-2\\e100_l64-64-64-64-64_ep190_sig_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-2\\e100_l64-64-64-64-64_ep190_sig_\\model\\assets\n",
      "[I 2026-01-15 00:43:55,179] Trial 2 finished with value: 0.9020178318023682 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 64, 'embedding_dim': 100, 'epochs': 190}. Best is trial 2 with value: 0.9020178318023682.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-2\\e100_l64-64-64-64-64_ep190_sig_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-2\\e100_l64-64-64-64-64_ep190_sig_\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-3\\e100_l64-64-64-64-64_ep405_sig_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-3\\e100_l64-64-64-64-64_ep405_sig_  \n",
      "run_experiment()  when: 2026-01-15 00:43:55.212012 params: {'epochs': 405, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 00:44:41.272635\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-3\\e100_l64-64-64-64-64_ep405_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep405_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-3\\e100_l64-64-64-64-64_ep405_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep405_sig_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-3\\e100_l64-64-64-64-64_ep405_sig_\\predictions-e100_l64-64-64-64-64_ep405_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-3\\e100_l64-64-64-64-64_ep405_sig_\\predictions-e100_l64-64-64-64-64_ep405_sig_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-3\\e100_l64-64-64-64-64_ep405_sig_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-3\\e100_l64-64-64-64-64_ep405_sig_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-3\\e100_l64-64-64-64-64_ep405_sig_\\model\\assets\n",
      "[I 2026-01-15 00:47:03,857] Trial 3 finished with value: 0.8813118934631348 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 64, 'embedding_dim': 100, 'epochs': 405}. Best is trial 2 with value: 0.9020178318023682.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-3\\e100_l64-64-64-64-64_ep405_sig_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-3\\e100_l64-64-64-64-64_ep405_sig_\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-4\\e100_l64-64-64_ep310_sig_204\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-4\\e100_l64-64-64_ep310_sig_204  \n",
      "run_experiment()  when: 2026-01-15 00:47:03.889982 params: {'epochs': 310, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 00:47:12.731800\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 0s/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-4\\e100_l64-64-64_ep310_sig_204\\normalized_training_df-e100_l64-64-64_ep310_sig_204.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-4\\e100_l64-64-64_ep310_sig_204\\normalized_training_df-e100_l64-64-64_ep310_sig_204.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-4\\e100_l64-64-64_ep310_sig_204\\predictions-e100_l64-64-64_ep310_sig_204.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-4\\e100_l64-64-64_ep310_sig_204\\predictions-e100_l64-64-64_ep310_sig_204.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-4\\e100_l64-64-64_ep310_sig_204\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-4\\e100_l64-64-64_ep310_sig_204\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-4\\e100_l64-64-64_ep310_sig_204\\model\\assets\n",
      "[I 2026-01-15 00:49:05,463] Trial 4 finished with value: 0.8957012295722961 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 100, 'epochs': 310}. Best is trial 2 with value: 0.9020178318023682.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-4\\e100_l64-64-64_ep310_sig_204\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-4\\e100_l64-64-64_ep310_sig_204\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-5\\e100_l64-64-64-64-64-64_ep45_si\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-5\\e100_l64-64-64-64-64-64_ep45_si  \n",
      "run_experiment()  when: 2026-01-15 00:49:05.523649 params: {'epochs': 45, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 00:49:51.760781\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 0s/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-5\\e100_l64-64-64-64-64-64_ep45_si\\normalized_training_df-e100_l64-64-64-64-64-64_ep45_si.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-5\\e100_l64-64-64-64-64-64_ep45_si\\normalized_training_df-e100_l64-64-64-64-64-64_ep45_si.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-5\\e100_l64-64-64-64-64-64_ep45_si\\predictions-e100_l64-64-64-64-64-64_ep45_si.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-5\\e100_l64-64-64-64-64-64_ep45_si\\predictions-e100_l64-64-64-64-64-64_ep45_si.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-5\\e100_l64-64-64-64-64-64_ep45_si\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-5\\e100_l64-64-64-64-64-64_ep45_si\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-5\\e100_l64-64-64-64-64-64_ep45_si\\model\\assets\n",
      "[I 2026-01-15 00:53:06,923] Trial 5 finished with value: 0.8554713129997253 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 45}. Best is trial 2 with value: 0.9020178318023682.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-5\\e100_l64-64-64-64-64-64_ep45_si\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-5\\e100_l64-64-64-64-64-64_ep45_si\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-6\\e100_l64-64-64-64_ep445_sig_378\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-6\\e100_l64-64-64-64_ep445_sig_378  \n",
      "run_experiment()  when: 2026-01-15 00:53:07.169128 params: {'epochs': 445, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 00:53:36.673784\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-6\\e100_l64-64-64-64_ep445_sig_378\\normalized_training_df-e100_l64-64-64-64_ep445_sig_378.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-6\\e100_l64-64-64-64_ep445_sig_378\\normalized_training_df-e100_l64-64-64-64_ep445_sig_378.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-6\\e100_l64-64-64-64_ep445_sig_378\\predictions-e100_l64-64-64-64_ep445_sig_378.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-6\\e100_l64-64-64-64_ep445_sig_378\\predictions-e100_l64-64-64-64_ep445_sig_378.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-6\\e100_l64-64-64-64_ep445_sig_378\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-6\\e100_l64-64-64-64_ep445_sig_378\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-6\\e100_l64-64-64-64_ep445_sig_378\\model\\assets\n",
      "[I 2026-01-15 00:54:40,953] Trial 6 finished with value: 0.8729562163352966 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 445}. Best is trial 2 with value: 0.9020178318023682.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-6\\e100_l64-64-64-64_ep445_sig_378\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-6\\e100_l64-64-64-64_ep445_sig_378\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-7\\e100_l64-64-64-64-64-64_ep140_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-7\\e100_l64-64-64-64-64-64_ep140_s  \n",
      "run_experiment()  when: 2026-01-15 00:54:41.179537 params: {'epochs': 140, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 00:55:35.164955\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 5ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-7\\e100_l64-64-64-64-64-64_ep140_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep140_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-7\\e100_l64-64-64-64-64-64_ep140_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep140_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-7\\e100_l64-64-64-64-64-64_ep140_s\\predictions-e100_l64-64-64-64-64-64_ep140_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-7\\e100_l64-64-64-64-64-64_ep140_s\\predictions-e100_l64-64-64-64-64-64_ep140_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-7\\e100_l64-64-64-64-64-64_ep140_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-7\\e100_l64-64-64-64-64-64_ep140_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-7\\e100_l64-64-64-64-64-64_ep140_s\\model\\assets\n",
      "[I 2026-01-15 00:59:55,104] Trial 7 finished with value: 0.9002845883369446 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 140}. Best is trial 2 with value: 0.9020178318023682.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-7\\e100_l64-64-64-64-64-64_ep140_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-7\\e100_l64-64-64-64-64-64_ep140_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-8\\e100_l64-64-64_ep30_sig_786\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-8\\e100_l64-64-64_ep30_sig_786  \n",
      "run_experiment()  when: 2026-01-15 00:59:55.352067 params: {'epochs': 30, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 01:01:09.772312\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 4ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-8\\e100_l64-64-64_ep30_sig_786\\normalized_training_df-e100_l64-64-64_ep30_sig_786.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-8\\e100_l64-64-64_ep30_sig_786\\normalized_training_df-e100_l64-64-64_ep30_sig_786.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-8\\e100_l64-64-64_ep30_sig_786\\predictions-e100_l64-64-64_ep30_sig_786.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-8\\e100_l64-64-64_ep30_sig_786\\predictions-e100_l64-64-64_ep30_sig_786.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-8\\e100_l64-64-64_ep30_sig_786\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-8\\e100_l64-64-64_ep30_sig_786\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-8\\e100_l64-64-64_ep30_sig_786\\model\\assets\n",
      "[I 2026-01-15 01:04:30,484] Trial 8 finished with value: 0.8907934427261353 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 100, 'epochs': 30}. Best is trial 2 with value: 0.9020178318023682.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-8\\e100_l64-64-64_ep30_sig_786\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-8\\e100_l64-64-64_ep30_sig_786\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-9\\e100_l64-64-64-64-64_ep260_sig_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-9\\e100_l64-64-64-64-64_ep260_sig_  \n",
      "run_experiment()  when: 2026-01-15 01:04:30.518326 params: {'epochs': 260, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 01:04:41.877343\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 800us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-9\\e100_l64-64-64-64-64_ep260_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep260_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-9\\e100_l64-64-64-64-64_ep260_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep260_sig_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-9\\e100_l64-64-64-64-64_ep260_sig_\\predictions-e100_l64-64-64-64-64_ep260_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-9\\e100_l64-64-64-64-64_ep260_sig_\\predictions-e100_l64-64-64-64-64_ep260_sig_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-9\\e100_l64-64-64-64-64_ep260_sig_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-9\\e100_l64-64-64-64-64_ep260_sig_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-9\\e100_l64-64-64-64-64_ep260_sig_\\model\\assets\n",
      "[I 2026-01-15 01:06:16,071] Trial 9 finished with value: 0.898769199848175 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 64, 'embedding_dim': 100, 'epochs': 260}. Best is trial 2 with value: 0.9020178318023682.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-9\\e100_l64-64-64-64-64_ep260_sig_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-9\\e100_l64-64-64-64-64_ep260_sig_\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-10\\e100_l64-64-64-64_ep155_sig_764\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-10\\e100_l64-64-64-64_ep155_sig_764  \n",
      "run_experiment()  when: 2026-01-15 01:06:16.339346 params: {'epochs': 155, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 01:07:12.240627\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-10\\e100_l64-64-64-64_ep155_sig_764\\normalized_training_df-e100_l64-64-64-64_ep155_sig_764.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-10\\e100_l64-64-64-64_ep155_sig_764\\normalized_training_df-e100_l64-64-64-64_ep155_sig_764.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-10\\e100_l64-64-64-64_ep155_sig_764\\predictions-e100_l64-64-64-64_ep155_sig_764.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-10\\e100_l64-64-64-64_ep155_sig_764\\predictions-e100_l64-64-64-64_ep155_sig_764.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-10\\e100_l64-64-64-64_ep155_sig_764\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-10\\e100_l64-64-64-64_ep155_sig_764\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-10\\e100_l64-64-64-64_ep155_sig_764\\model\\assets\n",
      "[I 2026-01-15 01:10:50,523] Trial 10 finished with value: 0.8947511911392212 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 155}. Best is trial 2 with value: 0.9020178318023682.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-10\\e100_l64-64-64-64_ep155_sig_764\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-10\\e100_l64-64-64-64_ep155_sig_764\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-11\\e100_l64-64-64-64-64-64_ep160_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-11\\e100_l64-64-64-64-64-64_ep160_s  \n",
      "run_experiment()  when: 2026-01-15 01:10:50.790109 params: {'epochs': 160, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 01:11:58.509976\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 800us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-11\\e100_l64-64-64-64-64-64_ep160_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep160_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-11\\e100_l64-64-64-64-64-64_ep160_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep160_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-11\\e100_l64-64-64-64-64-64_ep160_s\\predictions-e100_l64-64-64-64-64-64_ep160_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-11\\e100_l64-64-64-64-64-64_ep160_s\\predictions-e100_l64-64-64-64-64-64_ep160_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-11\\e100_l64-64-64-64-64-64_ep160_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-11\\e100_l64-64-64-64-64-64_ep160_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-11\\e100_l64-64-64-64-64-64_ep160_s\\model\\assets\n",
      "[I 2026-01-15 01:14:00,338] Trial 11 finished with value: 0.9066194891929626 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 160}. Best is trial 11 with value: 0.9066194891929626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-11\\e100_l64-64-64-64-64-64_ep160_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-11\\e100_l64-64-64-64-64-64_ep160_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-12\\e100_l64-64-64-64-64-64_ep160_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-12\\e100_l64-64-64-64-64-64_ep160_s  \n",
      "run_experiment()  when: 2026-01-15 01:14:00.377686 params: {'epochs': 160, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 01:14:12.207887\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 9ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-12\\e100_l64-64-64-64-64-64_ep160_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep160_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-12\\e100_l64-64-64-64-64-64_ep160_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep160_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-12\\e100_l64-64-64-64-64-64_ep160_s\\predictions-e100_l64-64-64-64-64-64_ep160_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-12\\e100_l64-64-64-64-64-64_ep160_s\\predictions-e100_l64-64-64-64-64-64_ep160_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-12\\e100_l64-64-64-64-64-64_ep160_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-12\\e100_l64-64-64-64-64-64_ep160_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-12\\e100_l64-64-64-64-64-64_ep160_s\\model\\assets\n",
      "[I 2026-01-15 01:17:08,510] Trial 12 finished with value: 0.8869611024856567 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 160}. Best is trial 11 with value: 0.9066194891929626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-12\\e100_l64-64-64-64-64-64_ep160_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-12\\e100_l64-64-64-64-64-64_ep160_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-13\\e100_l64-64-64-64-64-64_ep215_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-13\\e100_l64-64-64-64-64-64_ep215_s  \n",
      "run_experiment()  when: 2026-01-15 01:17:08.732670 params: {'epochs': 215, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 01:18:05.553799\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 6ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-13\\e100_l64-64-64-64-64-64_ep215_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep215_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-13\\e100_l64-64-64-64-64-64_ep215_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep215_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-13\\e100_l64-64-64-64-64-64_ep215_s\\predictions-e100_l64-64-64-64-64-64_ep215_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-13\\e100_l64-64-64-64-64-64_ep215_s\\predictions-e100_l64-64-64-64-64-64_ep215_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-13\\e100_l64-64-64-64-64-64_ep215_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-13\\e100_l64-64-64-64-64-64_ep215_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-13\\e100_l64-64-64-64-64-64_ep215_s\\model\\assets\n",
      "[I 2026-01-15 01:21:44,893] Trial 13 finished with value: 0.8737117648124695 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 215}. Best is trial 11 with value: 0.9066194891929626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-13\\e100_l64-64-64-64-64-64_ep215_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-13\\e100_l64-64-64-64-64-64_ep215_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-14\\e100_l64-64-64-64-64_ep100_sig_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-14\\e100_l64-64-64-64-64_ep100_sig_  \n",
      "run_experiment()  when: 2026-01-15 01:21:44.930794 params: {'epochs': 100, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 01:21:56.190892\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-14\\e100_l64-64-64-64-64_ep100_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep100_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-14\\e100_l64-64-64-64-64_ep100_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep100_sig_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-14\\e100_l64-64-64-64-64_ep100_sig_\\predictions-e100_l64-64-64-64-64_ep100_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-14\\e100_l64-64-64-64-64_ep100_sig_\\predictions-e100_l64-64-64-64-64_ep100_sig_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-14\\e100_l64-64-64-64-64_ep100_sig_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-14\\e100_l64-64-64-64-64_ep100_sig_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-14\\e100_l64-64-64-64-64_ep100_sig_\\model\\assets\n",
      "[I 2026-01-15 01:23:18,758] Trial 14 finished with value: 0.8839163184165955 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 64, 'embedding_dim': 100, 'epochs': 100}. Best is trial 11 with value: 0.9066194891929626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-14\\e100_l64-64-64-64-64_ep100_sig_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-14\\e100_l64-64-64-64-64_ep100_sig_\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-15\\e100_l64-64-64-64_ep195_sig_184\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-15\\e100_l64-64-64-64_ep195_sig_184  \n",
      "run_experiment()  when: 2026-01-15 01:23:18.799835 params: {'epochs': 195, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 01:24:22.834018\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-15\\e100_l64-64-64-64_ep195_sig_184\\normalized_training_df-e100_l64-64-64-64_ep195_sig_184.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-15\\e100_l64-64-64-64_ep195_sig_184\\normalized_training_df-e100_l64-64-64-64_ep195_sig_184.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-15\\e100_l64-64-64-64_ep195_sig_184\\predictions-e100_l64-64-64-64_ep195_sig_184.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-15\\e100_l64-64-64-64_ep195_sig_184\\predictions-e100_l64-64-64-64_ep195_sig_184.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-15\\e100_l64-64-64-64_ep195_sig_184\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-15\\e100_l64-64-64-64_ep195_sig_184\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-15\\e100_l64-64-64-64_ep195_sig_184\\model\\assets\n",
      "[I 2026-01-15 01:28:05,188] Trial 15 finished with value: 0.8868035078048706 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 195}. Best is trial 11 with value: 0.9066194891929626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-15\\e100_l64-64-64-64_ep195_sig_184\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-15\\e100_l64-64-64-64_ep195_sig_184\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-16\\e100_l64-64-64-64-64-64_ep100_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-16\\e100_l64-64-64-64-64-64_ep100_s  \n",
      "run_experiment()  when: 2026-01-15 01:28:05.484133 params: {'epochs': 100, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 01:29:23.546591\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-16\\e100_l64-64-64-64-64-64_ep100_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep100_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-16\\e100_l64-64-64-64-64-64_ep100_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep100_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-16\\e100_l64-64-64-64-64-64_ep100_s\\predictions-e100_l64-64-64-64-64-64_ep100_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-16\\e100_l64-64-64-64-64-64_ep100_s\\predictions-e100_l64-64-64-64-64-64_ep100_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-16\\e100_l64-64-64-64-64-64_ep100_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-16\\e100_l64-64-64-64-64-64_ep100_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-16\\e100_l64-64-64-64-64-64_ep100_s\\model\\assets\n",
      "[I 2026-01-15 01:31:04,943] Trial 16 finished with value: 0.890784502029419 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 100}. Best is trial 11 with value: 0.9066194891929626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-16\\e100_l64-64-64-64-64-64_ep100_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-16\\e100_l64-64-64-64-64-64_ep100_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-17\\e100_l64-64-64-64-64_ep230_sig_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-17\\e100_l64-64-64-64-64_ep230_sig_  \n",
      "run_experiment()  when: 2026-01-15 01:31:04.983130 params: {'epochs': 230, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 01:31:16.459091\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-17\\e100_l64-64-64-64-64_ep230_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep230_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-17\\e100_l64-64-64-64-64_ep230_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep230_sig_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-17\\e100_l64-64-64-64-64_ep230_sig_\\predictions-e100_l64-64-64-64-64_ep230_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-17\\e100_l64-64-64-64-64_ep230_sig_\\predictions-e100_l64-64-64-64-64_ep230_sig_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-17\\e100_l64-64-64-64-64_ep230_sig_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-17\\e100_l64-64-64-64-64_ep230_sig_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-17\\e100_l64-64-64-64-64_ep230_sig_\\model\\assets\n",
      "[I 2026-01-15 01:34:40,920] Trial 17 finished with value: 0.8706715703010559 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 64, 'embedding_dim': 100, 'epochs': 230}. Best is trial 11 with value: 0.9066194891929626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-17\\e100_l64-64-64-64-64_ep230_sig_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-17\\e100_l64-64-64-64-64_ep230_sig_\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-18\\e100_l64-64-64-64-64-64_ep315_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-18\\e100_l64-64-64-64-64-64_ep315_s  \n",
      "run_experiment()  when: 2026-01-15 01:34:41.228262 params: {'epochs': 315, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 01:35:39.912762\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 4ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-18\\e100_l64-64-64-64-64-64_ep315_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep315_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-18\\e100_l64-64-64-64-64-64_ep315_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep315_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-18\\e100_l64-64-64-64-64-64_ep315_s\\predictions-e100_l64-64-64-64-64-64_ep315_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-18\\e100_l64-64-64-64-64-64_ep315_s\\predictions-e100_l64-64-64-64-64-64_ep315_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-18\\e100_l64-64-64-64-64-64_ep315_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-18\\e100_l64-64-64-64-64-64_ep315_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-18\\e100_l64-64-64-64-64-64_ep315_s\\model\\assets\n",
      "[I 2026-01-15 01:39:37,769] Trial 18 finished with value: 0.8808159828186035 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 315}. Best is trial 11 with value: 0.9066194891929626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-18\\e100_l64-64-64-64-64-64_ep315_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-18\\e100_l64-64-64-64-64-64_ep315_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-19\\e100_l64-64-64-64-64_ep500_sig_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-19\\e100_l64-64-64-64-64_ep500_sig_  \n",
      "run_experiment()  when: 2026-01-15 01:39:38.030771 params: {'epochs': 500, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 01:39:54.842337\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-19\\e100_l64-64-64-64-64_ep500_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep500_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-19\\e100_l64-64-64-64-64_ep500_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep500_sig_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-19\\e100_l64-64-64-64-64_ep500_sig_\\predictions-e100_l64-64-64-64-64_ep500_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-19\\e100_l64-64-64-64-64_ep500_sig_\\predictions-e100_l64-64-64-64-64_ep500_sig_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-19\\e100_l64-64-64-64-64_ep500_sig_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-19\\e100_l64-64-64-64-64_ep500_sig_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-19\\e100_l64-64-64-64-64_ep500_sig_\\model\\assets\n",
      "[I 2026-01-15 01:40:54,202] Trial 19 finished with value: 0.8924571871757507 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 64, 'embedding_dim': 100, 'epochs': 500}. Best is trial 11 with value: 0.9066194891929626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-19\\e100_l64-64-64-64-64_ep500_sig_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-19\\e100_l64-64-64-64-64_ep500_sig_\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-20\\e100_l64-64-64-64_ep90_sig_572\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-20\\e100_l64-64-64-64_ep90_sig_572  \n",
      "run_experiment()  when: 2026-01-15 01:40:54.249117 params: {'epochs': 90, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 01:41:38.520882\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-20\\e100_l64-64-64-64_ep90_sig_572\\normalized_training_df-e100_l64-64-64-64_ep90_sig_572.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-20\\e100_l64-64-64-64_ep90_sig_572\\normalized_training_df-e100_l64-64-64-64_ep90_sig_572.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-20\\e100_l64-64-64-64_ep90_sig_572\\predictions-e100_l64-64-64-64_ep90_sig_572.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-20\\e100_l64-64-64-64_ep90_sig_572\\predictions-e100_l64-64-64-64_ep90_sig_572.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-20\\e100_l64-64-64-64_ep90_sig_572\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-20\\e100_l64-64-64-64_ep90_sig_572\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-20\\e100_l64-64-64-64_ep90_sig_572\\model\\assets\n",
      "[I 2026-01-15 01:43:04,387] Trial 20 finished with value: 0.8838701248168945 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 90}. Best is trial 11 with value: 0.9066194891929626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-20\\e100_l64-64-64-64_ep90_sig_572\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-20\\e100_l64-64-64-64_ep90_sig_572\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-21\\e100_l64-64-64-64-64-64_ep160_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-21\\e100_l64-64-64-64-64-64_ep160_s  \n",
      "run_experiment()  when: 2026-01-15 01:43:04.427262 params: {'epochs': 160, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 01:43:16.605524\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 10ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-21\\e100_l64-64-64-64-64-64_ep160_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep160_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-21\\e100_l64-64-64-64-64-64_ep160_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep160_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-21\\e100_l64-64-64-64-64-64_ep160_s\\predictions-e100_l64-64-64-64-64-64_ep160_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-21\\e100_l64-64-64-64-64-64_ep160_s\\predictions-e100_l64-64-64-64-64-64_ep160_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-21\\e100_l64-64-64-64-64-64_ep160_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-21\\e100_l64-64-64-64-64-64_ep160_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-21\\e100_l64-64-64-64-64-64_ep160_s\\model\\assets\n",
      "[I 2026-01-15 01:46:53,610] Trial 21 finished with value: 0.8874385356903076 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 160}. Best is trial 11 with value: 0.9066194891929626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-21\\e100_l64-64-64-64-64-64_ep160_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-21\\e100_l64-64-64-64-64-64_ep160_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-22\\e100_l64-64-64-64-64-64_ep130_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-22\\e100_l64-64-64-64-64-64_ep130_s  \n",
      "run_experiment()  when: 2026-01-15 01:46:53.888636 params: {'epochs': 130, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 01:47:49.510150\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 12ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-22\\e100_l64-64-64-64-64-64_ep130_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep130_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-22\\e100_l64-64-64-64-64-64_ep130_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep130_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-22\\e100_l64-64-64-64-64-64_ep130_s\\predictions-e100_l64-64-64-64-64-64_ep130_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-22\\e100_l64-64-64-64-64-64_ep130_s\\predictions-e100_l64-64-64-64-64-64_ep130_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-22\\e100_l64-64-64-64-64-64_ep130_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-22\\e100_l64-64-64-64-64-64_ep130_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-22\\e100_l64-64-64-64-64-64_ep130_s\\model\\assets\n",
      "[I 2026-01-15 01:51:47,460] Trial 22 finished with value: 0.8855845928192139 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 130}. Best is trial 11 with value: 0.9066194891929626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-22\\e100_l64-64-64-64-64-64_ep130_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-22\\e100_l64-64-64-64-64-64_ep130_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-23\\e100_l64-64-64-64-64-64_ep200_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-23\\e100_l64-64-64-64-64-64_ep200_s  \n",
      "run_experiment()  when: 2026-01-15 01:51:47.796625 params: {'epochs': 200, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 01:52:47.192958\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-23\\e100_l64-64-64-64-64-64_ep200_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep200_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-23\\e100_l64-64-64-64-64-64_ep200_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep200_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-23\\e100_l64-64-64-64-64-64_ep200_s\\predictions-e100_l64-64-64-64-64-64_ep200_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-23\\e100_l64-64-64-64-64-64_ep200_s\\predictions-e100_l64-64-64-64-64-64_ep200_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-23\\e100_l64-64-64-64-64-64_ep200_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-23\\e100_l64-64-64-64-64-64_ep200_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-23\\e100_l64-64-64-64-64-64_ep200_s\\model\\assets\n",
      "[I 2026-01-15 01:54:21,499] Trial 23 finished with value: 0.9007479548454285 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 200}. Best is trial 11 with value: 0.9066194891929626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-23\\e100_l64-64-64-64-64-64_ep200_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-23\\e100_l64-64-64-64-64-64_ep200_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-24\\e100_l64-64-64-64-64_ep200_sig_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-24\\e100_l64-64-64-64-64_ep200_sig_  \n",
      "run_experiment()  when: 2026-01-15 01:54:21.540902 params: {'epochs': 200, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 01:54:31.223608\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 5ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-24\\e100_l64-64-64-64-64_ep200_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep200_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-24\\e100_l64-64-64-64-64_ep200_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep200_sig_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-24\\e100_l64-64-64-64-64_ep200_sig_\\predictions-e100_l64-64-64-64-64_ep200_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-24\\e100_l64-64-64-64-64_ep200_sig_\\predictions-e100_l64-64-64-64-64_ep200_sig_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-24\\e100_l64-64-64-64-64_ep200_sig_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-24\\e100_l64-64-64-64-64_ep200_sig_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-24\\e100_l64-64-64-64-64_ep200_sig_\\model\\assets\n",
      "[I 2026-01-15 01:57:42,810] Trial 24 finished with value: 0.8970450758934021 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 64, 'embedding_dim': 100, 'epochs': 200}. Best is trial 11 with value: 0.9066194891929626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-24\\e100_l64-64-64-64-64_ep200_sig_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-24\\e100_l64-64-64-64-64_ep200_sig_\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-25\\e100_l64-64-64-64-64-64_ep250_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-25\\e100_l64-64-64-64-64-64_ep250_s  \n",
      "run_experiment()  when: 2026-01-15 01:57:43.065591 params: {'epochs': 250, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 01:58:38.495566\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 800us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-25\\e100_l64-64-64-64-64-64_ep250_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep250_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-25\\e100_l64-64-64-64-64-64_ep250_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep250_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-25\\e100_l64-64-64-64-64-64_ep250_s\\predictions-e100_l64-64-64-64-64-64_ep250_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-25\\e100_l64-64-64-64-64-64_ep250_s\\predictions-e100_l64-64-64-64-64-64_ep250_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-25\\e100_l64-64-64-64-64-64_ep250_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-25\\e100_l64-64-64-64-64-64_ep250_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-25\\e100_l64-64-64-64-64-64_ep250_s\\model\\assets\n",
      "[I 2026-01-15 02:00:30,905] Trial 25 finished with value: 0.8893338441848755 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 250}. Best is trial 11 with value: 0.9066194891929626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-25\\e100_l64-64-64-64-64-64_ep250_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-25\\e100_l64-64-64-64-64-64_ep250_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-26\\e100_l64-64-64-64-64_ep185_sig_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-26\\e100_l64-64-64-64-64_ep185_sig_  \n",
      "run_experiment()  when: 2026-01-15 02:00:30.945767 params: {'epochs': 185, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 02:00:41.952578\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-26\\e100_l64-64-64-64-64_ep185_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep185_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-26\\e100_l64-64-64-64-64_ep185_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep185_sig_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-26\\e100_l64-64-64-64-64_ep185_sig_\\predictions-e100_l64-64-64-64-64_ep185_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-26\\e100_l64-64-64-64-64_ep185_sig_\\predictions-e100_l64-64-64-64-64_ep185_sig_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-26\\e100_l64-64-64-64-64_ep185_sig_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-26\\e100_l64-64-64-64-64_ep185_sig_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-26\\e100_l64-64-64-64-64_ep185_sig_\\model\\assets\n",
      "[I 2026-01-15 02:03:53,901] Trial 26 finished with value: 0.8913635611534119 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 64, 'embedding_dim': 100, 'epochs': 185}. Best is trial 11 with value: 0.9066194891929626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-26\\e100_l64-64-64-64-64_ep185_sig_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-26\\e100_l64-64-64-64-64_ep185_sig_\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-27\\e100_l64-64-64-64-64-64_ep65_si\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-27\\e100_l64-64-64-64-64-64_ep65_si  \n",
      "run_experiment()  when: 2026-01-15 02:03:54.214076 params: {'epochs': 65, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 02:05:05.091864\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-27\\e100_l64-64-64-64-64-64_ep65_si\\normalized_training_df-e100_l64-64-64-64-64-64_ep65_si.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-27\\e100_l64-64-64-64-64-64_ep65_si\\normalized_training_df-e100_l64-64-64-64-64-64_ep65_si.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-27\\e100_l64-64-64-64-64-64_ep65_si\\predictions-e100_l64-64-64-64-64-64_ep65_si.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-27\\e100_l64-64-64-64-64-64_ep65_si\\predictions-e100_l64-64-64-64-64-64_ep65_si.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-27\\e100_l64-64-64-64-64-64_ep65_si\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-27\\e100_l64-64-64-64-64-64_ep65_si\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-27\\e100_l64-64-64-64-64-64_ep65_si\\model\\assets\n",
      "[I 2026-01-15 02:08:31,604] Trial 27 finished with value: 0.899278998374939 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 65}. Best is trial 11 with value: 0.9066194891929626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-27\\e100_l64-64-64-64-64-64_ep65_si\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-27\\e100_l64-64-64-64-64-64_ep65_si\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-28\\e100_l64-64-64-64-64-64_ep350_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-28\\e100_l64-64-64-64-64-64_ep350_s  \n",
      "run_experiment()  when: 2026-01-15 02:08:31.643898 params: {'epochs': 350, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 02:08:42.449897\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-28\\e100_l64-64-64-64-64-64_ep350_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep350_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-28\\e100_l64-64-64-64-64-64_ep350_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep350_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-28\\e100_l64-64-64-64-64-64_ep350_s\\predictions-e100_l64-64-64-64-64-64_ep350_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-28\\e100_l64-64-64-64-64-64_ep350_s\\predictions-e100_l64-64-64-64-64-64_ep350_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-28\\e100_l64-64-64-64-64-64_ep350_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-28\\e100_l64-64-64-64-64-64_ep350_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-28\\e100_l64-64-64-64-64-64_ep350_s\\model\\assets\n",
      "[I 2026-01-15 02:09:35,532] Trial 28 finished with value: 0.9007386565208435 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 350}. Best is trial 11 with value: 0.9066194891929626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-28\\e100_l64-64-64-64-64-64_ep350_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-28\\e100_l64-64-64-64-64-64_ep350_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-29\\e100_l64-64-64-64-64_ep265_sig_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-29\\e100_l64-64-64-64-64_ep265_sig_  \n",
      "run_experiment()  when: 2026-01-15 02:09:35.573097 params: {'epochs': 265, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 02:09:49.721934\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-29\\e100_l64-64-64-64-64_ep265_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep265_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-29\\e100_l64-64-64-64-64_ep265_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep265_sig_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-29\\e100_l64-64-64-64-64_ep265_sig_\\predictions-e100_l64-64-64-64-64_ep265_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-29\\e100_l64-64-64-64-64_ep265_sig_\\predictions-e100_l64-64-64-64-64_ep265_sig_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-29\\e100_l64-64-64-64-64_ep265_sig_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-29\\e100_l64-64-64-64-64_ep265_sig_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-29\\e100_l64-64-64-64-64_ep265_sig_\\model\\assets\n",
      "[I 2026-01-15 02:11:21,450] Trial 29 finished with value: 0.900553286075592 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 64, 'embedding_dim': 100, 'epochs': 265}. Best is trial 11 with value: 0.9066194891929626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-29\\e100_l64-64-64-64-64_ep265_sig_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-29\\e100_l64-64-64-64-64_ep265_sig_\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-30\\e100_l64-64-64-64_ep120_sig_163\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-30\\e100_l64-64-64-64_ep120_sig_163  \n",
      "run_experiment()  when: 2026-01-15 02:11:21.713652 params: {'epochs': 120, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 02:12:38.559209\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-30\\e100_l64-64-64-64_ep120_sig_163\\normalized_training_df-e100_l64-64-64-64_ep120_sig_163.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-30\\e100_l64-64-64-64_ep120_sig_163\\normalized_training_df-e100_l64-64-64-64_ep120_sig_163.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-30\\e100_l64-64-64-64_ep120_sig_163\\predictions-e100_l64-64-64-64_ep120_sig_163.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-30\\e100_l64-64-64-64_ep120_sig_163\\predictions-e100_l64-64-64-64_ep120_sig_163.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-30\\e100_l64-64-64-64_ep120_sig_163\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-30\\e100_l64-64-64-64_ep120_sig_163\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-30\\e100_l64-64-64-64_ep120_sig_163\\model\\assets\n",
      "[I 2026-01-15 02:16:11,237] Trial 30 finished with value: 0.889417290687561 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 120}. Best is trial 11 with value: 0.9066194891929626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-30\\e100_l64-64-64-64_ep120_sig_163\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-30\\e100_l64-64-64-64_ep120_sig_163\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-31\\e100_l64-64-64-64-64-64_ep365_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-31\\e100_l64-64-64-64-64-64_ep365_s  \n",
      "run_experiment()  when: 2026-01-15 02:16:11.510668 params: {'epochs': 365, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 02:17:10.984097\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 800us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-31\\e100_l64-64-64-64-64-64_ep365_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep365_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-31\\e100_l64-64-64-64-64-64_ep365_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep365_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-31\\e100_l64-64-64-64-64-64_ep365_s\\predictions-e100_l64-64-64-64-64-64_ep365_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-31\\e100_l64-64-64-64-64-64_ep365_s\\predictions-e100_l64-64-64-64-64-64_ep365_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-31\\e100_l64-64-64-64-64-64_ep365_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-31\\e100_l64-64-64-64-64-64_ep365_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-31\\e100_l64-64-64-64-64-64_ep365_s\\model\\assets\n",
      "[I 2026-01-15 02:18:01,465] Trial 31 finished with value: 0.8981573581695557 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 365}. Best is trial 11 with value: 0.9066194891929626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-31\\e100_l64-64-64-64-64-64_ep365_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-31\\e100_l64-64-64-64-64-64_ep365_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-32\\e100_l64-64-64-64-64-64_ep355_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-32\\e100_l64-64-64-64-64-64_ep355_s  \n",
      "run_experiment()  when: 2026-01-15 02:18:01.503050 params: {'epochs': 355, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 02:19:02.852851\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-32\\e100_l64-64-64-64-64-64_ep355_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep355_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-32\\e100_l64-64-64-64-64-64_ep355_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep355_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-32\\e100_l64-64-64-64-64-64_ep355_s\\predictions-e100_l64-64-64-64-64-64_ep355_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-32\\e100_l64-64-64-64-64-64_ep355_s\\predictions-e100_l64-64-64-64-64-64_ep355_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-32\\e100_l64-64-64-64-64-64_ep355_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-32\\e100_l64-64-64-64-64-64_ep355_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-32\\e100_l64-64-64-64-64-64_ep355_s\\model\\assets\n",
      "[I 2026-01-15 02:22:50,792] Trial 32 finished with value: 0.8958542346954346 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 355}. Best is trial 11 with value: 0.9066194891929626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-32\\e100_l64-64-64-64-64-64_ep355_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-32\\e100_l64-64-64-64-64-64_ep355_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-33\\e100_l64-64-64-64-64-64_ep295_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-33\\e100_l64-64-64-64-64-64_ep295_s  \n",
      "run_experiment()  when: 2026-01-15 02:22:50.839369 params: {'epochs': 295, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 02:23:50.128413\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-33\\e100_l64-64-64-64-64-64_ep295_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep295_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-33\\e100_l64-64-64-64-64-64_ep295_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep295_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-33\\e100_l64-64-64-64-64-64_ep295_s\\predictions-e100_l64-64-64-64-64-64_ep295_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-33\\e100_l64-64-64-64-64-64_ep295_s\\predictions-e100_l64-64-64-64-64-64_ep295_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-33\\e100_l64-64-64-64-64-64_ep295_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-33\\e100_l64-64-64-64-64-64_ep295_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-33\\e100_l64-64-64-64-64-64_ep295_s\\model\\assets\n",
      "[I 2026-01-15 02:26:08,065] Trial 33 finished with value: 0.88767009973526 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 295}. Best is trial 11 with value: 0.9066194891929626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-33\\e100_l64-64-64-64-64-64_ep295_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-33\\e100_l64-64-64-64-64-64_ep295_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-34\\e100_l64-64-64-64-64_ep410_sig_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-34\\e100_l64-64-64-64-64_ep410_sig_  \n",
      "run_experiment()  when: 2026-01-15 02:26:08.109672 params: {'epochs': 410, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 02:26:18.220794\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 5ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-34\\e100_l64-64-64-64-64_ep410_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep410_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-34\\e100_l64-64-64-64-64_ep410_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep410_sig_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-34\\e100_l64-64-64-64-64_ep410_sig_\\predictions-e100_l64-64-64-64-64_ep410_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-34\\e100_l64-64-64-64-64_ep410_sig_\\predictions-e100_l64-64-64-64-64_ep410_sig_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-34\\e100_l64-64-64-64-64_ep410_sig_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-34\\e100_l64-64-64-64-64_ep410_sig_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-34\\e100_l64-64-64-64-64_ep410_sig_\\model\\assets\n",
      "[I 2026-01-15 02:29:07,981] Trial 34 finished with value: 0.9002798795700073 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 64, 'embedding_dim': 100, 'epochs': 410}. Best is trial 11 with value: 0.9066194891929626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-34\\e100_l64-64-64-64-64_ep410_sig_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-34\\e100_l64-64-64-64-64_ep410_sig_\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-35\\e100_l64-64-64-64-64-64_ep230_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-35\\e100_l64-64-64-64-64-64_ep230_s  \n",
      "run_experiment()  when: 2026-01-15 02:29:08.258766 params: {'epochs': 230, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 02:30:05.980791\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 4ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-35\\e100_l64-64-64-64-64-64_ep230_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep230_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-35\\e100_l64-64-64-64-64-64_ep230_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep230_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-35\\e100_l64-64-64-64-64-64_ep230_s\\predictions-e100_l64-64-64-64-64-64_ep230_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-35\\e100_l64-64-64-64-64-64_ep230_s\\predictions-e100_l64-64-64-64-64-64_ep230_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-35\\e100_l64-64-64-64-64-64_ep230_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-35\\e100_l64-64-64-64-64-64_ep230_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-35\\e100_l64-64-64-64-64-64_ep230_s\\model\\assets\n",
      "[I 2026-01-15 02:33:42,161] Trial 35 finished with value: 0.9035749435424805 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 230}. Best is trial 11 with value: 0.9066194891929626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-35\\e100_l64-64-64-64-64-64_ep230_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-35\\e100_l64-64-64-64-64-64_ep230_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-36\\e100_l64-64-64-64-64_ep230_sig_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-36\\e100_l64-64-64-64-64_ep230_sig_  \n",
      "run_experiment()  when: 2026-01-15 02:33:42.424041 params: {'epochs': 230, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 02:34:37.991424\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-36\\e100_l64-64-64-64-64_ep230_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep230_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-36\\e100_l64-64-64-64-64_ep230_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep230_sig_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-36\\e100_l64-64-64-64-64_ep230_sig_\\predictions-e100_l64-64-64-64-64_ep230_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-36\\e100_l64-64-64-64-64_ep230_sig_\\predictions-e100_l64-64-64-64-64_ep230_sig_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-36\\e100_l64-64-64-64-64_ep230_sig_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-36\\e100_l64-64-64-64-64_ep230_sig_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-36\\e100_l64-64-64-64-64_ep230_sig_\\model\\assets\n",
      "[I 2026-01-15 02:35:56,543] Trial 36 finished with value: 0.9038389921188354 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 64, 'embedding_dim': 100, 'epochs': 230}. Best is trial 11 with value: 0.9066194891929626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-36\\e100_l64-64-64-64-64_ep230_sig_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-36\\e100_l64-64-64-64-64_ep230_sig_\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-37\\e100_l64-64-64-64-64_ep240_sig_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-37\\e100_l64-64-64-64-64_ep240_sig_  \n",
      "run_experiment()  when: 2026-01-15 02:35:56.583057 params: {'epochs': 240, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 02:36:06.608995\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 3ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-37\\e100_l64-64-64-64-64_ep240_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep240_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-37\\e100_l64-64-64-64-64_ep240_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep240_sig_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-37\\e100_l64-64-64-64-64_ep240_sig_\\predictions-e100_l64-64-64-64-64_ep240_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-37\\e100_l64-64-64-64-64_ep240_sig_\\predictions-e100_l64-64-64-64-64_ep240_sig_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-37\\e100_l64-64-64-64-64_ep240_sig_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-37\\e100_l64-64-64-64-64_ep240_sig_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-37\\e100_l64-64-64-64-64_ep240_sig_\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-37\\e100_l64-64-64-64-64_ep240_sig_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-37\\e100_l64-64-64-64-64_ep240_sig_\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-15 02:39:54,187] Trial 37 finished with value: 0.8822572827339172 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 64, 'embedding_dim': 100, 'epochs': 240}. Best is trial 11 with value: 0.9066194891929626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-38\\e100_l64-64-64-64-64_ep280_sig_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-38\\e100_l64-64-64-64-64_ep280_sig_  \n",
      "run_experiment()  when: 2026-01-15 02:39:54.490287 params: {'epochs': 280, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 02:41:09.825536\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 10ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-38\\e100_l64-64-64-64-64_ep280_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep280_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-38\\e100_l64-64-64-64-64_ep280_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep280_sig_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-38\\e100_l64-64-64-64-64_ep280_sig_\\predictions-e100_l64-64-64-64-64_ep280_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-38\\e100_l64-64-64-64-64_ep280_sig_\\predictions-e100_l64-64-64-64-64_ep280_sig_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-38\\e100_l64-64-64-64-64_ep280_sig_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-38\\e100_l64-64-64-64-64_ep280_sig_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-38\\e100_l64-64-64-64-64_ep280_sig_\\model\\assets\n",
      "[I 2026-01-15 02:44:51,729] Trial 38 finished with value: 0.885561466217041 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 64, 'embedding_dim': 100, 'epochs': 280}. Best is trial 11 with value: 0.9066194891929626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-38\\e100_l64-64-64-64-64_ep280_sig_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-38\\e100_l64-64-64-64-64_ep280_sig_\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-39\\e100_l64-64-64-64-64_ep175_sig_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-39\\e100_l64-64-64-64-64_ep175_sig_  \n",
      "run_experiment()  when: 2026-01-15 02:44:51.986310 params: {'epochs': 175, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 02:45:43.566890\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-39\\e100_l64-64-64-64-64_ep175_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep175_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-39\\e100_l64-64-64-64-64_ep175_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep175_sig_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-39\\e100_l64-64-64-64-64_ep175_sig_\\predictions-e100_l64-64-64-64-64_ep175_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-39\\e100_l64-64-64-64-64_ep175_sig_\\predictions-e100_l64-64-64-64-64_ep175_sig_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-39\\e100_l64-64-64-64-64_ep175_sig_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-39\\e100_l64-64-64-64-64_ep175_sig_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-39\\e100_l64-64-64-64-64_ep175_sig_\\model\\assets\n",
      "[I 2026-01-15 02:46:34,559] Trial 39 finished with value: 0.8932775855064392 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 64, 'embedding_dim': 100, 'epochs': 175}. Best is trial 11 with value: 0.9066194891929626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-39\\e100_l64-64-64-64-64_ep175_sig_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-39\\e100_l64-64-64-64-64_ep175_sig_\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-40\\e100_l64-64-64_ep225_sig_138\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-40\\e100_l64-64-64_ep225_sig_138  \n",
      "run_experiment()  when: 2026-01-15 02:46:34.601945 params: {'epochs': 225, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 02:47:05.110531\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1000us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-40\\e100_l64-64-64_ep225_sig_138\\normalized_training_df-e100_l64-64-64_ep225_sig_138.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-40\\e100_l64-64-64_ep225_sig_138\\normalized_training_df-e100_l64-64-64_ep225_sig_138.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-40\\e100_l64-64-64_ep225_sig_138\\predictions-e100_l64-64-64_ep225_sig_138.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-40\\e100_l64-64-64_ep225_sig_138\\predictions-e100_l64-64-64_ep225_sig_138.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-40\\e100_l64-64-64_ep225_sig_138\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-40\\e100_l64-64-64_ep225_sig_138\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-40\\e100_l64-64-64_ep225_sig_138\\model\\assets\n",
      "[I 2026-01-15 02:48:10,273] Trial 40 finished with value: 0.8933286070823669 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 100, 'epochs': 225}. Best is trial 11 with value: 0.9066194891929626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-40\\e100_l64-64-64_ep225_sig_138\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-40\\e100_l64-64-64_ep225_sig_138\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-41\\e100_l64-64-64-64-64-64_ep205_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-41\\e100_l64-64-64-64-64-64_ep205_s  \n",
      "run_experiment()  when: 2026-01-15 02:48:10.318060 params: {'epochs': 205, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 02:48:22.223360\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-41\\e100_l64-64-64-64-64-64_ep205_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep205_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-41\\e100_l64-64-64-64-64-64_ep205_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep205_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-41\\e100_l64-64-64-64-64-64_ep205_s\\predictions-e100_l64-64-64-64-64-64_ep205_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-41\\e100_l64-64-64-64-64-64_ep205_s\\predictions-e100_l64-64-64-64-64-64_ep205_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-41\\e100_l64-64-64-64-64-64_ep205_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-41\\e100_l64-64-64-64-64-64_ep205_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-41\\e100_l64-64-64-64-64-64_ep205_s\\model\\assets\n",
      "[I 2026-01-15 02:52:22,091] Trial 41 finished with value: 0.9087744951248169 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 205}. Best is trial 41 with value: 0.9087744951248169.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-41\\e100_l64-64-64-64-64-64_ep205_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-41\\e100_l64-64-64-64-64-64_ep205_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-42\\e100_l64-64-64-64-64-64_ep325_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-42\\e100_l64-64-64-64-64-64_ep325_s  \n",
      "run_experiment()  when: 2026-01-15 02:52:22.353274 params: {'epochs': 325, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 02:53:44.273416\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 3ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-42\\e100_l64-64-64-64-64-64_ep325_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep325_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-42\\e100_l64-64-64-64-64-64_ep325_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep325_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-42\\e100_l64-64-64-64-64-64_ep325_s\\predictions-e100_l64-64-64-64-64-64_ep325_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-42\\e100_l64-64-64-64-64-64_ep325_s\\predictions-e100_l64-64-64-64-64-64_ep325_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-42\\e100_l64-64-64-64-64-64_ep325_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-42\\e100_l64-64-64-64-64-64_ep325_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-42\\e100_l64-64-64-64-64-64_ep325_s\\model\\assets\n",
      "[I 2026-01-15 02:57:26,301] Trial 42 finished with value: 0.8928095102310181 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 325}. Best is trial 41 with value: 0.9087744951248169.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-42\\e100_l64-64-64-64-64-64_ep325_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-42\\e100_l64-64-64-64-64-64_ep325_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-43\\e100_l64-64-64-64-64_ep220_sig_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-43\\e100_l64-64-64-64-64_ep220_sig_  \n",
      "run_experiment()  when: 2026-01-15 02:57:26.343684 params: {'epochs': 220, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 02:57:39.687966\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-43\\e100_l64-64-64-64-64_ep220_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep220_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-43\\e100_l64-64-64-64-64_ep220_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep220_sig_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-43\\e100_l64-64-64-64-64_ep220_sig_\\predictions-e100_l64-64-64-64-64_ep220_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-43\\e100_l64-64-64-64-64_ep220_sig_\\predictions-e100_l64-64-64-64-64_ep220_sig_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-43\\e100_l64-64-64-64-64_ep220_sig_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-43\\e100_l64-64-64-64-64_ep220_sig_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-43\\e100_l64-64-64-64-64_ep220_sig_\\model\\assets\n",
      "[I 2026-01-15 02:59:09,296] Trial 43 finished with value: 0.8774932622909546 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 64, 'embedding_dim': 100, 'epochs': 220}. Best is trial 41 with value: 0.9087744951248169.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-43\\e100_l64-64-64-64-64_ep220_sig_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-43\\e100_l64-64-64-64-64_ep220_sig_\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-44\\e100_l64-64-64-64_ep170_sig_130\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-44\\e100_l64-64-64-64_ep170_sig_130  \n",
      "run_experiment()  when: 2026-01-15 02:59:09.570720 params: {'epochs': 170, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 03:00:28.790710\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 9ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-44\\e100_l64-64-64-64_ep170_sig_130\\normalized_training_df-e100_l64-64-64-64_ep170_sig_130.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-44\\e100_l64-64-64-64_ep170_sig_130\\normalized_training_df-e100_l64-64-64-64_ep170_sig_130.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-44\\e100_l64-64-64-64_ep170_sig_130\\predictions-e100_l64-64-64-64_ep170_sig_130.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-44\\e100_l64-64-64-64_ep170_sig_130\\predictions-e100_l64-64-64-64_ep170_sig_130.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-44\\e100_l64-64-64-64_ep170_sig_130\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-44\\e100_l64-64-64-64_ep170_sig_130\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-44\\e100_l64-64-64-64_ep170_sig_130\\model\\assets\n",
      "[I 2026-01-15 03:04:08,217] Trial 44 finished with value: 0.8842593431472778 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 170}. Best is trial 41 with value: 0.9087744951248169.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-44\\e100_l64-64-64-64_ep170_sig_130\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-44\\e100_l64-64-64-64_ep170_sig_130\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-45\\e100_l64-64-64-64-64-64_ep275_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-45\\e100_l64-64-64-64-64-64_ep275_s  \n",
      "run_experiment()  when: 2026-01-15 03:04:08.464532 params: {'epochs': 275, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 03:04:56.019003\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 4ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-45\\e100_l64-64-64-64-64-64_ep275_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep275_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-45\\e100_l64-64-64-64-64-64_ep275_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep275_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-45\\e100_l64-64-64-64-64-64_ep275_s\\predictions-e100_l64-64-64-64-64-64_ep275_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-45\\e100_l64-64-64-64-64-64_ep275_s\\predictions-e100_l64-64-64-64-64-64_ep275_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-45\\e100_l64-64-64-64-64-64_ep275_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-45\\e100_l64-64-64-64-64-64_ep275_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-45\\e100_l64-64-64-64-64-64_ep275_s\\model\\assets\n",
      "[I 2026-01-15 03:08:14,859] Trial 45 finished with value: 0.8951034545898438 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 275}. Best is trial 41 with value: 0.9087744951248169.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-45\\e100_l64-64-64-64-64-64_ep275_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-45\\e100_l64-64-64-64-64-64_ep275_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-46\\e100_l64-64-64-64-64-64_ep140_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-46\\e100_l64-64-64-64-64-64_ep140_s  \n",
      "run_experiment()  when: 2026-01-15 03:08:14.899286 params: {'epochs': 140, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 03:08:24.370259\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-46\\e100_l64-64-64-64-64-64_ep140_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep140_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-46\\e100_l64-64-64-64-64-64_ep140_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep140_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-46\\e100_l64-64-64-64-64-64_ep140_s\\predictions-e100_l64-64-64-64-64-64_ep140_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-46\\e100_l64-64-64-64-64-64_ep140_s\\predictions-e100_l64-64-64-64-64-64_ep140_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-46\\e100_l64-64-64-64-64-64_ep140_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-46\\e100_l64-64-64-64-64-64_ep140_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-46\\e100_l64-64-64-64-64-64_ep140_s\\model\\assets\n",
      "[I 2026-01-15 03:10:21,175] Trial 46 finished with value: 0.8846902847290039 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 140}. Best is trial 41 with value: 0.9087744951248169.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-46\\e100_l64-64-64-64-64-64_ep140_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-46\\e100_l64-64-64-64-64-64_ep140_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-47\\e100_l64-64-64-64-64_ep200_sig_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-47\\e100_l64-64-64-64-64_ep200_sig_  \n",
      "run_experiment()  when: 2026-01-15 03:10:21.455534 params: {'epochs': 200, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 03:11:27.065709\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 9ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-47\\e100_l64-64-64-64-64_ep200_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep200_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-47\\e100_l64-64-64-64-64_ep200_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep200_sig_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-47\\e100_l64-64-64-64-64_ep200_sig_\\predictions-e100_l64-64-64-64-64_ep200_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-47\\e100_l64-64-64-64-64_ep200_sig_\\predictions-e100_l64-64-64-64-64_ep200_sig_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-47\\e100_l64-64-64-64-64_ep200_sig_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-47\\e100_l64-64-64-64-64_ep200_sig_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-47\\e100_l64-64-64-64-64_ep200_sig_\\model\\assets\n",
      "[I 2026-01-15 03:15:24,176] Trial 47 finished with value: 0.8986300826072693 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 64, 'embedding_dim': 100, 'epochs': 200}. Best is trial 41 with value: 0.9087744951248169.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-47\\e100_l64-64-64-64-64_ep200_sig_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-47\\e100_l64-64-64-64-64_ep200_sig_\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-48\\e100_l64-64-64-64-64-64_ep250_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-48\\e100_l64-64-64-64-64-64_ep250_s  \n",
      "run_experiment()  when: 2026-01-15 03:15:24.522645 params: {'epochs': 250, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 03:16:27.359293\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-48\\e100_l64-64-64-64-64-64_ep250_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep250_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-48\\e100_l64-64-64-64-64-64_ep250_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep250_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-48\\e100_l64-64-64-64-64-64_ep250_s\\predictions-e100_l64-64-64-64-64-64_ep250_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-48\\e100_l64-64-64-64-64-64_ep250_s\\predictions-e100_l64-64-64-64-64-64_ep250_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-48\\e100_l64-64-64-64-64-64_ep250_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-48\\e100_l64-64-64-64-64-64_ep250_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-48\\e100_l64-64-64-64-64-64_ep250_s\\model\\assets\n",
      "[I 2026-01-15 03:18:34,222] Trial 48 finished with value: 0.8943712115287781 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 250}. Best is trial 41 with value: 0.9087744951248169.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-48\\e100_l64-64-64-64-64-64_ep250_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-48\\e100_l64-64-64-64-64-64_ep250_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-49\\e100_l64-64-64-64-64_ep15_sig_6\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-49\\e100_l64-64-64-64-64_ep15_sig_6  \n",
      "run_experiment()  when: 2026-01-15 03:18:34.260880 params: {'epochs': 15, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 03:18:43.913805\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-49\\e100_l64-64-64-64-64_ep15_sig_6\\normalized_training_df-e100_l64-64-64-64-64_ep15_sig_6.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-49\\e100_l64-64-64-64-64_ep15_sig_6\\normalized_training_df-e100_l64-64-64-64-64_ep15_sig_6.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-49\\e100_l64-64-64-64-64_ep15_sig_6\\predictions-e100_l64-64-64-64-64_ep15_sig_6.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-49\\e100_l64-64-64-64-64_ep15_sig_6\\predictions-e100_l64-64-64-64-64_ep15_sig_6.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-49\\e100_l64-64-64-64-64_ep15_sig_6\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-49\\e100_l64-64-64-64-64_ep15_sig_6\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-49\\e100_l64-64-64-64-64_ep15_sig_6\\model\\assets\n",
      "[I 2026-01-15 03:21:32,581] Trial 49 finished with value: 0.8821460604667664 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 64, 'embedding_dim': 100, 'epochs': 15}. Best is trial 41 with value: 0.9087744951248169.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-49\\e100_l64-64-64-64-64_ep15_sig_6\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-49\\e100_l64-64-64-64-64_ep15_sig_6\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-50\\e100_l64-64-64_ep115_sig_143\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-50\\e100_l64-64-64_ep115_sig_143  \n",
      "run_experiment()  when: 2026-01-15 03:21:32.623475 params: {'epochs': 115, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 03:22:31.882800\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-50\\e100_l64-64-64_ep115_sig_143\\normalized_training_df-e100_l64-64-64_ep115_sig_143.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-50\\e100_l64-64-64_ep115_sig_143\\normalized_training_df-e100_l64-64-64_ep115_sig_143.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-50\\e100_l64-64-64_ep115_sig_143\\predictions-e100_l64-64-64_ep115_sig_143.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-50\\e100_l64-64-64_ep115_sig_143\\predictions-e100_l64-64-64_ep115_sig_143.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-50\\e100_l64-64-64_ep115_sig_143\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-50\\e100_l64-64-64_ep115_sig_143\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-50\\e100_l64-64-64_ep115_sig_143\\model\\assets\n",
      "[I 2026-01-15 03:26:13,140] Trial 50 finished with value: 0.8896674513816833 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 100, 'epochs': 115}. Best is trial 41 with value: 0.9087744951248169.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-50\\e100_l64-64-64_ep115_sig_143\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-50\\e100_l64-64-64_ep115_sig_143\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-51\\e100_l64-64-64-64-64-64_ep210_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-51\\e100_l64-64-64-64-64-64_ep210_s  \n",
      "run_experiment()  when: 2026-01-15 03:26:13.424627 params: {'epochs': 210, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 03:26:50.512189\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1000us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-51\\e100_l64-64-64-64-64-64_ep210_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep210_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-51\\e100_l64-64-64-64-64-64_ep210_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep210_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-51\\e100_l64-64-64-64-64-64_ep210_s\\predictions-e100_l64-64-64-64-64-64_ep210_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-51\\e100_l64-64-64-64-64-64_ep210_s\\predictions-e100_l64-64-64-64-64-64_ep210_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-51\\e100_l64-64-64-64-64-64_ep210_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-51\\e100_l64-64-64-64-64-64_ep210_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-51\\e100_l64-64-64-64-64-64_ep210_s\\model\\assets\n",
      "[I 2026-01-15 03:27:54,563] Trial 51 finished with value: 0.8729748129844666 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 210}. Best is trial 41 with value: 0.9087744951248169.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-51\\e100_l64-64-64-64-64-64_ep210_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-51\\e100_l64-64-64-64-64-64_ep210_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-52\\e100_l64-64-64-64-64-64_ep150_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-52\\e100_l64-64-64-64-64-64_ep150_s  \n",
      "run_experiment()  when: 2026-01-15 03:27:54.834046 params: {'epochs': 150, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 03:28:52.796800\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1000us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-52\\e100_l64-64-64-64-64-64_ep150_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep150_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-52\\e100_l64-64-64-64-64-64_ep150_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep150_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-52\\e100_l64-64-64-64-64-64_ep150_s\\predictions-e100_l64-64-64-64-64-64_ep150_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-52\\e100_l64-64-64-64-64-64_ep150_s\\predictions-e100_l64-64-64-64-64-64_ep150_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-52\\e100_l64-64-64-64-64-64_ep150_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-52\\e100_l64-64-64-64-64-64_ep150_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-52\\e100_l64-64-64-64-64-64_ep150_s\\model\\assets\n",
      "[I 2026-01-15 03:32:33,200] Trial 52 finished with value: 0.894709587097168 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 150}. Best is trial 41 with value: 0.9087744951248169.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-52\\e100_l64-64-64-64-64-64_ep150_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-52\\e100_l64-64-64-64-64-64_ep150_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-53\\e100_l64-64-64-64-64-64_ep185_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-53\\e100_l64-64-64-64-64-64_ep185_s  \n",
      "run_experiment()  when: 2026-01-15 03:32:33.519654 params: {'epochs': 185, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 03:33:43.982864\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 8ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-53\\e100_l64-64-64-64-64-64_ep185_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep185_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-53\\e100_l64-64-64-64-64-64_ep185_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep185_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-53\\e100_l64-64-64-64-64-64_ep185_s\\predictions-e100_l64-64-64-64-64-64_ep185_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-53\\e100_l64-64-64-64-64-64_ep185_s\\predictions-e100_l64-64-64-64-64-64_ep185_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-53\\e100_l64-64-64-64-64-64_ep185_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-53\\e100_l64-64-64-64-64-64_ep185_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-53\\e100_l64-64-64-64-64-64_ep185_s\\model\\assets\n",
      "[I 2026-01-15 03:37:52,363] Trial 53 finished with value: 0.8778315186500549 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 185}. Best is trial 41 with value: 0.9087744951248169.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-53\\e100_l64-64-64-64-64-64_ep185_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-53\\e100_l64-64-64-64-64-64_ep185_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-54\\e100_l64-64-64-64-64-64_ep230_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-54\\e100_l64-64-64-64-64-64_ep230_s  \n",
      "run_experiment()  when: 2026-01-15 03:37:52.629149 params: {'epochs': 230, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 03:38:53.479340\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-54\\e100_l64-64-64-64-64-64_ep230_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep230_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-54\\e100_l64-64-64-64-64-64_ep230_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep230_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-54\\e100_l64-64-64-64-64-64_ep230_s\\predictions-e100_l64-64-64-64-64-64_ep230_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-54\\e100_l64-64-64-64-64-64_ep230_s\\predictions-e100_l64-64-64-64-64-64_ep230_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-54\\e100_l64-64-64-64-64-64_ep230_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-54\\e100_l64-64-64-64-64-64_ep230_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-54\\e100_l64-64-64-64-64-64_ep230_s\\model\\assets\n",
      "[I 2026-01-15 03:39:52,277] Trial 54 finished with value: 0.8839857578277588 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 230}. Best is trial 41 with value: 0.9087744951248169.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-54\\e100_l64-64-64-64-64-64_ep230_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-54\\e100_l64-64-64-64-64-64_ep230_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-55\\e100_l64-64-64-64-64-64_ep300_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-55\\e100_l64-64-64-64-64-64_ep300_s  \n",
      "run_experiment()  when: 2026-01-15 03:39:52.319123 params: {'epochs': 300, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 03:40:52.256929\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 6ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-55\\e100_l64-64-64-64-64-64_ep300_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep300_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-55\\e100_l64-64-64-64-64-64_ep300_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep300_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-55\\e100_l64-64-64-64-64-64_ep300_s\\predictions-e100_l64-64-64-64-64-64_ep300_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-55\\e100_l64-64-64-64-64-64_ep300_s\\predictions-e100_l64-64-64-64-64-64_ep300_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-55\\e100_l64-64-64-64-64-64_ep300_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-55\\e100_l64-64-64-64-64-64_ep300_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-55\\e100_l64-64-64-64-64-64_ep300_s\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-55\\e100_l64-64-64-64-64-64_ep300_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-55\\e100_l64-64-64-64-64-64_ep300_s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-15 03:44:39,621] Trial 55 finished with value: 0.8923460841178894 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 300}. Best is trial 41 with value: 0.9087744951248169.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-56\\e100_l64-64-64-64-64-64_ep205_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-56\\e100_l64-64-64-64-64-64_ep205_s  \n",
      "run_experiment()  when: 2026-01-15 03:44:39.912804 params: {'epochs': 205, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 03:45:49.769644\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-56\\e100_l64-64-64-64-64-64_ep205_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep205_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-56\\e100_l64-64-64-64-64-64_ep205_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep205_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-56\\e100_l64-64-64-64-64-64_ep205_s\\predictions-e100_l64-64-64-64-64-64_ep205_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-56\\e100_l64-64-64-64-64-64_ep205_s\\predictions-e100_l64-64-64-64-64-64_ep205_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-56\\e100_l64-64-64-64-64-64_ep205_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-56\\e100_l64-64-64-64-64-64_ep205_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-56\\e100_l64-64-64-64-64-64_ep205_s\\model\\assets\n",
      "[I 2026-01-15 03:48:32,409] Trial 56 finished with value: 0.8827486038208008 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 205}. Best is trial 41 with value: 0.9087744951248169.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-56\\e100_l64-64-64-64-64-64_ep205_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-56\\e100_l64-64-64-64-64-64_ep205_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-57\\e100_l64-64-64-64_ep175_sig_103\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-57\\e100_l64-64-64-64_ep175_sig_103  \n",
      "run_experiment()  when: 2026-01-15 03:48:32.447277 params: {'epochs': 175, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 03:48:45.034835\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-57\\e100_l64-64-64-64_ep175_sig_103\\normalized_training_df-e100_l64-64-64-64_ep175_sig_103.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-57\\e100_l64-64-64-64_ep175_sig_103\\normalized_training_df-e100_l64-64-64-64_ep175_sig_103.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-57\\e100_l64-64-64-64_ep175_sig_103\\predictions-e100_l64-64-64-64_ep175_sig_103.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-57\\e100_l64-64-64-64_ep175_sig_103\\predictions-e100_l64-64-64-64_ep175_sig_103.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-57\\e100_l64-64-64-64_ep175_sig_103\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-57\\e100_l64-64-64-64_ep175_sig_103\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-57\\e100_l64-64-64-64_ep175_sig_103\\model\\assets\n",
      "[I 2026-01-15 03:51:05,887] Trial 57 finished with value: 0.8972166776657104 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 175}. Best is trial 41 with value: 0.9087744951248169.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-57\\e100_l64-64-64-64_ep175_sig_103\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-57\\e100_l64-64-64-64_ep175_sig_103\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-58\\e100_l64-64-64-64-64-64_ep70_si\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-58\\e100_l64-64-64-64-64-64_ep70_si  \n",
      "run_experiment()  when: 2026-01-15 03:51:05.929515 params: {'epochs': 70, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 03:52:11.660959\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-58\\e100_l64-64-64-64-64-64_ep70_si\\normalized_training_df-e100_l64-64-64-64-64-64_ep70_si.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-58\\e100_l64-64-64-64-64-64_ep70_si\\normalized_training_df-e100_l64-64-64-64-64-64_ep70_si.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-58\\e100_l64-64-64-64-64-64_ep70_si\\predictions-e100_l64-64-64-64-64-64_ep70_si.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-58\\e100_l64-64-64-64-64-64_ep70_si\\predictions-e100_l64-64-64-64-64-64_ep70_si.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-58\\e100_l64-64-64-64-64-64_ep70_si\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-58\\e100_l64-64-64-64-64-64_ep70_si\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-58\\e100_l64-64-64-64-64-64_ep70_si\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-58\\e100_l64-64-64-64-64-64_ep70_si\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-58\\e100_l64-64-64-64-64-64_ep70_si\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-15 03:56:10,642] Trial 58 finished with value: 0.8868497610092163 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 70}. Best is trial 41 with value: 0.9087744951248169.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-59\\e100_l64-64-64-64-64_ep245_sig_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-59\\e100_l64-64-64-64-64_ep245_sig_  \n",
      "run_experiment()  when: 2026-01-15 03:56:10.909518 params: {'epochs': 245, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 03:57:34.520869\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-59\\e100_l64-64-64-64-64_ep245_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep245_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-59\\e100_l64-64-64-64-64_ep245_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep245_sig_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-59\\e100_l64-64-64-64-64_ep245_sig_\\predictions-e100_l64-64-64-64-64_ep245_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-59\\e100_l64-64-64-64-64_ep245_sig_\\predictions-e100_l64-64-64-64-64_ep245_sig_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-59\\e100_l64-64-64-64-64_ep245_sig_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-59\\e100_l64-64-64-64-64_ep245_sig_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-59\\e100_l64-64-64-64-64_ep245_sig_\\model\\assets\n",
      "[I 2026-01-15 03:58:42,197] Trial 59 finished with value: 0.8876748085021973 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 64, 'embedding_dim': 100, 'epochs': 245}. Best is trial 41 with value: 0.9087744951248169.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-59\\e100_l64-64-64-64-64_ep245_sig_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-59\\e100_l64-64-64-64-64_ep245_sig_\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-60\\e100_l64-64-64-64-64-64_ep145_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-60\\e100_l64-64-64-64-64-64_ep145_s  \n",
      "run_experiment()  when: 2026-01-15 03:58:42.236365 params: {'epochs': 145, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 03:59:08.094471\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-60\\e100_l64-64-64-64-64-64_ep145_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep145_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-60\\e100_l64-64-64-64-64-64_ep145_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep145_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-60\\e100_l64-64-64-64-64-64_ep145_s\\predictions-e100_l64-64-64-64-64-64_ep145_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-60\\e100_l64-64-64-64-64-64_ep145_s\\predictions-e100_l64-64-64-64-64-64_ep145_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-60\\e100_l64-64-64-64-64-64_ep145_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-60\\e100_l64-64-64-64-64-64_ep145_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-60\\e100_l64-64-64-64-64-64_ep145_s\\model\\assets\n",
      "[I 2026-01-15 04:02:45,622] Trial 60 finished with value: 0.8774052262306213 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 145}. Best is trial 41 with value: 0.9087744951248169.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-60\\e100_l64-64-64-64-64-64_ep145_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-60\\e100_l64-64-64-64-64-64_ep145_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-61\\e100_l64-64-64-64-64-64_ep265_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-61\\e100_l64-64-64-64-64-64_ep265_s  \n",
      "run_experiment()  when: 2026-01-15 04:02:45.916619 params: {'epochs': 265, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 04:03:57.102749\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 4ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-61\\e100_l64-64-64-64-64-64_ep265_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep265_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-61\\e100_l64-64-64-64-64-64_ep265_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep265_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-61\\e100_l64-64-64-64-64-64_ep265_s\\predictions-e100_l64-64-64-64-64-64_ep265_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-61\\e100_l64-64-64-64-64-64_ep265_s\\predictions-e100_l64-64-64-64-64-64_ep265_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-61\\e100_l64-64-64-64-64-64_ep265_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-61\\e100_l64-64-64-64-64-64_ep265_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-61\\e100_l64-64-64-64-64-64_ep265_s\\model\\assets\n",
      "[I 2026-01-15 04:06:22,555] Trial 61 finished with value: 0.8907380104064941 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 265}. Best is trial 41 with value: 0.9087744951248169.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-61\\e100_l64-64-64-64-64-64_ep265_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-61\\e100_l64-64-64-64-64-64_ep265_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-62\\e100_l64-64-64-64-64-64_ep460_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-62\\e100_l64-64-64-64-64-64_ep460_s  \n",
      "run_experiment()  when: 2026-01-15 04:06:22.596043 params: {'epochs': 460, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 04:06:34.054401\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-62\\e100_l64-64-64-64-64-64_ep460_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep460_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-62\\e100_l64-64-64-64-64-64_ep460_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep460_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-62\\e100_l64-64-64-64-64-64_ep460_s\\predictions-e100_l64-64-64-64-64-64_ep460_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-62\\e100_l64-64-64-64-64-64_ep460_s\\predictions-e100_l64-64-64-64-64-64_ep460_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-62\\e100_l64-64-64-64-64-64_ep460_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-62\\e100_l64-64-64-64-64-64_ep460_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-62\\e100_l64-64-64-64-64-64_ep460_s\\model\\assets\n",
      "[I 2026-01-15 04:09:02,071] Trial 62 finished with value: 0.8841619491577148 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 460}. Best is trial 41 with value: 0.9087744951248169.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-62\\e100_l64-64-64-64-64-64_ep460_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-62\\e100_l64-64-64-64-64-64_ep460_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-63\\e100_l64-64-64-64-64-64_ep185_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-63\\e100_l64-64-64-64-64-64_ep185_s  \n",
      "run_experiment()  when: 2026-01-15 04:09:02.343336 params: {'epochs': 185, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 04:10:05.546435\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-63\\e100_l64-64-64-64-64-64_ep185_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep185_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-63\\e100_l64-64-64-64-64-64_ep185_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep185_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-63\\e100_l64-64-64-64-64-64_ep185_s\\predictions-e100_l64-64-64-64-64-64_ep185_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-63\\e100_l64-64-64-64-64-64_ep185_s\\predictions-e100_l64-64-64-64-64-64_ep185_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-63\\e100_l64-64-64-64-64-64_ep185_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-63\\e100_l64-64-64-64-64-64_ep185_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-63\\e100_l64-64-64-64-64-64_ep185_s\\model\\assets\n",
      "[I 2026-01-15 04:13:21,360] Trial 63 finished with value: 0.8866459131240845 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 185}. Best is trial 41 with value: 0.9087744951248169.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-63\\e100_l64-64-64-64-64-64_ep185_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-63\\e100_l64-64-64-64-64-64_ep185_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-64\\e100_l64-64-64-64-64-64_ep215_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-64\\e100_l64-64-64-64-64-64_ep215_s  \n",
      "run_experiment()  when: 2026-01-15 04:13:21.400350 params: {'epochs': 215, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 04:13:32.022600\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-64\\e100_l64-64-64-64-64-64_ep215_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep215_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-64\\e100_l64-64-64-64-64-64_ep215_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep215_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-64\\e100_l64-64-64-64-64-64_ep215_s\\predictions-e100_l64-64-64-64-64-64_ep215_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-64\\e100_l64-64-64-64-64-64_ep215_s\\predictions-e100_l64-64-64-64-64-64_ep215_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-64\\e100_l64-64-64-64-64-64_ep215_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-64\\e100_l64-64-64-64-64-64_ep215_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-64\\e100_l64-64-64-64-64-64_ep215_s\\model\\assets\n",
      "[I 2026-01-15 04:15:12,292] Trial 64 finished with value: 0.9106746315956116 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 215}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-64\\e100_l64-64-64-64-64-64_ep215_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-64\\e100_l64-64-64-64-64-64_ep215_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-65\\e100_l64-64-64-64-64-64_ep230_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-65\\e100_l64-64-64-64-64-64_ep230_s  \n",
      "run_experiment()  when: 2026-01-15 04:15:12.348152 params: {'epochs': 230, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 04:16:23.939141\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 13ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-65\\e100_l64-64-64-64-64-64_ep230_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep230_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-65\\e100_l64-64-64-64-64-64_ep230_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep230_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-65\\e100_l64-64-64-64-64-64_ep230_s\\predictions-e100_l64-64-64-64-64-64_ep230_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-65\\e100_l64-64-64-64-64-64_ep230_s\\predictions-e100_l64-64-64-64-64-64_ep230_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-65\\e100_l64-64-64-64-64-64_ep230_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-65\\e100_l64-64-64-64-64-64_ep230_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-65\\e100_l64-64-64-64-64-64_ep230_s\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-65\\e100_l64-64-64-64-64-64_ep230_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-65\\e100_l64-64-64-64-64-64_ep230_s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-15 04:20:18,968] Trial 65 finished with value: 0.895789384841919 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 230}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-66\\e100_l64-64-64-64-64-64_ep165_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-66\\e100_l64-64-64-64-64-64_ep165_s  \n",
      "run_experiment()  when: 2026-01-15 04:20:19.031982 params: {'epochs': 165, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 04:21:21.802046\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 13ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-66\\e100_l64-64-64-64-64-64_ep165_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep165_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-66\\e100_l64-64-64-64-64-64_ep165_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep165_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-66\\e100_l64-64-64-64-64-64_ep165_s\\predictions-e100_l64-64-64-64-64-64_ep165_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-66\\e100_l64-64-64-64-64-64_ep165_s\\predictions-e100_l64-64-64-64-64-64_ep165_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-66\\e100_l64-64-64-64-64-64_ep165_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-66\\e100_l64-64-64-64-64-64_ep165_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-66\\e100_l64-64-64-64-64-64_ep165_s\\model\\assets\n",
      "[I 2026-01-15 04:23:48,693] Trial 66 finished with value: 0.8873502016067505 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 165}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-66\\e100_l64-64-64-64-64-64_ep165_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-66\\e100_l64-64-64-64-64-64_ep165_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-67\\e100_l64-64-64-64-64_ep195_sig_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-67\\e100_l64-64-64-64-64_ep195_sig_  \n",
      "run_experiment()  when: 2026-01-15 04:23:48.736574 params: {'epochs': 195, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 04:23:58.440637\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-67\\e100_l64-64-64-64-64_ep195_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep195_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-67\\e100_l64-64-64-64-64_ep195_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep195_sig_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-67\\e100_l64-64-64-64-64_ep195_sig_\\predictions-e100_l64-64-64-64-64_ep195_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-67\\e100_l64-64-64-64-64_ep195_sig_\\predictions-e100_l64-64-64-64-64_ep195_sig_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-67\\e100_l64-64-64-64-64_ep195_sig_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-67\\e100_l64-64-64-64-64_ep195_sig_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-67\\e100_l64-64-64-64-64_ep195_sig_\\model\\assets\n",
      "[I 2026-01-15 04:26:22,080] Trial 67 finished with value: 0.8875356912612915 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 64, 'embedding_dim': 100, 'epochs': 195}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-67\\e100_l64-64-64-64-64_ep195_sig_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-67\\e100_l64-64-64-64-64_ep195_sig_\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-68\\e100_l64-64-64-64-64-64_ep215_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-68\\e100_l64-64-64-64-64-64_ep215_s  \n",
      "run_experiment()  when: 2026-01-15 04:26:22.122909 params: {'epochs': 215, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 04:27:22.934173\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 16ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-68\\e100_l64-64-64-64-64-64_ep215_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep215_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-68\\e100_l64-64-64-64-64-64_ep215_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep215_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-68\\e100_l64-64-64-64-64-64_ep215_s\\predictions-e100_l64-64-64-64-64-64_ep215_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-68\\e100_l64-64-64-64-64-64_ep215_s\\predictions-e100_l64-64-64-64-64-64_ep215_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-68\\e100_l64-64-64-64-64-64_ep215_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-68\\e100_l64-64-64-64-64-64_ep215_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-68\\e100_l64-64-64-64-64-64_ep215_s\\model\\assets\n",
      "[I 2026-01-15 04:31:17,622] Trial 68 finished with value: 0.8887081146240234 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 215}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-68\\e100_l64-64-64-64-64-64_ep215_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-68\\e100_l64-64-64-64-64-64_ep215_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-69\\e100_l64-64-64-64-64-64_ep240_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-69\\e100_l64-64-64-64-64-64_ep240_s  \n",
      "run_experiment()  when: 2026-01-15 04:31:17.685653 params: {'epochs': 240, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 04:32:07.848940\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-69\\e100_l64-64-64-64-64-64_ep240_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep240_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-69\\e100_l64-64-64-64-64-64_ep240_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep240_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-69\\e100_l64-64-64-64-64-64_ep240_s\\predictions-e100_l64-64-64-64-64-64_ep240_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-69\\e100_l64-64-64-64-64-64_ep240_s\\predictions-e100_l64-64-64-64-64-64_ep240_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-69\\e100_l64-64-64-64-64-64_ep240_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-69\\e100_l64-64-64-64-64-64_ep240_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-69\\e100_l64-64-64-64-64-64_ep240_s\\model\\assets\n",
      "[I 2026-01-15 04:33:08,725] Trial 69 finished with value: 0.8963730931282043 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 240}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-69\\e100_l64-64-64-64-64-64_ep240_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-69\\e100_l64-64-64-64-64-64_ep240_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-70\\e100_l64-64-64-64-64_ep125_sig_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-70\\e100_l64-64-64-64-64_ep125_sig_  \n",
      "run_experiment()  when: 2026-01-15 04:33:08.776880 params: {'epochs': 125, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 04:33:22.708183\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-70\\e100_l64-64-64-64-64_ep125_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep125_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-70\\e100_l64-64-64-64-64_ep125_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep125_sig_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-70\\e100_l64-64-64-64-64_ep125_sig_\\predictions-e100_l64-64-64-64-64_ep125_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-70\\e100_l64-64-64-64-64_ep125_sig_\\predictions-e100_l64-64-64-64-64_ep125_sig_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-70\\e100_l64-64-64-64-64_ep125_sig_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-70\\e100_l64-64-64-64-64_ep125_sig_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-70\\e100_l64-64-64-64-64_ep125_sig_\\model\\assets\n",
      "[I 2026-01-15 04:34:20,934] Trial 70 finished with value: 0.8906313180923462 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 64, 'embedding_dim': 100, 'epochs': 125}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-70\\e100_l64-64-64-64-64_ep125_sig_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-70\\e100_l64-64-64-64-64_ep125_sig_\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-71\\e100_l64-64-64-64-64-64_ep275_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-71\\e100_l64-64-64-64-64-64_ep275_s  \n",
      "run_experiment()  when: 2026-01-15 04:34:20.977989 params: {'epochs': 275, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 04:34:40.485898\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-71\\e100_l64-64-64-64-64-64_ep275_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep275_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-71\\e100_l64-64-64-64-64-64_ep275_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep275_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-71\\e100_l64-64-64-64-64-64_ep275_s\\predictions-e100_l64-64-64-64-64-64_ep275_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-71\\e100_l64-64-64-64-64-64_ep275_s\\predictions-e100_l64-64-64-64-64-64_ep275_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-71\\e100_l64-64-64-64-64-64_ep275_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-71\\e100_l64-64-64-64-64-64_ep275_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-71\\e100_l64-64-64-64-64-64_ep275_s\\model\\assets\n",
      "[I 2026-01-15 04:38:22,871] Trial 71 finished with value: 0.8909326195716858 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 275}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-71\\e100_l64-64-64-64-64-64_ep275_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-71\\e100_l64-64-64-64-64-64_ep275_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-72\\e100_l64-64-64-64-64-64_ep315_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-72\\e100_l64-64-64-64-64-64_ep315_s  \n",
      "run_experiment()  when: 2026-01-15 04:38:23.197947 params: {'epochs': 315, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 04:39:35.533878\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-72\\e100_l64-64-64-64-64-64_ep315_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep315_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-72\\e100_l64-64-64-64-64-64_ep315_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep315_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-72\\e100_l64-64-64-64-64-64_ep315_s\\predictions-e100_l64-64-64-64-64-64_ep315_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-72\\e100_l64-64-64-64-64-64_ep315_s\\predictions-e100_l64-64-64-64-64-64_ep315_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-72\\e100_l64-64-64-64-64-64_ep315_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-72\\e100_l64-64-64-64-64-64_ep315_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-72\\e100_l64-64-64-64-64-64_ep315_s\\model\\assets\n",
      "[I 2026-01-15 04:43:08,565] Trial 72 finished with value: 0.8750371336936951 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 315}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-72\\e100_l64-64-64-64-64-64_ep315_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-72\\e100_l64-64-64-64-64-64_ep315_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-73\\e100_l64-64-64-64-64-64_ep400_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-73\\e100_l64-64-64-64-64-64_ep400_s  \n",
      "run_experiment()  when: 2026-01-15 04:43:08.609312 params: {'epochs': 400, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 04:43:19.319979\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-73\\e100_l64-64-64-64-64-64_ep400_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep400_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-73\\e100_l64-64-64-64-64-64_ep400_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep400_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-73\\e100_l64-64-64-64-64-64_ep400_s\\predictions-e100_l64-64-64-64-64-64_ep400_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-73\\e100_l64-64-64-64-64-64_ep400_s\\predictions-e100_l64-64-64-64-64-64_ep400_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-73\\e100_l64-64-64-64-64-64_ep400_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-73\\e100_l64-64-64-64-64-64_ep400_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-73\\e100_l64-64-64-64-64-64_ep400_s\\model\\assets\n",
      "[I 2026-01-15 04:45:26,401] Trial 73 finished with value: 0.8983567357063293 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 400}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-73\\e100_l64-64-64-64-64-64_ep400_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-73\\e100_l64-64-64-64-64-64_ep400_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-74\\e100_l64-64-64-64-64-64_ep335_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-74\\e100_l64-64-64-64-64-64_ep335_s  \n",
      "run_experiment()  when: 2026-01-15 04:45:26.716472 params: {'epochs': 335, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 04:46:48.747612\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 5ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-74\\e100_l64-64-64-64-64-64_ep335_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep335_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-74\\e100_l64-64-64-64-64-64_ep335_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep335_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-74\\e100_l64-64-64-64-64-64_ep335_s\\predictions-e100_l64-64-64-64-64-64_ep335_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-74\\e100_l64-64-64-64-64-64_ep335_s\\predictions-e100_l64-64-64-64-64-64_ep335_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-74\\e100_l64-64-64-64-64-64_ep335_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-74\\e100_l64-64-64-64-64-64_ep335_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-74\\e100_l64-64-64-64-64-64_ep335_s\\model\\assets\n",
      "[I 2026-01-15 04:50:45,439] Trial 74 finished with value: 0.8973000645637512 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 335}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-74\\e100_l64-64-64-64-64-64_ep335_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-74\\e100_l64-64-64-64-64-64_ep335_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-75\\e100_l64-64-64-64-64-64_ep260_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-75\\e100_l64-64-64-64-64-64_ep260_s  \n",
      "run_experiment()  when: 2026-01-15 04:50:45.483759 params: {'epochs': 260, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 04:51:55.654432\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-75\\e100_l64-64-64-64-64-64_ep260_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep260_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-75\\e100_l64-64-64-64-64-64_ep260_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep260_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-75\\e100_l64-64-64-64-64-64_ep260_s\\predictions-e100_l64-64-64-64-64-64_ep260_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-75\\e100_l64-64-64-64-64-64_ep260_s\\predictions-e100_l64-64-64-64-64-64_ep260_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-75\\e100_l64-64-64-64-64-64_ep260_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-75\\e100_l64-64-64-64-64-64_ep260_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-75\\e100_l64-64-64-64-64-64_ep260_s\\model\\assets\n",
      "[I 2026-01-15 04:52:46,214] Trial 75 finished with value: 0.9057112336158752 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 260}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-75\\e100_l64-64-64-64-64-64_ep260_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-75\\e100_l64-64-64-64-64-64_ep260_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-76\\e100_l64-64-64-64-64-64_ep185_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-76\\e100_l64-64-64-64-64-64_ep185_s  \n",
      "run_experiment()  when: 2026-01-15 04:52:46.264587 params: {'epochs': 185, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 04:53:50.343526\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 13ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-76\\e100_l64-64-64-64-64-64_ep185_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep185_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-76\\e100_l64-64-64-64-64-64_ep185_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep185_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-76\\e100_l64-64-64-64-64-64_ep185_s\\predictions-e100_l64-64-64-64-64-64_ep185_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-76\\e100_l64-64-64-64-64-64_ep185_s\\predictions-e100_l64-64-64-64-64-64_ep185_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-76\\e100_l64-64-64-64-64-64_ep185_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-76\\e100_l64-64-64-64-64-64_ep185_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-76\\e100_l64-64-64-64-64-64_ep185_s\\model\\assets\n",
      "[I 2026-01-15 04:57:44,822] Trial 76 finished with value: 0.8978515863418579 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 185}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-76\\e100_l64-64-64-64-64-64_ep185_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-76\\e100_l64-64-64-64-64-64_ep185_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-77\\e100_l64-64-64-64-64-64_ep255_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-77\\e100_l64-64-64-64-64-64_ep255_s  \n",
      "run_experiment()  when: 2026-01-15 04:57:45.116247 params: {'epochs': 255, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 04:58:47.980092\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 12ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-77\\e100_l64-64-64-64-64-64_ep255_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep255_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-77\\e100_l64-64-64-64-64-64_ep255_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep255_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-77\\e100_l64-64-64-64-64-64_ep255_s\\predictions-e100_l64-64-64-64-64-64_ep255_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-77\\e100_l64-64-64-64-64-64_ep255_s\\predictions-e100_l64-64-64-64-64-64_ep255_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-77\\e100_l64-64-64-64-64-64_ep255_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-77\\e100_l64-64-64-64-64-64_ep255_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-77\\e100_l64-64-64-64-64-64_ep255_s\\model\\assets\n",
      "[I 2026-01-15 05:02:25,979] Trial 77 finished with value: 0.8943063616752625 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 255}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-77\\e100_l64-64-64-64-64-64_ep255_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-77\\e100_l64-64-64-64-64-64_ep255_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-78\\e100_l64-64-64-64_ep215_sig_571\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-78\\e100_l64-64-64-64_ep215_sig_571  \n",
      "run_experiment()  when: 2026-01-15 05:02:26.025786 params: {'epochs': 215, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 05:02:40.268706\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 800us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-78\\e100_l64-64-64-64_ep215_sig_571\\normalized_training_df-e100_l64-64-64-64_ep215_sig_571.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-78\\e100_l64-64-64-64_ep215_sig_571\\normalized_training_df-e100_l64-64-64-64_ep215_sig_571.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-78\\e100_l64-64-64-64_ep215_sig_571\\predictions-e100_l64-64-64-64_ep215_sig_571.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-78\\e100_l64-64-64-64_ep215_sig_571\\predictions-e100_l64-64-64-64_ep215_sig_571.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-78\\e100_l64-64-64-64_ep215_sig_571\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-78\\e100_l64-64-64-64_ep215_sig_571\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-78\\e100_l64-64-64-64_ep215_sig_571\\model\\assets\n",
      "[I 2026-01-15 05:04:23,498] Trial 78 finished with value: 0.8802043199539185 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 215}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-78\\e100_l64-64-64-64_ep215_sig_571\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-78\\e100_l64-64-64-64_ep215_sig_571\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-79\\e100_l64-64-64-64-64_ep290_sig_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-79\\e100_l64-64-64-64-64_ep290_sig_  \n",
      "run_experiment()  when: 2026-01-15 05:04:23.543894 params: {'epochs': 290, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 05:05:33.583658\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 15ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-79\\e100_l64-64-64-64-64_ep290_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep290_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-79\\e100_l64-64-64-64-64_ep290_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep290_sig_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-79\\e100_l64-64-64-64-64_ep290_sig_\\predictions-e100_l64-64-64-64-64_ep290_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-79\\e100_l64-64-64-64-64_ep290_sig_\\predictions-e100_l64-64-64-64-64_ep290_sig_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-79\\e100_l64-64-64-64-64_ep290_sig_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-79\\e100_l64-64-64-64-64_ep290_sig_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-79\\e100_l64-64-64-64-64_ep290_sig_\\model\\assets\n",
      "[I 2026-01-15 05:09:18,125] Trial 79 finished with value: 0.872859001159668 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 64, 'embedding_dim': 100, 'epochs': 290}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-79\\e100_l64-64-64-64-64_ep290_sig_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-79\\e100_l64-64-64-64-64_ep290_sig_\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-80\\e100_l64-64-64-64-64-64_ep235_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-80\\e100_l64-64-64-64-64-64_ep235_s  \n",
      "run_experiment()  when: 2026-01-15 05:09:18.426813 params: {'epochs': 235, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 05:10:15.368079\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-80\\e100_l64-64-64-64-64-64_ep235_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep235_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-80\\e100_l64-64-64-64-64-64_ep235_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep235_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-80\\e100_l64-64-64-64-64-64_ep235_s\\predictions-e100_l64-64-64-64-64-64_ep235_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-80\\e100_l64-64-64-64-64-64_ep235_s\\predictions-e100_l64-64-64-64-64-64_ep235_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-80\\e100_l64-64-64-64-64-64_ep235_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-80\\e100_l64-64-64-64-64-64_ep235_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-80\\e100_l64-64-64-64-64-64_ep235_s\\model\\assets\n",
      "[I 2026-01-15 05:11:47,432] Trial 80 finished with value: 0.8961831331253052 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 235}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-80\\e100_l64-64-64-64-64-64_ep235_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-80\\e100_l64-64-64-64-64-64_ep235_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-81\\e100_l64-64-64-64-64-64_ep195_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-81\\e100_l64-64-64-64-64-64_ep195_s  \n",
      "run_experiment()  when: 2026-01-15 05:11:47.477633 params: {'epochs': 195, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 05:11:59.293431\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 7ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-81\\e100_l64-64-64-64-64-64_ep195_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep195_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-81\\e100_l64-64-64-64-64-64_ep195_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep195_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-81\\e100_l64-64-64-64-64-64_ep195_s\\predictions-e100_l64-64-64-64-64-64_ep195_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-81\\e100_l64-64-64-64-64-64_ep195_s\\predictions-e100_l64-64-64-64-64-64_ep195_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-81\\e100_l64-64-64-64-64-64_ep195_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-81\\e100_l64-64-64-64-64-64_ep195_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-81\\e100_l64-64-64-64-64-64_ep195_s\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-81\\e100_l64-64-64-64-64-64_ep195_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-81\\e100_l64-64-64-64-64-64_ep195_s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-15 05:15:45,515] Trial 81 finished with value: 0.887035071849823 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 195}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-82\\e100_l64-64-64-64-64-64_ep155_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-82\\e100_l64-64-64-64-64-64_ep155_s  \n",
      "run_experiment()  when: 2026-01-15 05:15:45.787849 params: {'epochs': 155, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 05:16:42.001555\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-82\\e100_l64-64-64-64-64-64_ep155_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep155_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-82\\e100_l64-64-64-64-64-64_ep155_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep155_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-82\\e100_l64-64-64-64-64-64_ep155_s\\predictions-e100_l64-64-64-64-64-64_ep155_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-82\\e100_l64-64-64-64-64-64_ep155_s\\predictions-e100_l64-64-64-64-64-64_ep155_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-82\\e100_l64-64-64-64-64-64_ep155_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-82\\e100_l64-64-64-64-64-64_ep155_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-82\\e100_l64-64-64-64-64-64_ep155_s\\model\\assets\n",
      "[I 2026-01-15 05:20:26,325] Trial 82 finished with value: 0.8841202259063721 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 155}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-82\\e100_l64-64-64-64-64-64_ep155_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-82\\e100_l64-64-64-64-64-64_ep155_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-83\\e100_l64-64-64-64-64-64_ep350_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-83\\e100_l64-64-64-64-64-64_ep350_s  \n",
      "run_experiment()  when: 2026-01-15 05:20:26.370710 params: {'epochs': 350, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 05:20:37.413028\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-83\\e100_l64-64-64-64-64-64_ep350_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep350_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-83\\e100_l64-64-64-64-64-64_ep350_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep350_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-83\\e100_l64-64-64-64-64-64_ep350_s\\predictions-e100_l64-64-64-64-64-64_ep350_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-83\\e100_l64-64-64-64-64-64_ep350_s\\predictions-e100_l64-64-64-64-64-64_ep350_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-83\\e100_l64-64-64-64-64-64_ep350_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-83\\e100_l64-64-64-64-64-64_ep350_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-83\\e100_l64-64-64-64-64-64_ep350_s\\model\\assets\n",
      "[I 2026-01-15 05:21:45,041] Trial 83 finished with value: 0.9088996052742004 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 350}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-83\\e100_l64-64-64-64-64-64_ep350_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-83\\e100_l64-64-64-64-64-64_ep350_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-84\\e100_l64-64-64-64-64-64_ep380_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-84\\e100_l64-64-64-64-64-64_ep380_s  \n",
      "run_experiment()  when: 2026-01-15 05:21:45.084881 params: {'epochs': 380, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 05:22:37.433286\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-84\\e100_l64-64-64-64-64-64_ep380_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep380_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-84\\e100_l64-64-64-64-64-64_ep380_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep380_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-84\\e100_l64-64-64-64-64-64_ep380_s\\predictions-e100_l64-64-64-64-64-64_ep380_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-84\\e100_l64-64-64-64-64-64_ep380_s\\predictions-e100_l64-64-64-64-64-64_ep380_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-84\\e100_l64-64-64-64-64-64_ep380_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-84\\e100_l64-64-64-64-64-64_ep380_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-84\\e100_l64-64-64-64-64-64_ep380_s\\model\\assets\n",
      "[I 2026-01-15 05:25:06,338] Trial 84 finished with value: 0.8973278403282166 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 380}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-84\\e100_l64-64-64-64-64-64_ep380_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-84\\e100_l64-64-64-64-64-64_ep380_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-85\\e100_l64-64-64-64-64-64_ep205_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-85\\e100_l64-64-64-64-64-64_ep205_s  \n",
      "run_experiment()  when: 2026-01-15 05:25:06.379678 params: {'epochs': 205, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 05:25:19.586629\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 800us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-85\\e100_l64-64-64-64-64-64_ep205_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep205_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-85\\e100_l64-64-64-64-64-64_ep205_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep205_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-85\\e100_l64-64-64-64-64-64_ep205_s\\predictions-e100_l64-64-64-64-64-64_ep205_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-85\\e100_l64-64-64-64-64-64_ep205_s\\predictions-e100_l64-64-64-64-64-64_ep205_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-85\\e100_l64-64-64-64-64-64_ep205_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-85\\e100_l64-64-64-64-64-64_ep205_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-85\\e100_l64-64-64-64-64-64_ep205_s\\model\\assets\n",
      "[I 2026-01-15 05:27:36,230] Trial 85 finished with value: 0.8865393400192261 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 205}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-85\\e100_l64-64-64-64-64-64_ep205_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-85\\e100_l64-64-64-64-64-64_ep205_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-86\\e100_l64-64-64-64-64-64_ep265_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-86\\e100_l64-64-64-64-64-64_ep265_s  \n",
      "run_experiment()  when: 2026-01-15 05:27:36.275760 params: {'epochs': 265, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 05:28:35.400750\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 8ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-86\\e100_l64-64-64-64-64-64_ep265_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep265_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-86\\e100_l64-64-64-64-64-64_ep265_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep265_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-86\\e100_l64-64-64-64-64-64_ep265_s\\predictions-e100_l64-64-64-64-64-64_ep265_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-86\\e100_l64-64-64-64-64-64_ep265_s\\predictions-e100_l64-64-64-64-64-64_ep265_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-86\\e100_l64-64-64-64-64-64_ep265_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-86\\e100_l64-64-64-64-64-64_ep265_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-86\\e100_l64-64-64-64-64-64_ep265_s\\model\\assets\n",
      "[I 2026-01-15 05:32:17,546] Trial 86 finished with value: 0.8966466188430786 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 265}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-86\\e100_l64-64-64-64-64-64_ep265_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-86\\e100_l64-64-64-64-64-64_ep265_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-87\\e100_l64-64-64-64-64_ep220_sig_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-87\\e100_l64-64-64-64-64_ep220_sig_  \n",
      "run_experiment()  when: 2026-01-15 05:32:17.593800 params: {'epochs': 220, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 05:33:15.363388\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 800us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-87\\e100_l64-64-64-64-64_ep220_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep220_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-87\\e100_l64-64-64-64-64_ep220_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep220_sig_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-87\\e100_l64-64-64-64-64_ep220_sig_\\predictions-e100_l64-64-64-64-64_ep220_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-87\\e100_l64-64-64-64-64_ep220_sig_\\predictions-e100_l64-64-64-64-64_ep220_sig_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-87\\e100_l64-64-64-64-64_ep220_sig_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-87\\e100_l64-64-64-64-64_ep220_sig_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-87\\e100_l64-64-64-64-64_ep220_sig_\\model\\assets\n",
      "[I 2026-01-15 05:34:06,370] Trial 87 finished with value: 0.8843333721160889 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 64, 'embedding_dim': 100, 'epochs': 220}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-87\\e100_l64-64-64-64-64_ep220_sig_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-87\\e100_l64-64-64-64-64_ep220_sig_\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-88\\e100_l64-64-64-64-64-64_ep175_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-88\\e100_l64-64-64-64-64-64_ep175_s  \n",
      "run_experiment()  when: 2026-01-15 05:34:06.415447 params: {'epochs': 175, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 05:35:05.452715\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 12ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-88\\e100_l64-64-64-64-64-64_ep175_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep175_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-88\\e100_l64-64-64-64-64-64_ep175_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep175_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-88\\e100_l64-64-64-64-64-64_ep175_s\\predictions-e100_l64-64-64-64-64-64_ep175_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-88\\e100_l64-64-64-64-64-64_ep175_s\\predictions-e100_l64-64-64-64-64-64_ep175_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-88\\e100_l64-64-64-64-64-64_ep175_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-88\\e100_l64-64-64-64-64-64_ep175_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-88\\e100_l64-64-64-64-64-64_ep175_s\\model\\assets\n",
      "[I 2026-01-15 05:38:44,137] Trial 88 finished with value: 0.8818819522857666 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 175}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-88\\e100_l64-64-64-64-64-64_ep175_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-88\\e100_l64-64-64-64-64-64_ep175_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-89\\e100_l64-64-64-64_ep135_sig_438\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-89\\e100_l64-64-64-64_ep135_sig_438  \n",
      "run_experiment()  when: 2026-01-15 05:38:44.190308 params: {'epochs': 135, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 05:39:46.098829\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-89\\e100_l64-64-64-64_ep135_sig_438\\normalized_training_df-e100_l64-64-64-64_ep135_sig_438.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-89\\e100_l64-64-64-64_ep135_sig_438\\normalized_training_df-e100_l64-64-64-64_ep135_sig_438.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-89\\e100_l64-64-64-64_ep135_sig_438\\predictions-e100_l64-64-64-64_ep135_sig_438.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-89\\e100_l64-64-64-64_ep135_sig_438\\predictions-e100_l64-64-64-64_ep135_sig_438.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-89\\e100_l64-64-64-64_ep135_sig_438\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-89\\e100_l64-64-64-64_ep135_sig_438\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-89\\e100_l64-64-64-64_ep135_sig_438\\model\\assets\n",
      "[I 2026-01-15 05:41:14,761] Trial 89 finished with value: 0.8752039074897766 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 135}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-89\\e100_l64-64-64-64_ep135_sig_438\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-89\\e100_l64-64-64-64_ep135_sig_438\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-90\\e100_l64-64-64_ep165_sig_184\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-90\\e100_l64-64-64_ep165_sig_184  \n",
      "run_experiment()  when: 2026-01-15 05:41:14.803166 params: {'epochs': 165, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 05:41:26.802557\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-90\\e100_l64-64-64_ep165_sig_184\\normalized_training_df-e100_l64-64-64_ep165_sig_184.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-90\\e100_l64-64-64_ep165_sig_184\\normalized_training_df-e100_l64-64-64_ep165_sig_184.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-90\\e100_l64-64-64_ep165_sig_184\\predictions-e100_l64-64-64_ep165_sig_184.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-90\\e100_l64-64-64_ep165_sig_184\\predictions-e100_l64-64-64_ep165_sig_184.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-90\\e100_l64-64-64_ep165_sig_184\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-90\\e100_l64-64-64_ep165_sig_184\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-90\\e100_l64-64-64_ep165_sig_184\\model\\assets\n",
      "[I 2026-01-15 05:45:17,931] Trial 90 finished with value: 0.8943573832511902 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 100, 'epochs': 165}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-90\\e100_l64-64-64_ep165_sig_184\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-90\\e100_l64-64-64_ep165_sig_184\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-91\\e100_l64-64-64-64-64-64_ep350_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-91\\e100_l64-64-64-64-64-64_ep350_s  \n",
      "run_experiment()  when: 2026-01-15 05:45:18.179925 params: {'epochs': 350, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 05:46:19.200674\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 13ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-91\\e100_l64-64-64-64-64-64_ep350_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep350_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-91\\e100_l64-64-64-64-64-64_ep350_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep350_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-91\\e100_l64-64-64-64-64-64_ep350_s\\predictions-e100_l64-64-64-64-64-64_ep350_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-91\\e100_l64-64-64-64-64-64_ep350_s\\predictions-e100_l64-64-64-64-64-64_ep350_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-91\\e100_l64-64-64-64-64-64_ep350_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-91\\e100_l64-64-64-64-64-64_ep350_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-91\\e100_l64-64-64-64-64-64_ep350_s\\model\\assets\n",
      "[I 2026-01-15 05:50:01,564] Trial 91 finished with value: 0.8884209394454956 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 350}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-91\\e100_l64-64-64-64-64-64_ep350_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-91\\e100_l64-64-64-64-64-64_ep350_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-92\\e100_l64-64-64-64-64-64_ep425_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-92\\e100_l64-64-64-64-64-64_ep425_s  \n",
      "run_experiment()  when: 2026-01-15 05:50:01.843705 params: {'epochs': 425, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 05:50:28.263663\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-92\\e100_l64-64-64-64-64-64_ep425_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep425_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-92\\e100_l64-64-64-64-64-64_ep425_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep425_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-92\\e100_l64-64-64-64-64-64_ep425_s\\predictions-e100_l64-64-64-64-64-64_ep425_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-92\\e100_l64-64-64-64-64-64_ep425_s\\predictions-e100_l64-64-64-64-64-64_ep425_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-92\\e100_l64-64-64-64-64-64_ep425_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-92\\e100_l64-64-64-64-64-64_ep425_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-92\\e100_l64-64-64-64-64-64_ep425_s\\model\\assets\n",
      "[I 2026-01-15 05:51:37,653] Trial 92 finished with value: 0.8834066390991211 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 425}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-92\\e100_l64-64-64-64-64-64_ep425_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-92\\e100_l64-64-64-64-64-64_ep425_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-93\\e100_l64-64-64-64-64-64_ep340_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-93\\e100_l64-64-64-64-64-64_ep340_s  \n",
      "run_experiment()  when: 2026-01-15 05:51:37.935840 params: {'epochs': 340, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 05:52:52.998869\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 10ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-93\\e100_l64-64-64-64-64-64_ep340_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep340_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-93\\e100_l64-64-64-64-64-64_ep340_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep340_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-93\\e100_l64-64-64-64-64-64_ep340_s\\predictions-e100_l64-64-64-64-64-64_ep340_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-93\\e100_l64-64-64-64-64-64_ep340_s\\predictions-e100_l64-64-64-64-64-64_ep340_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-93\\e100_l64-64-64-64-64-64_ep340_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-93\\e100_l64-64-64-64-64-64_ep340_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-93\\e100_l64-64-64-64-64-64_ep340_s\\model\\assets\n",
      "[I 2026-01-15 05:56:47,698] Trial 93 finished with value: 0.8940421938896179 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 340}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-93\\e100_l64-64-64-64-64-64_ep340_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-93\\e100_l64-64-64-64-64-64_ep340_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-94\\e100_l64-64-64-64-64-64_ep365_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-94\\e100_l64-64-64-64-64-64_ep365_s  \n",
      "run_experiment()  when: 2026-01-15 05:56:48.007141 params: {'epochs': 365, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 05:57:48.732933\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 12ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-94\\e100_l64-64-64-64-64-64_ep365_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep365_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-94\\e100_l64-64-64-64-64-64_ep365_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep365_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-94\\e100_l64-64-64-64-64-64_ep365_s\\predictions-e100_l64-64-64-64-64-64_ep365_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-94\\e100_l64-64-64-64-64-64_ep365_s\\predictions-e100_l64-64-64-64-64-64_ep365_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-94\\e100_l64-64-64-64-64-64_ep365_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-94\\e100_l64-64-64-64-64-64_ep365_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-94\\e100_l64-64-64-64-64-64_ep365_s\\model\\assets\n",
      "[I 2026-01-15 06:01:36,621] Trial 94 finished with value: 0.9094557762145996 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 365}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-94\\e100_l64-64-64-64-64-64_ep365_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-94\\e100_l64-64-64-64-64-64_ep365_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-95\\e100_l64-64-64-64-64-64_ep385_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-95\\e100_l64-64-64-64-64-64_ep385_s  \n",
      "run_experiment()  when: 2026-01-15 06:01:36.674280 params: {'epochs': 385, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 06:02:44.112293\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-95\\e100_l64-64-64-64-64-64_ep385_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep385_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-95\\e100_l64-64-64-64-64-64_ep385_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep385_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-95\\e100_l64-64-64-64-64-64_ep385_s\\predictions-e100_l64-64-64-64-64-64_ep385_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-95\\e100_l64-64-64-64-64-64_ep385_s\\predictions-e100_l64-64-64-64-64-64_ep385_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-95\\e100_l64-64-64-64-64-64_ep385_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-95\\e100_l64-64-64-64-64-64_ep385_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-95\\e100_l64-64-64-64-64-64_ep385_s\\model\\assets\n",
      "[I 2026-01-15 06:03:38,339] Trial 95 finished with value: 0.8894588947296143 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 385}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-95\\e100_l64-64-64-64-64-64_ep385_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-95\\e100_l64-64-64-64-64-64_ep385_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-96\\e100_l64-64-64-64-64-64_ep365_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-96\\e100_l64-64-64-64-64-64_ep365_s  \n",
      "run_experiment()  when: 2026-01-15 06:03:38.384032 params: {'epochs': 365, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 06:04:15.599648\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 7ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-96\\e100_l64-64-64-64-64-64_ep365_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep365_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-96\\e100_l64-64-64-64-64-64_ep365_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep365_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-96\\e100_l64-64-64-64-64-64_ep365_s\\predictions-e100_l64-64-64-64-64-64_ep365_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-96\\e100_l64-64-64-64-64-64_ep365_s\\predictions-e100_l64-64-64-64-64-64_ep365_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-96\\e100_l64-64-64-64-64-64_ep365_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-96\\e100_l64-64-64-64-64-64_ep365_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-96\\e100_l64-64-64-64-64-64_ep365_s\\model\\assets\n",
      "[I 2026-01-15 06:07:59,271] Trial 96 finished with value: 0.9014661908149719 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 365}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-96\\e100_l64-64-64-64-64-64_ep365_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-96\\e100_l64-64-64-64-64-64_ep365_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-97\\e100_l64-64-64-64-64-64_ep365_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-97\\e100_l64-64-64-64-64-64_ep365_s  \n",
      "run_experiment()  when: 2026-01-15 06:07:59.577179 params: {'epochs': 365, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 06:09:08.493401\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 3ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-97\\e100_l64-64-64-64-64-64_ep365_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep365_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-97\\e100_l64-64-64-64-64-64_ep365_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep365_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-97\\e100_l64-64-64-64-64-64_ep365_s\\predictions-e100_l64-64-64-64-64-64_ep365_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-97\\e100_l64-64-64-64-64-64_ep365_s\\predictions-e100_l64-64-64-64-64-64_ep365_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-97\\e100_l64-64-64-64-64-64_ep365_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-97\\e100_l64-64-64-64-64-64_ep365_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-97\\e100_l64-64-64-64-64-64_ep365_s\\model\\assets\n",
      "[I 2026-01-15 06:12:02,808] Trial 97 finished with value: 0.9011790156364441 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 365}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-97\\e100_l64-64-64-64-64-64_ep365_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-97\\e100_l64-64-64-64-64-64_ep365_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-98\\e100_l64-64-64-64-64-64_ep390_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-98\\e100_l64-64-64-64-64-64_ep390_s  \n",
      "run_experiment()  when: 2026-01-15 06:12:02.852444 params: {'epochs': 390, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 06:12:12.335916\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-98\\e100_l64-64-64-64-64-64_ep390_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep390_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-98\\e100_l64-64-64-64-64-64_ep390_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep390_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-98\\e100_l64-64-64-64-64-64_ep390_s\\predictions-e100_l64-64-64-64-64-64_ep390_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-98\\e100_l64-64-64-64-64-64_ep390_s\\predictions-e100_l64-64-64-64-64-64_ep390_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-98\\e100_l64-64-64-64-64-64_ep390_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-98\\e100_l64-64-64-64-64-64_ep390_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-98\\e100_l64-64-64-64-64-64_ep390_s\\model\\assets\n",
      "[I 2026-01-15 06:14:28,183] Trial 98 finished with value: 0.8735774159431458 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 390}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-98\\e100_l64-64-64-64-64-64_ep390_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-98\\e100_l64-64-64-64-64-64_ep390_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-99\\e100_l64-64-64-64-64-64_ep420_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-99\\e100_l64-64-64-64-64-64_ep420_s  \n",
      "run_experiment()  when: 2026-01-15 06:14:28.438796 params: {'epochs': 420, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 06:15:24.132105\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 7ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-99\\e100_l64-64-64-64-64-64_ep420_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep420_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-99\\e100_l64-64-64-64-64-64_ep420_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep420_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-99\\e100_l64-64-64-64-64-64_ep420_s\\predictions-e100_l64-64-64-64-64-64_ep420_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-99\\e100_l64-64-64-64-64-64_ep420_s\\predictions-e100_l64-64-64-64-64-64_ep420_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-99\\e100_l64-64-64-64-64-64_ep420_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-99\\e100_l64-64-64-64-64-64_ep420_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-99\\e100_l64-64-64-64-64-64_ep420_s\\model\\assets\n",
      "[I 2026-01-15 06:19:09,998] Trial 99 finished with value: 0.8922904133796692 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 420}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-99\\e100_l64-64-64-64-64-64_ep420_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-99\\e100_l64-64-64-64-64-64_ep420_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-100\\e100_l64-64-64-64-64_ep360_sig_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-100\\e100_l64-64-64-64-64_ep360_sig_  \n",
      "run_experiment()  when: 2026-01-15 06:19:10.044429 params: {'epochs': 360, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 06:20:06.808562\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-100\\e100_l64-64-64-64-64_ep360_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep360_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-100\\e100_l64-64-64-64-64_ep360_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep360_sig_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-100\\e100_l64-64-64-64-64_ep360_sig_\\predictions-e100_l64-64-64-64-64_ep360_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-100\\e100_l64-64-64-64-64_ep360_sig_\\predictions-e100_l64-64-64-64-64_ep360_sig_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-100\\e100_l64-64-64-64-64_ep360_sig_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-100\\e100_l64-64-64-64-64_ep360_sig_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-100\\e100_l64-64-64-64-64_ep360_sig_\\model\\assets\n",
      "[I 2026-01-15 06:20:58,388] Trial 100 finished with value: 0.899677574634552 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 64, 'embedding_dim': 100, 'epochs': 360}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-100\\e100_l64-64-64-64-64_ep360_sig_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-100\\e100_l64-64-64-64-64_ep360_sig_\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-101\\e100_l64-64-64-64-64-64_ep370_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-101\\e100_l64-64-64-64-64-64_ep370_s  \n",
      "run_experiment()  when: 2026-01-15 06:20:58.431409 params: {'epochs': 370, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 06:21:37.919984\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-101\\e100_l64-64-64-64-64-64_ep370_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep370_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-101\\e100_l64-64-64-64-64-64_ep370_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep370_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-101\\e100_l64-64-64-64-64-64_ep370_s\\predictions-e100_l64-64-64-64-64-64_ep370_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-101\\e100_l64-64-64-64-64-64_ep370_s\\predictions-e100_l64-64-64-64-64-64_ep370_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-101\\e100_l64-64-64-64-64-64_ep370_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-101\\e100_l64-64-64-64-64-64_ep370_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-101\\e100_l64-64-64-64-64-64_ep370_s\\model\\assets\n",
      "[I 2026-01-15 06:25:14,346] Trial 101 finished with value: 0.8724696636199951 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 370}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-101\\e100_l64-64-64-64-64-64_ep370_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-101\\e100_l64-64-64-64-64-64_ep370_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-102\\e100_l64-64-64-64-64-64_ep325_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-102\\e100_l64-64-64-64-64-64_ep325_s  \n",
      "run_experiment()  when: 2026-01-15 06:25:14.638841 params: {'epochs': 325, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 06:26:20.008142\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-102\\e100_l64-64-64-64-64-64_ep325_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep325_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-102\\e100_l64-64-64-64-64-64_ep325_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep325_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-102\\e100_l64-64-64-64-64-64_ep325_s\\predictions-e100_l64-64-64-64-64-64_ep325_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-102\\e100_l64-64-64-64-64-64_ep325_s\\predictions-e100_l64-64-64-64-64-64_ep325_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-102\\e100_l64-64-64-64-64-64_ep325_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-102\\e100_l64-64-64-64-64-64_ep325_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-102\\e100_l64-64-64-64-64-64_ep325_s\\model\\assets\n",
      "[I 2026-01-15 06:27:46,557] Trial 102 finished with value: 0.9089460968971252 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 325}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-102\\e100_l64-64-64-64-64-64_ep325_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-102\\e100_l64-64-64-64-64-64_ep325_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-103\\e100_l64-64-64-64-64-64_ep305_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-103\\e100_l64-64-64-64-64-64_ep305_s  \n",
      "run_experiment()  when: 2026-01-15 06:27:46.599545 params: {'epochs': 305, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 06:27:57.473562\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 14ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-103\\e100_l64-64-64-64-64-64_ep305_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep305_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-103\\e100_l64-64-64-64-64-64_ep305_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep305_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-103\\e100_l64-64-64-64-64-64_ep305_s\\predictions-e100_l64-64-64-64-64-64_ep305_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-103\\e100_l64-64-64-64-64-64_ep305_s\\predictions-e100_l64-64-64-64-64-64_ep305_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-103\\e100_l64-64-64-64-64-64_ep305_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-103\\e100_l64-64-64-64-64-64_ep305_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-103\\e100_l64-64-64-64-64-64_ep305_s\\model\\assets\n",
      "[I 2026-01-15 06:31:45,563] Trial 103 finished with value: 0.8988987803459167 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 305}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-103\\e100_l64-64-64-64-64-64_ep305_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-103\\e100_l64-64-64-64-64-64_ep305_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-104\\e100_l64-64-64-64-64-64_ep345_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-104\\e100_l64-64-64-64-64-64_ep345_s  \n",
      "run_experiment()  when: 2026-01-15 06:31:45.855808 params: {'epochs': 345, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 06:32:57.520982\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 12ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-104\\e100_l64-64-64-64-64-64_ep345_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep345_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-104\\e100_l64-64-64-64-64-64_ep345_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep345_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-104\\e100_l64-64-64-64-64-64_ep345_s\\predictions-e100_l64-64-64-64-64-64_ep345_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-104\\e100_l64-64-64-64-64-64_ep345_s\\predictions-e100_l64-64-64-64-64-64_ep345_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-104\\e100_l64-64-64-64-64-64_ep345_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-104\\e100_l64-64-64-64-64-64_ep345_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-104\\e100_l64-64-64-64-64-64_ep345_s\\model\\assets\n",
      "[I 2026-01-15 06:36:43,486] Trial 104 finished with value: 0.8877397179603577 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 345}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-104\\e100_l64-64-64-64-64-64_ep345_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-104\\e100_l64-64-64-64-64-64_ep345_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-105\\e100_l64-64-64-64-64-64_ep320_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-105\\e100_l64-64-64-64-64-64_ep320_s  \n",
      "run_experiment()  when: 2026-01-15 06:36:43.757398 params: {'epochs': 320, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 06:37:09.493731\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-105\\e100_l64-64-64-64-64-64_ep320_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep320_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-105\\e100_l64-64-64-64-64-64_ep320_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep320_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-105\\e100_l64-64-64-64-64-64_ep320_s\\predictions-e100_l64-64-64-64-64-64_ep320_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-105\\e100_l64-64-64-64-64-64_ep320_s\\predictions-e100_l64-64-64-64-64-64_ep320_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-105\\e100_l64-64-64-64-64-64_ep320_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-105\\e100_l64-64-64-64-64-64_ep320_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-105\\e100_l64-64-64-64-64-64_ep320_s\\model\\assets\n",
      "[I 2026-01-15 06:38:05,540] Trial 105 finished with value: 0.8865764141082764 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 320}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-105\\e100_l64-64-64-64-64-64_ep320_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-105\\e100_l64-64-64-64-64-64_ep320_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-106\\e100_l64-64-64-64-64-64_ep330_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-106\\e100_l64-64-64-64-64-64_ep330_s  \n",
      "run_experiment()  when: 2026-01-15 06:38:05.818424 params: {'epochs': 330, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 06:39:25.186173\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 8ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-106\\e100_l64-64-64-64-64-64_ep330_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep330_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-106\\e100_l64-64-64-64-64-64_ep330_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep330_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-106\\e100_l64-64-64-64-64-64_ep330_s\\predictions-e100_l64-64-64-64-64-64_ep330_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-106\\e100_l64-64-64-64-64-64_ep330_s\\predictions-e100_l64-64-64-64-64-64_ep330_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-106\\e100_l64-64-64-64-64-64_ep330_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-106\\e100_l64-64-64-64-64-64_ep330_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-106\\e100_l64-64-64-64-64-64_ep330_s\\model\\assets\n",
      "[I 2026-01-15 06:43:04,415] Trial 106 finished with value: 0.8938661217689514 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 330}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-106\\e100_l64-64-64-64-64-64_ep330_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-106\\e100_l64-64-64-64-64-64_ep330_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-107\\e100_l64-64-64-64-64-64_ep375_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-107\\e100_l64-64-64-64-64-64_ep375_s  \n",
      "run_experiment()  when: 2026-01-15 06:43:04.735903 params: {'epochs': 375, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 06:44:01.212630\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 5ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-107\\e100_l64-64-64-64-64-64_ep375_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep375_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-107\\e100_l64-64-64-64-64-64_ep375_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep375_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-107\\e100_l64-64-64-64-64-64_ep375_s\\predictions-e100_l64-64-64-64-64-64_ep375_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-107\\e100_l64-64-64-64-64-64_ep375_s\\predictions-e100_l64-64-64-64-64-64_ep375_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-107\\e100_l64-64-64-64-64-64_ep375_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-107\\e100_l64-64-64-64-64-64_ep375_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-107\\e100_l64-64-64-64-64-64_ep375_s\\model\\assets\n",
      "[I 2026-01-15 06:46:39,367] Trial 107 finished with value: 0.8995106220245361 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 375}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-107\\e100_l64-64-64-64-64-64_ep375_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-107\\e100_l64-64-64-64-64-64_ep375_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-108\\e100_l64-64-64-64-64-64_ep245_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-108\\e100_l64-64-64-64-64-64_ep245_s  \n",
      "run_experiment()  when: 2026-01-15 06:46:39.405645 params: {'epochs': 245, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 06:46:52.186966\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-108\\e100_l64-64-64-64-64-64_ep245_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep245_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-108\\e100_l64-64-64-64-64-64_ep245_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep245_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-108\\e100_l64-64-64-64-64-64_ep245_s\\predictions-e100_l64-64-64-64-64-64_ep245_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-108\\e100_l64-64-64-64-64-64_ep245_s\\predictions-e100_l64-64-64-64-64-64_ep245_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-108\\e100_l64-64-64-64-64-64_ep245_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-108\\e100_l64-64-64-64-64-64_ep245_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-108\\e100_l64-64-64-64-64-64_ep245_s\\model\\assets\n",
      "[I 2026-01-15 06:49:25,622] Trial 108 finished with value: 0.8892318606376648 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 245}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-108\\e100_l64-64-64-64-64-64_ep245_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-108\\e100_l64-64-64-64-64-64_ep245_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-109\\e100_l64-64-64-64-64-64_ep395_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-109\\e100_l64-64-64-64-64-64_ep395_s  \n",
      "run_experiment()  when: 2026-01-15 06:49:25.915096 params: {'epochs': 395, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 06:50:36.609299\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 10ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-109\\e100_l64-64-64-64-64-64_ep395_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep395_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-109\\e100_l64-64-64-64-64-64_ep395_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep395_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-109\\e100_l64-64-64-64-64-64_ep395_s\\predictions-e100_l64-64-64-64-64-64_ep395_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-109\\e100_l64-64-64-64-64-64_ep395_s\\predictions-e100_l64-64-64-64-64-64_ep395_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-109\\e100_l64-64-64-64-64-64_ep395_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-109\\e100_l64-64-64-64-64-64_ep395_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-109\\e100_l64-64-64-64-64-64_ep395_s\\model\\assets\n",
      "[I 2026-01-15 06:53:25,069] Trial 109 finished with value: 0.8718439936637878 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 395}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-109\\e100_l64-64-64-64-64-64_ep395_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-109\\e100_l64-64-64-64-64-64_ep395_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-110\\e100_l64-64-64-64-64-64_ep190_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-110\\e100_l64-64-64-64-64-64_ep190_s  \n",
      "run_experiment()  when: 2026-01-15 06:53:25.109418 params: {'epochs': 190, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 06:53:34.932291\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 800us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-110\\e100_l64-64-64-64-64-64_ep190_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep190_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-110\\e100_l64-64-64-64-64-64_ep190_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep190_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-110\\e100_l64-64-64-64-64-64_ep190_s\\predictions-e100_l64-64-64-64-64-64_ep190_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-110\\e100_l64-64-64-64-64-64_ep190_s\\predictions-e100_l64-64-64-64-64-64_ep190_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-110\\e100_l64-64-64-64-64-64_ep190_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-110\\e100_l64-64-64-64-64-64_ep190_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-110\\e100_l64-64-64-64-64-64_ep190_s\\model\\assets\n",
      "[I 2026-01-15 06:55:45,956] Trial 110 finished with value: 0.89049232006073 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 190}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-110\\e100_l64-64-64-64-64-64_ep190_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-110\\e100_l64-64-64-64-64-64_ep190_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-111\\e100_l64-64-64-64-64-64_ep365_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-111\\e100_l64-64-64-64-64-64_ep365_s  \n",
      "run_experiment()  when: 2026-01-15 06:55:46.199082 params: {'epochs': 365, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 06:56:54.435439\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 9ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-111\\e100_l64-64-64-64-64-64_ep365_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep365_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-111\\e100_l64-64-64-64-64-64_ep365_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep365_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-111\\e100_l64-64-64-64-64-64_ep365_s\\predictions-e100_l64-64-64-64-64-64_ep365_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-111\\e100_l64-64-64-64-64-64_ep365_s\\predictions-e100_l64-64-64-64-64-64_ep365_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-111\\e100_l64-64-64-64-64-64_ep365_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-111\\e100_l64-64-64-64-64-64_ep365_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-111\\e100_l64-64-64-64-64-64_ep365_s\\model\\assets\n",
      "[I 2026-01-15 06:59:56,292] Trial 111 finished with value: 0.882609486579895 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 365}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-111\\e100_l64-64-64-64-64-64_ep365_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-111\\e100_l64-64-64-64-64-64_ep365_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-112\\e100_l64-64-64-64-64-64_ep355_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-112\\e100_l64-64-64-64-64-64_ep355_s  \n",
      "run_experiment()  when: 2026-01-15 06:59:56.333305 params: {'epochs': 355, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 07:00:08.034472\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-112\\e100_l64-64-64-64-64-64_ep355_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep355_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-112\\e100_l64-64-64-64-64-64_ep355_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep355_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-112\\e100_l64-64-64-64-64-64_ep355_s\\predictions-e100_l64-64-64-64-64-64_ep355_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-112\\e100_l64-64-64-64-64-64_ep355_s\\predictions-e100_l64-64-64-64-64-64_ep355_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-112\\e100_l64-64-64-64-64-64_ep355_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-112\\e100_l64-64-64-64-64-64_ep355_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-112\\e100_l64-64-64-64-64-64_ep355_s\\model\\assets\n",
      "[I 2026-01-15 07:02:00,776] Trial 112 finished with value: 0.8939773440361023 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 355}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-112\\e100_l64-64-64-64-64-64_ep355_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-112\\e100_l64-64-64-64-64-64_ep355_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-113\\e100_l64-64-64-64-64-64_ep225_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-113\\e100_l64-64-64-64-64-64_ep225_s  \n",
      "run_experiment()  when: 2026-01-15 07:02:01.021927 params: {'epochs': 225, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 07:03:10.939250\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-113\\e100_l64-64-64-64-64-64_ep225_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep225_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-113\\e100_l64-64-64-64-64-64_ep225_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep225_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-113\\e100_l64-64-64-64-64-64_ep225_s\\predictions-e100_l64-64-64-64-64-64_ep225_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-113\\e100_l64-64-64-64-64-64_ep225_s\\predictions-e100_l64-64-64-64-64-64_ep225_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-113\\e100_l64-64-64-64-64-64_ep225_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-113\\e100_l64-64-64-64-64-64_ep225_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-113\\e100_l64-64-64-64-64-64_ep225_s\\model\\assets\n",
      "[I 2026-01-15 07:05:29,931] Trial 113 finished with value: 0.8854363560676575 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 225}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-113\\e100_l64-64-64-64-64-64_ep225_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-113\\e100_l64-64-64-64-64-64_ep225_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-114\\e100_l64-64-64-64-64-64_ep340_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-114\\e100_l64-64-64-64-64-64_ep340_s  \n",
      "run_experiment()  when: 2026-01-15 07:05:29.971205 params: {'epochs': 340, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 07:05:40.111135\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-114\\e100_l64-64-64-64-64-64_ep340_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep340_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-114\\e100_l64-64-64-64-64-64_ep340_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep340_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-114\\e100_l64-64-64-64-64-64_ep340_s\\predictions-e100_l64-64-64-64-64-64_ep340_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-114\\e100_l64-64-64-64-64-64_ep340_s\\predictions-e100_l64-64-64-64-64-64_ep340_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-114\\e100_l64-64-64-64-64-64_ep340_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-114\\e100_l64-64-64-64-64-64_ep340_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-114\\e100_l64-64-64-64-64-64_ep340_s\\model\\assets\n",
      "[I 2026-01-15 07:08:08,538] Trial 114 finished with value: 0.9024441242218018 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 340}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-114\\e100_l64-64-64-64-64-64_ep340_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-114\\e100_l64-64-64-64-64-64_ep340_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-115\\e100_l64-64-64-64-64-64_ep330_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-115\\e100_l64-64-64-64-64-64_ep330_s  \n",
      "run_experiment()  when: 2026-01-15 07:08:08.820977 params: {'epochs': 330, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 07:09:28.201839\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 6ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-115\\e100_l64-64-64-64-64-64_ep330_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep330_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-115\\e100_l64-64-64-64-64-64_ep330_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep330_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-115\\e100_l64-64-64-64-64-64_ep330_s\\predictions-e100_l64-64-64-64-64-64_ep330_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-115\\e100_l64-64-64-64-64-64_ep330_s\\predictions-e100_l64-64-64-64-64-64_ep330_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-115\\e100_l64-64-64-64-64-64_ep330_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-115\\e100_l64-64-64-64-64-64_ep330_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-115\\e100_l64-64-64-64-64-64_ep330_s\\model\\assets\n",
      "[I 2026-01-15 07:12:20,684] Trial 115 finished with value: 0.8928790092468262 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 330}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-115\\e100_l64-64-64-64-64-64_ep330_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-115\\e100_l64-64-64-64-64-64_ep330_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-116\\e100_l64-64-64-64-64-64_ep315_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-116\\e100_l64-64-64-64-64-64_ep315_s  \n",
      "run_experiment()  when: 2026-01-15 07:12:20.725351 params: {'epochs': 315, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 07:12:31.950461\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-116\\e100_l64-64-64-64-64-64_ep315_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep315_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-116\\e100_l64-64-64-64-64-64_ep315_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep315_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-116\\e100_l64-64-64-64-64-64_ep315_s\\predictions-e100_l64-64-64-64-64-64_ep315_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-116\\e100_l64-64-64-64-64-64_ep315_s\\predictions-e100_l64-64-64-64-64-64_ep315_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-116\\e100_l64-64-64-64-64-64_ep315_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-116\\e100_l64-64-64-64-64-64_ep315_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-116\\e100_l64-64-64-64-64-64_ep315_s\\model\\assets\n",
      "[I 2026-01-15 07:14:50,594] Trial 116 finished with value: 0.8935417532920837 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 315}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-116\\e100_l64-64-64-64-64-64_ep315_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-116\\e100_l64-64-64-64-64-64_ep315_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-117\\e100_l64-64-64-64-64-64_ep410_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-117\\e100_l64-64-64-64-64-64_ep410_s  \n",
      "run_experiment()  when: 2026-01-15 07:14:50.889196 params: {'epochs': 410, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 07:15:51.037821\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-117\\e100_l64-64-64-64-64-64_ep410_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep410_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-117\\e100_l64-64-64-64-64-64_ep410_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep410_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-117\\e100_l64-64-64-64-64-64_ep410_s\\predictions-e100_l64-64-64-64-64-64_ep410_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-117\\e100_l64-64-64-64-64-64_ep410_s\\predictions-e100_l64-64-64-64-64-64_ep410_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-117\\e100_l64-64-64-64-64-64_ep410_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-117\\e100_l64-64-64-64-64-64_ep410_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-117\\e100_l64-64-64-64-64-64_ep410_s\\model\\assets\n",
      "[I 2026-01-15 07:19:38,541] Trial 117 finished with value: 0.8686186671257019 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 410}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-117\\e100_l64-64-64-64-64-64_ep410_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-117\\e100_l64-64-64-64-64-64_ep410_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-118\\e100_l64-64-64-64-64_ep295_sig_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-118\\e100_l64-64-64-64-64_ep295_sig_  \n",
      "run_experiment()  when: 2026-01-15 07:19:38.592064 params: {'epochs': 295, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 07:20:40.207712\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 800us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-118\\e100_l64-64-64-64-64_ep295_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep295_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-118\\e100_l64-64-64-64-64_ep295_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep295_sig_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-118\\e100_l64-64-64-64-64_ep295_sig_\\predictions-e100_l64-64-64-64-64_ep295_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-118\\e100_l64-64-64-64-64_ep295_sig_\\predictions-e100_l64-64-64-64-64_ep295_sig_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-118\\e100_l64-64-64-64-64_ep295_sig_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-118\\e100_l64-64-64-64-64_ep295_sig_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-118\\e100_l64-64-64-64-64_ep295_sig_\\model\\assets\n",
      "[I 2026-01-15 07:22:15,553] Trial 118 finished with value: 0.891919732093811 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 64, 'embedding_dim': 100, 'epochs': 295}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-118\\e100_l64-64-64-64-64_ep295_sig_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-118\\e100_l64-64-64-64-64_ep295_sig_\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-119\\e100_l64-64-64-64-64-64_ep210_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-119\\e100_l64-64-64-64-64-64_ep210_s  \n",
      "run_experiment()  when: 2026-01-15 07:22:15.593183 params: {'epochs': 210, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 07:22:27.921313\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-119\\e100_l64-64-64-64-64-64_ep210_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep210_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-119\\e100_l64-64-64-64-64-64_ep210_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep210_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-119\\e100_l64-64-64-64-64-64_ep210_s\\predictions-e100_l64-64-64-64-64-64_ep210_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-119\\e100_l64-64-64-64-64-64_ep210_s\\predictions-e100_l64-64-64-64-64-64_ep210_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-119\\e100_l64-64-64-64-64-64_ep210_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-119\\e100_l64-64-64-64-64-64_ep210_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-119\\e100_l64-64-64-64-64-64_ep210_s\\model\\assets\n",
      "[I 2026-01-15 07:26:16,888] Trial 119 finished with value: 0.8895887732505798 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 210}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-119\\e100_l64-64-64-64-64-64_ep210_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-119\\e100_l64-64-64-64-64-64_ep210_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-120\\e100_l64-64-64-64-64-64_ep275_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-120\\e100_l64-64-64-64-64-64_ep275_s  \n",
      "run_experiment()  when: 2026-01-15 07:26:17.146811 params: {'epochs': 275, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 07:27:13.337521\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 3ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-120\\e100_l64-64-64-64-64-64_ep275_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep275_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-120\\e100_l64-64-64-64-64-64_ep275_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep275_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-120\\e100_l64-64-64-64-64-64_ep275_s\\predictions-e100_l64-64-64-64-64-64_ep275_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-120\\e100_l64-64-64-64-64-64_ep275_s\\predictions-e100_l64-64-64-64-64-64_ep275_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-120\\e100_l64-64-64-64-64-64_ep275_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-120\\e100_l64-64-64-64-64-64_ep275_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-120\\e100_l64-64-64-64-64-64_ep275_s\\model\\assets\n",
      "[I 2026-01-15 07:31:02,529] Trial 120 finished with value: 0.8844493627548218 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 275}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-120\\e100_l64-64-64-64-64-64_ep275_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-120\\e100_l64-64-64-64-64-64_ep275_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-121\\e100_l64-64-64-64-64-64_ep345_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-121\\e100_l64-64-64-64-64-64_ep345_s  \n",
      "run_experiment()  when: 2026-01-15 07:31:02.839454 params: {'epochs': 345, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 07:31:47.033413\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-121\\e100_l64-64-64-64-64-64_ep345_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep345_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-121\\e100_l64-64-64-64-64-64_ep345_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep345_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-121\\e100_l64-64-64-64-64-64_ep345_s\\predictions-e100_l64-64-64-64-64-64_ep345_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-121\\e100_l64-64-64-64-64-64_ep345_s\\predictions-e100_l64-64-64-64-64-64_ep345_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-121\\e100_l64-64-64-64-64-64_ep345_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-121\\e100_l64-64-64-64-64-64_ep345_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-121\\e100_l64-64-64-64-64-64_ep345_s\\model\\assets\n",
      "[I 2026-01-15 07:32:37,198] Trial 121 finished with value: 0.8923739194869995 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 345}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-121\\e100_l64-64-64-64-64-64_ep345_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-121\\e100_l64-64-64-64-64-64_ep345_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-122\\e100_l64-64-64-64-64-64_ep375_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-122\\e100_l64-64-64-64-64-64_ep375_s  \n",
      "run_experiment()  when: 2026-01-15 07:32:37.242604 params: {'epochs': 375, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 07:33:18.133205\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 7ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-122\\e100_l64-64-64-64-64-64_ep375_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep375_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-122\\e100_l64-64-64-64-64-64_ep375_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep375_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-122\\e100_l64-64-64-64-64-64_ep375_s\\predictions-e100_l64-64-64-64-64-64_ep375_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-122\\e100_l64-64-64-64-64-64_ep375_s\\predictions-e100_l64-64-64-64-64-64_ep375_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-122\\e100_l64-64-64-64-64-64_ep375_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-122\\e100_l64-64-64-64-64-64_ep375_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-122\\e100_l64-64-64-64-64-64_ep375_s\\model\\assets\n",
      "[I 2026-01-15 07:36:44,732] Trial 122 finished with value: 0.8983798623085022 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 375}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-122\\e100_l64-64-64-64-64-64_ep375_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-122\\e100_l64-64-64-64-64-64_ep375_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-123\\e100_l64-64-64-64-64-64_ep285_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-123\\e100_l64-64-64-64-64-64_ep285_s  \n",
      "run_experiment()  when: 2026-01-15 07:36:44.771193 params: {'epochs': 285, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 07:37:20.821323\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-123\\e100_l64-64-64-64-64-64_ep285_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep285_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-123\\e100_l64-64-64-64-64-64_ep285_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep285_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-123\\e100_l64-64-64-64-64-64_ep285_s\\predictions-e100_l64-64-64-64-64-64_ep285_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-123\\e100_l64-64-64-64-64-64_ep285_s\\predictions-e100_l64-64-64-64-64-64_ep285_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-123\\e100_l64-64-64-64-64-64_ep285_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-123\\e100_l64-64-64-64-64-64_ep285_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-123\\e100_l64-64-64-64-64-64_ep285_s\\model\\assets\n",
      "[I 2026-01-15 07:38:26,841] Trial 123 finished with value: 0.8823592066764832 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 285}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-123\\e100_l64-64-64-64-64-64_ep285_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-123\\e100_l64-64-64-64-64-64_ep285_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-124\\e100_l64-64-64-64-64-64_ep335_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-124\\e100_l64-64-64-64-64-64_ep335_s  \n",
      "run_experiment()  when: 2026-01-15 07:38:27.106175 params: {'epochs': 335, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 07:39:29.110607\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 6ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-124\\e100_l64-64-64-64-64-64_ep335_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep335_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-124\\e100_l64-64-64-64-64-64_ep335_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep335_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-124\\e100_l64-64-64-64-64-64_ep335_s\\predictions-e100_l64-64-64-64-64-64_ep335_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-124\\e100_l64-64-64-64-64-64_ep335_s\\predictions-e100_l64-64-64-64-64-64_ep335_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-124\\e100_l64-64-64-64-64-64_ep335_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-124\\e100_l64-64-64-64-64-64_ep335_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-124\\e100_l64-64-64-64-64-64_ep335_s\\model\\assets\n",
      "[I 2026-01-15 07:43:23,469] Trial 124 finished with value: 0.8981990814208984 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 335}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-124\\e100_l64-64-64-64-64-64_ep335_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-124\\e100_l64-64-64-64-64-64_ep335_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-125\\e100_l64-64-64-64-64-64_ep360_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-125\\e100_l64-64-64-64-64-64_ep360_s  \n",
      "run_experiment()  when: 2026-01-15 07:43:23.751395 params: {'epochs': 360, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 07:44:25.431610\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 4ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-125\\e100_l64-64-64-64-64-64_ep360_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep360_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-125\\e100_l64-64-64-64-64-64_ep360_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep360_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-125\\e100_l64-64-64-64-64-64_ep360_s\\predictions-e100_l64-64-64-64-64-64_ep360_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-125\\e100_l64-64-64-64-64-64_ep360_s\\predictions-e100_l64-64-64-64-64-64_ep360_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-125\\e100_l64-64-64-64-64-64_ep360_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-125\\e100_l64-64-64-64-64-64_ep360_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-125\\e100_l64-64-64-64-64-64_ep360_s\\model\\assets\n",
      "[I 2026-01-15 07:46:49,572] Trial 125 finished with value: 0.8969293832778931 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 360}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-125\\e100_l64-64-64-64-64-64_ep360_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-125\\e100_l64-64-64-64-64-64_ep360_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-126\\e100_l64-64-64-64-64-64_ep235_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-126\\e100_l64-64-64-64-64-64_ep235_s  \n",
      "run_experiment()  when: 2026-01-15 07:46:49.615196 params: {'epochs': 235, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 07:47:00.252754\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 3ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-126\\e100_l64-64-64-64-64-64_ep235_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep235_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-126\\e100_l64-64-64-64-64-64_ep235_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep235_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-126\\e100_l64-64-64-64-64-64_ep235_s\\predictions-e100_l64-64-64-64-64-64_ep235_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-126\\e100_l64-64-64-64-64-64_ep235_s\\predictions-e100_l64-64-64-64-64-64_ep235_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-126\\e100_l64-64-64-64-64-64_ep235_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-126\\e100_l64-64-64-64-64-64_ep235_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-126\\e100_l64-64-64-64-64-64_ep235_s\\model\\assets\n",
      "[I 2026-01-15 07:49:41,298] Trial 126 finished with value: 0.8968691825866699 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 235}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-126\\e100_l64-64-64-64-64-64_ep235_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-126\\e100_l64-64-64-64-64-64_ep235_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-127\\e100_l64-64-64-64-64-64_ep385_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-127\\e100_l64-64-64-64-64-64_ep385_s  \n",
      "run_experiment()  when: 2026-01-15 07:49:41.622725 params: {'epochs': 385, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 07:50:44.480608\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 3ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-127\\e100_l64-64-64-64-64-64_ep385_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep385_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-127\\e100_l64-64-64-64-64-64_ep385_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep385_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-127\\e100_l64-64-64-64-64-64_ep385_s\\predictions-e100_l64-64-64-64-64-64_ep385_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-127\\e100_l64-64-64-64-64-64_ep385_s\\predictions-e100_l64-64-64-64-64-64_ep385_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-127\\e100_l64-64-64-64-64-64_ep385_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-127\\e100_l64-64-64-64-64-64_ep385_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-127\\e100_l64-64-64-64-64-64_ep385_s\\model\\assets\n",
      "[I 2026-01-15 07:54:45,979] Trial 127 finished with value: 0.8964890241622925 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 385}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-127\\e100_l64-64-64-64-64-64_ep385_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-127\\e100_l64-64-64-64-64-64_ep385_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-128\\e100_l64-64-64-64-64-64_ep255_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-128\\e100_l64-64-64-64-64-64_ep255_s  \n",
      "run_experiment()  when: 2026-01-15 07:54:46.306446 params: {'epochs': 255, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 07:55:49.394931\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 3ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-128\\e100_l64-64-64-64-64-64_ep255_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep255_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-128\\e100_l64-64-64-64-64-64_ep255_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep255_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-128\\e100_l64-64-64-64-64-64_ep255_s\\predictions-e100_l64-64-64-64-64-64_ep255_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-128\\e100_l64-64-64-64-64-64_ep255_s\\predictions-e100_l64-64-64-64-64-64_ep255_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-128\\e100_l64-64-64-64-64-64_ep255_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-128\\e100_l64-64-64-64-64-64_ep255_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-128\\e100_l64-64-64-64-64-64_ep255_s\\model\\assets\n",
      "[I 2026-01-15 07:59:25,671] Trial 128 finished with value: 0.8929855823516846 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 255}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-128\\e100_l64-64-64-64-64-64_ep255_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-128\\e100_l64-64-64-64-64-64_ep255_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-129\\e100_l64-64-64-64_ep180_sig_164\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-129\\e100_l64-64-64-64_ep180_sig_164  \n",
      "run_experiment()  when: 2026-01-15 07:59:25.712730 params: {'epochs': 180, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 07:59:36.920202\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-129\\e100_l64-64-64-64_ep180_sig_164\\normalized_training_df-e100_l64-64-64-64_ep180_sig_164.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-129\\e100_l64-64-64-64_ep180_sig_164\\normalized_training_df-e100_l64-64-64-64_ep180_sig_164.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-129\\e100_l64-64-64-64_ep180_sig_164\\predictions-e100_l64-64-64-64_ep180_sig_164.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-129\\e100_l64-64-64-64_ep180_sig_164\\predictions-e100_l64-64-64-64_ep180_sig_164.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-129\\e100_l64-64-64-64_ep180_sig_164\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-129\\e100_l64-64-64-64_ep180_sig_164\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-129\\e100_l64-64-64-64_ep180_sig_164\\model\\assets\n",
      "[I 2026-01-15 08:01:14,671] Trial 129 finished with value: 0.8941811323165894 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 180}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-129\\e100_l64-64-64-64_ep180_sig_164\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-129\\e100_l64-64-64-64_ep180_sig_164\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-130\\e100_l64-64-64-64-64-64_ep350_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-130\\e100_l64-64-64-64-64-64_ep350_s  \n",
      "run_experiment()  when: 2026-01-15 08:01:14.766062 params: {'epochs': 350, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 08:02:17.256688\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-130\\e100_l64-64-64-64-64-64_ep350_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep350_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-130\\e100_l64-64-64-64-64-64_ep350_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep350_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-130\\e100_l64-64-64-64-64-64_ep350_s\\predictions-e100_l64-64-64-64-64-64_ep350_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-130\\e100_l64-64-64-64-64-64_ep350_s\\predictions-e100_l64-64-64-64-64-64_ep350_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-130\\e100_l64-64-64-64-64-64_ep350_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-130\\e100_l64-64-64-64-64-64_ep350_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-130\\e100_l64-64-64-64-64-64_ep350_s\\model\\assets\n",
      "[I 2026-01-15 08:06:07,914] Trial 130 finished with value: 0.8909975290298462 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 350}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-130\\e100_l64-64-64-64-64-64_ep350_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-130\\e100_l64-64-64-64-64-64_ep350_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-131\\e100_l64-64-64-64-64-64_ep200_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-131\\e100_l64-64-64-64-64-64_ep200_s  \n",
      "run_experiment()  when: 2026-01-15 08:06:08.195610 params: {'epochs': 200, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 08:07:05.974166\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-131\\e100_l64-64-64-64-64-64_ep200_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep200_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-131\\e100_l64-64-64-64-64-64_ep200_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep200_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-131\\e100_l64-64-64-64-64-64_ep200_s\\predictions-e100_l64-64-64-64-64-64_ep200_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-131\\e100_l64-64-64-64-64-64_ep200_s\\predictions-e100_l64-64-64-64-64-64_ep200_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-131\\e100_l64-64-64-64-64-64_ep200_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-131\\e100_l64-64-64-64-64-64_ep200_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-131\\e100_l64-64-64-64-64-64_ep200_s\\model\\assets\n",
      "[I 2026-01-15 08:08:58,557] Trial 131 finished with value: 0.8931015133857727 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 200}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-131\\e100_l64-64-64-64-64-64_ep200_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-131\\e100_l64-64-64-64-64-64_ep200_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-132\\e100_l64-64-64-64-64-64_ep215_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-132\\e100_l64-64-64-64-64-64_ep215_s  \n",
      "run_experiment()  when: 2026-01-15 08:08:58.608791 params: {'epochs': 215, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 08:09:10.644580\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-132\\e100_l64-64-64-64-64-64_ep215_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep215_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-132\\e100_l64-64-64-64-64-64_ep215_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep215_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-132\\e100_l64-64-64-64-64-64_ep215_s\\predictions-e100_l64-64-64-64-64-64_ep215_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-132\\e100_l64-64-64-64-64-64_ep215_s\\predictions-e100_l64-64-64-64-64-64_ep215_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-132\\e100_l64-64-64-64-64-64_ep215_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-132\\e100_l64-64-64-64-64-64_ep215_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-132\\e100_l64-64-64-64-64-64_ep215_s\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-132\\e100_l64-64-64-64-64-64_ep215_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-132\\e100_l64-64-64-64-64-64_ep215_s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-15 08:12:27,786] Trial 132 finished with value: 0.8950200080871582 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 215}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-133\\e100_l64-64-64-64-64-64_ep205_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-133\\e100_l64-64-64-64-64-64_ep205_s  \n",
      "run_experiment()  when: 2026-01-15 08:12:28.074749 params: {'epochs': 205, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 08:13:33.038813\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-133\\e100_l64-64-64-64-64-64_ep205_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep205_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-133\\e100_l64-64-64-64-64-64_ep205_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep205_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-133\\e100_l64-64-64-64-64-64_ep205_s\\predictions-e100_l64-64-64-64-64-64_ep205_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-133\\e100_l64-64-64-64-64-64_ep205_s\\predictions-e100_l64-64-64-64-64-64_ep205_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-133\\e100_l64-64-64-64-64-64_ep205_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-133\\e100_l64-64-64-64-64-64_ep205_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-133\\e100_l64-64-64-64-64-64_ep205_s\\model\\assets\n",
      "[I 2026-01-15 08:17:34,854] Trial 133 finished with value: 0.880769670009613 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 205}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-133\\e100_l64-64-64-64-64-64_ep205_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-133\\e100_l64-64-64-64-64-64_ep205_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-134\\e100_l64-64-64-64-64-64_ep225_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-134\\e100_l64-64-64-64-64-64_ep225_s  \n",
      "run_experiment()  when: 2026-01-15 08:17:34.897378 params: {'epochs': 225, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 08:17:44.005421\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-134\\e100_l64-64-64-64-64-64_ep225_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep225_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-134\\e100_l64-64-64-64-64-64_ep225_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep225_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-134\\e100_l64-64-64-64-64-64_ep225_s\\predictions-e100_l64-64-64-64-64-64_ep225_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-134\\e100_l64-64-64-64-64-64_ep225_s\\predictions-e100_l64-64-64-64-64-64_ep225_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-134\\e100_l64-64-64-64-64-64_ep225_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-134\\e100_l64-64-64-64-64-64_ep225_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-134\\e100_l64-64-64-64-64-64_ep225_s\\model\\assets\n",
      "[I 2026-01-15 08:19:03,373] Trial 134 finished with value: 0.896859884262085 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 225}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-134\\e100_l64-64-64-64-64-64_ep225_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-134\\e100_l64-64-64-64-64-64_ep225_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-135\\e100_l64-64-64-64-64-64_ep160_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-135\\e100_l64-64-64-64-64-64_ep160_s  \n",
      "run_experiment()  when: 2026-01-15 08:19:03.679164 params: {'epochs': 160, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 08:20:04.285576\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 15ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-135\\e100_l64-64-64-64-64-64_ep160_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep160_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-135\\e100_l64-64-64-64-64-64_ep160_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep160_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-135\\e100_l64-64-64-64-64-64_ep160_s\\predictions-e100_l64-64-64-64-64-64_ep160_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-135\\e100_l64-64-64-64-64-64_ep160_s\\predictions-e100_l64-64-64-64-64-64_ep160_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-135\\e100_l64-64-64-64-64-64_ep160_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-135\\e100_l64-64-64-64-64-64_ep160_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-135\\e100_l64-64-64-64-64-64_ep160_s\\model\\assets\n",
      "[I 2026-01-15 08:23:54,311] Trial 135 finished with value: 0.8557307124137878 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 160}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-135\\e100_l64-64-64-64-64-64_ep160_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-135\\e100_l64-64-64-64-64-64_ep160_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-136\\e100_l64-64-64-64-64-64_ep195_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-136\\e100_l64-64-64-64-64-64_ep195_s  \n",
      "run_experiment()  when: 2026-01-15 08:23:54.579520 params: {'epochs': 195, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 08:24:52.079041\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-136\\e100_l64-64-64-64-64-64_ep195_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep195_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-136\\e100_l64-64-64-64-64-64_ep195_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep195_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-136\\e100_l64-64-64-64-64-64_ep195_s\\predictions-e100_l64-64-64-64-64-64_ep195_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-136\\e100_l64-64-64-64-64-64_ep195_s\\predictions-e100_l64-64-64-64-64-64_ep195_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-136\\e100_l64-64-64-64-64-64_ep195_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-136\\e100_l64-64-64-64-64-64_ep195_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-136\\e100_l64-64-64-64-64-64_ep195_s\\model\\assets\n",
      "[I 2026-01-15 08:28:42,415] Trial 136 finished with value: 0.8950014114379883 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 195}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-136\\e100_l64-64-64-64-64-64_ep195_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-136\\e100_l64-64-64-64-64-64_ep195_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-137\\e100_l64-64-64-64-64-64_ep245_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-137\\e100_l64-64-64-64-64-64_ep245_s  \n",
      "run_experiment()  when: 2026-01-15 08:28:42.507104 params: {'epochs': 245, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 08:28:55.537065\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-137\\e100_l64-64-64-64-64-64_ep245_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep245_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-137\\e100_l64-64-64-64-64-64_ep245_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep245_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-137\\e100_l64-64-64-64-64-64_ep245_s\\predictions-e100_l64-64-64-64-64-64_ep245_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-137\\e100_l64-64-64-64-64-64_ep245_s\\predictions-e100_l64-64-64-64-64-64_ep245_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-137\\e100_l64-64-64-64-64-64_ep245_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-137\\e100_l64-64-64-64-64-64_ep245_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-137\\e100_l64-64-64-64-64-64_ep245_s\\model\\assets\n",
      "[I 2026-01-15 08:30:19,366] Trial 137 finished with value: 0.883415937423706 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 245}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-137\\e100_l64-64-64-64-64-64_ep245_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-137\\e100_l64-64-64-64-64-64_ep245_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-138\\e100_l64-64-64-64-64_ep370_sig_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-138\\e100_l64-64-64-64-64_ep370_sig_  \n",
      "run_experiment()  when: 2026-01-15 08:30:19.700934 params: {'epochs': 370, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 08:31:25.276697\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 9ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-138\\e100_l64-64-64-64-64_ep370_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep370_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-138\\e100_l64-64-64-64-64_ep370_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep370_sig_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-138\\e100_l64-64-64-64-64_ep370_sig_\\predictions-e100_l64-64-64-64-64_ep370_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-138\\e100_l64-64-64-64-64_ep370_sig_\\predictions-e100_l64-64-64-64-64_ep370_sig_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-138\\e100_l64-64-64-64-64_ep370_sig_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-138\\e100_l64-64-64-64-64_ep370_sig_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-138\\e100_l64-64-64-64-64_ep370_sig_\\model\\assets\n",
      "[I 2026-01-15 08:35:13,858] Trial 138 finished with value: 0.8847830295562744 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 64, 'embedding_dim': 100, 'epochs': 370}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-138\\e100_l64-64-64-64-64_ep370_sig_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-138\\e100_l64-64-64-64-64_ep370_sig_\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-139\\e100_l64-64-64-64-64-64_ep170_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-139\\e100_l64-64-64-64-64-64_ep170_s  \n",
      "run_experiment()  when: 2026-01-15 08:35:14.134420 params: {'epochs': 170, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 08:36:31.441753\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-139\\e100_l64-64-64-64-64-64_ep170_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep170_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-139\\e100_l64-64-64-64-64-64_ep170_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep170_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-139\\e100_l64-64-64-64-64-64_ep170_s\\predictions-e100_l64-64-64-64-64-64_ep170_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-139\\e100_l64-64-64-64-64-64_ep170_s\\predictions-e100_l64-64-64-64-64-64_ep170_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-139\\e100_l64-64-64-64-64-64_ep170_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-139\\e100_l64-64-64-64-64-64_ep170_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-139\\e100_l64-64-64-64-64-64_ep170_s\\model\\assets\n",
      "[I 2026-01-15 08:38:54,934] Trial 139 finished with value: 0.8809967041015625 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 170}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-139\\e100_l64-64-64-64-64-64_ep170_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-139\\e100_l64-64-64-64-64-64_ep170_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-140\\e100_l64-64-64-64-64-64_ep340_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-140\\e100_l64-64-64-64-64-64_ep340_s  \n",
      "run_experiment()  when: 2026-01-15 08:38:54.974757 params: {'epochs': 340, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 08:39:06.713149\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-140\\e100_l64-64-64-64-64-64_ep340_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep340_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-140\\e100_l64-64-64-64-64-64_ep340_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep340_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-140\\e100_l64-64-64-64-64-64_ep340_s\\predictions-e100_l64-64-64-64-64-64_ep340_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-140\\e100_l64-64-64-64-64-64_ep340_s\\predictions-e100_l64-64-64-64-64-64_ep340_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-140\\e100_l64-64-64-64-64-64_ep340_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-140\\e100_l64-64-64-64-64-64_ep340_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-140\\e100_l64-64-64-64-64-64_ep340_s\\model\\assets\n",
      "[I 2026-01-15 08:41:40,462] Trial 140 finished with value: 0.8791986107826233 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 340}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-140\\e100_l64-64-64-64-64-64_ep340_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-140\\e100_l64-64-64-64-64-64_ep340_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-141\\e100_l64-64-64-64-64-64_ep355_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-141\\e100_l64-64-64-64-64-64_ep355_s  \n",
      "run_experiment()  when: 2026-01-15 08:41:40.733420 params: {'epochs': 355, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 08:42:48.665532\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 8ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-141\\e100_l64-64-64-64-64-64_ep355_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep355_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-141\\e100_l64-64-64-64-64-64_ep355_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep355_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-141\\e100_l64-64-64-64-64-64_ep355_s\\predictions-e100_l64-64-64-64-64-64_ep355_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-141\\e100_l64-64-64-64-64-64_ep355_s\\predictions-e100_l64-64-64-64-64-64_ep355_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-141\\e100_l64-64-64-64-64-64_ep355_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-141\\e100_l64-64-64-64-64-64_ep355_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-141\\e100_l64-64-64-64-64-64_ep355_s\\model\\assets\n",
      "[I 2026-01-15 08:46:52,340] Trial 141 finished with value: 0.8948624134063721 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 355}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-141\\e100_l64-64-64-64-64-64_ep355_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-141\\e100_l64-64-64-64-64-64_ep355_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-142\\e100_l64-64-64-64-64-64_ep310_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-142\\e100_l64-64-64-64-64-64_ep310_s  \n",
      "run_experiment()  when: 2026-01-15 08:46:52.392259 params: {'epochs': 310, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 08:47:55.053472\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 800us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-142\\e100_l64-64-64-64-64-64_ep310_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep310_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-142\\e100_l64-64-64-64-64-64_ep310_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep310_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-142\\e100_l64-64-64-64-64-64_ep310_s\\predictions-e100_l64-64-64-64-64-64_ep310_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-142\\e100_l64-64-64-64-64-64_ep310_s\\predictions-e100_l64-64-64-64-64-64_ep310_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-142\\e100_l64-64-64-64-64-64_ep310_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-142\\e100_l64-64-64-64-64-64_ep310_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-142\\e100_l64-64-64-64-64-64_ep310_s\\model\\assets\n",
      "[I 2026-01-15 08:48:48,970] Trial 142 finished with value: 0.8927398920059204 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 310}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-142\\e100_l64-64-64-64-64-64_ep310_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-142\\e100_l64-64-64-64-64-64_ep310_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-143\\e100_l64-64-64-64-64-64_ep380_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-143\\e100_l64-64-64-64-64-64_ep380_s  \n",
      "run_experiment()  when: 2026-01-15 08:48:49.012884 params: {'epochs': 380, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 08:49:15.554089\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-143\\e100_l64-64-64-64-64-64_ep380_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep380_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-143\\e100_l64-64-64-64-64-64_ep380_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep380_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-143\\e100_l64-64-64-64-64-64_ep380_s\\predictions-e100_l64-64-64-64-64-64_ep380_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-143\\e100_l64-64-64-64-64-64_ep380_s\\predictions-e100_l64-64-64-64-64-64_ep380_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-143\\e100_l64-64-64-64-64-64_ep380_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-143\\e100_l64-64-64-64-64-64_ep380_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-143\\e100_l64-64-64-64-64-64_ep380_s\\model\\assets\n",
      "[I 2026-01-15 08:51:33,289] Trial 143 finished with value: 0.9042839407920837 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 380}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-143\\e100_l64-64-64-64-64-64_ep380_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-143\\e100_l64-64-64-64-64-64_ep380_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-144\\e100_l64-64-64-64-64-64_ep405_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-144\\e100_l64-64-64-64-64-64_ep405_s  \n",
      "run_experiment()  when: 2026-01-15 08:51:33.331175 params: {'epochs': 405, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 08:51:45.179866\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-144\\e100_l64-64-64-64-64-64_ep405_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep405_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-144\\e100_l64-64-64-64-64-64_ep405_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep405_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-144\\e100_l64-64-64-64-64-64_ep405_s\\predictions-e100_l64-64-64-64-64-64_ep405_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-144\\e100_l64-64-64-64-64-64_ep405_s\\predictions-e100_l64-64-64-64-64-64_ep405_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-144\\e100_l64-64-64-64-64-64_ep405_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-144\\e100_l64-64-64-64-64-64_ep405_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-144\\e100_l64-64-64-64-64-64_ep405_s\\model\\assets\n",
      "[I 2026-01-15 08:54:07,940] Trial 144 finished with value: 0.8885738849639893 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 405}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-144\\e100_l64-64-64-64-64-64_ep405_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-144\\e100_l64-64-64-64-64-64_ep405_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-145\\e100_l64-64-64-64-64-64_ep365_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-145\\e100_l64-64-64-64-64-64_ep365_s  \n",
      "run_experiment()  when: 2026-01-15 08:54:08.201253 params: {'epochs': 365, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 08:55:23.203585\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-145\\e100_l64-64-64-64-64-64_ep365_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep365_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-145\\e100_l64-64-64-64-64-64_ep365_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep365_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-145\\e100_l64-64-64-64-64-64_ep365_s\\predictions-e100_l64-64-64-64-64-64_ep365_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-145\\e100_l64-64-64-64-64-64_ep365_s\\predictions-e100_l64-64-64-64-64-64_ep365_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-145\\e100_l64-64-64-64-64-64_ep365_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-145\\e100_l64-64-64-64-64-64_ep365_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-145\\e100_l64-64-64-64-64-64_ep365_s\\model\\assets\n",
      "[I 2026-01-15 08:59:13,355] Trial 145 finished with value: 0.8764829635620117 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 365}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-145\\e100_l64-64-64-64-64-64_ep365_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-145\\e100_l64-64-64-64-64-64_ep365_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-146\\e100_l64-64-64-64-64-64_ep380_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-146\\e100_l64-64-64-64-64-64_ep380_s  \n",
      "run_experiment()  when: 2026-01-15 08:59:13.628589 params: {'epochs': 380, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 09:00:04.670971\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-146\\e100_l64-64-64-64-64-64_ep380_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep380_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-146\\e100_l64-64-64-64-64-64_ep380_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep380_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-146\\e100_l64-64-64-64-64-64_ep380_s\\predictions-e100_l64-64-64-64-64-64_ep380_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-146\\e100_l64-64-64-64-64-64_ep380_s\\predictions-e100_l64-64-64-64-64-64_ep380_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-146\\e100_l64-64-64-64-64-64_ep380_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-146\\e100_l64-64-64-64-64-64_ep380_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-146\\e100_l64-64-64-64-64-64_ep380_s\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-146\\e100_l64-64-64-64-64-64_ep380_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-146\\e100_l64-64-64-64-64-64_ep380_s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-15 09:01:14,242] Trial 146 finished with value: 0.8873410224914551 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 380}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-147\\e100_l64-64-64-64-64-64_ep435_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-147\\e100_l64-64-64-64-64-64_ep435_s  \n",
      "run_experiment()  when: 2026-01-15 09:01:14.527874 params: {'epochs': 435, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 09:02:22.067074\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-147\\e100_l64-64-64-64-64-64_ep435_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep435_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-147\\e100_l64-64-64-64-64-64_ep435_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep435_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-147\\e100_l64-64-64-64-64-64_ep435_s\\predictions-e100_l64-64-64-64-64-64_ep435_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-147\\e100_l64-64-64-64-64-64_ep435_s\\predictions-e100_l64-64-64-64-64-64_ep435_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-147\\e100_l64-64-64-64-64-64_ep435_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-147\\e100_l64-64-64-64-64-64_ep435_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-147\\e100_l64-64-64-64-64-64_ep435_s\\model\\assets\n",
      "[I 2026-01-15 09:06:04,192] Trial 147 finished with value: 0.883327841758728 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 435}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-147\\e100_l64-64-64-64-64-64_ep435_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-147\\e100_l64-64-64-64-64-64_ep435_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-148\\e100_l64-64-64-64-64-64_ep325_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-148\\e100_l64-64-64-64-64-64_ep325_s  \n",
      "run_experiment()  when: 2026-01-15 09:06:04.235648 params: {'epochs': 325, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 09:07:17.473358\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-148\\e100_l64-64-64-64-64-64_ep325_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep325_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-148\\e100_l64-64-64-64-64-64_ep325_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep325_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-148\\e100_l64-64-64-64-64-64_ep325_s\\predictions-e100_l64-64-64-64-64-64_ep325_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-148\\e100_l64-64-64-64-64-64_ep325_s\\predictions-e100_l64-64-64-64-64-64_ep325_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-148\\e100_l64-64-64-64-64-64_ep325_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-148\\e100_l64-64-64-64-64-64_ep325_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-148\\e100_l64-64-64-64-64-64_ep325_s\\model\\assets\n",
      "[I 2026-01-15 09:08:48,469] Trial 148 finished with value: 0.89274001121521 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 325}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-148\\e100_l64-64-64-64-64-64_ep325_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-148\\e100_l64-64-64-64-64-64_ep325_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-149\\e100_l64-64-64-64-64-64_ep390_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-149\\e100_l64-64-64-64-64-64_ep390_s  \n",
      "run_experiment()  when: 2026-01-15 09:08:48.511078 params: {'epochs': 390, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 09:08:59.828334\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 16ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-149\\e100_l64-64-64-64-64-64_ep390_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep390_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-149\\e100_l64-64-64-64-64-64_ep390_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep390_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-149\\e100_l64-64-64-64-64-64_ep390_s\\predictions-e100_l64-64-64-64-64-64_ep390_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-149\\e100_l64-64-64-64-64-64_ep390_s\\predictions-e100_l64-64-64-64-64-64_ep390_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-149\\e100_l64-64-64-64-64-64_ep390_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-149\\e100_l64-64-64-64-64-64_ep390_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-149\\e100_l64-64-64-64-64-64_ep390_s\\model\\assets\n",
      "[I 2026-01-15 09:12:29,101] Trial 149 finished with value: 0.8938753008842468 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 390}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-149\\e100_l64-64-64-64-64-64_ep390_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-149\\e100_l64-64-64-64-64-64_ep390_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-150\\e100_l64-64-64-64-64-64_ep220_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-150\\e100_l64-64-64-64-64-64_ep220_s  \n",
      "run_experiment()  when: 2026-01-15 09:12:29.401993 params: {'epochs': 220, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 09:13:33.531642\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-150\\e100_l64-64-64-64-64-64_ep220_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep220_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-150\\e100_l64-64-64-64-64-64_ep220_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep220_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-150\\e100_l64-64-64-64-64-64_ep220_s\\predictions-e100_l64-64-64-64-64-64_ep220_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-150\\e100_l64-64-64-64-64-64_ep220_s\\predictions-e100_l64-64-64-64-64-64_ep220_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-150\\e100_l64-64-64-64-64-64_ep220_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-150\\e100_l64-64-64-64-64-64_ep220_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-150\\e100_l64-64-64-64-64-64_ep220_s\\model\\assets\n",
      "[I 2026-01-15 09:16:19,432] Trial 150 finished with value: 0.8859274983406067 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 220}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-150\\e100_l64-64-64-64-64-64_ep220_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-150\\e100_l64-64-64-64-64-64_ep220_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-151\\e100_l64-64-64-64-64-64_ep340_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-151\\e100_l64-64-64-64-64-64_ep340_s  \n",
      "run_experiment()  when: 2026-01-15 09:16:19.474104 params: {'epochs': 340, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 09:16:30.798166\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 800us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-151\\e100_l64-64-64-64-64-64_ep340_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep340_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-151\\e100_l64-64-64-64-64-64_ep340_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep340_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-151\\e100_l64-64-64-64-64-64_ep340_s\\predictions-e100_l64-64-64-64-64-64_ep340_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-151\\e100_l64-64-64-64-64-64_ep340_s\\predictions-e100_l64-64-64-64-64-64_ep340_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-151\\e100_l64-64-64-64-64-64_ep340_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-151\\e100_l64-64-64-64-64-64_ep340_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-151\\e100_l64-64-64-64-64-64_ep340_s\\model\\assets\n",
      "[I 2026-01-15 09:19:03,093] Trial 151 finished with value: 0.8915536403656006 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 340}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-151\\e100_l64-64-64-64-64-64_ep340_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-151\\e100_l64-64-64-64-64-64_ep340_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-152\\e100_l64-64-64-64-64-64_ep355_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-152\\e100_l64-64-64-64-64-64_ep355_s  \n",
      "run_experiment()  when: 2026-01-15 09:19:05.139748 params: {'epochs': 355, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 09:20:11.640705\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 3ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-152\\e100_l64-64-64-64-64-64_ep355_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep355_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-152\\e100_l64-64-64-64-64-64_ep355_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep355_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-152\\e100_l64-64-64-64-64-64_ep355_s\\predictions-e100_l64-64-64-64-64-64_ep355_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-152\\e100_l64-64-64-64-64-64_ep355_s\\predictions-e100_l64-64-64-64-64-64_ep355_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-152\\e100_l64-64-64-64-64-64_ep355_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-152\\e100_l64-64-64-64-64-64_ep355_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-152\\e100_l64-64-64-64-64-64_ep355_s\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-152\\e100_l64-64-64-64-64-64_ep355_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-152\\e100_l64-64-64-64-64-64_ep355_s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-15 09:24:19,497] Trial 152 finished with value: 0.8820210099220276 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 355}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-153\\e100_l64-64-64-64-64-64_ep370_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-153\\e100_l64-64-64-64-64-64_ep370_s  \n",
      "run_experiment()  when: 2026-01-15 09:24:19.778615 params: {'epochs': 370, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 09:25:23.333226\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 10ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-153\\e100_l64-64-64-64-64-64_ep370_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep370_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-153\\e100_l64-64-64-64-64-64_ep370_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep370_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-153\\e100_l64-64-64-64-64-64_ep370_s\\predictions-e100_l64-64-64-64-64-64_ep370_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-153\\e100_l64-64-64-64-64-64_ep370_s\\predictions-e100_l64-64-64-64-64-64_ep370_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-153\\e100_l64-64-64-64-64-64_ep370_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-153\\e100_l64-64-64-64-64-64_ep370_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-153\\e100_l64-64-64-64-64-64_ep370_s\\model\\assets\n",
      "[I 2026-01-15 09:28:01,994] Trial 153 finished with value: 0.8961368799209595 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 370}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-153\\e100_l64-64-64-64-64-64_ep370_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-153\\e100_l64-64-64-64-64-64_ep370_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-154\\e100_l64-64-64-64-64-64_ep185_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-154\\e100_l64-64-64-64-64-64_ep185_s  \n",
      "run_experiment()  when: 2026-01-15 09:28:02.044567 params: {'epochs': 185, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 09:28:16.310219\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 800us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-154\\e100_l64-64-64-64-64-64_ep185_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep185_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-154\\e100_l64-64-64-64-64-64_ep185_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep185_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-154\\e100_l64-64-64-64-64-64_ep185_s\\predictions-e100_l64-64-64-64-64-64_ep185_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-154\\e100_l64-64-64-64-64-64_ep185_s\\predictions-e100_l64-64-64-64-64-64_ep185_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-154\\e100_l64-64-64-64-64-64_ep185_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-154\\e100_l64-64-64-64-64-64_ep185_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-154\\e100_l64-64-64-64-64-64_ep185_s\\model\\assets\n",
      "[I 2026-01-15 09:30:44,502] Trial 154 finished with value: 0.8976105451583862 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 185}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-154\\e100_l64-64-64-64-64-64_ep185_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-154\\e100_l64-64-64-64-64-64_ep185_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-155\\e100_l64-64-64-64-64-64_ep230_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-155\\e100_l64-64-64-64-64-64_ep230_s  \n",
      "run_experiment()  when: 2026-01-15 09:30:44.827942 params: {'epochs': 230, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 09:32:03.636351\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 9ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-155\\e100_l64-64-64-64-64-64_ep230_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep230_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-155\\e100_l64-64-64-64-64-64_ep230_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep230_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-155\\e100_l64-64-64-64-64-64_ep230_s\\predictions-e100_l64-64-64-64-64-64_ep230_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-155\\e100_l64-64-64-64-64-64_ep230_s\\predictions-e100_l64-64-64-64-64-64_ep230_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-155\\e100_l64-64-64-64-64-64_ep230_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-155\\e100_l64-64-64-64-64-64_ep230_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-155\\e100_l64-64-64-64-64-64_ep230_s\\model\\assets\n",
      "[I 2026-01-15 09:35:52,992] Trial 155 finished with value: 0.8999834060668945 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 230}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-155\\e100_l64-64-64-64-64-64_ep230_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-155\\e100_l64-64-64-64-64-64_ep230_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-156\\e100_l64-64-64-64-64-64_ep145_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-156\\e100_l64-64-64-64-64-64_ep145_s  \n",
      "run_experiment()  when: 2026-01-15 09:35:53.293607 params: {'epochs': 145, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 09:37:11.809903\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-156\\e100_l64-64-64-64-64-64_ep145_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep145_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-156\\e100_l64-64-64-64-64-64_ep145_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep145_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-156\\e100_l64-64-64-64-64-64_ep145_s\\predictions-e100_l64-64-64-64-64-64_ep145_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-156\\e100_l64-64-64-64-64-64_ep145_s\\predictions-e100_l64-64-64-64-64-64_ep145_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-156\\e100_l64-64-64-64-64-64_ep145_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-156\\e100_l64-64-64-64-64-64_ep145_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-156\\e100_l64-64-64-64-64-64_ep145_s\\model\\assets\n",
      "[I 2026-01-15 09:38:31,558] Trial 156 finished with value: 0.8866598606109619 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 145}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-156\\e100_l64-64-64-64-64-64_ep145_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-156\\e100_l64-64-64-64-64-64_ep145_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-157\\e100_l64-64-64-64-64_ep110_sig_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-157\\e100_l64-64-64-64-64_ep110_sig_  \n",
      "run_experiment()  when: 2026-01-15 09:38:31.601492 params: {'epochs': 110, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 09:38:44.286276\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 10ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-157\\e100_l64-64-64-64-64_ep110_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep110_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-157\\e100_l64-64-64-64-64_ep110_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep110_sig_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-157\\e100_l64-64-64-64-64_ep110_sig_\\predictions-e100_l64-64-64-64-64_ep110_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-157\\e100_l64-64-64-64-64_ep110_sig_\\predictions-e100_l64-64-64-64-64_ep110_sig_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-157\\e100_l64-64-64-64-64_ep110_sig_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-157\\e100_l64-64-64-64-64_ep110_sig_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-157\\e100_l64-64-64-64-64_ep110_sig_\\model\\assets\n",
      "[I 2026-01-15 09:42:33,466] Trial 157 finished with value: 0.8688411116600037 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 64, 'embedding_dim': 100, 'epochs': 110}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-157\\e100_l64-64-64-64-64_ep110_sig_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-157\\e100_l64-64-64-64-64_ep110_sig_\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-158\\e100_l64-64-64-64-64-64_ep350_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-158\\e100_l64-64-64-64-64-64_ep350_s  \n",
      "run_experiment()  when: 2026-01-15 09:42:33.510836 params: {'epochs': 350, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 09:43:33.110104\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-158\\e100_l64-64-64-64-64-64_ep350_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep350_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-158\\e100_l64-64-64-64-64-64_ep350_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep350_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-158\\e100_l64-64-64-64-64-64_ep350_s\\predictions-e100_l64-64-64-64-64-64_ep350_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-158\\e100_l64-64-64-64-64-64_ep350_s\\predictions-e100_l64-64-64-64-64-64_ep350_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-158\\e100_l64-64-64-64-64-64_ep350_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-158\\e100_l64-64-64-64-64-64_ep350_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-158\\e100_l64-64-64-64-64-64_ep350_s\\model\\assets\n",
      "[I 2026-01-15 09:47:21,405] Trial 158 finished with value: 0.8844493627548218 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 350}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-158\\e100_l64-64-64-64-64-64_ep350_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-158\\e100_l64-64-64-64-64-64_ep350_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-159\\e100_l64-64-64_ep210_sig_103\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-159\\e100_l64-64-64_ep210_sig_103  \n",
      "run_experiment()  when: 2026-01-15 09:47:21.449660 params: {'epochs': 210, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 09:48:22.080149\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 800us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-159\\e100_l64-64-64_ep210_sig_103\\normalized_training_df-e100_l64-64-64_ep210_sig_103.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-159\\e100_l64-64-64_ep210_sig_103\\normalized_training_df-e100_l64-64-64_ep210_sig_103.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-159\\e100_l64-64-64_ep210_sig_103\\predictions-e100_l64-64-64_ep210_sig_103.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-159\\e100_l64-64-64_ep210_sig_103\\predictions-e100_l64-64-64_ep210_sig_103.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-159\\e100_l64-64-64_ep210_sig_103\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-159\\e100_l64-64-64_ep210_sig_103\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-159\\e100_l64-64-64_ep210_sig_103\\model\\assets\n",
      "[I 2026-01-15 09:49:14,515] Trial 159 finished with value: 0.9030234217643738 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 100, 'epochs': 210}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-159\\e100_l64-64-64_ep210_sig_103\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-159\\e100_l64-64-64_ep210_sig_103\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-160\\e100_l64-64-64-64-64_ep210_sig_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-160\\e100_l64-64-64-64-64_ep210_sig_  \n",
      "run_experiment()  when: 2026-01-15 09:49:14.560063 params: {'epochs': 210, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 09:49:45.393019\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1000us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-160\\e100_l64-64-64-64-64_ep210_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep210_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-160\\e100_l64-64-64-64-64_ep210_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep210_sig_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-160\\e100_l64-64-64-64-64_ep210_sig_\\predictions-e100_l64-64-64-64-64_ep210_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-160\\e100_l64-64-64-64-64_ep210_sig_\\predictions-e100_l64-64-64-64-64_ep210_sig_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-160\\e100_l64-64-64-64-64_ep210_sig_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-160\\e100_l64-64-64-64-64_ep210_sig_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-160\\e100_l64-64-64-64-64_ep210_sig_\\model\\assets\n",
      "[I 2026-01-15 09:51:00,753] Trial 160 finished with value: 0.8935045599937439 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 64, 'embedding_dim': 100, 'epochs': 210}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-160\\e100_l64-64-64-64-64_ep210_sig_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-160\\e100_l64-64-64-64-64_ep210_sig_\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-161\\e100_l64-64-64_ep195_sig_185\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-161\\e100_l64-64-64_ep195_sig_185  \n",
      "run_experiment()  when: 2026-01-15 09:51:00.803911 params: {'epochs': 195, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 09:51:13.256080\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-161\\e100_l64-64-64_ep195_sig_185\\normalized_training_df-e100_l64-64-64_ep195_sig_185.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-161\\e100_l64-64-64_ep195_sig_185\\normalized_training_df-e100_l64-64-64_ep195_sig_185.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-161\\e100_l64-64-64_ep195_sig_185\\predictions-e100_l64-64-64_ep195_sig_185.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-161\\e100_l64-64-64_ep195_sig_185\\predictions-e100_l64-64-64_ep195_sig_185.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-161\\e100_l64-64-64_ep195_sig_185\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-161\\e100_l64-64-64_ep195_sig_185\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-161\\e100_l64-64-64_ep195_sig_185\\model\\assets\n",
      "[I 2026-01-15 09:54:53,025] Trial 161 finished with value: 0.8913542628288269 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 100, 'epochs': 195}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-161\\e100_l64-64-64_ep195_sig_185\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-161\\e100_l64-64-64_ep195_sig_185\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-162\\e100_l64-64-64-64_ep470_sig_684\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-162\\e100_l64-64-64-64_ep470_sig_684  \n",
      "run_experiment()  when: 2026-01-15 09:54:53.306721 params: {'epochs': 470, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 09:56:16.587905\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-162\\e100_l64-64-64-64_ep470_sig_684\\normalized_training_df-e100_l64-64-64-64_ep470_sig_684.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-162\\e100_l64-64-64-64_ep470_sig_684\\normalized_training_df-e100_l64-64-64-64_ep470_sig_684.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-162\\e100_l64-64-64-64_ep470_sig_684\\predictions-e100_l64-64-64-64_ep470_sig_684.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-162\\e100_l64-64-64-64_ep470_sig_684\\predictions-e100_l64-64-64-64_ep470_sig_684.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-162\\e100_l64-64-64-64_ep470_sig_684\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-162\\e100_l64-64-64-64_ep470_sig_684\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-162\\e100_l64-64-64-64_ep470_sig_684\\model\\assets\n",
      "[I 2026-01-15 09:59:43,328] Trial 162 finished with value: 0.9021475315093994 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 470}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-162\\e100_l64-64-64-64_ep470_sig_684\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-162\\e100_l64-64-64-64_ep470_sig_684\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-163\\e100_l64-64-64_ep235_sig_854\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-163\\e100_l64-64-64_ep235_sig_854  \n",
      "run_experiment()  when: 2026-01-15 09:59:43.371673 params: {'epochs': 235, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 09:59:55.939034\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 800us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-163\\e100_l64-64-64_ep235_sig_854\\normalized_training_df-e100_l64-64-64_ep235_sig_854.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-163\\e100_l64-64-64_ep235_sig_854\\normalized_training_df-e100_l64-64-64_ep235_sig_854.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-163\\e100_l64-64-64_ep235_sig_854\\predictions-e100_l64-64-64_ep235_sig_854.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-163\\e100_l64-64-64_ep235_sig_854\\predictions-e100_l64-64-64_ep235_sig_854.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-163\\e100_l64-64-64_ep235_sig_854\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-163\\e100_l64-64-64_ep235_sig_854\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-163\\e100_l64-64-64_ep235_sig_854\\model\\assets\n",
      "[I 2026-01-15 10:01:37,113] Trial 163 finished with value: 0.8952656984329224 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 100, 'epochs': 235}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-163\\e100_l64-64-64_ep235_sig_854\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-163\\e100_l64-64-64_ep235_sig_854\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-164\\e100_l64-64-64_ep445_sig_844\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-164\\e100_l64-64-64_ep445_sig_844  \n",
      "run_experiment()  when: 2026-01-15 10:01:37.373032 params: {'epochs': 445, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 10:02:47.221078\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 7ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-164\\e100_l64-64-64_ep445_sig_844\\normalized_training_df-e100_l64-64-64_ep445_sig_844.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-164\\e100_l64-64-64_ep445_sig_844\\normalized_training_df-e100_l64-64-64_ep445_sig_844.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-164\\e100_l64-64-64_ep445_sig_844\\predictions-e100_l64-64-64_ep445_sig_844.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-164\\e100_l64-64-64_ep445_sig_844\\predictions-e100_l64-64-64_ep445_sig_844.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-164\\e100_l64-64-64_ep445_sig_844\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-164\\e100_l64-64-64_ep445_sig_844\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-164\\e100_l64-64-64_ep445_sig_844\\model\\assets\n",
      "[I 2026-01-15 10:06:42,413] Trial 164 finished with value: 0.8852324485778809 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 100, 'epochs': 445}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-164\\e100_l64-64-64_ep445_sig_844\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-164\\e100_l64-64-64_ep445_sig_844\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-165\\e100_l64-64-64-64_ep500_sig_150\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-165\\e100_l64-64-64-64_ep500_sig_150  \n",
      "run_experiment()  when: 2026-01-15 10:06:42.655970 params: {'epochs': 500, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 10:07:44.711644\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-165\\e100_l64-64-64-64_ep500_sig_150\\normalized_training_df-e100_l64-64-64-64_ep500_sig_150.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-165\\e100_l64-64-64-64_ep500_sig_150\\normalized_training_df-e100_l64-64-64-64_ep500_sig_150.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-165\\e100_l64-64-64-64_ep500_sig_150\\predictions-e100_l64-64-64-64_ep500_sig_150.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-165\\e100_l64-64-64-64_ep500_sig_150\\predictions-e100_l64-64-64-64_ep500_sig_150.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-165\\e100_l64-64-64-64_ep500_sig_150\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-165\\e100_l64-64-64-64_ep500_sig_150\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-165\\e100_l64-64-64-64_ep500_sig_150\\model\\assets\n",
      "[I 2026-01-15 10:09:17,521] Trial 165 finished with value: 0.8722518682479858 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 500}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-165\\e100_l64-64-64-64_ep500_sig_150\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-165\\e100_l64-64-64-64_ep500_sig_150\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-166\\e100_l64-64-64-64_ep465_sig_129\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-166\\e100_l64-64-64-64_ep465_sig_129  \n",
      "run_experiment()  when: 2026-01-15 10:09:17.564673 params: {'epochs': 465, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 10:09:32.325003\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 6ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-166\\e100_l64-64-64-64_ep465_sig_129\\normalized_training_df-e100_l64-64-64-64_ep465_sig_129.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-166\\e100_l64-64-64-64_ep465_sig_129\\normalized_training_df-e100_l64-64-64-64_ep465_sig_129.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-166\\e100_l64-64-64-64_ep465_sig_129\\predictions-e100_l64-64-64-64_ep465_sig_129.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-166\\e100_l64-64-64-64_ep465_sig_129\\predictions-e100_l64-64-64-64_ep465_sig_129.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-166\\e100_l64-64-64-64_ep465_sig_129\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-166\\e100_l64-64-64-64_ep465_sig_129\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-166\\e100_l64-64-64-64_ep465_sig_129\\model\\assets\n",
      "[I 2026-01-15 10:13:32,479] Trial 166 finished with value: 0.8912615776062012 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 465}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-166\\e100_l64-64-64-64_ep465_sig_129\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-166\\e100_l64-64-64-64_ep465_sig_129\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-167\\e100_l64-64-64-64_ep215_sig_178\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-167\\e100_l64-64-64-64_ep215_sig_178  \n",
      "run_experiment()  when: 2026-01-15 10:13:32.789637 params: {'epochs': 215, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 10:14:54.760061\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 7ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-167\\e100_l64-64-64-64_ep215_sig_178\\normalized_training_df-e100_l64-64-64-64_ep215_sig_178.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-167\\e100_l64-64-64-64_ep215_sig_178\\normalized_training_df-e100_l64-64-64-64_ep215_sig_178.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-167\\e100_l64-64-64-64_ep215_sig_178\\predictions-e100_l64-64-64-64_ep215_sig_178.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-167\\e100_l64-64-64-64_ep215_sig_178\\predictions-e100_l64-64-64-64_ep215_sig_178.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-167\\e100_l64-64-64-64_ep215_sig_178\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-167\\e100_l64-64-64-64_ep215_sig_178\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-167\\e100_l64-64-64-64_ep215_sig_178\\model\\assets\n",
      "[I 2026-01-15 10:17:25,896] Trial 167 finished with value: 0.903213381767273 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 215}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-167\\e100_l64-64-64-64_ep215_sig_178\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-167\\e100_l64-64-64-64_ep215_sig_178\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-168\\e100_l64-64-64-64_ep215_sig_216\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-168\\e100_l64-64-64-64_ep215_sig_216  \n",
      "run_experiment()  when: 2026-01-15 10:17:25.937838 params: {'epochs': 215, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 10:17:36.382028\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-168\\e100_l64-64-64-64_ep215_sig_216\\normalized_training_df-e100_l64-64-64-64_ep215_sig_216.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-168\\e100_l64-64-64-64_ep215_sig_216\\normalized_training_df-e100_l64-64-64-64_ep215_sig_216.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-168\\e100_l64-64-64-64_ep215_sig_216\\predictions-e100_l64-64-64-64_ep215_sig_216.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-168\\e100_l64-64-64-64_ep215_sig_216\\predictions-e100_l64-64-64-64_ep215_sig_216.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-168\\e100_l64-64-64-64_ep215_sig_216\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-168\\e100_l64-64-64-64_ep215_sig_216\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-168\\e100_l64-64-64-64_ep215_sig_216\\model\\assets\n",
      "[I 2026-01-15 10:20:01,340] Trial 168 finished with value: 0.8930366039276123 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 215}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-168\\e100_l64-64-64-64_ep215_sig_216\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-168\\e100_l64-64-64-64_ep215_sig_216\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-169\\e100_l64-64-64-64_ep205_sig_140\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-169\\e100_l64-64-64-64_ep205_sig_140  \n",
      "run_experiment()  when: 2026-01-15 10:20:01.615701 params: {'epochs': 205, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 10:21:02.689516\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 8ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-169\\e100_l64-64-64-64_ep205_sig_140\\normalized_training_df-e100_l64-64-64-64_ep205_sig_140.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-169\\e100_l64-64-64-64_ep205_sig_140\\normalized_training_df-e100_l64-64-64-64_ep205_sig_140.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-169\\e100_l64-64-64-64_ep205_sig_140\\predictions-e100_l64-64-64-64_ep205_sig_140.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-169\\e100_l64-64-64-64_ep205_sig_140\\predictions-e100_l64-64-64-64_ep205_sig_140.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-169\\e100_l64-64-64-64_ep205_sig_140\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-169\\e100_l64-64-64-64_ep205_sig_140\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-169\\e100_l64-64-64-64_ep205_sig_140\\model\\assets\n",
      "[I 2026-01-15 10:24:59,358] Trial 169 finished with value: 0.8842732310295105 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 205}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-169\\e100_l64-64-64-64_ep205_sig_140\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-169\\e100_l64-64-64-64_ep205_sig_140\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-170\\e100_l64-64-64-64_ep260_sig_929\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-170\\e100_l64-64-64-64_ep260_sig_929  \n",
      "run_experiment()  when: 2026-01-15 10:24:59.403933 params: {'epochs': 260, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 10:26:11.949833\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 800us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-170\\e100_l64-64-64-64_ep260_sig_929\\normalized_training_df-e100_l64-64-64-64_ep260_sig_929.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-170\\e100_l64-64-64-64_ep260_sig_929\\normalized_training_df-e100_l64-64-64-64_ep260_sig_929.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-170\\e100_l64-64-64-64_ep260_sig_929\\predictions-e100_l64-64-64-64_ep260_sig_929.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-170\\e100_l64-64-64-64_ep260_sig_929\\predictions-e100_l64-64-64-64_ep260_sig_929.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-170\\e100_l64-64-64-64_ep260_sig_929\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-170\\e100_l64-64-64-64_ep260_sig_929\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-170\\e100_l64-64-64-64_ep260_sig_929\\model\\assets\n",
      "[I 2026-01-15 10:28:17,820] Trial 170 finished with value: 0.8818725943565369 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 260}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-170\\e100_l64-64-64-64_ep260_sig_929\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-170\\e100_l64-64-64-64_ep260_sig_929\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-171\\e100_l64-64-64_ep200_sig_198\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-171\\e100_l64-64-64_ep200_sig_198  \n",
      "run_experiment()  when: 2026-01-15 10:28:17.859813 params: {'epochs': 200, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 10:28:31.432704\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-171\\e100_l64-64-64_ep200_sig_198\\normalized_training_df-e100_l64-64-64_ep200_sig_198.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-171\\e100_l64-64-64_ep200_sig_198\\normalized_training_df-e100_l64-64-64_ep200_sig_198.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-171\\e100_l64-64-64_ep200_sig_198\\predictions-e100_l64-64-64_ep200_sig_198.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-171\\e100_l64-64-64_ep200_sig_198\\predictions-e100_l64-64-64_ep200_sig_198.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-171\\e100_l64-64-64_ep200_sig_198\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-171\\e100_l64-64-64_ep200_sig_198\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-171\\e100_l64-64-64_ep200_sig_198\\model\\assets\n",
      "[I 2026-01-15 10:31:17,883] Trial 171 finished with value: 0.8974902033805847 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 100, 'epochs': 200}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-171\\e100_l64-64-64_ep200_sig_198\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-171\\e100_l64-64-64_ep200_sig_198\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-172\\e100_l64-64-64_ep225_sig_320\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-172\\e100_l64-64-64_ep225_sig_320  \n",
      "run_experiment()  when: 2026-01-15 10:31:18.138796 params: {'epochs': 225, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 10:32:38.511613\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 12ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-172\\e100_l64-64-64_ep225_sig_320\\normalized_training_df-e100_l64-64-64_ep225_sig_320.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-172\\e100_l64-64-64_ep225_sig_320\\normalized_training_df-e100_l64-64-64_ep225_sig_320.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-172\\e100_l64-64-64_ep225_sig_320\\predictions-e100_l64-64-64_ep225_sig_320.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-172\\e100_l64-64-64_ep225_sig_320\\predictions-e100_l64-64-64_ep225_sig_320.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-172\\e100_l64-64-64_ep225_sig_320\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-172\\e100_l64-64-64_ep225_sig_320\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-172\\e100_l64-64-64_ep225_sig_320\\model\\assets\n",
      "[I 2026-01-15 10:36:11,898] Trial 172 finished with value: 0.8812284469604492 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 100, 'epochs': 225}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-172\\e100_l64-64-64_ep225_sig_320\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-172\\e100_l64-64-64_ep225_sig_320\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-173\\e100_l64-64-64-64_ep245_sig_215\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-173\\e100_l64-64-64-64_ep245_sig_215  \n",
      "run_experiment()  when: 2026-01-15 10:36:11.937635 params: {'epochs': 245, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 10:36:22.397937\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-173\\e100_l64-64-64-64_ep245_sig_215\\normalized_training_df-e100_l64-64-64-64_ep245_sig_215.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-173\\e100_l64-64-64-64_ep245_sig_215\\normalized_training_df-e100_l64-64-64-64_ep245_sig_215.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-173\\e100_l64-64-64-64_ep245_sig_215\\predictions-e100_l64-64-64-64_ep245_sig_215.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-173\\e100_l64-64-64-64_ep245_sig_215\\predictions-e100_l64-64-64-64_ep245_sig_215.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-173\\e100_l64-64-64-64_ep245_sig_215\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-173\\e100_l64-64-64-64_ep245_sig_215\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-173\\e100_l64-64-64-64_ep245_sig_215\\model\\assets\n",
      "[I 2026-01-15 10:37:56,300] Trial 173 finished with value: 0.9046221971511841 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 245}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-173\\e100_l64-64-64-64_ep245_sig_215\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-173\\e100_l64-64-64-64_ep245_sig_215\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-174\\e100_l64-64-64-64_ep240_sig_798\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-174\\e100_l64-64-64-64_ep240_sig_798  \n",
      "run_experiment()  when: 2026-01-15 10:37:56.347316 params: {'epochs': 240, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 10:38:55.660220\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 6ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-174\\e100_l64-64-64-64_ep240_sig_798\\normalized_training_df-e100_l64-64-64-64_ep240_sig_798.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-174\\e100_l64-64-64-64_ep240_sig_798\\normalized_training_df-e100_l64-64-64-64_ep240_sig_798.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-174\\e100_l64-64-64-64_ep240_sig_798\\predictions-e100_l64-64-64-64_ep240_sig_798.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-174\\e100_l64-64-64-64_ep240_sig_798\\predictions-e100_l64-64-64-64_ep240_sig_798.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-174\\e100_l64-64-64-64_ep240_sig_798\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-174\\e100_l64-64-64-64_ep240_sig_798\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-174\\e100_l64-64-64-64_ep240_sig_798\\model\\assets\n",
      "[I 2026-01-15 10:42:43,068] Trial 174 finished with value: 0.9024765491485596 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 240}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-174\\e100_l64-64-64-64_ep240_sig_798\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-174\\e100_l64-64-64-64_ep240_sig_798\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-175\\e100_l64-64-64-64_ep245_sig_259\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-175\\e100_l64-64-64-64_ep245_sig_259  \n",
      "run_experiment()  when: 2026-01-15 10:42:43.115372 params: {'epochs': 245, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 10:44:11.164041\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-175\\e100_l64-64-64-64_ep245_sig_259\\normalized_training_df-e100_l64-64-64-64_ep245_sig_259.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-175\\e100_l64-64-64-64_ep245_sig_259\\normalized_training_df-e100_l64-64-64-64_ep245_sig_259.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-175\\e100_l64-64-64-64_ep245_sig_259\\predictions-e100_l64-64-64-64_ep245_sig_259.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-175\\e100_l64-64-64-64_ep245_sig_259\\predictions-e100_l64-64-64-64_ep245_sig_259.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-175\\e100_l64-64-64-64_ep245_sig_259\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-175\\e100_l64-64-64-64_ep245_sig_259\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-175\\e100_l64-64-64-64_ep245_sig_259\\model\\assets\n",
      "[I 2026-01-15 10:45:22,899] Trial 175 finished with value: 0.8901771903038025 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 245}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-175\\e100_l64-64-64-64_ep245_sig_259\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-175\\e100_l64-64-64-64_ep245_sig_259\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-176\\e100_l64-64-64-64_ep265_sig_216\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-176\\e100_l64-64-64-64_ep265_sig_216  \n",
      "run_experiment()  when: 2026-01-15 10:45:22.940586 params: {'epochs': 265, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 10:46:06.350756\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-176\\e100_l64-64-64-64_ep265_sig_216\\normalized_training_df-e100_l64-64-64-64_ep265_sig_216.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-176\\e100_l64-64-64-64_ep265_sig_216\\normalized_training_df-e100_l64-64-64-64_ep265_sig_216.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-176\\e100_l64-64-64-64_ep265_sig_216\\predictions-e100_l64-64-64-64_ep265_sig_216.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-176\\e100_l64-64-64-64_ep265_sig_216\\predictions-e100_l64-64-64-64_ep265_sig_216.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-176\\e100_l64-64-64-64_ep265_sig_216\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-176\\e100_l64-64-64-64_ep265_sig_216\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-176\\e100_l64-64-64-64_ep265_sig_216\\model\\assets\n",
      "[I 2026-01-15 10:49:39,940] Trial 176 finished with value: 0.8864281177520752 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 265}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-176\\e100_l64-64-64-64_ep265_sig_216\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-176\\e100_l64-64-64-64_ep265_sig_216\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-177\\e100_l64-64-64-64_ep240_sig_226\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-177\\e100_l64-64-64-64_ep240_sig_226  \n",
      "run_experiment()  when: 2026-01-15 10:49:39.984525 params: {'epochs': 240, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 10:50:43.748873\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-177\\e100_l64-64-64-64_ep240_sig_226\\normalized_training_df-e100_l64-64-64-64_ep240_sig_226.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-177\\e100_l64-64-64-64_ep240_sig_226\\normalized_training_df-e100_l64-64-64-64_ep240_sig_226.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-177\\e100_l64-64-64-64_ep240_sig_226\\predictions-e100_l64-64-64-64_ep240_sig_226.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-177\\e100_l64-64-64-64_ep240_sig_226\\predictions-e100_l64-64-64-64_ep240_sig_226.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-177\\e100_l64-64-64-64_ep240_sig_226\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-177\\e100_l64-64-64-64_ep240_sig_226\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-177\\e100_l64-64-64-64_ep240_sig_226\\model\\assets\n",
      "[I 2026-01-15 10:53:59,165] Trial 177 finished with value: 0.894612193107605 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 240}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-177\\e100_l64-64-64-64_ep240_sig_226\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-177\\e100_l64-64-64-64_ep240_sig_226\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-178\\e100_l64-64-64-64_ep235_sig_476\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-178\\e100_l64-64-64-64_ep235_sig_476  \n",
      "run_experiment()  when: 2026-01-15 10:53:59.206457 params: {'epochs': 235, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 10:54:11.766841\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-178\\e100_l64-64-64-64_ep235_sig_476\\normalized_training_df-e100_l64-64-64-64_ep235_sig_476.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-178\\e100_l64-64-64-64_ep235_sig_476\\normalized_training_df-e100_l64-64-64-64_ep235_sig_476.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-178\\e100_l64-64-64-64_ep235_sig_476\\predictions-e100_l64-64-64-64_ep235_sig_476.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-178\\e100_l64-64-64-64_ep235_sig_476\\predictions-e100_l64-64-64-64_ep235_sig_476.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-178\\e100_l64-64-64-64_ep235_sig_476\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-178\\e100_l64-64-64-64_ep235_sig_476\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-178\\e100_l64-64-64-64_ep235_sig_476\\model\\assets\n",
      "[I 2026-01-15 10:56:28,708] Trial 178 finished with value: 0.892911434173584 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 235}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-178\\e100_l64-64-64-64_ep235_sig_476\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-178\\e100_l64-64-64-64_ep235_sig_476\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-179\\e100_l64-64-64-64_ep255_sig_888\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-179\\e100_l64-64-64-64_ep255_sig_888  \n",
      "run_experiment()  when: 2026-01-15 10:56:29.045552 params: {'epochs': 255, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 10:57:55.071867\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 12ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-179\\e100_l64-64-64-64_ep255_sig_888\\normalized_training_df-e100_l64-64-64-64_ep255_sig_888.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-179\\e100_l64-64-64-64_ep255_sig_888\\normalized_training_df-e100_l64-64-64-64_ep255_sig_888.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-179\\e100_l64-64-64-64_ep255_sig_888\\predictions-e100_l64-64-64-64_ep255_sig_888.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-179\\e100_l64-64-64-64_ep255_sig_888\\predictions-e100_l64-64-64-64_ep255_sig_888.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-179\\e100_l64-64-64-64_ep255_sig_888\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-179\\e100_l64-64-64-64_ep255_sig_888\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-179\\e100_l64-64-64-64_ep255_sig_888\\model\\assets\n",
      "[I 2026-01-15 11:01:49,990] Trial 179 finished with value: 0.9077828526496887 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 255}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-179\\e100_l64-64-64-64_ep255_sig_888\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-179\\e100_l64-64-64-64_ep255_sig_888\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-180\\e100_l64-64-64-64_ep465_sig_505\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-180\\e100_l64-64-64-64_ep465_sig_505  \n",
      "run_experiment()  when: 2026-01-15 11:01:50.232230 params: {'epochs': 465, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 11:03:08.674007\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-180\\e100_l64-64-64-64_ep465_sig_505\\normalized_training_df-e100_l64-64-64-64_ep465_sig_505.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-180\\e100_l64-64-64-64_ep465_sig_505\\normalized_training_df-e100_l64-64-64-64_ep465_sig_505.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-180\\e100_l64-64-64-64_ep465_sig_505\\predictions-e100_l64-64-64-64_ep465_sig_505.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-180\\e100_l64-64-64-64_ep465_sig_505\\predictions-e100_l64-64-64-64_ep465_sig_505.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-180\\e100_l64-64-64-64_ep465_sig_505\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-180\\e100_l64-64-64-64_ep465_sig_505\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-180\\e100_l64-64-64-64_ep465_sig_505\\model\\assets\n",
      "[I 2026-01-15 11:04:53,382] Trial 180 finished with value: 0.8906174898147583 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 465}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-180\\e100_l64-64-64-64_ep465_sig_505\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-180\\e100_l64-64-64-64_ep465_sig_505\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-181\\e100_l64-64-64-64_ep255_sig_972\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-181\\e100_l64-64-64-64_ep255_sig_972  \n",
      "run_experiment()  when: 2026-01-15 11:04:53.422582 params: {'epochs': 255, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 11:05:05.648803\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 7ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-181\\e100_l64-64-64-64_ep255_sig_972\\normalized_training_df-e100_l64-64-64-64_ep255_sig_972.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-181\\e100_l64-64-64-64_ep255_sig_972\\normalized_training_df-e100_l64-64-64-64_ep255_sig_972.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-181\\e100_l64-64-64-64_ep255_sig_972\\predictions-e100_l64-64-64-64_ep255_sig_972.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-181\\e100_l64-64-64-64_ep255_sig_972\\predictions-e100_l64-64-64-64_ep255_sig_972.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-181\\e100_l64-64-64-64_ep255_sig_972\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-181\\e100_l64-64-64-64_ep255_sig_972\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-181\\e100_l64-64-64-64_ep255_sig_972\\model\\assets\n",
      "[I 2026-01-15 11:08:21,428] Trial 181 finished with value: 0.8996636271476746 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 255}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-181\\e100_l64-64-64-64_ep255_sig_972\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-181\\e100_l64-64-64-64_ep255_sig_972\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-182\\e100_l64-64-64-64_ep480_sig_180\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-182\\e100_l64-64-64-64_ep480_sig_180  \n",
      "run_experiment()  when: 2026-01-15 11:08:21.791528 params: {'epochs': 480, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 11:09:29.152359\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 9ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-182\\e100_l64-64-64-64_ep480_sig_180\\normalized_training_df-e100_l64-64-64-64_ep480_sig_180.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-182\\e100_l64-64-64-64_ep480_sig_180\\normalized_training_df-e100_l64-64-64-64_ep480_sig_180.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-182\\e100_l64-64-64-64_ep480_sig_180\\predictions-e100_l64-64-64-64_ep480_sig_180.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-182\\e100_l64-64-64-64_ep480_sig_180\\predictions-e100_l64-64-64-64_ep480_sig_180.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-182\\e100_l64-64-64-64_ep480_sig_180\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-182\\e100_l64-64-64-64_ep480_sig_180\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-182\\e100_l64-64-64-64_ep480_sig_180\\model\\assets\n",
      "[I 2026-01-15 11:13:15,630] Trial 182 finished with value: 0.896841287612915 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 480}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-182\\e100_l64-64-64-64_ep480_sig_180\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-182\\e100_l64-64-64-64_ep480_sig_180\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-183\\e100_l64-64-64-64_ep270_sig_227\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-183\\e100_l64-64-64-64_ep270_sig_227  \n",
      "run_experiment()  when: 2026-01-15 11:13:15.993395 params: {'epochs': 270, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 11:14:35.084340\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-183\\e100_l64-64-64-64_ep270_sig_227\\normalized_training_df-e100_l64-64-64-64_ep270_sig_227.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-183\\e100_l64-64-64-64_ep270_sig_227\\normalized_training_df-e100_l64-64-64-64_ep270_sig_227.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-183\\e100_l64-64-64-64_ep270_sig_227\\predictions-e100_l64-64-64-64_ep270_sig_227.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-183\\e100_l64-64-64-64_ep270_sig_227\\predictions-e100_l64-64-64-64_ep270_sig_227.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-183\\e100_l64-64-64-64_ep270_sig_227\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-183\\e100_l64-64-64-64_ep270_sig_227\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-183\\e100_l64-64-64-64_ep270_sig_227\\model\\assets\n",
      "[I 2026-01-15 11:15:38,357] Trial 183 finished with value: 0.891470193862915 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 270}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-183\\e100_l64-64-64-64_ep270_sig_227\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-183\\e100_l64-64-64-64_ep270_sig_227\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-184\\e100_l64-64-64-64_ep250_sig_915\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-184\\e100_l64-64-64-64_ep250_sig_915  \n",
      "run_experiment()  when: 2026-01-15 11:15:38.397032 params: {'epochs': 250, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 11:16:29.200782\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 5ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-184\\e100_l64-64-64-64_ep250_sig_915\\normalized_training_df-e100_l64-64-64-64_ep250_sig_915.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-184\\e100_l64-64-64-64_ep250_sig_915\\normalized_training_df-e100_l64-64-64-64_ep250_sig_915.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-184\\e100_l64-64-64-64_ep250_sig_915\\predictions-e100_l64-64-64-64_ep250_sig_915.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-184\\e100_l64-64-64-64_ep250_sig_915\\predictions-e100_l64-64-64-64_ep250_sig_915.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-184\\e100_l64-64-64-64_ep250_sig_915\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-184\\e100_l64-64-64-64_ep250_sig_915\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-184\\e100_l64-64-64-64_ep250_sig_915\\model\\assets\n",
      "[I 2026-01-15 11:20:13,307] Trial 184 finished with value: 0.8825585842132568 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 250}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-184\\e100_l64-64-64-64_ep250_sig_915\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-184\\e100_l64-64-64-64_ep250_sig_915\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-185\\e100_l64-64-64-64_ep220_sig_136\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-185\\e100_l64-64-64-64_ep220_sig_136  \n",
      "run_experiment()  when: 2026-01-15 11:20:13.602184 params: {'epochs': 220, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 11:21:31.599111\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-185\\e100_l64-64-64-64_ep220_sig_136\\normalized_training_df-e100_l64-64-64-64_ep220_sig_136.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-185\\e100_l64-64-64-64_ep220_sig_136\\normalized_training_df-e100_l64-64-64-64_ep220_sig_136.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-185\\e100_l64-64-64-64_ep220_sig_136\\predictions-e100_l64-64-64-64_ep220_sig_136.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-185\\e100_l64-64-64-64_ep220_sig_136\\predictions-e100_l64-64-64-64_ep220_sig_136.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-185\\e100_l64-64-64-64_ep220_sig_136\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-185\\e100_l64-64-64-64_ep220_sig_136\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-185\\e100_l64-64-64-64_ep220_sig_136\\model\\assets\n",
      "[I 2026-01-15 11:24:45,288] Trial 185 finished with value: 0.8923739790916443 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 220}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-185\\e100_l64-64-64-64_ep220_sig_136\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-185\\e100_l64-64-64-64_ep220_sig_136\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-186\\e100_l64-64-64-64_ep230_sig_756\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-186\\e100_l64-64-64-64_ep230_sig_756  \n",
      "run_experiment()  when: 2026-01-15 11:24:45.328277 params: {'epochs': 230, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 11:24:56.831868\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-186\\e100_l64-64-64-64_ep230_sig_756\\normalized_training_df-e100_l64-64-64-64_ep230_sig_756.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-186\\e100_l64-64-64-64_ep230_sig_756\\normalized_training_df-e100_l64-64-64-64_ep230_sig_756.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-186\\e100_l64-64-64-64_ep230_sig_756\\predictions-e100_l64-64-64-64_ep230_sig_756.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-186\\e100_l64-64-64-64_ep230_sig_756\\predictions-e100_l64-64-64-64_ep230_sig_756.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-186\\e100_l64-64-64-64_ep230_sig_756\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-186\\e100_l64-64-64-64_ep230_sig_756\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-186\\e100_l64-64-64-64_ep230_sig_756\\model\\assets\n",
      "[I 2026-01-15 11:26:51,239] Trial 186 finished with value: 0.8865206837654114 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 230}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-186\\e100_l64-64-64-64_ep230_sig_756\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-186\\e100_l64-64-64-64_ep230_sig_756\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-187\\e100_l64-64-64-64_ep280_sig_123\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-187\\e100_l64-64-64-64_ep280_sig_123  \n",
      "run_experiment()  when: 2026-01-15 11:26:51.543324 params: {'epochs': 280, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 11:28:17.059334\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-187\\e100_l64-64-64-64_ep280_sig_123\\normalized_training_df-e100_l64-64-64-64_ep280_sig_123.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-187\\e100_l64-64-64-64_ep280_sig_123\\normalized_training_df-e100_l64-64-64-64_ep280_sig_123.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-187\\e100_l64-64-64-64_ep280_sig_123\\predictions-e100_l64-64-64-64_ep280_sig_123.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-187\\e100_l64-64-64-64_ep280_sig_123\\predictions-e100_l64-64-64-64_ep280_sig_123.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-187\\e100_l64-64-64-64_ep280_sig_123\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-187\\e100_l64-64-64-64_ep280_sig_123\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-187\\e100_l64-64-64-64_ep280_sig_123\\model\\assets\n",
      "[I 2026-01-15 11:32:06,976] Trial 187 finished with value: 0.9056417942047119 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 280}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-187\\e100_l64-64-64-64_ep280_sig_123\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-187\\e100_l64-64-64-64_ep280_sig_123\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-188\\e100_l64-64-64-64_ep285_sig_456\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-188\\e100_l64-64-64-64_ep285_sig_456  \n",
      "run_experiment()  when: 2026-01-15 11:32:07.020793 params: {'epochs': 285, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 11:33:17.182425\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-188\\e100_l64-64-64-64_ep285_sig_456\\normalized_training_df-e100_l64-64-64-64_ep285_sig_456.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-188\\e100_l64-64-64-64_ep285_sig_456\\normalized_training_df-e100_l64-64-64-64_ep285_sig_456.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-188\\e100_l64-64-64-64_ep285_sig_456\\predictions-e100_l64-64-64-64_ep285_sig_456.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-188\\e100_l64-64-64-64_ep285_sig_456\\predictions-e100_l64-64-64-64_ep285_sig_456.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-188\\e100_l64-64-64-64_ep285_sig_456\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-188\\e100_l64-64-64-64_ep285_sig_456\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-188\\e100_l64-64-64-64_ep285_sig_456\\model\\assets\n",
      "[I 2026-01-15 11:36:42,230] Trial 188 finished with value: 0.8968227505683899 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 285}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-188\\e100_l64-64-64-64_ep285_sig_456\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-188\\e100_l64-64-64-64_ep285_sig_456\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-189\\e100_l64-64-64-64_ep255_sig_626\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-189\\e100_l64-64-64-64_ep255_sig_626  \n",
      "run_experiment()  when: 2026-01-15 11:36:42.272668 params: {'epochs': 255, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 11:36:53.564188\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1000us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-189\\e100_l64-64-64-64_ep255_sig_626\\normalized_training_df-e100_l64-64-64-64_ep255_sig_626.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-189\\e100_l64-64-64-64_ep255_sig_626\\normalized_training_df-e100_l64-64-64-64_ep255_sig_626.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-189\\e100_l64-64-64-64_ep255_sig_626\\predictions-e100_l64-64-64-64_ep255_sig_626.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-189\\e100_l64-64-64-64_ep255_sig_626\\predictions-e100_l64-64-64-64_ep255_sig_626.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-189\\e100_l64-64-64-64_ep255_sig_626\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-189\\e100_l64-64-64-64_ep255_sig_626\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-189\\e100_l64-64-64-64_ep255_sig_626\\model\\assets\n",
      "[I 2026-01-15 11:38:55,969] Trial 189 finished with value: 0.9002242088317871 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 255}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-189\\e100_l64-64-64-64_ep255_sig_626\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-189\\e100_l64-64-64-64_ep255_sig_626\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-190\\e100_l64-64-64-64_ep275_sig_591\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-190\\e100_l64-64-64-64_ep275_sig_591  \n",
      "run_experiment()  when: 2026-01-15 11:38:56.259427 params: {'epochs': 275, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 11:40:11.441577\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-190\\e100_l64-64-64-64_ep275_sig_591\\normalized_training_df-e100_l64-64-64-64_ep275_sig_591.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-190\\e100_l64-64-64-64_ep275_sig_591\\normalized_training_df-e100_l64-64-64-64_ep275_sig_591.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-190\\e100_l64-64-64-64_ep275_sig_591\\predictions-e100_l64-64-64-64_ep275_sig_591.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-190\\e100_l64-64-64-64_ep275_sig_591\\predictions-e100_l64-64-64-64_ep275_sig_591.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-190\\e100_l64-64-64-64_ep275_sig_591\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-190\\e100_l64-64-64-64_ep275_sig_591\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-190\\e100_l64-64-64-64_ep275_sig_591\\model\\assets\n",
      "[I 2026-01-15 11:44:00,722] Trial 190 finished with value: 0.8838052153587341 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 275}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-190\\e100_l64-64-64-64_ep275_sig_591\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-190\\e100_l64-64-64-64_ep275_sig_591\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-191\\e100_l64-64-64-64_ep245_sig_667\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-191\\e100_l64-64-64-64_ep245_sig_667  \n",
      "run_experiment()  when: 2026-01-15 11:44:01.031923 params: {'epochs': 245, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 11:45:17.351843\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-191\\e100_l64-64-64-64_ep245_sig_667\\normalized_training_df-e100_l64-64-64-64_ep245_sig_667.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-191\\e100_l64-64-64-64_ep245_sig_667\\normalized_training_df-e100_l64-64-64-64_ep245_sig_667.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-191\\e100_l64-64-64-64_ep245_sig_667\\predictions-e100_l64-64-64-64_ep245_sig_667.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-191\\e100_l64-64-64-64_ep245_sig_667\\predictions-e100_l64-64-64-64_ep245_sig_667.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-191\\e100_l64-64-64-64_ep245_sig_667\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-191\\e100_l64-64-64-64_ep245_sig_667\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-191\\e100_l64-64-64-64_ep245_sig_667\\model\\assets\n",
      "[I 2026-01-15 11:47:13,531] Trial 191 finished with value: 0.89747154712677 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 245}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-191\\e100_l64-64-64-64_ep245_sig_667\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-191\\e100_l64-64-64-64_ep245_sig_667\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-192\\e100_l64-64-64-64_ep215_sig_131\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-192\\e100_l64-64-64-64_ep215_sig_131  \n",
      "run_experiment()  when: 2026-01-15 11:47:13.572069 params: {'epochs': 215, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 11:47:27.349921\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-192\\e100_l64-64-64-64_ep215_sig_131\\normalized_training_df-e100_l64-64-64-64_ep215_sig_131.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-192\\e100_l64-64-64-64_ep215_sig_131\\normalized_training_df-e100_l64-64-64-64_ep215_sig_131.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-192\\e100_l64-64-64-64_ep215_sig_131\\predictions-e100_l64-64-64-64_ep215_sig_131.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-192\\e100_l64-64-64-64_ep215_sig_131\\predictions-e100_l64-64-64-64_ep215_sig_131.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-192\\e100_l64-64-64-64_ep215_sig_131\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-192\\e100_l64-64-64-64_ep215_sig_131\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-192\\e100_l64-64-64-64_ep215_sig_131\\model\\assets\n",
      "[I 2026-01-15 11:50:30,002] Trial 192 finished with value: 0.8891993761062622 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 215}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-192\\e100_l64-64-64-64_ep215_sig_131\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-192\\e100_l64-64-64-64_ep215_sig_131\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-193\\e100_l64-64-64-64_ep240_sig_724\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-193\\e100_l64-64-64-64_ep240_sig_724  \n",
      "run_experiment()  when: 2026-01-15 11:50:30.316015 params: {'epochs': 240, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 11:52:02.489753\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-193\\e100_l64-64-64-64_ep240_sig_724\\normalized_training_df-e100_l64-64-64-64_ep240_sig_724.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-193\\e100_l64-64-64-64_ep240_sig_724\\normalized_training_df-e100_l64-64-64-64_ep240_sig_724.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-193\\e100_l64-64-64-64_ep240_sig_724\\predictions-e100_l64-64-64-64_ep240_sig_724.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-193\\e100_l64-64-64-64_ep240_sig_724\\predictions-e100_l64-64-64-64_ep240_sig_724.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-193\\e100_l64-64-64-64_ep240_sig_724\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-193\\e100_l64-64-64-64_ep240_sig_724\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-193\\e100_l64-64-64-64_ep240_sig_724\\model\\assets\n",
      "[I 2026-01-15 11:55:36,539] Trial 193 finished with value: 0.901461660861969 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 240}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-193\\e100_l64-64-64-64_ep240_sig_724\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-193\\e100_l64-64-64-64_ep240_sig_724\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-194\\e100_l64-64-64-64_ep300_sig_135\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-194\\e100_l64-64-64-64_ep300_sig_135  \n",
      "run_experiment()  when: 2026-01-15 11:55:36.587451 params: {'epochs': 300, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 11:55:47.960070\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-194\\e100_l64-64-64-64_ep300_sig_135\\normalized_training_df-e100_l64-64-64-64_ep300_sig_135.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-194\\e100_l64-64-64-64_ep300_sig_135\\normalized_training_df-e100_l64-64-64-64_ep300_sig_135.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-194\\e100_l64-64-64-64_ep300_sig_135\\predictions-e100_l64-64-64-64_ep300_sig_135.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-194\\e100_l64-64-64-64_ep300_sig_135\\predictions-e100_l64-64-64-64_ep300_sig_135.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-194\\e100_l64-64-64-64_ep300_sig_135\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-194\\e100_l64-64-64-64_ep300_sig_135\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-194\\e100_l64-64-64-64_ep300_sig_135\\model\\assets\n",
      "[I 2026-01-15 11:57:14,457] Trial 194 finished with value: 0.9030836820602417 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 300}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-194\\e100_l64-64-64-64_ep300_sig_135\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-194\\e100_l64-64-64-64_ep300_sig_135\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-195\\e100_l64-64-64-64_ep295_sig_170\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-195\\e100_l64-64-64-64_ep295_sig_170  \n",
      "run_experiment()  when: 2026-01-15 11:57:14.740423 params: {'epochs': 295, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 11:58:17.554739\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-195\\e100_l64-64-64-64_ep295_sig_170\\normalized_training_df-e100_l64-64-64-64_ep295_sig_170.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-195\\e100_l64-64-64-64_ep295_sig_170\\normalized_training_df-e100_l64-64-64-64_ep295_sig_170.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-195\\e100_l64-64-64-64_ep295_sig_170\\predictions-e100_l64-64-64-64_ep295_sig_170.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-195\\e100_l64-64-64-64_ep295_sig_170\\predictions-e100_l64-64-64-64_ep295_sig_170.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-195\\e100_l64-64-64-64_ep295_sig_170\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-195\\e100_l64-64-64-64_ep295_sig_170\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-195\\e100_l64-64-64-64_ep295_sig_170\\model\\assets\n",
      "[I 2026-01-15 12:02:03,078] Trial 195 finished with value: 0.8883928656578064 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 295}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-195\\e100_l64-64-64-64_ep295_sig_170\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-195\\e100_l64-64-64-64_ep295_sig_170\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-196\\e100_l64-64-64-64_ep265_sig_280\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-196\\e100_l64-64-64-64_ep265_sig_280  \n",
      "run_experiment()  when: 2026-01-15 12:02:03.122740 params: {'epochs': 265, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 12:03:01.588860\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-196\\e100_l64-64-64-64_ep265_sig_280\\normalized_training_df-e100_l64-64-64-64_ep265_sig_280.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-196\\e100_l64-64-64-64_ep265_sig_280\\normalized_training_df-e100_l64-64-64-64_ep265_sig_280.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-196\\e100_l64-64-64-64_ep265_sig_280\\predictions-e100_l64-64-64-64_ep265_sig_280.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-196\\e100_l64-64-64-64_ep265_sig_280\\predictions-e100_l64-64-64-64_ep265_sig_280.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-196\\e100_l64-64-64-64_ep265_sig_280\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-196\\e100_l64-64-64-64_ep265_sig_280\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-196\\e100_l64-64-64-64_ep265_sig_280\\model\\assets\n",
      "[I 2026-01-15 12:03:52,402] Trial 196 finished with value: 0.9025739431381226 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 265}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-196\\e100_l64-64-64-64_ep265_sig_280\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-196\\e100_l64-64-64-64_ep265_sig_280\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-197\\e100_l64-64-64-64_ep300_sig_105\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-197\\e100_l64-64-64-64_ep300_sig_105  \n",
      "run_experiment()  when: 2026-01-15 12:03:52.459020 params: {'epochs': 300, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 12:05:02.777829\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-197\\e100_l64-64-64-64_ep300_sig_105\\normalized_training_df-e100_l64-64-64-64_ep300_sig_105.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-197\\e100_l64-64-64-64_ep300_sig_105\\normalized_training_df-e100_l64-64-64-64_ep300_sig_105.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-197\\e100_l64-64-64-64_ep300_sig_105\\predictions-e100_l64-64-64-64_ep300_sig_105.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-197\\e100_l64-64-64-64_ep300_sig_105\\predictions-e100_l64-64-64-64_ep300_sig_105.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-197\\e100_l64-64-64-64_ep300_sig_105\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-197\\e100_l64-64-64-64_ep300_sig_105\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-197\\e100_l64-64-64-64_ep300_sig_105\\model\\assets\n",
      "[I 2026-01-15 12:08:53,774] Trial 197 finished with value: 0.8924804925918579 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 300}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-197\\e100_l64-64-64-64_ep300_sig_105\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-197\\e100_l64-64-64-64_ep300_sig_105\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-198\\e100_l64-64-64-64_ep280_sig_188\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-198\\e100_l64-64-64-64_ep280_sig_188  \n",
      "run_experiment()  when: 2026-01-15 12:08:53.816637 params: {'epochs': 280, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 12:10:14.266385\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-198\\e100_l64-64-64-64_ep280_sig_188\\normalized_training_df-e100_l64-64-64-64_ep280_sig_188.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-198\\e100_l64-64-64-64_ep280_sig_188\\normalized_training_df-e100_l64-64-64-64_ep280_sig_188.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-198\\e100_l64-64-64-64_ep280_sig_188\\predictions-e100_l64-64-64-64_ep280_sig_188.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-198\\e100_l64-64-64-64_ep280_sig_188\\predictions-e100_l64-64-64-64_ep280_sig_188.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-198\\e100_l64-64-64-64_ep280_sig_188\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-198\\e100_l64-64-64-64_ep280_sig_188\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-198\\e100_l64-64-64-64_ep280_sig_188\\model\\assets\n",
      "[I 2026-01-15 12:14:03,878] Trial 198 finished with value: 0.8963407278060913 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 280}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-198\\e100_l64-64-64-64_ep280_sig_188\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-198\\e100_l64-64-64-64_ep280_sig_188\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-199\\e100_l64-64-64-64_ep270_sig_453\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-199\\e100_l64-64-64-64_ep270_sig_453  \n",
      "run_experiment()  when: 2026-01-15 12:14:04.205505 params: {'epochs': 270, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 12:14:58.064326\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1000us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-199\\e100_l64-64-64-64_ep270_sig_453\\normalized_training_df-e100_l64-64-64-64_ep270_sig_453.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-199\\e100_l64-64-64-64_ep270_sig_453\\normalized_training_df-e100_l64-64-64-64_ep270_sig_453.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-199\\e100_l64-64-64-64_ep270_sig_453\\predictions-e100_l64-64-64-64_ep270_sig_453.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-199\\e100_l64-64-64-64_ep270_sig_453\\predictions-e100_l64-64-64-64_ep270_sig_453.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-199\\e100_l64-64-64-64_ep270_sig_453\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-199\\e100_l64-64-64-64_ep270_sig_453\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-199\\e100_l64-64-64-64_ep270_sig_453\\model\\assets\n",
      "[I 2026-01-15 12:15:55,497] Trial 199 finished with value: 0.905674159526825 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 270}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-199\\e100_l64-64-64-64_ep270_sig_453\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-199\\e100_l64-64-64-64_ep270_sig_453\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-200\\e100_l64-64-64-64_ep265_sig_188\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-200\\e100_l64-64-64-64_ep265_sig_188  \n",
      "run_experiment()  when: 2026-01-15 12:15:55.819875 params: {'epochs': 265, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 12:17:11.625830\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-200\\e100_l64-64-64-64_ep265_sig_188\\normalized_training_df-e100_l64-64-64-64_ep265_sig_188.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-200\\e100_l64-64-64-64_ep265_sig_188\\normalized_training_df-e100_l64-64-64-64_ep265_sig_188.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-200\\e100_l64-64-64-64_ep265_sig_188\\predictions-e100_l64-64-64-64_ep265_sig_188.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-200\\e100_l64-64-64-64_ep265_sig_188\\predictions-e100_l64-64-64-64_ep265_sig_188.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-200\\e100_l64-64-64-64_ep265_sig_188\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-200\\e100_l64-64-64-64_ep265_sig_188\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-200\\e100_l64-64-64-64_ep265_sig_188\\model\\assets\n",
      "[I 2026-01-15 12:20:51,587] Trial 200 finished with value: 0.8860851526260376 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 265}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-200\\e100_l64-64-64-64_ep265_sig_188\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-200\\e100_l64-64-64-64_ep265_sig_188\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-201\\e100_l64-64-64-64_ep285_sig_204\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-201\\e100_l64-64-64-64_ep285_sig_204  \n",
      "run_experiment()  when: 2026-01-15 12:20:51.895173 params: {'epochs': 285, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 12:21:52.476119\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-201\\e100_l64-64-64-64_ep285_sig_204\\normalized_training_df-e100_l64-64-64-64_ep285_sig_204.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-201\\e100_l64-64-64-64_ep285_sig_204\\normalized_training_df-e100_l64-64-64-64_ep285_sig_204.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-201\\e100_l64-64-64-64_ep285_sig_204\\predictions-e100_l64-64-64-64_ep285_sig_204.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-201\\e100_l64-64-64-64_ep285_sig_204\\predictions-e100_l64-64-64-64_ep285_sig_204.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-201\\e100_l64-64-64-64_ep285_sig_204\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-201\\e100_l64-64-64-64_ep285_sig_204\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-201\\e100_l64-64-64-64_ep285_sig_204\\model\\assets\n",
      "[I 2026-01-15 12:24:55,504] Trial 201 finished with value: 0.8865161538124084 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 285}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-201\\e100_l64-64-64-64_ep285_sig_204\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-201\\e100_l64-64-64-64_ep285_sig_204\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-202\\e100_l64-64-64-64_ep260_sig_125\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-202\\e100_l64-64-64-64_ep260_sig_125  \n",
      "run_experiment()  when: 2026-01-15 12:24:55.546779 params: {'epochs': 260, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 12:25:09.061615\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-202\\e100_l64-64-64-64_ep260_sig_125\\normalized_training_df-e100_l64-64-64-64_ep260_sig_125.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-202\\e100_l64-64-64-64_ep260_sig_125\\normalized_training_df-e100_l64-64-64-64_ep260_sig_125.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-202\\e100_l64-64-64-64_ep260_sig_125\\predictions-e100_l64-64-64-64_ep260_sig_125.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-202\\e100_l64-64-64-64_ep260_sig_125\\predictions-e100_l64-64-64-64_ep260_sig_125.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-202\\e100_l64-64-64-64_ep260_sig_125\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-202\\e100_l64-64-64-64_ep260_sig_125\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-202\\e100_l64-64-64-64_ep260_sig_125\\model\\assets\n",
      "[I 2026-01-15 12:27:42,706] Trial 202 finished with value: 0.8946168422698975 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 260}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-202\\e100_l64-64-64-64_ep260_sig_125\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-202\\e100_l64-64-64-64_ep260_sig_125\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-203\\e100_l64-64-64-64_ep275_sig_120\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-203\\e100_l64-64-64-64_ep275_sig_120  \n",
      "run_experiment()  when: 2026-01-15 12:27:43.061081 params: {'epochs': 275, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 12:28:50.208398\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 3ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-203\\e100_l64-64-64-64_ep275_sig_120\\normalized_training_df-e100_l64-64-64-64_ep275_sig_120.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-203\\e100_l64-64-64-64_ep275_sig_120\\normalized_training_df-e100_l64-64-64-64_ep275_sig_120.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-203\\e100_l64-64-64-64_ep275_sig_120\\predictions-e100_l64-64-64-64_ep275_sig_120.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-203\\e100_l64-64-64-64_ep275_sig_120\\predictions-e100_l64-64-64-64_ep275_sig_120.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-203\\e100_l64-64-64-64_ep275_sig_120\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-203\\e100_l64-64-64-64_ep275_sig_120\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-203\\e100_l64-64-64-64_ep275_sig_120\\model\\assets\n",
      "[I 2026-01-15 12:32:55,918] Trial 203 finished with value: 0.8908770084381104 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 275}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-203\\e100_l64-64-64-64_ep275_sig_120\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-203\\e100_l64-64-64-64_ep275_sig_120\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-204\\e100_l64-64-64-64_ep250_sig_515\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-204\\e100_l64-64-64-64_ep250_sig_515  \n",
      "run_experiment()  when: 2026-01-15 12:32:56.232522 params: {'epochs': 250, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 12:34:07.031476\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-204\\e100_l64-64-64-64_ep250_sig_515\\normalized_training_df-e100_l64-64-64-64_ep250_sig_515.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-204\\e100_l64-64-64-64_ep250_sig_515\\normalized_training_df-e100_l64-64-64-64_ep250_sig_515.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-204\\e100_l64-64-64-64_ep250_sig_515\\predictions-e100_l64-64-64-64_ep250_sig_515.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-204\\e100_l64-64-64-64_ep250_sig_515\\predictions-e100_l64-64-64-64_ep250_sig_515.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-204\\e100_l64-64-64-64_ep250_sig_515\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-204\\e100_l64-64-64-64_ep250_sig_515\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-204\\e100_l64-64-64-64_ep250_sig_515\\model\\assets\n",
      "[I 2026-01-15 12:35:48,372] Trial 204 finished with value: 0.8915674686431885 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 250}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-204\\e100_l64-64-64-64_ep250_sig_515\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-204\\e100_l64-64-64-64_ep250_sig_515\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-205\\e100_l64-64-64-64_ep310_sig_952\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-205\\e100_l64-64-64-64_ep310_sig_952  \n",
      "run_experiment()  when: 2026-01-15 12:35:48.414242 params: {'epochs': 310, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 12:36:00.160402\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 6ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-205\\e100_l64-64-64-64_ep310_sig_952\\normalized_training_df-e100_l64-64-64-64_ep310_sig_952.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-205\\e100_l64-64-64-64_ep310_sig_952\\normalized_training_df-e100_l64-64-64-64_ep310_sig_952.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-205\\e100_l64-64-64-64_ep310_sig_952\\predictions-e100_l64-64-64-64_ep310_sig_952.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-205\\e100_l64-64-64-64_ep310_sig_952\\predictions-e100_l64-64-64-64_ep310_sig_952.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-205\\e100_l64-64-64-64_ep310_sig_952\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-205\\e100_l64-64-64-64_ep310_sig_952\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-205\\e100_l64-64-64-64_ep310_sig_952\\model\\assets\n",
      "[I 2026-01-15 12:39:30,992] Trial 205 finished with value: 0.8943202495574951 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 310}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-205\\e100_l64-64-64-64_ep310_sig_952\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-205\\e100_l64-64-64-64_ep310_sig_952\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-206\\e100_l64-64-64-64_ep265_sig_698\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-206\\e100_l64-64-64-64_ep265_sig_698  \n",
      "run_experiment()  when: 2026-01-15 12:39:31.305081 params: {'epochs': 265, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 12:40:33.514913\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 8ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-206\\e100_l64-64-64-64_ep265_sig_698\\normalized_training_df-e100_l64-64-64-64_ep265_sig_698.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-206\\e100_l64-64-64-64_ep265_sig_698\\normalized_training_df-e100_l64-64-64-64_ep265_sig_698.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-206\\e100_l64-64-64-64_ep265_sig_698\\predictions-e100_l64-64-64-64_ep265_sig_698.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-206\\e100_l64-64-64-64_ep265_sig_698\\predictions-e100_l64-64-64-64_ep265_sig_698.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-206\\e100_l64-64-64-64_ep265_sig_698\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-206\\e100_l64-64-64-64_ep265_sig_698\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-206\\e100_l64-64-64-64_ep265_sig_698\\model\\assets\n",
      "[I 2026-01-15 12:44:53,196] Trial 206 finished with value: 0.8864326477050781 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 265}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-206\\e100_l64-64-64-64_ep265_sig_698\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-206\\e100_l64-64-64-64_ep265_sig_698\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-207\\e100_l64-64-64-64_ep320_sig_108\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-207\\e100_l64-64-64-64_ep320_sig_108  \n",
      "run_experiment()  when: 2026-01-15 12:44:53.475533 params: {'epochs': 320, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 12:46:25.026217\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1000us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-207\\e100_l64-64-64-64_ep320_sig_108\\normalized_training_df-e100_l64-64-64-64_ep320_sig_108.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-207\\e100_l64-64-64-64_ep320_sig_108\\normalized_training_df-e100_l64-64-64-64_ep320_sig_108.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-207\\e100_l64-64-64-64_ep320_sig_108\\predictions-e100_l64-64-64-64_ep320_sig_108.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-207\\e100_l64-64-64-64_ep320_sig_108\\predictions-e100_l64-64-64-64_ep320_sig_108.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-207\\e100_l64-64-64-64_ep320_sig_108\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-207\\e100_l64-64-64-64_ep320_sig_108\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-207\\e100_l64-64-64-64_ep320_sig_108\\model\\assets\n",
      "[I 2026-01-15 12:48:11,984] Trial 207 finished with value: 0.8936343789100647 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 320}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-207\\e100_l64-64-64-64_ep320_sig_108\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-207\\e100_l64-64-64-64_ep320_sig_108\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-208\\e100_l64-64-64-64_ep295_sig_593\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-208\\e100_l64-64-64-64_ep295_sig_593  \n",
      "run_experiment()  when: 2026-01-15 12:48:12.026734 params: {'epochs': 295, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 12:48:24.648753\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-208\\e100_l64-64-64-64_ep295_sig_593\\normalized_training_df-e100_l64-64-64-64_ep295_sig_593.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-208\\e100_l64-64-64-64_ep295_sig_593\\normalized_training_df-e100_l64-64-64-64_ep295_sig_593.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-208\\e100_l64-64-64-64_ep295_sig_593\\predictions-e100_l64-64-64-64_ep295_sig_593.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-208\\e100_l64-64-64-64_ep295_sig_593\\predictions-e100_l64-64-64-64_ep295_sig_593.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-208\\e100_l64-64-64-64_ep295_sig_593\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-208\\e100_l64-64-64-64_ep295_sig_593\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-208\\e100_l64-64-64-64_ep295_sig_593\\model\\assets\n",
      "[I 2026-01-15 12:51:49,123] Trial 208 finished with value: 0.8941487073898315 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 295}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-208\\e100_l64-64-64-64_ep295_sig_593\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-208\\e100_l64-64-64-64_ep295_sig_593\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-209\\e100_l64-64-64-64_ep230_sig_881\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-209\\e100_l64-64-64-64_ep230_sig_881  \n",
      "run_experiment()  when: 2026-01-15 12:51:49.391325 params: {'epochs': 230, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 12:52:57.129596\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-209\\e100_l64-64-64-64_ep230_sig_881\\normalized_training_df-e100_l64-64-64-64_ep230_sig_881.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-209\\e100_l64-64-64-64_ep230_sig_881\\normalized_training_df-e100_l64-64-64-64_ep230_sig_881.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-209\\e100_l64-64-64-64_ep230_sig_881\\predictions-e100_l64-64-64-64_ep230_sig_881.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-209\\e100_l64-64-64-64_ep230_sig_881\\predictions-e100_l64-64-64-64_ep230_sig_881.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-209\\e100_l64-64-64-64_ep230_sig_881\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-209\\e100_l64-64-64-64_ep230_sig_881\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-209\\e100_l64-64-64-64_ep230_sig_881\\model\\assets\n",
      "[I 2026-01-15 12:56:38,934] Trial 209 finished with value: 0.8956595659255981 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 230}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-209\\e100_l64-64-64-64_ep230_sig_881\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-209\\e100_l64-64-64-64_ep230_sig_881\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-210\\e100_l64-64-64-64_ep85_sig_586\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-210\\e100_l64-64-64-64_ep85_sig_586  \n",
      "run_experiment()  when: 2026-01-15 12:56:39.261382 params: {'epochs': 85, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 12:57:47.916884\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 8ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-210\\e100_l64-64-64-64_ep85_sig_586\\normalized_training_df-e100_l64-64-64-64_ep85_sig_586.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-210\\e100_l64-64-64-64_ep85_sig_586\\normalized_training_df-e100_l64-64-64-64_ep85_sig_586.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-210\\e100_l64-64-64-64_ep85_sig_586\\predictions-e100_l64-64-64-64_ep85_sig_586.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-210\\e100_l64-64-64-64_ep85_sig_586\\predictions-e100_l64-64-64-64_ep85_sig_586.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-210\\e100_l64-64-64-64_ep85_sig_586\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-210\\e100_l64-64-64-64_ep85_sig_586\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-210\\e100_l64-64-64-64_ep85_sig_586\\model\\assets\n",
      "[I 2026-01-15 13:00:14,545] Trial 210 finished with value: 0.8907334208488464 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 85}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-210\\e100_l64-64-64-64_ep85_sig_586\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-210\\e100_l64-64-64-64_ep85_sig_586\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-211\\e100_l64-64-64-64-64_ep255_sig_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-211\\e100_l64-64-64-64-64_ep255_sig_  \n",
      "run_experiment()  when: 2026-01-15 13:00:14.587259 params: {'epochs': 255, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 13:00:24.766245\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 8ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-211\\e100_l64-64-64-64-64_ep255_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep255_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-211\\e100_l64-64-64-64-64_ep255_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep255_sig_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-211\\e100_l64-64-64-64-64_ep255_sig_\\predictions-e100_l64-64-64-64-64_ep255_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-211\\e100_l64-64-64-64-64_ep255_sig_\\predictions-e100_l64-64-64-64-64_ep255_sig_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-211\\e100_l64-64-64-64-64_ep255_sig_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-211\\e100_l64-64-64-64-64_ep255_sig_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-211\\e100_l64-64-64-64-64_ep255_sig_\\model\\assets\n",
      "[I 2026-01-15 13:03:02,264] Trial 211 finished with value: 0.8968690633773804 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 64, 'embedding_dim': 100, 'epochs': 255}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-211\\e100_l64-64-64-64-64_ep255_sig_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-211\\e100_l64-64-64-64-64_ep255_sig_\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-212\\e100_l64-64-64-64_ep210_sig_115\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-212\\e100_l64-64-64-64_ep210_sig_115  \n",
      "run_experiment()  when: 2026-01-15 13:03:02.508387 params: {'epochs': 210, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 13:04:29.236227\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 9ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-212\\e100_l64-64-64-64_ep210_sig_115\\normalized_training_df-e100_l64-64-64-64_ep210_sig_115.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-212\\e100_l64-64-64-64_ep210_sig_115\\normalized_training_df-e100_l64-64-64-64_ep210_sig_115.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-212\\e100_l64-64-64-64_ep210_sig_115\\predictions-e100_l64-64-64-64_ep210_sig_115.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-212\\e100_l64-64-64-64_ep210_sig_115\\predictions-e100_l64-64-64-64_ep210_sig_115.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-212\\e100_l64-64-64-64_ep210_sig_115\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-212\\e100_l64-64-64-64_ep210_sig_115\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-212\\e100_l64-64-64-64_ep210_sig_115\\model\\assets\n",
      "[I 2026-01-15 13:07:37,911] Trial 212 finished with value: 0.8947374820709229 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 210}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-212\\e100_l64-64-64-64_ep210_sig_115\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-212\\e100_l64-64-64-64_ep210_sig_115\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-213\\e100_l64-64-64-64_ep330_sig_219\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-213\\e100_l64-64-64-64_ep330_sig_219  \n",
      "run_experiment()  when: 2026-01-15 13:07:37.954973 params: {'epochs': 330, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 13:07:51.806003\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 800us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-213\\e100_l64-64-64-64_ep330_sig_219\\normalized_training_df-e100_l64-64-64-64_ep330_sig_219.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-213\\e100_l64-64-64-64_ep330_sig_219\\normalized_training_df-e100_l64-64-64-64_ep330_sig_219.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-213\\e100_l64-64-64-64_ep330_sig_219\\predictions-e100_l64-64-64-64_ep330_sig_219.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-213\\e100_l64-64-64-64_ep330_sig_219\\predictions-e100_l64-64-64-64_ep330_sig_219.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-213\\e100_l64-64-64-64_ep330_sig_219\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-213\\e100_l64-64-64-64_ep330_sig_219\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-213\\e100_l64-64-64-64_ep330_sig_219\\model\\assets\n",
      "[I 2026-01-15 13:10:03,455] Trial 213 finished with value: 0.8835780620574951 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 330}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-213\\e100_l64-64-64-64_ep330_sig_219\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-213\\e100_l64-64-64-64_ep330_sig_219\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-214\\e100_l64-64-64-64-64_ep270_sig_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-214\\e100_l64-64-64-64-64_ep270_sig_  \n",
      "run_experiment()  when: 2026-01-15 13:10:03.735428 params: {'epochs': 270, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 13:11:14.368291\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 3ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-214\\e100_l64-64-64-64-64_ep270_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep270_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-214\\e100_l64-64-64-64-64_ep270_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep270_sig_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-214\\e100_l64-64-64-64-64_ep270_sig_\\predictions-e100_l64-64-64-64-64_ep270_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-214\\e100_l64-64-64-64-64_ep270_sig_\\predictions-e100_l64-64-64-64-64_ep270_sig_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-214\\e100_l64-64-64-64-64_ep270_sig_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-214\\e100_l64-64-64-64-64_ep270_sig_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-214\\e100_l64-64-64-64-64_ep270_sig_\\model\\assets\n",
      "[I 2026-01-15 13:15:03,232] Trial 214 finished with value: 0.8820534944534302 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 64, 'embedding_dim': 100, 'epochs': 270}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-214\\e100_l64-64-64-64-64_ep270_sig_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-214\\e100_l64-64-64-64-64_ep270_sig_\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-215\\e100_l64-64-64-64_ep240_sig_632\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-215\\e100_l64-64-64-64_ep240_sig_632  \n",
      "run_experiment()  when: 2026-01-15 13:15:03.275362 params: {'epochs': 240, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 13:15:16.367362\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-215\\e100_l64-64-64-64_ep240_sig_632\\normalized_training_df-e100_l64-64-64-64_ep240_sig_632.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-215\\e100_l64-64-64-64_ep240_sig_632\\normalized_training_df-e100_l64-64-64-64_ep240_sig_632.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-215\\e100_l64-64-64-64_ep240_sig_632\\predictions-e100_l64-64-64-64_ep240_sig_632.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-215\\e100_l64-64-64-64_ep240_sig_632\\predictions-e100_l64-64-64-64_ep240_sig_632.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-215\\e100_l64-64-64-64_ep240_sig_632\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-215\\e100_l64-64-64-64_ep240_sig_632\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-215\\e100_l64-64-64-64_ep240_sig_632\\model\\assets\n",
      "[I 2026-01-15 13:16:38,536] Trial 215 finished with value: 0.8970080614089966 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 240}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-215\\e100_l64-64-64-64_ep240_sig_632\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-215\\e100_l64-64-64-64_ep240_sig_632\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-216\\e100_l64-64-64-64_ep225_sig_185\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-216\\e100_l64-64-64-64_ep225_sig_185  \n",
      "run_experiment()  when: 2026-01-15 13:16:38.806261 params: {'epochs': 225, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 13:17:49.726214\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 8ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-216\\e100_l64-64-64-64_ep225_sig_185\\normalized_training_df-e100_l64-64-64-64_ep225_sig_185.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-216\\e100_l64-64-64-64_ep225_sig_185\\normalized_training_df-e100_l64-64-64-64_ep225_sig_185.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-216\\e100_l64-64-64-64_ep225_sig_185\\predictions-e100_l64-64-64-64_ep225_sig_185.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-216\\e100_l64-64-64-64_ep225_sig_185\\predictions-e100_l64-64-64-64_ep225_sig_185.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-216\\e100_l64-64-64-64_ep225_sig_185\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-216\\e100_l64-64-64-64_ep225_sig_185\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-216\\e100_l64-64-64-64_ep225_sig_185\\model\\assets\n",
      "[I 2026-01-15 13:21:31,516] Trial 216 finished with value: 0.8948485255241394 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 225}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-216\\e100_l64-64-64-64_ep225_sig_185\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-216\\e100_l64-64-64-64_ep225_sig_185\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-217\\e100_l64-64-64-64_ep285_sig_131\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-217\\e100_l64-64-64-64_ep285_sig_131  \n",
      "run_experiment()  when: 2026-01-15 13:21:31.571576 params: {'epochs': 285, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 13:23:06.795786\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-217\\e100_l64-64-64-64_ep285_sig_131\\normalized_training_df-e100_l64-64-64-64_ep285_sig_131.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-217\\e100_l64-64-64-64_ep285_sig_131\\normalized_training_df-e100_l64-64-64-64_ep285_sig_131.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-217\\e100_l64-64-64-64_ep285_sig_131\\predictions-e100_l64-64-64-64_ep285_sig_131.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-217\\e100_l64-64-64-64_ep285_sig_131\\predictions-e100_l64-64-64-64_ep285_sig_131.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-217\\e100_l64-64-64-64_ep285_sig_131\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-217\\e100_l64-64-64-64_ep285_sig_131\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-217\\e100_l64-64-64-64_ep285_sig_131\\model\\assets\n",
      "[I 2026-01-15 13:25:34,865] Trial 217 finished with value: 0.8951311707496643 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 285}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-217\\e100_l64-64-64-64_ep285_sig_131\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-217\\e100_l64-64-64-64_ep285_sig_131\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-218\\e100_l64-64-64-64_ep190_sig_208\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-218\\e100_l64-64-64-64_ep190_sig_208  \n",
      "run_experiment()  when: 2026-01-15 13:25:34.906923 params: {'epochs': 190, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 13:25:47.221072\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-218\\e100_l64-64-64-64_ep190_sig_208\\normalized_training_df-e100_l64-64-64-64_ep190_sig_208.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-218\\e100_l64-64-64-64_ep190_sig_208\\normalized_training_df-e100_l64-64-64-64_ep190_sig_208.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-218\\e100_l64-64-64-64_ep190_sig_208\\predictions-e100_l64-64-64-64_ep190_sig_208.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-218\\e100_l64-64-64-64_ep190_sig_208\\predictions-e100_l64-64-64-64_ep190_sig_208.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-218\\e100_l64-64-64-64_ep190_sig_208\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-218\\e100_l64-64-64-64_ep190_sig_208\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-218\\e100_l64-64-64-64_ep190_sig_208\\model\\assets\n",
      "[I 2026-01-15 13:28:28,573] Trial 218 finished with value: 0.8922162652015686 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 190}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-218\\e100_l64-64-64-64_ep190_sig_208\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-218\\e100_l64-64-64-64_ep190_sig_208\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-219\\e100_l64-64-64_ep305_sig_142\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-219\\e100_l64-64-64_ep305_sig_142  \n",
      "run_experiment()  when: 2026-01-15 13:28:28.618328 params: {'epochs': 305, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 13:29:45.844212\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-219\\e100_l64-64-64_ep305_sig_142\\normalized_training_df-e100_l64-64-64_ep305_sig_142.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-219\\e100_l64-64-64_ep305_sig_142\\normalized_training_df-e100_l64-64-64_ep305_sig_142.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-219\\e100_l64-64-64_ep305_sig_142\\predictions-e100_l64-64-64_ep305_sig_142.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-219\\e100_l64-64-64_ep305_sig_142\\predictions-e100_l64-64-64_ep305_sig_142.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-219\\e100_l64-64-64_ep305_sig_142\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-219\\e100_l64-64-64_ep305_sig_142\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-219\\e100_l64-64-64_ep305_sig_142\\model\\assets\n",
      "[I 2026-01-15 13:32:42,293] Trial 219 finished with value: 0.8959978818893433 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 100, 'epochs': 305}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-219\\e100_l64-64-64_ep305_sig_142\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-219\\e100_l64-64-64_ep305_sig_142\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-220\\e100_l64-64-64-64-64_ep225_sig_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-220\\e100_l64-64-64-64-64_ep225_sig_  \n",
      "run_experiment()  when: 2026-01-15 13:32:42.337453 params: {'epochs': 225, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 13:32:52.778386\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-220\\e100_l64-64-64-64-64_ep225_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep225_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-220\\e100_l64-64-64-64-64_ep225_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep225_sig_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-220\\e100_l64-64-64-64-64_ep225_sig_\\predictions-e100_l64-64-64-64-64_ep225_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-220\\e100_l64-64-64-64-64_ep225_sig_\\predictions-e100_l64-64-64-64-64_ep225_sig_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-220\\e100_l64-64-64-64-64_ep225_sig_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-220\\e100_l64-64-64-64-64_ep225_sig_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-220\\e100_l64-64-64-64-64_ep225_sig_\\model\\assets\n",
      "[I 2026-01-15 13:35:04,977] Trial 220 finished with value: 0.8810431957244873 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 64, 'embedding_dim': 100, 'epochs': 225}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-220\\e100_l64-64-64-64-64_ep225_sig_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-220\\e100_l64-64-64-64-64_ep225_sig_\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-221\\e100_l64-64-64-64-64-64_ep340_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-221\\e100_l64-64-64-64-64-64_ep340_s  \n",
      "run_experiment()  when: 2026-01-15 13:35:05.057533 params: {'epochs': 340, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 13:36:01.157221\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-221\\e100_l64-64-64-64-64-64_ep340_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep340_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-221\\e100_l64-64-64-64-64-64_ep340_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep340_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-221\\e100_l64-64-64-64-64-64_ep340_s\\predictions-e100_l64-64-64-64-64-64_ep340_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-221\\e100_l64-64-64-64-64-64_ep340_s\\predictions-e100_l64-64-64-64-64-64_ep340_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-221\\e100_l64-64-64-64-64-64_ep340_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-221\\e100_l64-64-64-64-64-64_ep340_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-221\\e100_l64-64-64-64-64-64_ep340_s\\model\\assets\n",
      "[I 2026-01-15 13:39:43,065] Trial 221 finished with value: 0.8850193619728088 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 340}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-221\\e100_l64-64-64-64-64-64_ep340_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-221\\e100_l64-64-64-64-64-64_ep340_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-222\\e100_l64-64-64-64-64-64_ep250_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-222\\e100_l64-64-64-64-64-64_ep250_s  \n",
      "run_experiment()  when: 2026-01-15 13:39:43.354895 params: {'epochs': 250, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 13:41:11.955784\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-222\\e100_l64-64-64-64-64-64_ep250_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep250_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-222\\e100_l64-64-64-64-64-64_ep250_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep250_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-222\\e100_l64-64-64-64-64-64_ep250_s\\predictions-e100_l64-64-64-64-64-64_ep250_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-222\\e100_l64-64-64-64-64-64_ep250_s\\predictions-e100_l64-64-64-64-64-64_ep250_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-222\\e100_l64-64-64-64-64-64_ep250_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-222\\e100_l64-64-64-64-64-64_ep250_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-222\\e100_l64-64-64-64-64-64_ep250_s\\model\\assets\n",
      "[I 2026-01-15 13:42:04,579] Trial 222 finished with value: 0.8902652263641357 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 250}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-222\\e100_l64-64-64-64-64-64_ep250_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-222\\e100_l64-64-64-64-64-64_ep250_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-223\\e100_l64-64-64-64_ep205_sig_143\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-223\\e100_l64-64-64-64_ep205_sig_143  \n",
      "run_experiment()  when: 2026-01-15 13:42:04.623293 params: {'epochs': 205, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 13:43:17.170615\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 12ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-223\\e100_l64-64-64-64_ep205_sig_143\\normalized_training_df-e100_l64-64-64-64_ep205_sig_143.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-223\\e100_l64-64-64-64_ep205_sig_143\\normalized_training_df-e100_l64-64-64-64_ep205_sig_143.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-223\\e100_l64-64-64-64_ep205_sig_143\\predictions-e100_l64-64-64-64_ep205_sig_143.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-223\\e100_l64-64-64-64_ep205_sig_143\\predictions-e100_l64-64-64-64_ep205_sig_143.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-223\\e100_l64-64-64-64_ep205_sig_143\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-223\\e100_l64-64-64-64_ep205_sig_143\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-223\\e100_l64-64-64-64_ep205_sig_143\\model\\assets\n",
      "[I 2026-01-15 13:47:17,697] Trial 223 finished with value: 0.89622962474823 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 205}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-223\\e100_l64-64-64-64_ep205_sig_143\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-223\\e100_l64-64-64-64_ep205_sig_143\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-224\\e100_l64-64-64-64-64-64_ep235_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-224\\e100_l64-64-64-64-64-64_ep235_s  \n",
      "run_experiment()  when: 2026-01-15 13:47:18.036140 params: {'epochs': 235, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 13:48:30.635195\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 11ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-224\\e100_l64-64-64-64-64-64_ep235_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep235_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-224\\e100_l64-64-64-64-64-64_ep235_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep235_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-224\\e100_l64-64-64-64-64-64_ep235_s\\predictions-e100_l64-64-64-64-64-64_ep235_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-224\\e100_l64-64-64-64-64-64_ep235_s\\predictions-e100_l64-64-64-64-64-64_ep235_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-224\\e100_l64-64-64-64-64-64_ep235_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-224\\e100_l64-64-64-64-64-64_ep235_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-224\\e100_l64-64-64-64-64-64_ep235_s\\model\\assets\n",
      "[I 2026-01-15 13:52:33,560] Trial 224 finished with value: 0.8979859352111816 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 235}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-224\\e100_l64-64-64-64-64-64_ep235_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-224\\e100_l64-64-64-64-64-64_ep235_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-225\\e100_l64-64-64-64_ep360_sig_141\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-225\\e100_l64-64-64-64_ep360_sig_141  \n",
      "run_experiment()  when: 2026-01-15 13:52:33.612949 params: {'epochs': 360, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 13:53:44.141366\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 800us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-225\\e100_l64-64-64-64_ep360_sig_141\\normalized_training_df-e100_l64-64-64-64_ep360_sig_141.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-225\\e100_l64-64-64-64_ep360_sig_141\\normalized_training_df-e100_l64-64-64-64_ep360_sig_141.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-225\\e100_l64-64-64-64_ep360_sig_141\\predictions-e100_l64-64-64-64_ep360_sig_141.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-225\\e100_l64-64-64-64_ep360_sig_141\\predictions-e100_l64-64-64-64_ep360_sig_141.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-225\\e100_l64-64-64-64_ep360_sig_141\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-225\\e100_l64-64-64-64_ep360_sig_141\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-225\\e100_l64-64-64-64_ep360_sig_141\\model\\assets\n",
      "[I 2026-01-15 13:54:37,017] Trial 225 finished with value: 0.900975227355957 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 360}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-225\\e100_l64-64-64-64_ep360_sig_141\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-225\\e100_l64-64-64-64_ep360_sig_141\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-226\\e100_l64-64-64-64-64-64_ep260_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-226\\e100_l64-64-64-64-64-64_ep260_s  \n",
      "run_experiment()  when: 2026-01-15 13:54:37.060425 params: {'epochs': 260, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 13:54:54.877427\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 800us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-226\\e100_l64-64-64-64-64-64_ep260_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep260_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-226\\e100_l64-64-64-64-64-64_ep260_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep260_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-226\\e100_l64-64-64-64-64-64_ep260_s\\predictions-e100_l64-64-64-64-64-64_ep260_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-226\\e100_l64-64-64-64-64-64_ep260_s\\predictions-e100_l64-64-64-64-64-64_ep260_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-226\\e100_l64-64-64-64-64-64_ep260_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-226\\e100_l64-64-64-64-64-64_ep260_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-226\\e100_l64-64-64-64-64-64_ep260_s\\model\\assets\n",
      "[I 2026-01-15 13:55:45,532] Trial 226 finished with value: 0.8982453942298889 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 260}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-226\\e100_l64-64-64-64-64-64_ep260_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-226\\e100_l64-64-64-64-64-64_ep260_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-227\\e100_l64-64-64-64-64-64_ep215_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-227\\e100_l64-64-64-64-64-64_ep215_s  \n",
      "run_experiment()  when: 2026-01-15 13:55:45.580980 params: {'epochs': 215, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 13:57:00.806489\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 892us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-227\\e100_l64-64-64-64-64-64_ep215_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep215_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-227\\e100_l64-64-64-64-64-64_ep215_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep215_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-227\\e100_l64-64-64-64-64-64_ep215_s\\predictions-e100_l64-64-64-64-64-64_ep215_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-227\\e100_l64-64-64-64-64-64_ep215_s\\predictions-e100_l64-64-64-64-64-64_ep215_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-227\\e100_l64-64-64-64-64-64_ep215_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-227\\e100_l64-64-64-64-64-64_ep215_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-227\\e100_l64-64-64-64-64-64_ep215_s\\model\\assets\n",
      "[I 2026-01-15 14:00:27,465] Trial 227 finished with value: 0.8841480016708374 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 215}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-227\\e100_l64-64-64-64-64-64_ep215_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-227\\e100_l64-64-64-64-64-64_ep215_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-228\\e100_l64-64-64-64_ep275_sig_116\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-228\\e100_l64-64-64-64_ep275_sig_116  \n",
      "run_experiment()  when: 2026-01-15 14:00:27.506294 params: {'epochs': 275, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 14:00:39.900489\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 798us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-228\\e100_l64-64-64-64_ep275_sig_116\\normalized_training_df-e100_l64-64-64-64_ep275_sig_116.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-228\\e100_l64-64-64-64_ep275_sig_116\\normalized_training_df-e100_l64-64-64-64_ep275_sig_116.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-228\\e100_l64-64-64-64_ep275_sig_116\\predictions-e100_l64-64-64-64_ep275_sig_116.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-228\\e100_l64-64-64-64_ep275_sig_116\\predictions-e100_l64-64-64-64_ep275_sig_116.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-228\\e100_l64-64-64-64_ep275_sig_116\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-228\\e100_l64-64-64-64_ep275_sig_116\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-228\\e100_l64-64-64-64_ep275_sig_116\\model\\assets\n",
      "[I 2026-01-15 14:01:26,824] Trial 228 finished with value: 0.8847830295562744 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 275}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-228\\e100_l64-64-64-64_ep275_sig_116\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-228\\e100_l64-64-64-64_ep275_sig_116\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-229\\e100_l64-64-64-64-64-64_ep180_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-229\\e100_l64-64-64-64-64-64_ep180_s  \n",
      "run_experiment()  when: 2026-01-15 14:01:26.859771 params: {'epochs': 180, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 14:01:38.375791\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-229\\e100_l64-64-64-64-64-64_ep180_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep180_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-229\\e100_l64-64-64-64-64-64_ep180_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep180_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-229\\e100_l64-64-64-64-64-64_ep180_s\\predictions-e100_l64-64-64-64-64-64_ep180_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-229\\e100_l64-64-64-64-64-64_ep180_s\\predictions-e100_l64-64-64-64-64-64_ep180_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-229\\e100_l64-64-64-64-64-64_ep180_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-229\\e100_l64-64-64-64-64-64_ep180_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-229\\e100_l64-64-64-64-64-64_ep180_s\\model\\assets\n",
      "[I 2026-01-15 14:02:40,212] Trial 229 finished with value: 0.8853668570518494 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 180}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-229\\e100_l64-64-64-64-64-64_ep180_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-229\\e100_l64-64-64-64-64-64_ep180_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-230\\e100_l64-64-64-64_ep350_sig_564\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-230\\e100_l64-64-64-64_ep350_sig_564  \n",
      "run_experiment()  when: 2026-01-15 14:02:40.244870 params: {'epochs': 350, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 14:02:53.404437\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 8ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-230\\e100_l64-64-64-64_ep350_sig_564\\normalized_training_df-e100_l64-64-64-64_ep350_sig_564.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-230\\e100_l64-64-64-64_ep350_sig_564\\normalized_training_df-e100_l64-64-64-64_ep350_sig_564.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-230\\e100_l64-64-64-64_ep350_sig_564\\predictions-e100_l64-64-64-64_ep350_sig_564.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-230\\e100_l64-64-64-64_ep350_sig_564\\predictions-e100_l64-64-64-64_ep350_sig_564.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-230\\e100_l64-64-64-64_ep350_sig_564\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-230\\e100_l64-64-64-64_ep350_sig_564\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-230\\e100_l64-64-64-64_ep350_sig_564\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-15 14:05:55,594] Trial 230 finished with value: 0.8917388916015625 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 350}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-230\\e100_l64-64-64-64_ep350_sig_564\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-230\\e100_l64-64-64-64_ep350_sig_564\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-231\\e100_l64-64-64-64_ep240_sig_179\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-231\\e100_l64-64-64-64_ep240_sig_179  \n",
      "run_experiment()  when: 2026-01-15 14:05:55.777834 params: {'epochs': 240, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 14:06:45.674673\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-231\\e100_l64-64-64-64_ep240_sig_179\\normalized_training_df-e100_l64-64-64-64_ep240_sig_179.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-231\\e100_l64-64-64-64_ep240_sig_179\\normalized_training_df-e100_l64-64-64-64_ep240_sig_179.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-231\\e100_l64-64-64-64_ep240_sig_179\\predictions-e100_l64-64-64-64_ep240_sig_179.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-231\\e100_l64-64-64-64_ep240_sig_179\\predictions-e100_l64-64-64-64_ep240_sig_179.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-231\\e100_l64-64-64-64_ep240_sig_179\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-231\\e100_l64-64-64-64_ep240_sig_179\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-231\\e100_l64-64-64-64_ep240_sig_179\\model\\assets\n",
      "[I 2026-01-15 14:07:47,430] Trial 231 finished with value: 0.8996820449829102 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 240}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-231\\e100_l64-64-64-64_ep240_sig_179\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-231\\e100_l64-64-64-64_ep240_sig_179\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-232\\e100_l64-64-64-64_ep485_sig_112\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-232\\e100_l64-64-64-64_ep485_sig_112  \n",
      "run_experiment()  when: 2026-01-15 14:07:47.488231 params: {'epochs': 485, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 14:08:21.961784\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-232\\e100_l64-64-64-64_ep485_sig_112\\normalized_training_df-e100_l64-64-64-64_ep485_sig_112.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-232\\e100_l64-64-64-64_ep485_sig_112\\normalized_training_df-e100_l64-64-64-64_ep485_sig_112.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-232\\e100_l64-64-64-64_ep485_sig_112\\predictions-e100_l64-64-64-64_ep485_sig_112.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-232\\e100_l64-64-64-64_ep485_sig_112\\predictions-e100_l64-64-64-64_ep485_sig_112.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-232\\e100_l64-64-64-64_ep485_sig_112\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-232\\e100_l64-64-64-64_ep485_sig_112\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-232\\e100_l64-64-64-64_ep485_sig_112\\model\\assets\n",
      "[I 2026-01-15 14:09:42,122] Trial 232 finished with value: 0.9020084738731384 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 485}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-232\\e100_l64-64-64-64_ep485_sig_112\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-232\\e100_l64-64-64-64_ep485_sig_112\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-233\\e100_l64-64-64-64_ep490_sig_383\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-233\\e100_l64-64-64-64_ep490_sig_383  \n",
      "run_experiment()  when: 2026-01-15 14:09:42.167385 params: {'epochs': 490, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 14:09:56.669753\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-233\\e100_l64-64-64-64_ep490_sig_383\\normalized_training_df-e100_l64-64-64-64_ep490_sig_383.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-233\\e100_l64-64-64-64_ep490_sig_383\\normalized_training_df-e100_l64-64-64-64_ep490_sig_383.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-233\\e100_l64-64-64-64_ep490_sig_383\\predictions-e100_l64-64-64-64_ep490_sig_383.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-233\\e100_l64-64-64-64_ep490_sig_383\\predictions-e100_l64-64-64-64_ep490_sig_383.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-233\\e100_l64-64-64-64_ep490_sig_383\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-233\\e100_l64-64-64-64_ep490_sig_383\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-233\\e100_l64-64-64-64_ep490_sig_383\\model\\assets\n",
      "[I 2026-01-15 14:12:49,746] Trial 233 finished with value: 0.8964242935180664 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 490}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-233\\e100_l64-64-64-64_ep490_sig_383\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-233\\e100_l64-64-64-64_ep490_sig_383\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-234\\e100_l64-64-64-64_ep220_sig_182\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-234\\e100_l64-64-64-64_ep220_sig_182  \n",
      "run_experiment()  when: 2026-01-15 14:12:49.791868 params: {'epochs': 220, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 14:13:05.175073\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-234\\e100_l64-64-64-64_ep220_sig_182\\normalized_training_df-e100_l64-64-64-64_ep220_sig_182.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-234\\e100_l64-64-64-64_ep220_sig_182\\normalized_training_df-e100_l64-64-64-64_ep220_sig_182.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-234\\e100_l64-64-64-64_ep220_sig_182\\predictions-e100_l64-64-64-64_ep220_sig_182.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-234\\e100_l64-64-64-64_ep220_sig_182\\predictions-e100_l64-64-64-64_ep220_sig_182.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-234\\e100_l64-64-64-64_ep220_sig_182\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-234\\e100_l64-64-64-64_ep220_sig_182\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-234\\e100_l64-64-64-64_ep220_sig_182\\model\\assets\n",
      "[I 2026-01-15 14:14:20,094] Trial 234 finished with value: 0.8871788382530212 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 220}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-234\\e100_l64-64-64-64_ep220_sig_182\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-234\\e100_l64-64-64-64_ep220_sig_182\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-235\\e100_l64-64-64-64_ep485_sig_322\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-235\\e100_l64-64-64-64_ep485_sig_322  \n",
      "run_experiment()  when: 2026-01-15 14:14:20.140982 params: {'epochs': 485, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 14:14:36.034228\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-235\\e100_l64-64-64-64_ep485_sig_322\\normalized_training_df-e100_l64-64-64-64_ep485_sig_322.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-235\\e100_l64-64-64-64_ep485_sig_322\\normalized_training_df-e100_l64-64-64-64_ep485_sig_322.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-235\\e100_l64-64-64-64_ep485_sig_322\\predictions-e100_l64-64-64-64_ep485_sig_322.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-235\\e100_l64-64-64-64_ep485_sig_322\\predictions-e100_l64-64-64-64_ep485_sig_322.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-235\\e100_l64-64-64-64_ep485_sig_322\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-235\\e100_l64-64-64-64_ep485_sig_322\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-235\\e100_l64-64-64-64_ep485_sig_322\\model\\assets\n",
      "[I 2026-01-15 14:16:29,986] Trial 235 finished with value: 0.8862149715423584 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 485}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-235\\e100_l64-64-64-64_ep485_sig_322\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-235\\e100_l64-64-64-64_ep485_sig_322\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-236\\e100_l64-64-64-64-64_ep495_sig_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-236\\e100_l64-64-64-64-64_ep495_sig_  \n",
      "run_experiment()  when: 2026-01-15 14:16:30.245025 params: {'epochs': 495, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 14:17:30.208574\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 7ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-236\\e100_l64-64-64-64-64_ep495_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep495_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-236\\e100_l64-64-64-64-64_ep495_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep495_sig_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-236\\e100_l64-64-64-64-64_ep495_sig_\\predictions-e100_l64-64-64-64-64_ep495_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-236\\e100_l64-64-64-64-64_ep495_sig_\\predictions-e100_l64-64-64-64-64_ep495_sig_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-236\\e100_l64-64-64-64-64_ep495_sig_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-236\\e100_l64-64-64-64-64_ep495_sig_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-236\\e100_l64-64-64-64-64_ep495_sig_\\model\\assets\n",
      "[I 2026-01-15 14:21:23,259] Trial 236 finished with value: 0.8826790452003479 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 64, 'embedding_dim': 100, 'epochs': 495}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-236\\e100_l64-64-64-64-64_ep495_sig_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-236\\e100_l64-64-64-64-64_ep495_sig_\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-237\\e100_l64-64-64-64-64-64_ep330_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-237\\e100_l64-64-64-64-64-64_ep330_s  \n",
      "run_experiment()  when: 2026-01-15 14:21:23.302164 params: {'epochs': 330, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 14:21:35.805581\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-237\\e100_l64-64-64-64-64-64_ep330_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep330_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-237\\e100_l64-64-64-64-64-64_ep330_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep330_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-237\\e100_l64-64-64-64-64-64_ep330_s\\predictions-e100_l64-64-64-64-64-64_ep330_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-237\\e100_l64-64-64-64-64-64_ep330_s\\predictions-e100_l64-64-64-64-64-64_ep330_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-237\\e100_l64-64-64-64-64-64_ep330_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-237\\e100_l64-64-64-64-64-64_ep330_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-237\\e100_l64-64-64-64-64-64_ep330_s\\model\\assets\n",
      "[I 2026-01-15 14:23:07,033] Trial 237 finished with value: 0.8934954404830933 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 330}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-237\\e100_l64-64-64-64-64-64_ep330_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-237\\e100_l64-64-64-64-64-64_ep330_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-238\\e100_l64-64-64-64_ep455_sig_515\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-238\\e100_l64-64-64-64_ep455_sig_515  \n",
      "run_experiment()  when: 2026-01-15 14:23:07.227416 params: {'epochs': 455, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 14:24:03.410734\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 800us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-238\\e100_l64-64-64-64_ep455_sig_515\\normalized_training_df-e100_l64-64-64-64_ep455_sig_515.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-238\\e100_l64-64-64-64_ep455_sig_515\\normalized_training_df-e100_l64-64-64-64_ep455_sig_515.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-238\\e100_l64-64-64-64_ep455_sig_515\\predictions-e100_l64-64-64-64_ep455_sig_515.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-238\\e100_l64-64-64-64_ep455_sig_515\\predictions-e100_l64-64-64-64_ep455_sig_515.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-238\\e100_l64-64-64-64_ep455_sig_515\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-238\\e100_l64-64-64-64_ep455_sig_515\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-238\\e100_l64-64-64-64_ep455_sig_515\\model\\assets\n",
      "[I 2026-01-15 14:26:07,793] Trial 238 finished with value: 0.8916694521903992 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 455}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-238\\e100_l64-64-64-64_ep455_sig_515\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-238\\e100_l64-64-64-64_ep455_sig_515\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-239\\e100_l64-64-64-64-64-64_ep250_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-239\\e100_l64-64-64-64-64-64_ep250_s  \n",
      "run_experiment()  when: 2026-01-15 14:26:07.842112 params: {'epochs': 250, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 14:26:22.209904\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-239\\e100_l64-64-64-64-64-64_ep250_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep250_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-239\\e100_l64-64-64-64-64-64_ep250_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep250_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-239\\e100_l64-64-64-64-64-64_ep250_s\\predictions-e100_l64-64-64-64-64-64_ep250_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-239\\e100_l64-64-64-64-64-64_ep250_s\\predictions-e100_l64-64-64-64-64-64_ep250_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-239\\e100_l64-64-64-64-64-64_ep250_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-239\\e100_l64-64-64-64-64-64_ep250_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-239\\e100_l64-64-64-64-64-64_ep250_s\\model\\assets\n",
      "[I 2026-01-15 14:29:42,216] Trial 239 finished with value: 0.901503324508667 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 250}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-239\\e100_l64-64-64-64-64-64_ep250_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-239\\e100_l64-64-64-64-64-64_ep250_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-240\\e100_l64-64-64_ep250_sig_966\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-240\\e100_l64-64-64_ep250_sig_966  \n",
      "run_experiment()  when: 2026-01-15 14:29:42.422107 params: {'epochs': 250, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 14:30:18.584697\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-240\\e100_l64-64-64_ep250_sig_966\\normalized_training_df-e100_l64-64-64_ep250_sig_966.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-240\\e100_l64-64-64_ep250_sig_966\\normalized_training_df-e100_l64-64-64_ep250_sig_966.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-240\\e100_l64-64-64_ep250_sig_966\\predictions-e100_l64-64-64_ep250_sig_966.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-240\\e100_l64-64-64_ep250_sig_966\\predictions-e100_l64-64-64_ep250_sig_966.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-240\\e100_l64-64-64_ep250_sig_966\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-240\\e100_l64-64-64_ep250_sig_966\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-240\\e100_l64-64-64_ep250_sig_966\\model\\assets\n",
      "[I 2026-01-15 14:31:42,819] Trial 240 finished with value: 0.8999600410461426 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 100, 'epochs': 250}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-240\\e100_l64-64-64_ep250_sig_966\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-240\\e100_l64-64-64_ep250_sig_966\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-241\\e100_l64-64-64-64-64-64_ep475_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-241\\e100_l64-64-64-64-64-64_ep475_s  \n",
      "run_experiment()  when: 2026-01-15 14:31:43.096299 params: {'epochs': 475, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 14:33:11.439174\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 5ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-241\\e100_l64-64-64-64-64-64_ep475_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep475_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-241\\e100_l64-64-64-64-64-64_ep475_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep475_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-241\\e100_l64-64-64-64-64-64_ep475_s\\predictions-e100_l64-64-64-64-64-64_ep475_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-241\\e100_l64-64-64-64-64-64_ep475_s\\predictions-e100_l64-64-64-64-64-64_ep475_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-241\\e100_l64-64-64-64-64-64_ep475_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-241\\e100_l64-64-64-64-64-64_ep475_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-241\\e100_l64-64-64-64-64-64_ep475_s\\model\\assets\n",
      "[I 2026-01-15 14:37:18,517] Trial 241 finished with value: 0.8972073793411255 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 475}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-241\\e100_l64-64-64-64-64-64_ep475_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-241\\e100_l64-64-64-64-64-64_ep475_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-242\\e100_l64-64-64-64-64-64_ep260_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-242\\e100_l64-64-64-64-64-64_ep260_s  \n",
      "run_experiment()  when: 2026-01-15 14:37:18.638775 params: {'epochs': 260, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 14:38:38.035560\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-242\\e100_l64-64-64-64-64-64_ep260_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep260_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-242\\e100_l64-64-64-64-64-64_ep260_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep260_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-242\\e100_l64-64-64-64-64-64_ep260_s\\predictions-e100_l64-64-64-64-64-64_ep260_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-242\\e100_l64-64-64-64-64-64_ep260_s\\predictions-e100_l64-64-64-64-64-64_ep260_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-242\\e100_l64-64-64-64-64-64_ep260_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-242\\e100_l64-64-64-64-64-64_ep260_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-242\\e100_l64-64-64-64-64-64_ep260_s\\model\\assets\n",
      "[I 2026-01-15 14:42:38,638] Trial 242 finished with value: 0.8937224745750427 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 260}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-242\\e100_l64-64-64-64-64-64_ep260_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-242\\e100_l64-64-64-64-64-64_ep260_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-243\\e100_l64-64-64-64-64-64_ep245_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-243\\e100_l64-64-64-64-64-64_ep245_s  \n",
      "run_experiment()  when: 2026-01-15 14:42:38.704020 params: {'epochs': 245, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 14:42:52.161059\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-243\\e100_l64-64-64-64-64-64_ep245_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep245_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-243\\e100_l64-64-64-64-64-64_ep245_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep245_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-243\\e100_l64-64-64-64-64-64_ep245_s\\predictions-e100_l64-64-64-64-64-64_ep245_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-243\\e100_l64-64-64-64-64-64_ep245_s\\predictions-e100_l64-64-64-64-64-64_ep245_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-243\\e100_l64-64-64-64-64-64_ep245_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-243\\e100_l64-64-64-64-64-64_ep245_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-243\\e100_l64-64-64-64-64-64_ep245_s\\model\\assets\n",
      "[I 2026-01-15 14:43:52,112] Trial 243 finished with value: 0.894709587097168 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 245}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-243\\e100_l64-64-64-64-64-64_ep245_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-243\\e100_l64-64-64-64-64-64_ep245_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-244\\e100_l64-64-64-64-64-64_ep270_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-244\\e100_l64-64-64-64-64-64_ep270_s  \n",
      "run_experiment()  when: 2026-01-15 14:43:52.184873 params: {'epochs': 270, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 14:44:08.657106\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-244\\e100_l64-64-64-64-64-64_ep270_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep270_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-244\\e100_l64-64-64-64-64-64_ep270_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep270_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-244\\e100_l64-64-64-64-64-64_ep270_s\\predictions-e100_l64-64-64-64-64-64_ep270_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-244\\e100_l64-64-64-64-64-64_ep270_s\\predictions-e100_l64-64-64-64-64-64_ep270_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-244\\e100_l64-64-64-64-64-64_ep270_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-244\\e100_l64-64-64-64-64-64_ep270_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-244\\e100_l64-64-64-64-64-64_ep270_s\\model\\assets\n",
      "[I 2026-01-15 14:45:54,194] Trial 244 finished with value: 0.8986855745315552 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 270}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-244\\e100_l64-64-64-64-64-64_ep270_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-244\\e100_l64-64-64-64-64-64_ep270_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-245\\e100_l64-64-64-64-64-64_ep200_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-245\\e100_l64-64-64-64-64-64_ep200_s  \n",
      "run_experiment()  when: 2026-01-15 14:45:54.572656 params: {'epochs': 200, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 14:47:07.534870\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-245\\e100_l64-64-64-64-64-64_ep200_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep200_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-245\\e100_l64-64-64-64-64-64_ep200_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep200_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-245\\e100_l64-64-64-64-64-64_ep200_s\\predictions-e100_l64-64-64-64-64-64_ep200_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-245\\e100_l64-64-64-64-64-64_ep200_s\\predictions-e100_l64-64-64-64-64-64_ep200_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-245\\e100_l64-64-64-64-64-64_ep200_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-245\\e100_l64-64-64-64-64-64_ep200_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-245\\e100_l64-64-64-64-64-64_ep200_s\\model\\assets\n",
      "[I 2026-01-15 14:51:20,464] Trial 245 finished with value: 0.8871834874153137 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 200}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-245\\e100_l64-64-64-64-64-64_ep200_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-245\\e100_l64-64-64-64-64-64_ep200_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-246\\e100_l64-64-64-64-64-64_ep230_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-246\\e100_l64-64-64-64-64-64_ep230_s  \n",
      "run_experiment()  when: 2026-01-15 14:51:20.814375 params: {'epochs': 230, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 14:52:36.067494\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-246\\e100_l64-64-64-64-64-64_ep230_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep230_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-246\\e100_l64-64-64-64-64-64_ep230_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep230_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-246\\e100_l64-64-64-64-64-64_ep230_s\\predictions-e100_l64-64-64-64-64-64_ep230_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-246\\e100_l64-64-64-64-64-64_ep230_s\\predictions-e100_l64-64-64-64-64-64_ep230_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-246\\e100_l64-64-64-64-64-64_ep230_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-246\\e100_l64-64-64-64-64-64_ep230_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-246\\e100_l64-64-64-64-64-64_ep230_s\\model\\assets\n",
      "[I 2026-01-15 14:54:31,575] Trial 246 finished with value: 0.9062488079071045 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 230}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-246\\e100_l64-64-64-64-64-64_ep230_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-246\\e100_l64-64-64-64-64-64_ep230_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-247\\e100_l64-64-64-64-64-64_ep235_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-247\\e100_l64-64-64-64-64-64_ep235_s  \n",
      "run_experiment()  when: 2026-01-15 14:54:31.634309 params: {'epochs': 235, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 14:54:46.733935\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 10ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-247\\e100_l64-64-64-64-64-64_ep235_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep235_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-247\\e100_l64-64-64-64-64-64_ep235_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep235_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-247\\e100_l64-64-64-64-64-64_ep235_s\\predictions-e100_l64-64-64-64-64-64_ep235_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-247\\e100_l64-64-64-64-64-64_ep235_s\\predictions-e100_l64-64-64-64-64-64_ep235_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-247\\e100_l64-64-64-64-64-64_ep235_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-247\\e100_l64-64-64-64-64-64_ep235_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-247\\e100_l64-64-64-64-64-64_ep235_s\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-247\\e100_l64-64-64-64-64-64_ep235_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-247\\e100_l64-64-64-64-64-64_ep235_s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-15 14:58:11,096] Trial 247 finished with value: 0.8877812623977661 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 235}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-248\\e100_l64-64-64-64_ep230_sig_527\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-248\\e100_l64-64-64-64_ep230_sig_527  \n",
      "run_experiment()  when: 2026-01-15 14:58:11.230887 params: {'epochs': 230, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 14:59:20.006265\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-248\\e100_l64-64-64-64_ep230_sig_527\\normalized_training_df-e100_l64-64-64-64_ep230_sig_527.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-248\\e100_l64-64-64-64_ep230_sig_527\\normalized_training_df-e100_l64-64-64-64_ep230_sig_527.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-248\\e100_l64-64-64-64_ep230_sig_527\\predictions-e100_l64-64-64-64_ep230_sig_527.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-248\\e100_l64-64-64-64_ep230_sig_527\\predictions-e100_l64-64-64-64_ep230_sig_527.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-248\\e100_l64-64-64-64_ep230_sig_527\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-248\\e100_l64-64-64-64_ep230_sig_527\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-248\\e100_l64-64-64-64_ep230_sig_527\\model\\assets\n",
      "[I 2026-01-15 15:01:23,966] Trial 248 finished with value: 0.8912940621376038 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 230}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-248\\e100_l64-64-64-64_ep230_sig_527\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-248\\e100_l64-64-64-64_ep230_sig_527\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-249\\e100_l64-64-64-64_ep220_sig_219\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-249\\e100_l64-64-64-64_ep220_sig_219  \n",
      "run_experiment()  when: 2026-01-15 15:01:24.010541 params: {'epochs': 220, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 15:01:40.454756\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-249\\e100_l64-64-64-64_ep220_sig_219\\normalized_training_df-e100_l64-64-64-64_ep220_sig_219.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-249\\e100_l64-64-64-64_ep220_sig_219\\normalized_training_df-e100_l64-64-64-64_ep220_sig_219.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-249\\e100_l64-64-64-64_ep220_sig_219\\predictions-e100_l64-64-64-64_ep220_sig_219.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-249\\e100_l64-64-64-64_ep220_sig_219\\predictions-e100_l64-64-64-64_ep220_sig_219.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-249\\e100_l64-64-64-64_ep220_sig_219\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-249\\e100_l64-64-64-64_ep220_sig_219\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-249\\e100_l64-64-64-64_ep220_sig_219\\model\\assets\n",
      "[I 2026-01-15 15:05:04,757] Trial 249 finished with value: 0.9076113700866699 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 220}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-249\\e100_l64-64-64-64_ep220_sig_219\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-249\\e100_l64-64-64-64_ep220_sig_219\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-250\\e100_l64-64-64-64_ep215_sig_225\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-250\\e100_l64-64-64-64_ep215_sig_225  \n",
      "run_experiment()  when: 2026-01-15 15:05:04.982298 params: {'epochs': 215, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 15:06:26.818421\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-250\\e100_l64-64-64-64_ep215_sig_225\\normalized_training_df-e100_l64-64-64-64_ep215_sig_225.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-250\\e100_l64-64-64-64_ep215_sig_225\\normalized_training_df-e100_l64-64-64-64_ep215_sig_225.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-250\\e100_l64-64-64-64_ep215_sig_225\\predictions-e100_l64-64-64-64_ep215_sig_225.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-250\\e100_l64-64-64-64_ep215_sig_225\\predictions-e100_l64-64-64-64_ep215_sig_225.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-250\\e100_l64-64-64-64_ep215_sig_225\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-250\\e100_l64-64-64-64_ep215_sig_225\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-250\\e100_l64-64-64-64_ep215_sig_225\\model\\assets\n",
      "[I 2026-01-15 15:07:57,938] Trial 250 finished with value: 0.8926379680633545 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 215}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-250\\e100_l64-64-64-64_ep215_sig_225\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-250\\e100_l64-64-64-64_ep215_sig_225\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-251\\e100_l64-64-64-64_ep210_sig_226\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-251\\e100_l64-64-64-64_ep210_sig_226  \n",
      "run_experiment()  when: 2026-01-15 15:07:57.985197 params: {'epochs': 210, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 15:08:11.014557\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-251\\e100_l64-64-64-64_ep210_sig_226\\normalized_training_df-e100_l64-64-64-64_ep210_sig_226.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-251\\e100_l64-64-64-64_ep210_sig_226\\normalized_training_df-e100_l64-64-64-64_ep210_sig_226.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-251\\e100_l64-64-64-64_ep210_sig_226\\predictions-e100_l64-64-64-64_ep210_sig_226.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-251\\e100_l64-64-64-64_ep210_sig_226\\predictions-e100_l64-64-64-64_ep210_sig_226.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-251\\e100_l64-64-64-64_ep210_sig_226\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-251\\e100_l64-64-64-64_ep210_sig_226\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-251\\e100_l64-64-64-64_ep210_sig_226\\model\\assets\n",
      "[I 2026-01-15 15:11:39,564] Trial 251 finished with value: 0.9005857706069946 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 210}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-251\\e100_l64-64-64-64_ep210_sig_226\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-251\\e100_l64-64-64-64_ep210_sig_226\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-252\\e100_l64-64-64-64_ep475_sig_141\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-252\\e100_l64-64-64-64_ep475_sig_141  \n",
      "run_experiment()  when: 2026-01-15 15:11:39.613900 params: {'epochs': 475, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 15:11:55.709330\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-252\\e100_l64-64-64-64_ep475_sig_141\\normalized_training_df-e100_l64-64-64-64_ep475_sig_141.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-252\\e100_l64-64-64-64_ep475_sig_141\\normalized_training_df-e100_l64-64-64-64_ep475_sig_141.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-252\\e100_l64-64-64-64_ep475_sig_141\\predictions-e100_l64-64-64-64_ep475_sig_141.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-252\\e100_l64-64-64-64_ep475_sig_141\\predictions-e100_l64-64-64-64_ep475_sig_141.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-252\\e100_l64-64-64-64_ep475_sig_141\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-252\\e100_l64-64-64-64_ep475_sig_141\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-252\\e100_l64-64-64-64_ep475_sig_141\\model\\assets\n",
      "[I 2026-01-15 15:13:37,191] Trial 252 finished with value: 0.9070551991462708 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 475}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-252\\e100_l64-64-64-64_ep475_sig_141\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-252\\e100_l64-64-64-64_ep475_sig_141\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-253\\e100_l64-64-64-64_ep225_sig_117\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-253\\e100_l64-64-64-64_ep225_sig_117  \n",
      "run_experiment()  when: 2026-01-15 15:13:37.511097 params: {'epochs': 225, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 15:15:16.551422\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-253\\e100_l64-64-64-64_ep225_sig_117\\normalized_training_df-e100_l64-64-64-64_ep225_sig_117.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-253\\e100_l64-64-64-64_ep225_sig_117\\normalized_training_df-e100_l64-64-64-64_ep225_sig_117.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-253\\e100_l64-64-64-64_ep225_sig_117\\predictions-e100_l64-64-64-64_ep225_sig_117.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-253\\e100_l64-64-64-64_ep225_sig_117\\predictions-e100_l64-64-64-64_ep225_sig_117.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-253\\e100_l64-64-64-64_ep225_sig_117\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-253\\e100_l64-64-64-64_ep225_sig_117\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-253\\e100_l64-64-64-64_ep225_sig_117\\model\\assets\n",
      "[I 2026-01-15 15:19:08,982] Trial 253 finished with value: 0.8977866768836975 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 225}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-253\\e100_l64-64-64-64_ep225_sig_117\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-253\\e100_l64-64-64-64_ep225_sig_117\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-254\\e100_l64-64-64-64_ep220_sig_594\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-254\\e100_l64-64-64-64_ep220_sig_594  \n",
      "run_experiment()  when: 2026-01-15 15:19:09.025780 params: {'epochs': 220, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 15:19:21.874384\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-254\\e100_l64-64-64-64_ep220_sig_594\\normalized_training_df-e100_l64-64-64-64_ep220_sig_594.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-254\\e100_l64-64-64-64_ep220_sig_594\\normalized_training_df-e100_l64-64-64-64_ep220_sig_594.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-254\\e100_l64-64-64-64_ep220_sig_594\\predictions-e100_l64-64-64-64_ep220_sig_594.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-254\\e100_l64-64-64-64_ep220_sig_594\\predictions-e100_l64-64-64-64_ep220_sig_594.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-254\\e100_l64-64-64-64_ep220_sig_594\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-254\\e100_l64-64-64-64_ep220_sig_594\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-254\\e100_l64-64-64-64_ep220_sig_594\\model\\assets\n",
      "[I 2026-01-15 15:20:50,282] Trial 254 finished with value: 0.8901263475418091 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 220}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-254\\e100_l64-64-64-64_ep220_sig_594\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-254\\e100_l64-64-64-64_ep220_sig_594\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-255\\e100_l64-64-64-64_ep235_sig_117\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-255\\e100_l64-64-64-64_ep235_sig_117  \n",
      "run_experiment()  when: 2026-01-15 15:20:50.514410 params: {'epochs': 235, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 15:21:54.965089\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-255\\e100_l64-64-64-64_ep235_sig_117\\normalized_training_df-e100_l64-64-64-64_ep235_sig_117.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-255\\e100_l64-64-64-64_ep235_sig_117\\normalized_training_df-e100_l64-64-64-64_ep235_sig_117.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-255\\e100_l64-64-64-64_ep235_sig_117\\predictions-e100_l64-64-64-64_ep235_sig_117.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-255\\e100_l64-64-64-64_ep235_sig_117\\predictions-e100_l64-64-64-64_ep235_sig_117.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-255\\e100_l64-64-64-64_ep235_sig_117\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-255\\e100_l64-64-64-64_ep235_sig_117\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-255\\e100_l64-64-64-64_ep235_sig_117\\model\\assets\n",
      "[I 2026-01-15 15:23:37,122] Trial 255 finished with value: 0.8998536467552185 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 235}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-255\\e100_l64-64-64-64_ep235_sig_117\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-255\\e100_l64-64-64-64_ep235_sig_117\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-256\\e100_l64-64-64-64_ep200_sig_395\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-256\\e100_l64-64-64-64_ep200_sig_395  \n",
      "run_experiment()  when: 2026-01-15 15:23:37.172607 params: {'epochs': 200, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 15:23:52.954101\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-256\\e100_l64-64-64-64_ep200_sig_395\\normalized_training_df-e100_l64-64-64-64_ep200_sig_395.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-256\\e100_l64-64-64-64_ep200_sig_395\\normalized_training_df-e100_l64-64-64-64_ep200_sig_395.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-256\\e100_l64-64-64-64_ep200_sig_395\\predictions-e100_l64-64-64-64_ep200_sig_395.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-256\\e100_l64-64-64-64_ep200_sig_395\\predictions-e100_l64-64-64-64_ep200_sig_395.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-256\\e100_l64-64-64-64_ep200_sig_395\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-256\\e100_l64-64-64-64_ep200_sig_395\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-256\\e100_l64-64-64-64_ep200_sig_395\\model\\assets\n",
      "[I 2026-01-15 15:27:54,387] Trial 256 finished with value: 0.9009009599685669 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 200}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-256\\e100_l64-64-64-64_ep200_sig_395\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-256\\e100_l64-64-64-64_ep200_sig_395\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-257\\e100_l64-64-64-64-64_ep280_sig_\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-257\\e100_l64-64-64-64-64_ep280_sig_  \n",
      "run_experiment()  when: 2026-01-15 15:27:54.680711 params: {'epochs': 280, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 15:29:03.968740\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 13ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-257\\e100_l64-64-64-64-64_ep280_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep280_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-257\\e100_l64-64-64-64-64_ep280_sig_\\normalized_training_df-e100_l64-64-64-64-64_ep280_sig_.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-257\\e100_l64-64-64-64-64_ep280_sig_\\predictions-e100_l64-64-64-64-64_ep280_sig_.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-257\\e100_l64-64-64-64-64_ep280_sig_\\predictions-e100_l64-64-64-64-64_ep280_sig_.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-257\\e100_l64-64-64-64-64_ep280_sig_\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-257\\e100_l64-64-64-64-64_ep280_sig_\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-257\\e100_l64-64-64-64-64_ep280_sig_\\model\\assets\n",
      "[I 2026-01-15 15:32:21,823] Trial 257 finished with value: 0.8926240801811218 and parameters: {'learning_rate': 0.0001, 'depth': 5, 'units': 64, 'embedding_dim': 100, 'epochs': 280}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-257\\e100_l64-64-64-64-64_ep280_sig_\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-257\\e100_l64-64-64-64-64_ep280_sig_\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-258\\e100_l64-64-64-64_ep155_sig_199\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-258\\e100_l64-64-64-64_ep155_sig_199  \n",
      "run_experiment()  when: 2026-01-15 15:32:21.865904 params: {'epochs': 155, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 15:32:37.586301\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-258\\e100_l64-64-64-64_ep155_sig_199\\normalized_training_df-e100_l64-64-64-64_ep155_sig_199.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-258\\e100_l64-64-64-64_ep155_sig_199\\normalized_training_df-e100_l64-64-64-64_ep155_sig_199.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-258\\e100_l64-64-64-64_ep155_sig_199\\predictions-e100_l64-64-64-64_ep155_sig_199.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-258\\e100_l64-64-64-64_ep155_sig_199\\predictions-e100_l64-64-64-64_ep155_sig_199.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-258\\e100_l64-64-64-64_ep155_sig_199\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-258\\e100_l64-64-64-64_ep155_sig_199\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-258\\e100_l64-64-64-64_ep155_sig_199\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-15 15:34:26,987] Trial 258 finished with value: 0.9044923782348633 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 155}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-258\\e100_l64-64-64-64_ep155_sig_199\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-258\\e100_l64-64-64-64_ep155_sig_199\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-259\\e100_l64-64-64-64_ep145_sig_389\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-259\\e100_l64-64-64-64_ep145_sig_389  \n",
      "run_experiment()  when: 2026-01-15 15:34:27.173921 params: {'epochs': 145, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 15:34:58.442831\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-259\\e100_l64-64-64-64_ep145_sig_389\\normalized_training_df-e100_l64-64-64-64_ep145_sig_389.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-259\\e100_l64-64-64-64_ep145_sig_389\\normalized_training_df-e100_l64-64-64-64_ep145_sig_389.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-259\\e100_l64-64-64-64_ep145_sig_389\\predictions-e100_l64-64-64-64_ep145_sig_389.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-259\\e100_l64-64-64-64_ep145_sig_389\\predictions-e100_l64-64-64-64_ep145_sig_389.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-259\\e100_l64-64-64-64_ep145_sig_389\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-259\\e100_l64-64-64-64_ep145_sig_389\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-259\\e100_l64-64-64-64_ep145_sig_389\\model\\assets\n",
      "[I 2026-01-15 15:36:18,285] Trial 259 finished with value: 0.8932821750640869 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 145}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-259\\e100_l64-64-64-64_ep145_sig_389\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-259\\e100_l64-64-64-64_ep145_sig_389\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-260\\e100_l64-64-64-64_ep155_sig_124\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-260\\e100_l64-64-64-64_ep155_sig_124  \n",
      "run_experiment()  when: 2026-01-15 15:36:18.549838 params: {'epochs': 155, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 15:37:30.074329\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-260\\e100_l64-64-64-64_ep155_sig_124\\normalized_training_df-e100_l64-64-64-64_ep155_sig_124.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-260\\e100_l64-64-64-64_ep155_sig_124\\normalized_training_df-e100_l64-64-64-64_ep155_sig_124.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-260\\e100_l64-64-64-64_ep155_sig_124\\predictions-e100_l64-64-64-64_ep155_sig_124.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-260\\e100_l64-64-64-64_ep155_sig_124\\predictions-e100_l64-64-64-64_ep155_sig_124.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-260\\e100_l64-64-64-64_ep155_sig_124\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-260\\e100_l64-64-64-64_ep155_sig_124\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-260\\e100_l64-64-64-64_ep155_sig_124\\model\\assets\n",
      "[I 2026-01-15 15:41:32,812] Trial 260 finished with value: 0.8902096748352051 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 155}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-260\\e100_l64-64-64-64_ep155_sig_124\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-260\\e100_l64-64-64-64_ep155_sig_124\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-261\\e100_l64-64-64-64_ep130_sig_198\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-261\\e100_l64-64-64-64_ep130_sig_198  \n",
      "run_experiment()  when: 2026-01-15 15:41:32.860002 params: {'epochs': 130, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 15:41:45.960597\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-261\\e100_l64-64-64-64_ep130_sig_198\\normalized_training_df-e100_l64-64-64-64_ep130_sig_198.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-261\\e100_l64-64-64-64_ep130_sig_198\\normalized_training_df-e100_l64-64-64-64_ep130_sig_198.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-261\\e100_l64-64-64-64_ep130_sig_198\\predictions-e100_l64-64-64-64_ep130_sig_198.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-261\\e100_l64-64-64-64_ep130_sig_198\\predictions-e100_l64-64-64-64_ep130_sig_198.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-261\\e100_l64-64-64-64_ep130_sig_198\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-261\\e100_l64-64-64-64_ep130_sig_198\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-261\\e100_l64-64-64-64_ep130_sig_198\\model\\assets\n",
      "[I 2026-01-15 15:43:10,164] Trial 261 finished with value: 0.8972584009170532 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 130}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-261\\e100_l64-64-64-64_ep130_sig_198\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-261\\e100_l64-64-64-64_ep130_sig_198\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-262\\e100_l64-64-64-64_ep165_sig_975\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-262\\e100_l64-64-64-64_ep165_sig_975  \n",
      "run_experiment()  when: 2026-01-15 15:43:10.425176 params: {'epochs': 165, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 15:44:23.359101\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 10ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-262\\e100_l64-64-64-64_ep165_sig_975\\normalized_training_df-e100_l64-64-64-64_ep165_sig_975.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-262\\e100_l64-64-64-64_ep165_sig_975\\normalized_training_df-e100_l64-64-64-64_ep165_sig_975.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-262\\e100_l64-64-64-64_ep165_sig_975\\predictions-e100_l64-64-64-64_ep165_sig_975.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-262\\e100_l64-64-64-64_ep165_sig_975\\predictions-e100_l64-64-64-64_ep165_sig_975.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-262\\e100_l64-64-64-64_ep165_sig_975\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-262\\e100_l64-64-64-64_ep165_sig_975\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-262\\e100_l64-64-64-64_ep165_sig_975\\model\\assets\n",
      "[I 2026-01-15 15:46:39,033] Trial 262 finished with value: 0.8873735666275024 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 165}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-262\\e100_l64-64-64-64_ep165_sig_975\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-262\\e100_l64-64-64-64_ep165_sig_975\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-263\\e100_l64-64-64-64_ep475_sig_174\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-263\\e100_l64-64-64-64_ep475_sig_174  \n",
      "run_experiment()  when: 2026-01-15 15:46:39.075635 params: {'epochs': 475, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 15:46:55.419843\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-263\\e100_l64-64-64-64_ep475_sig_174\\normalized_training_df-e100_l64-64-64-64_ep475_sig_174.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-263\\e100_l64-64-64-64_ep475_sig_174\\normalized_training_df-e100_l64-64-64-64_ep475_sig_174.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-263\\e100_l64-64-64-64_ep475_sig_174\\predictions-e100_l64-64-64-64_ep475_sig_174.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-263\\e100_l64-64-64-64_ep475_sig_174\\predictions-e100_l64-64-64-64_ep475_sig_174.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-263\\e100_l64-64-64-64_ep475_sig_174\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-263\\e100_l64-64-64-64_ep475_sig_174\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-263\\e100_l64-64-64-64_ep475_sig_174\\model\\assets\n",
      "[I 2026-01-15 15:49:47,702] Trial 263 finished with value: 0.8902096152305603 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 475}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-263\\e100_l64-64-64-64_ep475_sig_174\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-263\\e100_l64-64-64-64_ep475_sig_174\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-264\\e100_l64-64-64-64_ep315_sig_173\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-264\\e100_l64-64-64-64_ep315_sig_173  \n",
      "run_experiment()  when: 2026-01-15 15:49:47.751750 params: {'epochs': 315, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 15:51:05.203361\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-264\\e100_l64-64-64-64_ep315_sig_173\\normalized_training_df-e100_l64-64-64-64_ep315_sig_173.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-264\\e100_l64-64-64-64_ep315_sig_173\\normalized_training_df-e100_l64-64-64-64_ep315_sig_173.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-264\\e100_l64-64-64-64_ep315_sig_173\\predictions-e100_l64-64-64-64_ep315_sig_173.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-264\\e100_l64-64-64-64_ep315_sig_173\\predictions-e100_l64-64-64-64_ep315_sig_173.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-264\\e100_l64-64-64-64_ep315_sig_173\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-264\\e100_l64-64-64-64_ep315_sig_173\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-264\\e100_l64-64-64-64_ep315_sig_173\\model\\assets\n",
      "[I 2026-01-15 15:52:30,289] Trial 264 finished with value: 0.8884255290031433 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 315}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-264\\e100_l64-64-64-64_ep315_sig_173\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-264\\e100_l64-64-64-64_ep315_sig_173\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-265\\e100_l64-64-64-64_ep265_sig_822\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-265\\e100_l64-64-64-64_ep265_sig_822  \n",
      "run_experiment()  when: 2026-01-15 15:52:30.357559 params: {'epochs': 265, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 15:53:12.705520\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-265\\e100_l64-64-64-64_ep265_sig_822\\normalized_training_df-e100_l64-64-64-64_ep265_sig_822.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-265\\e100_l64-64-64-64_ep265_sig_822\\normalized_training_df-e100_l64-64-64-64_ep265_sig_822.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-265\\e100_l64-64-64-64_ep265_sig_822\\predictions-e100_l64-64-64-64_ep265_sig_822.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-265\\e100_l64-64-64-64_ep265_sig_822\\predictions-e100_l64-64-64-64_ep265_sig_822.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-265\\e100_l64-64-64-64_ep265_sig_822\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-265\\e100_l64-64-64-64_ep265_sig_822\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-265\\e100_l64-64-64-64_ep265_sig_822\\model\\assets\n",
      "[I 2026-01-15 15:56:49,045] Trial 265 finished with value: 0.9080562591552734 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 265}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-265\\e100_l64-64-64-64_ep265_sig_822\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-265\\e100_l64-64-64-64_ep265_sig_822\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-266\\e100_l64-64-64-64_ep265_sig_728\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-266\\e100_l64-64-64-64_ep265_sig_728  \n",
      "run_experiment()  when: 2026-01-15 15:56:49.323776 params: {'epochs': 265, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 15:58:15.495921\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-266\\e100_l64-64-64-64_ep265_sig_728\\normalized_training_df-e100_l64-64-64-64_ep265_sig_728.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-266\\e100_l64-64-64-64_ep265_sig_728\\normalized_training_df-e100_l64-64-64-64_ep265_sig_728.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-266\\e100_l64-64-64-64_ep265_sig_728\\predictions-e100_l64-64-64-64_ep265_sig_728.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-266\\e100_l64-64-64-64_ep265_sig_728\\predictions-e100_l64-64-64-64_ep265_sig_728.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-266\\e100_l64-64-64-64_ep265_sig_728\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-266\\e100_l64-64-64-64_ep265_sig_728\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-266\\e100_l64-64-64-64_ep265_sig_728\\model\\assets\n",
      "[I 2026-01-15 15:59:23,839] Trial 266 finished with value: 0.8926149010658264 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 265}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-266\\e100_l64-64-64-64_ep265_sig_728\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-266\\e100_l64-64-64-64_ep265_sig_728\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-267\\e100_l64-64-64-64_ep255_sig_206\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-267\\e100_l64-64-64-64_ep255_sig_206  \n",
      "run_experiment()  when: 2026-01-15 15:59:23.896404 params: {'epochs': 255, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 16:00:22.068700\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 12ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-267\\e100_l64-64-64-64_ep255_sig_206\\normalized_training_df-e100_l64-64-64-64_ep255_sig_206.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-267\\e100_l64-64-64-64_ep255_sig_206\\normalized_training_df-e100_l64-64-64-64_ep255_sig_206.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-267\\e100_l64-64-64-64_ep255_sig_206\\predictions-e100_l64-64-64-64_ep255_sig_206.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-267\\e100_l64-64-64-64_ep255_sig_206\\predictions-e100_l64-64-64-64_ep255_sig_206.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-267\\e100_l64-64-64-64_ep255_sig_206\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-267\\e100_l64-64-64-64_ep255_sig_206\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-267\\e100_l64-64-64-64_ep255_sig_206\\model\\assets\n",
      "[I 2026-01-15 16:04:25,486] Trial 267 finished with value: 0.8854919672012329 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 255}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-267\\e100_l64-64-64-64_ep255_sig_206\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-267\\e100_l64-64-64-64_ep255_sig_206\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-268\\e100_l64-64-64-64-64-64_ep290_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-268\\e100_l64-64-64-64-64-64_ep290_s  \n",
      "run_experiment()  when: 2026-01-15 16:04:25.822468 params: {'epochs': 290, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 16:05:48.446144\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-268\\e100_l64-64-64-64-64-64_ep290_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep290_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-268\\e100_l64-64-64-64-64-64_ep290_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep290_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-268\\e100_l64-64-64-64-64-64_ep290_s\\predictions-e100_l64-64-64-64-64-64_ep290_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-268\\e100_l64-64-64-64-64-64_ep290_s\\predictions-e100_l64-64-64-64-64-64_ep290_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-268\\e100_l64-64-64-64-64-64_ep290_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-268\\e100_l64-64-64-64-64-64_ep290_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-268\\e100_l64-64-64-64-64-64_ep290_s\\model\\assets\n",
      "[I 2026-01-15 16:08:44,523] Trial 268 finished with value: 0.8911551237106323 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 290}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-268\\e100_l64-64-64-64-64-64_ep290_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-268\\e100_l64-64-64-64-64-64_ep290_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-269\\e100_l64-64-64-64_ep275_sig_131\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-269\\e100_l64-64-64-64_ep275_sig_131  \n",
      "run_experiment()  when: 2026-01-15 16:08:44.569408 params: {'epochs': 275, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 16:09:01.536243\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-269\\e100_l64-64-64-64_ep275_sig_131\\normalized_training_df-e100_l64-64-64-64_ep275_sig_131.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-269\\e100_l64-64-64-64_ep275_sig_131\\normalized_training_df-e100_l64-64-64-64_ep275_sig_131.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-269\\e100_l64-64-64-64_ep275_sig_131\\predictions-e100_l64-64-64-64_ep275_sig_131.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-269\\e100_l64-64-64-64_ep275_sig_131\\predictions-e100_l64-64-64-64_ep275_sig_131.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-269\\e100_l64-64-64-64_ep275_sig_131\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-269\\e100_l64-64-64-64_ep275_sig_131\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-269\\e100_l64-64-64-64_ep275_sig_131\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-269\\e100_l64-64-64-64_ep275_sig_131\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-269\\e100_l64-64-64-64_ep275_sig_131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-15 16:11:37,288] Trial 269 finished with value: 0.8892874121665955 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 275}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-270\\e100_l64-64-64_ep240_sig_951\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-270\\e100_l64-64-64_ep240_sig_951  \n",
      "run_experiment()  when: 2026-01-15 16:11:37.414456 params: {'epochs': 240, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 16:12:48.727947\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-270\\e100_l64-64-64_ep240_sig_951\\normalized_training_df-e100_l64-64-64_ep240_sig_951.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-270\\e100_l64-64-64_ep240_sig_951\\normalized_training_df-e100_l64-64-64_ep240_sig_951.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-270\\e100_l64-64-64_ep240_sig_951\\predictions-e100_l64-64-64_ep240_sig_951.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-270\\e100_l64-64-64_ep240_sig_951\\predictions-e100_l64-64-64_ep240_sig_951.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-270\\e100_l64-64-64_ep240_sig_951\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-270\\e100_l64-64-64_ep240_sig_951\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-270\\e100_l64-64-64_ep240_sig_951\\model\\assets\n",
      "[I 2026-01-15 16:14:07,983] Trial 270 finished with value: 0.9003586769104004 and parameters: {'learning_rate': 0.0001, 'depth': 3, 'units': 64, 'embedding_dim': 100, 'epochs': 240}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-270\\e100_l64-64-64_ep240_sig_951\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-270\\e100_l64-64-64_ep240_sig_951\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-271\\e100_l64-64-64-64-64-64_ep245_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-271\\e100_l64-64-64-64-64-64_ep245_s  \n",
      "run_experiment()  when: 2026-01-15 16:14:08.027233 params: {'epochs': 245, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 16:14:59.763246\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 8ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-271\\e100_l64-64-64-64-64-64_ep245_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep245_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-271\\e100_l64-64-64-64-64-64_ep245_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep245_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-271\\e100_l64-64-64-64-64-64_ep245_s\\predictions-e100_l64-64-64-64-64-64_ep245_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-271\\e100_l64-64-64-64-64-64_ep245_s\\predictions-e100_l64-64-64-64-64-64_ep245_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-271\\e100_l64-64-64-64-64-64_ep245_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-271\\e100_l64-64-64-64-64-64_ep245_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-271\\e100_l64-64-64-64-64-64_ep245_s\\model\\assets\n",
      "[I 2026-01-15 16:17:47,262] Trial 271 finished with value: 0.8848384618759155 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 245}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-271\\e100_l64-64-64-64-64-64_ep245_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-271\\e100_l64-64-64-64-64-64_ep245_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-272\\e100_l64-64-64-64-64-64_ep260_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-272\\e100_l64-64-64-64-64-64_ep260_s  \n",
      "run_experiment()  when: 2026-01-15 16:17:47.308548 params: {'epochs': 260, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 16:18:03.641723\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 4ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-272\\e100_l64-64-64-64-64-64_ep260_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep260_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-272\\e100_l64-64-64-64-64-64_ep260_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep260_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-272\\e100_l64-64-64-64-64-64_ep260_s\\predictions-e100_l64-64-64-64-64-64_ep260_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-272\\e100_l64-64-64-64-64-64_ep260_s\\predictions-e100_l64-64-64-64-64-64_ep260_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-272\\e100_l64-64-64-64-64-64_ep260_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-272\\e100_l64-64-64-64-64-64_ep260_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-272\\e100_l64-64-64-64-64-64_ep260_s\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-272\\e100_l64-64-64-64-64-64_ep260_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-272\\e100_l64-64-64-64-64-64_ep260_s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-15 16:21:10,811] Trial 272 finished with value: 0.9049744009971619 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 260}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-273\\e100_l64-64-64-64_ep270_sig_342\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-273\\e100_l64-64-64-64_ep270_sig_342  \n",
      "run_experiment()  when: 2026-01-15 16:21:11.156567 params: {'epochs': 270, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 16:22:45.556546\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 3ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-273\\e100_l64-64-64-64_ep270_sig_342\\normalized_training_df-e100_l64-64-64-64_ep270_sig_342.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-273\\e100_l64-64-64-64_ep270_sig_342\\normalized_training_df-e100_l64-64-64-64_ep270_sig_342.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-273\\e100_l64-64-64-64_ep270_sig_342\\predictions-e100_l64-64-64-64_ep270_sig_342.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-273\\e100_l64-64-64-64_ep270_sig_342\\predictions-e100_l64-64-64-64_ep270_sig_342.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-273\\e100_l64-64-64-64_ep270_sig_342\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-273\\e100_l64-64-64-64_ep270_sig_342\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-273\\e100_l64-64-64-64_ep270_sig_342\\model\\assets\n",
      "[I 2026-01-15 16:27:17,716] Trial 273 finished with value: 0.8923089504241943 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 270}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-273\\e100_l64-64-64-64_ep270_sig_342\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-273\\e100_l64-64-64-64_ep270_sig_342\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-274\\e100_l64-64-64-64-64-64_ep260_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-274\\e100_l64-64-64-64-64-64_ep260_s  \n",
      "run_experiment()  when: 2026-01-15 16:27:18.058046 params: {'epochs': 260, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 16:27:41.532969\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-274\\e100_l64-64-64-64-64-64_ep260_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep260_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-274\\e100_l64-64-64-64-64-64_ep260_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep260_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-274\\e100_l64-64-64-64-64-64_ep260_s\\predictions-e100_l64-64-64-64-64-64_ep260_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-274\\e100_l64-64-64-64-64-64_ep260_s\\predictions-e100_l64-64-64-64-64-64_ep260_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-274\\e100_l64-64-64-64-64-64_ep260_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-274\\e100_l64-64-64-64-64-64_ep260_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-274\\e100_l64-64-64-64-64-64_ep260_s\\model\\assets\n",
      "[I 2026-01-15 16:28:59,818] Trial 274 finished with value: 0.8803849816322327 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 260}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-274\\e100_l64-64-64-64-64-64_ep260_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-274\\e100_l64-64-64-64-64-64_ep260_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-275\\e100_l64-64-64-64_ep260_sig_201\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-275\\e100_l64-64-64-64_ep260_sig_201  \n",
      "run_experiment()  when: 2026-01-15 16:28:59.873959 params: {'epochs': 260, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 16:30:13.117581\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-275\\e100_l64-64-64-64_ep260_sig_201\\normalized_training_df-e100_l64-64-64-64_ep260_sig_201.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-275\\e100_l64-64-64-64_ep260_sig_201\\normalized_training_df-e100_l64-64-64-64_ep260_sig_201.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-275\\e100_l64-64-64-64_ep260_sig_201\\predictions-e100_l64-64-64-64_ep260_sig_201.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-275\\e100_l64-64-64-64_ep260_sig_201\\predictions-e100_l64-64-64-64_ep260_sig_201.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-275\\e100_l64-64-64-64_ep260_sig_201\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-275\\e100_l64-64-64-64_ep260_sig_201\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-275\\e100_l64-64-64-64_ep260_sig_201\\model\\assets\n",
      "[I 2026-01-15 16:33:32,968] Trial 275 finished with value: 0.8804221153259277 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 260}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-275\\e100_l64-64-64-64_ep260_sig_201\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-275\\e100_l64-64-64-64_ep260_sig_201\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-276\\e100_l64-64-64-64-64-64_ep290_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-276\\e100_l64-64-64-64-64-64_ep290_s  \n",
      "run_experiment()  when: 2026-01-15 16:33:33.013583 params: {'epochs': 290, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 16:33:47.415534\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-276\\e100_l64-64-64-64-64-64_ep290_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep290_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-276\\e100_l64-64-64-64-64-64_ep290_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep290_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-276\\e100_l64-64-64-64-64-64_ep290_s\\predictions-e100_l64-64-64-64-64-64_ep290_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-276\\e100_l64-64-64-64-64-64_ep290_s\\predictions-e100_l64-64-64-64-64-64_ep290_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-276\\e100_l64-64-64-64-64-64_ep290_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-276\\e100_l64-64-64-64-64-64_ep290_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-276\\e100_l64-64-64-64-64-64_ep290_s\\model\\assets\n",
      "[I 2026-01-15 16:35:49,737] Trial 276 finished with value: 0.8967486619949341 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 290}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-276\\e100_l64-64-64-64-64-64_ep290_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-276\\e100_l64-64-64-64-64-64_ep290_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-277\\e100_l64-64-64-64_ep225_sig_802\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-277\\e100_l64-64-64-64_ep225_sig_802  \n",
      "run_experiment()  when: 2026-01-15 16:35:50.036792 params: {'epochs': 225, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 16:37:23.149308\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 10ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-277\\e100_l64-64-64-64_ep225_sig_802\\normalized_training_df-e100_l64-64-64-64_ep225_sig_802.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-277\\e100_l64-64-64-64_ep225_sig_802\\normalized_training_df-e100_l64-64-64-64_ep225_sig_802.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-277\\e100_l64-64-64-64_ep225_sig_802\\predictions-e100_l64-64-64-64_ep225_sig_802.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-277\\e100_l64-64-64-64_ep225_sig_802\\predictions-e100_l64-64-64-64_ep225_sig_802.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-277\\e100_l64-64-64-64_ep225_sig_802\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-277\\e100_l64-64-64-64_ep225_sig_802\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-277\\e100_l64-64-64-64_ep225_sig_802\\model\\assets\n",
      "[I 2026-01-15 16:40:26,808] Trial 277 finished with value: 0.8904970288276672 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 225}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-277\\e100_l64-64-64-64_ep225_sig_802\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-277\\e100_l64-64-64-64_ep225_sig_802\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-278\\e100_l64-64-64-64-64-64_ep420_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-278\\e100_l64-64-64-64-64-64_ep420_s  \n",
      "run_experiment()  when: 2026-01-15 16:40:26.860941 params: {'epochs': 420, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 16:40:41.424564\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-278\\e100_l64-64-64-64-64-64_ep420_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep420_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-278\\e100_l64-64-64-64-64-64_ep420_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep420_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-278\\e100_l64-64-64-64-64-64_ep420_s\\predictions-e100_l64-64-64-64-64-64_ep420_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-278\\e100_l64-64-64-64-64-64_ep420_s\\predictions-e100_l64-64-64-64-64-64_ep420_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-278\\e100_l64-64-64-64-64-64_ep420_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-278\\e100_l64-64-64-64-64-64_ep420_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-278\\e100_l64-64-64-64-64-64_ep420_s\\model\\assets\n",
      "[I 2026-01-15 16:43:07,691] Trial 278 finished with value: 0.8985375165939331 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 420}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-278\\e100_l64-64-64-64-64-64_ep420_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-278\\e100_l64-64-64-64-64-64_ep420_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-279\\e100_l64-64-64-64_ep250_sig_228\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-279\\e100_l64-64-64-64_ep250_sig_228  \n",
      "run_experiment()  when: 2026-01-15 16:43:08.001970 params: {'epochs': 250, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 16:45:00.349405\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 8ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-279\\e100_l64-64-64-64_ep250_sig_228\\normalized_training_df-e100_l64-64-64-64_ep250_sig_228.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-279\\e100_l64-64-64-64_ep250_sig_228\\normalized_training_df-e100_l64-64-64-64_ep250_sig_228.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-279\\e100_l64-64-64-64_ep250_sig_228\\predictions-e100_l64-64-64-64_ep250_sig_228.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-279\\e100_l64-64-64-64_ep250_sig_228\\predictions-e100_l64-64-64-64_ep250_sig_228.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-279\\e100_l64-64-64-64_ep250_sig_228\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-279\\e100_l64-64-64-64_ep250_sig_228\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-279\\e100_l64-64-64-64_ep250_sig_228\\model\\assets\n",
      "[I 2026-01-15 16:48:53,833] Trial 279 finished with value: 0.8840646743774414 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 250}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-279\\e100_l64-64-64-64_ep250_sig_228\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-279\\e100_l64-64-64-64_ep250_sig_228\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-280\\e100_l64-64-64-64-64-64_ep280_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-280\\e100_l64-64-64-64-64-64_ep280_s  \n",
      "run_experiment()  when: 2026-01-15 16:48:53.899990 params: {'epochs': 280, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 16:50:35.437606\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-280\\e100_l64-64-64-64-64-64_ep280_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep280_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-280\\e100_l64-64-64-64-64-64_ep280_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep280_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-280\\e100_l64-64-64-64-64-64_ep280_s\\predictions-e100_l64-64-64-64-64-64_ep280_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-280\\e100_l64-64-64-64-64-64_ep280_s\\predictions-e100_l64-64-64-64-64-64_ep280_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-280\\e100_l64-64-64-64-64-64_ep280_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-280\\e100_l64-64-64-64-64-64_ep280_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-280\\e100_l64-64-64-64-64-64_ep280_s\\model\\assets\n",
      "[I 2026-01-15 16:52:24,530] Trial 280 finished with value: 0.8966976404190063 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 280}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-280\\e100_l64-64-64-64-64-64_ep280_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-280\\e100_l64-64-64-64-64-64_ep280_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-281\\e100_l64-64-64-64_ep240_sig_138\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-281\\e100_l64-64-64-64_ep240_sig_138  \n",
      "run_experiment()  when: 2026-01-15 16:52:24.600672 params: {'epochs': 240, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 16:52:40.150711\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-281\\e100_l64-64-64-64_ep240_sig_138\\normalized_training_df-e100_l64-64-64-64_ep240_sig_138.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-281\\e100_l64-64-64-64_ep240_sig_138\\normalized_training_df-e100_l64-64-64-64_ep240_sig_138.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-281\\e100_l64-64-64-64_ep240_sig_138\\predictions-e100_l64-64-64-64_ep240_sig_138.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-281\\e100_l64-64-64-64_ep240_sig_138\\predictions-e100_l64-64-64-64_ep240_sig_138.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-281\\e100_l64-64-64-64_ep240_sig_138\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-281\\e100_l64-64-64-64_ep240_sig_138\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-281\\e100_l64-64-64-64_ep240_sig_138\\model\\assets\n",
      "[I 2026-01-15 16:54:44,757] Trial 281 finished with value: 0.8998953104019165 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 240}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-281\\e100_l64-64-64-64_ep240_sig_138\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-281\\e100_l64-64-64-64_ep240_sig_138\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-282\\e100_l64-64-64-64-64-64_ep265_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-282\\e100_l64-64-64-64-64-64_ep265_s  \n",
      "run_experiment()  when: 2026-01-15 16:54:44.811984 params: {'epochs': 265, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 16:55:00.288518\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-282\\e100_l64-64-64-64-64-64_ep265_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep265_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-282\\e100_l64-64-64-64-64-64_ep265_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep265_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-282\\e100_l64-64-64-64-64-64_ep265_s\\predictions-e100_l64-64-64-64-64-64_ep265_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-282\\e100_l64-64-64-64-64-64_ep265_s\\predictions-e100_l64-64-64-64-64-64_ep265_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-282\\e100_l64-64-64-64-64-64_ep265_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-282\\e100_l64-64-64-64-64-64_ep265_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-282\\e100_l64-64-64-64-64-64_ep265_s\\model\\assets\n",
      "[I 2026-01-15 16:55:58,115] Trial 282 finished with value: 0.8979303240776062 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 265}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-282\\e100_l64-64-64-64-64-64_ep265_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-282\\e100_l64-64-64-64-64-64_ep265_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-283\\e100_l64-64-64-64_ep230_sig_397\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-283\\e100_l64-64-64-64_ep230_sig_397  \n",
      "run_experiment()  when: 2026-01-15 16:55:58.173559 params: {'epochs': 230, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 16:56:12.652953\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-283\\e100_l64-64-64-64_ep230_sig_397\\normalized_training_df-e100_l64-64-64-64_ep230_sig_397.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-283\\e100_l64-64-64-64_ep230_sig_397\\normalized_training_df-e100_l64-64-64-64_ep230_sig_397.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-283\\e100_l64-64-64-64_ep230_sig_397\\predictions-e100_l64-64-64-64_ep230_sig_397.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-283\\e100_l64-64-64-64_ep230_sig_397\\predictions-e100_l64-64-64-64_ep230_sig_397.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-283\\e100_l64-64-64-64_ep230_sig_397\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-283\\e100_l64-64-64-64_ep230_sig_397\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-283\\e100_l64-64-64-64_ep230_sig_397\\model\\assets\n",
      "[I 2026-01-15 16:58:53,134] Trial 283 finished with value: 0.896215558052063 and parameters: {'learning_rate': 0.0001, 'depth': 4, 'units': 64, 'embedding_dim': 100, 'epochs': 230}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-283\\e100_l64-64-64-64_ep230_sig_397\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-283\\e100_l64-64-64-64_ep230_sig_397\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-284\\e100_l64-64-64-64-64-64_ep305_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-284\\e100_l64-64-64-64-64-64_ep305_s  \n",
      "run_experiment()  when: 2026-01-15 16:58:53.443868 params: {'epochs': 305, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 16:59:58.182569\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 7ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-284\\e100_l64-64-64-64-64-64_ep305_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep305_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-284\\e100_l64-64-64-64-64-64_ep305_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep305_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-284\\e100_l64-64-64-64-64-64_ep305_s\\predictions-e100_l64-64-64-64-64-64_ep305_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-284\\e100_l64-64-64-64-64-64_ep305_s\\predictions-e100_l64-64-64-64-64-64_ep305_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-284\\e100_l64-64-64-64-64-64_ep305_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-284\\e100_l64-64-64-64-64-64_ep305_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-284\\e100_l64-64-64-64-64-64_ep305_s\\model\\assets\n",
      "[I 2026-01-15 17:04:06,577] Trial 284 finished with value: 0.9105727672576904 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 305}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-284\\e100_l64-64-64-64-64-64_ep305_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-284\\e100_l64-64-64-64-64-64_ep305_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-285\\e100_l64-64-64-64-64-64_ep310_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-285\\e100_l64-64-64-64-64-64_ep310_s  \n",
      "run_experiment()  when: 2026-01-15 17:04:06.889331 params: {'epochs': 310, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 17:05:26.436558\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-285\\e100_l64-64-64-64-64-64_ep310_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep310_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-285\\e100_l64-64-64-64-64-64_ep310_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep310_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-285\\e100_l64-64-64-64-64-64_ep310_s\\predictions-e100_l64-64-64-64-64-64_ep310_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-285\\e100_l64-64-64-64-64-64_ep310_s\\predictions-e100_l64-64-64-64-64-64_ep310_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-285\\e100_l64-64-64-64-64-64_ep310_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-285\\e100_l64-64-64-64-64-64_ep310_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-285\\e100_l64-64-64-64-64-64_ep310_s\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-285\\e100_l64-64-64-64-64-64_ep310_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-285\\e100_l64-64-64-64-64-64_ep310_s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-15 17:06:24,294] Trial 285 finished with value: 0.876399576663971 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 310}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-286\\e100_l64-64-64-64-64-64_ep320_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-286\\e100_l64-64-64-64-64-64_ep320_s  \n",
      "run_experiment()  when: 2026-01-15 17:06:24.585074 params: {'epochs': 320, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 17:07:47.640362\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 7ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-286\\e100_l64-64-64-64-64-64_ep320_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep320_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-286\\e100_l64-64-64-64-64-64_ep320_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep320_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-286\\e100_l64-64-64-64-64-64_ep320_s\\predictions-e100_l64-64-64-64-64-64_ep320_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-286\\e100_l64-64-64-64-64-64_ep320_s\\predictions-e100_l64-64-64-64-64-64_ep320_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-286\\e100_l64-64-64-64-64-64_ep320_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-286\\e100_l64-64-64-64-64-64_ep320_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-286\\e100_l64-64-64-64-64-64_ep320_s\\model\\assets\n",
      "[I 2026-01-15 17:11:11,804] Trial 286 finished with value: 0.8811171650886536 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 320}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-286\\e100_l64-64-64-64-64-64_ep320_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-286\\e100_l64-64-64-64-64-64_ep320_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-287\\e100_l64-64-64-64-64-64_ep300_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-287\\e100_l64-64-64-64-64-64_ep300_s  \n",
      "run_experiment()  when: 2026-01-15 17:11:11.848148 params: {'epochs': 300, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 17:11:26.042337\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-287\\e100_l64-64-64-64-64-64_ep300_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep300_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-287\\e100_l64-64-64-64-64-64_ep300_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep300_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-287\\e100_l64-64-64-64-64-64_ep300_s\\predictions-e100_l64-64-64-64-64-64_ep300_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-287\\e100_l64-64-64-64-64-64_ep300_s\\predictions-e100_l64-64-64-64-64-64_ep300_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-287\\e100_l64-64-64-64-64-64_ep300_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-287\\e100_l64-64-64-64-64-64_ep300_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-287\\e100_l64-64-64-64-64-64_ep300_s\\model\\assets\n",
      "[I 2026-01-15 17:13:46,500] Trial 287 finished with value: 0.8768722414970398 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 300}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-287\\e100_l64-64-64-64-64-64_ep300_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-287\\e100_l64-64-64-64-64-64_ep300_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-288\\e100_l64-64-64-64-64-64_ep290_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-288\\e100_l64-64-64-64-64-64_ep290_s  \n",
      "run_experiment()  when: 2026-01-15 17:13:46.548701 params: {'epochs': 290, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 17:15:15.364329\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 11ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-288\\e100_l64-64-64-64-64-64_ep290_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep290_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-288\\e100_l64-64-64-64-64-64_ep290_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep290_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-288\\e100_l64-64-64-64-64-64_ep290_s\\predictions-e100_l64-64-64-64-64-64_ep290_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-288\\e100_l64-64-64-64-64-64_ep290_s\\predictions-e100_l64-64-64-64-64-64_ep290_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-288\\e100_l64-64-64-64-64-64_ep290_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-288\\e100_l64-64-64-64-64-64_ep290_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-288\\e100_l64-64-64-64-64-64_ep290_s\\model\\assets\n",
      "[I 2026-01-15 17:20:13,039] Trial 288 finished with value: 0.9006831645965576 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 290}. Best is trial 64 with value: 0.9106746315956116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-288\\e100_l64-64-64-64-64-64_ep290_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-288\\e100_l64-64-64-64-64-64_ep290_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-289\\e100_l64-64-64-64-64-64_ep280_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-289\\e100_l64-64-64-64-64-64_ep280_s  \n",
      "run_experiment()  when: 2026-01-15 17:20:13.083429 params: {'epochs': 280, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 17:20:26.388077\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-289\\e100_l64-64-64-64-64-64_ep280_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep280_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-289\\e100_l64-64-64-64-64-64_ep280_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep280_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-289\\e100_l64-64-64-64-64-64_ep280_s\\predictions-e100_l64-64-64-64-64-64_ep280_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-289\\e100_l64-64-64-64-64-64_ep280_s\\predictions-e100_l64-64-64-64-64-64_ep280_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-289\\e100_l64-64-64-64-64-64_ep280_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-289\\e100_l64-64-64-64-64-64_ep280_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-289\\e100_l64-64-64-64-64-64_ep280_s\\model\\assets\n",
      "[I 2026-01-15 17:21:57,261] Trial 289 finished with value: 0.9166388511657715 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 280}. Best is trial 289 with value: 0.9166388511657715.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-289\\e100_l64-64-64-64-64-64_ep280_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-289\\e100_l64-64-64-64-64-64_ep280_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-290\\e100_l64-64-64-64-64-64_ep300_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-290\\e100_l64-64-64-64-64-64_ep300_s  \n",
      "run_experiment()  when: 2026-01-15 17:21:57.560965 params: {'epochs': 300, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 17:23:19.345095\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 1s 3ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-290\\e100_l64-64-64-64-64-64_ep300_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep300_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-290\\e100_l64-64-64-64-64-64_ep300_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep300_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-290\\e100_l64-64-64-64-64-64_ep300_s\\predictions-e100_l64-64-64-64-64-64_ep300_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-290\\e100_l64-64-64-64-64-64_ep300_s\\predictions-e100_l64-64-64-64-64-64_ep300_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-290\\e100_l64-64-64-64-64-64_ep300_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-290\\e100_l64-64-64-64-64-64_ep300_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-290\\e100_l64-64-64-64-64-64_ep300_s\\model\\assets\n",
      "[I 2026-01-15 17:27:04,285] Trial 290 finished with value: 0.8863632082939148 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 300}. Best is trial 289 with value: 0.9166388511657715.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-290\\e100_l64-64-64-64-64-64_ep300_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-290\\e100_l64-64-64-64-64-64_ep300_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-291\\e100_l64-64-64-64-64-64_ep305_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-291\\e100_l64-64-64-64-64-64_ep305_s  \n",
      "run_experiment()  when: 2026-01-15 17:27:04.331392 params: {'epochs': 305, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 17:27:20.227053\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-291\\e100_l64-64-64-64-64-64_ep305_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep305_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-291\\e100_l64-64-64-64-64-64_ep305_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep305_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-291\\e100_l64-64-64-64-64-64_ep305_s\\predictions-e100_l64-64-64-64-64-64_ep305_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-291\\e100_l64-64-64-64-64-64_ep305_s\\predictions-e100_l64-64-64-64-64-64_ep305_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-291\\e100_l64-64-64-64-64-64_ep305_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-291\\e100_l64-64-64-64-64-64_ep305_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-291\\e100_l64-64-64-64-64-64_ep305_s\\model\\assets\n",
      "[I 2026-01-15 17:29:14,651] Trial 291 finished with value: 0.8891993165016174 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 305}. Best is trial 289 with value: 0.9166388511657715.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-291\\e100_l64-64-64-64-64-64_ep305_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-291\\e100_l64-64-64-64-64-64_ep305_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-292\\e100_l64-64-64-64-64-64_ep290_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-292\\e100_l64-64-64-64-64-64_ep290_s  \n",
      "run_experiment()  when: 2026-01-15 17:29:14.886267 params: {'epochs': 290, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 17:30:23.416216\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-292\\e100_l64-64-64-64-64-64_ep290_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep290_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-292\\e100_l64-64-64-64-64-64_ep290_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep290_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-292\\e100_l64-64-64-64-64-64_ep290_s\\predictions-e100_l64-64-64-64-64-64_ep290_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-292\\e100_l64-64-64-64-64-64_ep290_s\\predictions-e100_l64-64-64-64-64-64_ep290_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-292\\e100_l64-64-64-64-64-64_ep290_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-292\\e100_l64-64-64-64-64-64_ep290_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-292\\e100_l64-64-64-64-64-64_ep290_s\\model\\assets\n",
      "[I 2026-01-15 17:32:13,948] Trial 292 finished with value: 0.8913496732711792 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 290}. Best is trial 289 with value: 0.9166388511657715.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-292\\e100_l64-64-64-64-64-64_ep290_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-292\\e100_l64-64-64-64-64-64_ep290_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-293\\e100_l64-64-64-64-64-64_ep210_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-293\\e100_l64-64-64-64-64-64_ep210_s  \n",
      "run_experiment()  when: 2026-01-15 17:32:13.998105 params: {'epochs': 210, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 17:32:33.093260\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-293\\e100_l64-64-64-64-64-64_ep210_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep210_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-293\\e100_l64-64-64-64-64-64_ep210_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep210_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-293\\e100_l64-64-64-64-64-64_ep210_s\\predictions-e100_l64-64-64-64-64-64_ep210_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-293\\e100_l64-64-64-64-64-64_ep210_s\\predictions-e100_l64-64-64-64-64-64_ep210_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-293\\e100_l64-64-64-64-64-64_ep210_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-293\\e100_l64-64-64-64-64-64_ep210_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-293\\e100_l64-64-64-64-64-64_ep210_s\\model\\assets\n",
      "[I 2026-01-15 17:36:15,163] Trial 293 finished with value: 0.8916277885437012 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 210}. Best is trial 289 with value: 0.9166388511657715.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-293\\e100_l64-64-64-64-64-64_ep210_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-293\\e100_l64-64-64-64-64-64_ep210_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-294\\e100_l64-64-64-64-64-64_ep280_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-294\\e100_l64-64-64-64-64-64_ep280_s  \n",
      "run_experiment()  when: 2026-01-15 17:36:15.442132 params: {'epochs': 280, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 17:37:22.675366\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-294\\e100_l64-64-64-64-64-64_ep280_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep280_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-294\\e100_l64-64-64-64-64-64_ep280_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep280_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-294\\e100_l64-64-64-64-64-64_ep280_s\\predictions-e100_l64-64-64-64-64-64_ep280_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-294\\e100_l64-64-64-64-64-64_ep280_s\\predictions-e100_l64-64-64-64-64-64_ep280_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-294\\e100_l64-64-64-64-64-64_ep280_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-294\\e100_l64-64-64-64-64-64_ep280_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-294\\e100_l64-64-64-64-64-64_ep280_s\\model\\assets\n",
      "[I 2026-01-15 17:40:11,198] Trial 294 finished with value: 0.9030141830444336 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 280}. Best is trial 289 with value: 0.9166388511657715.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-294\\e100_l64-64-64-64-64-64_ep280_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-294\\e100_l64-64-64-64-64-64_ep280_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-295\\e100_l64-64-64-64-64-64_ep220_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-295\\e100_l64-64-64-64-64-64_ep220_s  \n",
      "run_experiment()  when: 2026-01-15 17:40:11.246597 params: {'epochs': 220, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 17:40:24.857984\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-295\\e100_l64-64-64-64-64-64_ep220_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep220_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-295\\e100_l64-64-64-64-64-64_ep220_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep220_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-295\\e100_l64-64-64-64-64-64_ep220_s\\predictions-e100_l64-64-64-64-64-64_ep220_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-295\\e100_l64-64-64-64-64-64_ep220_s\\predictions-e100_l64-64-64-64-64-64_ep220_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-295\\e100_l64-64-64-64-64-64_ep220_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-295\\e100_l64-64-64-64-64-64_ep220_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-295\\e100_l64-64-64-64-64-64_ep220_s\\model\\assets\n",
      "[I 2026-01-15 17:42:44,521] Trial 295 finished with value: 0.8980368375778198 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 220}. Best is trial 289 with value: 0.9166388511657715.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-295\\e100_l64-64-64-64-64-64_ep220_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-295\\e100_l64-64-64-64-64-64_ep220_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-296\\e100_l64-64-64-64-64-64_ep270_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-296\\e100_l64-64-64-64-64-64_ep270_s  \n",
      "run_experiment()  when: 2026-01-15 17:42:44.764488 params: {'epochs': 270, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 17:43:39.561406\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-296\\e100_l64-64-64-64-64-64_ep270_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep270_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-296\\e100_l64-64-64-64-64-64_ep270_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep270_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-296\\e100_l64-64-64-64-64-64_ep270_s\\predictions-e100_l64-64-64-64-64-64_ep270_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-296\\e100_l64-64-64-64-64-64_ep270_s\\predictions-e100_l64-64-64-64-64-64_ep270_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-296\\e100_l64-64-64-64-64-64_ep270_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-296\\e100_l64-64-64-64-64-64_ep270_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-296\\e100_l64-64-64-64-64-64_ep270_s\\model\\assets\n",
      "[I 2026-01-15 17:44:48,779] Trial 296 finished with value: 0.880107045173645 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 270}. Best is trial 289 with value: 0.9166388511657715.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-296\\e100_l64-64-64-64-64-64_ep270_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-296\\e100_l64-64-64-64-64-64_ep270_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-297\\e100_l64-64-64-64-64-64_ep150_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-297\\e100_l64-64-64-64-64-64_ep150_s  \n",
      "run_experiment()  when: 2026-01-15 17:44:48.828067 params: {'epochs': 150, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 17:45:30.824654\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-297\\e100_l64-64-64-64-64-64_ep150_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep150_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-297\\e100_l64-64-64-64-64-64_ep150_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep150_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-297\\e100_l64-64-64-64-64-64_ep150_s\\predictions-e100_l64-64-64-64-64-64_ep150_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-297\\e100_l64-64-64-64-64-64_ep150_s\\predictions-e100_l64-64-64-64-64-64_ep150_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-297\\e100_l64-64-64-64-64-64_ep150_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-297\\e100_l64-64-64-64-64-64_ep150_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-297\\e100_l64-64-64-64-64-64_ep150_s\\model\\assets\n",
      "[I 2026-01-15 17:47:23,275] Trial 297 finished with value: 0.8908306360244751 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 150}. Best is trial 289 with value: 0.9166388511657715.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-297\\e100_l64-64-64-64-64-64_ep150_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-297\\e100_l64-64-64-64-64-64_ep150_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-298\\e100_l64-64-64-64-64-64_ep175_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-298\\e100_l64-64-64-64-64-64_ep175_s  \n",
      "run_experiment()  when: 2026-01-15 17:47:23.324223 params: {'epochs': 175, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 17:47:41.504829\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-298\\e100_l64-64-64-64-64-64_ep175_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep175_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-298\\e100_l64-64-64-64-64-64_ep175_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep175_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-298\\e100_l64-64-64-64-64-64_ep175_s\\predictions-e100_l64-64-64-64-64-64_ep175_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-298\\e100_l64-64-64-64-64-64_ep175_s\\predictions-e100_l64-64-64-64-64-64_ep175_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-298\\e100_l64-64-64-64-64-64_ep175_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-298\\e100_l64-64-64-64-64-64_ep175_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-298\\e100_l64-64-64-64-64-64_ep175_s\\model\\assets\n",
      "[I 2026-01-15 17:50:49,186] Trial 298 finished with value: 0.8648973703384399 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 175}. Best is trial 289 with value: 0.9166388511657715.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-298\\e100_l64-64-64-64-64-64_ep175_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-298\\e100_l64-64-64-64-64-64_ep175_s\n",
      "Creating dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-299\\e100_l64-64-64-64-64-64_ep190_s\n",
      "run_experiment()  exp_dir: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-299\\e100_l64-64-64-64-64-64_ep190_s  \n",
      "run_experiment()  when: 2026-01-15 17:50:49.341770 params: {'epochs': 190, 'batch_size': 32}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-15 17:52:05.489627\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:349: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_school_schedule_features()\n",
      "build_holiday_features()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-299\\e100_l64-64-64-64-64-64_ep190_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep190_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-299\\e100_l64-64-64-64-64-64_ep190_s\\normalized_training_df-e100_l64-64-64-64-64-64_ep190_s.xlsx\n",
      "Writing XLSX: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-299\\e100_l64-64-64-64-64-64_ep190_s\\predictions-e100_l64-64-64-64-64-64_ep190_s.xlsx\n",
      "   XLSX Done: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-299\\e100_l64-64-64-64-64-64_ep190_s\\predictions-e100_l64-64-64-64-64-64_ep190_s.xlsx\n",
      "[save_model] starting artifact save → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-299\\e100_l64-64-64-64-64-64_ep190_s\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-299\\e100_l64-64-64-64-64-64_ep190_s\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-299\\e100_l64-64-64-64-64-64_ep190_s\\model\\assets\n",
      "[I 2026-01-15 17:53:11,091] Trial 299 finished with value: 0.8897693753242493 and parameters: {'learning_rate': 0.0001, 'depth': 6, 'units': 64, 'embedding_dim': 100, 'epochs': 190}. Best is trial 289 with value: 0.9166388511657715.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-299\\e100_l64-64-64-64-64-64_ep190_s\\model\n",
      "Saved experiment → f:/exp/keras/optuna/study-no-itemPurchaseCount-20260115_003731/trial-299\\e100_l64-64-64-64-64-64_ep190_s\n"
     ]
    }
   ],
   "source": [
    "import optuna \n",
    "def objective(trial):\n",
    "\n",
    "    lr = trial.suggest_float(\"learning_rate\", 0.0001, 0.0001)\n",
    "    depth = trial.suggest_int(\"depth\", 3, 6)\n",
    "    units = trial.suggest_int(\"units\", 64, 64)\n",
    "    embedding_dim = trial.suggest_int(\"embedding_dim\", 100, 100 )\n",
    "    epochs = trial.suggest_int(\"epochs\", 10, 500, step=5)\n",
    "    # output_activation = trial.suggest_categorical(\"output_activation\", [\"sigmoid\", \"linear\"])\n",
    "    output_activation = \"sigmoid\"\n",
    "    metrics = [\"AUC\", \"Precision\", \"Recall\"]\n",
    "    # metrics = [\"Accuracy\", \"MAE\", \"MSE\", \"MAPE\", \"MSLE\", \"Precision\", \"Recall\", \"AUC\",  \"BinaryCrossentropy\", \"RootMeanSquaredError\"]\n",
    "    \n",
    "    layers_cfg = []\n",
    "    for _ in range(depth):\n",
    "        layers_cfg.append({ \"units\": units, \"activation\": \"relu\" })\n",
    "\n",
    "    build_params = {\n",
    "        \"embedding_dim\": embedding_dim,\n",
    "        \"layers\": layers_cfg,\n",
    "        \"output_activation\": output_activation,\n",
    "        \"optimizer\": \"adam\",\n",
    "        \"learning_rate\": lr,\n",
    "        \"loss\": \"binary_crossentropy\" if output_activation == \"sigmoid\" else \"mse\",\n",
    "        \"metrics\": metrics\n",
    "    }\n",
    "\n",
    "    train_params = {\n",
    "        \"epochs\": epochs,\n",
    "        \"batch_size\": 32,\n",
    "     \n",
    "    }\n",
    "    outputDir = f\"f:/exp/keras/optuna/{trial.study.study_name}/trial-{trial.number}\"\n",
    "            \n",
    "    groceryML.run_experiment(groceryML.training_df, build_params, train_params, outputDir)\n",
    "\n",
    "    return groceryML.last_val_auc\n",
    "############################################################################\n",
    "\n",
    "\n",
    "sampler = optuna.samplers.TPESampler()\n",
    "\n",
    "study_name = f\"study-no-itemPurchaseCount-{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "study = optuna.create_study(\n",
    "    study_name= study_name,\n",
    "    sampler=sampler,\n",
    "    direction=\"maximize\",   # or minimize — see note below\n",
    "    storage=\"sqlite:///optuna_grocery.db\",\n",
    "    load_if_exists=True\n",
    ")\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "runTimestamp = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "\n",
    "study.optimize(objective, n_trials=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cef528-5472-429d-9657-42dd746a184c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
