{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f94e9fd3-99b1-438c-9ac0-6d5455c99af4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pdb;\n",
    "from grocery_ml_tensorflow import GroceryML\n",
    "from grocery_ml_core import GroceryMLCore\n",
    "from hidden_layer_param_builder import HiddenLayerParamSetBuilder\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option(\"display.float_format\", lambda x: f\"{x:.6f}\")\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", 2000)\n",
    "\n",
    "print(os.getcwd())\n",
    "# print(\"GPUs Available:\", tf.config.list_physical_devices('GPU'))\n",
    "#tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "def run_all_experiments(df, model_param_sets, output_dir):\n",
    "    total = len(model_param_sets)\n",
    "    print(f\"run_all_experiments() when: {datetime.now()}  output_dir: {output_dir}\");\n",
    "    for index, params in enumerate(model_param_sets, 1):\n",
    "        print(f\"Running Exp {index}/{total}...\")\n",
    "        groceryML.run_experiment(df,  params[\"buildParams\"], params[\"trainParams\"], output_dir)\n",
    "\n",
    "\n",
    "try:\n",
    "    groceryML = GroceryML();\n",
    "    groceryMLCore = GroceryMLCore();\n",
    "    groceryML.build_training_df()\n",
    "    if groceryML.training_df is None:\n",
    "        raise();\n",
    "    ts = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "    groceryML.training_df.to_csv(f\"training_df-{ts}.csv\");\n",
    "except Exception as ex: \n",
    "    print(ex)\n",
    "    ts = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "    groceryML.training_df.to_csv(f\"training_df-{ts}-exception.csv\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93f79e5e-c00e-4803-99a6-2edd32947964",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_all_experiments() when: 2026-01-11 03:51:25.183305  output_dir: exp/keras/keras-1/test-shot-no-trust-2026_01_11_03_51_25\n",
      "Running Exp 1/1...\n",
      "Creating dir: exp/keras/keras-1/test-shot-no-trust-2026_01_11_03_51_25\\e1_l1_ep1_sig_422\n",
      "run_experiment()  exp_dir: exp/keras/keras-1/test-shot-no-trust-2026_01_11_03_51_25\\e1_l1_ep1_sig_422  \n",
      "run_experiment()  when: 2026-01-11 03:51:25.184304 params: {'epochs': 1}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-11 03:51:26.550497\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 600us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: exp/keras/keras-1/test-shot-no-trust-2026_01_11_03_51_25\\e1_l1_ep1_sig_422\\normalized_training_df-e1_l1_ep1_sig_422.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/test-shot-no-trust-2026_01_11_03_51_25\\e1_l1_ep1_sig_422\\normalized_training_df-e1_l1_ep1_sig_422.xlsx\n",
      "Writing XLSX: exp/keras/keras-1/test-shot-no-trust-2026_01_11_03_51_25\\e1_l1_ep1_sig_422\\predictions-e1_l1_ep1_sig_422.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/test-shot-no-trust-2026_01_11_03_51_25\\e1_l1_ep1_sig_422\\predictions-e1_l1_ep1_sig_422.xlsx\n",
      "[save_model] starting artifact save → exp/keras/keras-1/test-shot-no-trust-2026_01_11_03_51_25\\e1_l1_ep1_sig_422\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/test-shot-no-trust-2026_01_11_03_51_25\\e1_l1_ep1_sig_422\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/test-shot-no-trust-2026_01_11_03_51_25\\e1_l1_ep1_sig_422\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → exp/keras/keras-1/test-shot-no-trust-2026_01_11_03_51_25\\e1_l1_ep1_sig_422\\model\n",
      "Saved experiment → exp/keras/keras-1/test-shot-no-trust-2026_01_11_03_51_25\\e1_l1_ep1_sig_422\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# quick test shot\n",
    "layers = [\n",
    "    { \"units\": 1, \"activation\": \"relu\" }\n",
    "]\n",
    "modelParamsList = []\n",
    "modelParamsList.append({\n",
    "    \"trainParams\": { \"epochs\": 1 },\n",
    "    \"buildParams\": {\n",
    "    \"embedding_dim\": 1,\n",
    "    \"layers\": layers,\n",
    "    \"activation\": \"relu\",\n",
    "    \"output_activation\": \"sigmoid\",\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"loss\": \"binary_crossentropy\",\n",
    "    \"metrics\": \"BinaryCrossentropy\"\n",
    "    }\n",
    "})\n",
    "ts = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "run_all_experiments(groceryML.training_df, modelParamsList, f\"exp/keras/keras-1/test-shot-no-trust-{ts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de565bd7-0b9e-452d-98f2-9974631ad404",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_all_experiments() when: 2026-01-11 03:52:13.147767  output_dir: exp/keras/keras-1/2026_01_11_03_52_13\n",
      "Running Exp 1/21...\n",
      "Creating dir: exp/keras/keras-1/2026_01_11_03_52_13\\e1024_l128-128_ep10_sig_343\n",
      "run_experiment()  exp_dir: exp/keras/keras-1/2026_01_11_03_52_13\\e1024_l128-128_ep10_sig_343  \n",
      "run_experiment()  when: 2026-01-11 03:52:13.149768 params: {'epochs': 10}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-11 03:52:47.888977\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_03_52_13\\e1024_l128-128_ep10_sig_343\\normalized_training_df-e1024_l128-128_ep10_sig_343.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_03_52_13\\e1024_l128-128_ep10_sig_343\\normalized_training_df-e1024_l128-128_ep10_sig_343.xlsx\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_03_52_13\\e1024_l128-128_ep10_sig_343\\predictions-e1024_l128-128_ep10_sig_343.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_03_52_13\\e1024_l128-128_ep10_sig_343\\predictions-e1024_l128-128_ep10_sig_343.xlsx\n",
      "[save_model] starting artifact save → exp/keras/keras-1/2026_01_11_03_52_13\\e1024_l128-128_ep10_sig_343\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_03_52_13\\e1024_l128-128_ep10_sig_343\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_03_52_13\\e1024_l128-128_ep10_sig_343\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → exp/keras/keras-1/2026_01_11_03_52_13\\e1024_l128-128_ep10_sig_343\\model\n",
      "Saved experiment → exp/keras/keras-1/2026_01_11_03_52_13\\e1024_l128-128_ep10_sig_343\n",
      "Running Exp 2/21...\n",
      "Creating dir: exp/keras/keras-1/2026_01_11_03_52_13\\e256_l128-128_ep10_sig_192\n",
      "run_experiment()  exp_dir: exp/keras/keras-1/2026_01_11_03_52_13\\e256_l128-128_ep10_sig_192  \n",
      "run_experiment()  when: 2026-01-11 03:53:35.837000 params: {'epochs': 10}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-11 03:53:47.128503\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_03_52_13\\e256_l128-128_ep10_sig_192\\normalized_training_df-e256_l128-128_ep10_sig_192.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_03_52_13\\e256_l128-128_ep10_sig_192\\normalized_training_df-e256_l128-128_ep10_sig_192.xlsx\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_03_52_13\\e256_l128-128_ep10_sig_192\\predictions-e256_l128-128_ep10_sig_192.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_03_52_13\\e256_l128-128_ep10_sig_192\\predictions-e256_l128-128_ep10_sig_192.xlsx\n",
      "[save_model] starting artifact save → exp/keras/keras-1/2026_01_11_03_52_13\\e256_l128-128_ep10_sig_192\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_03_52_13\\e256_l128-128_ep10_sig_192\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_03_52_13\\e256_l128-128_ep10_sig_192\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → exp/keras/keras-1/2026_01_11_03_52_13\\e256_l128-128_ep10_sig_192\\model\n",
      "Saved experiment → exp/keras/keras-1/2026_01_11_03_52_13\\e256_l128-128_ep10_sig_192\n",
      "Running Exp 3/21...\n",
      "Creating dir: exp/keras/keras-1/2026_01_11_03_52_13\\e128_l128-128_ep10_sig_224\n",
      "run_experiment()  exp_dir: exp/keras/keras-1/2026_01_11_03_52_13\\e128_l128-128_ep10_sig_224  \n",
      "run_experiment()  when: 2026-01-11 03:54:35.010745 params: {'epochs': 10}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-11 03:54:44.408533\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_03_52_13\\e128_l128-128_ep10_sig_224\\normalized_training_df-e128_l128-128_ep10_sig_224.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_03_52_13\\e128_l128-128_ep10_sig_224\\normalized_training_df-e128_l128-128_ep10_sig_224.xlsx\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_03_52_13\\e128_l128-128_ep10_sig_224\\predictions-e128_l128-128_ep10_sig_224.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_03_52_13\\e128_l128-128_ep10_sig_224\\predictions-e128_l128-128_ep10_sig_224.xlsx\n",
      "[save_model] starting artifact save → exp/keras/keras-1/2026_01_11_03_52_13\\e128_l128-128_ep10_sig_224\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_03_52_13\\e128_l128-128_ep10_sig_224\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_03_52_13\\e128_l128-128_ep10_sig_224\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → exp/keras/keras-1/2026_01_11_03_52_13\\e128_l128-128_ep10_sig_224\\model\n",
      "Saved experiment → exp/keras/keras-1/2026_01_11_03_52_13\\e128_l128-128_ep10_sig_224\n",
      "Running Exp 4/21...\n",
      "Creating dir: exp/keras/keras-1/2026_01_11_03_52_13\\e64_l128-128_ep10_sig_210\n",
      "run_experiment()  exp_dir: exp/keras/keras-1/2026_01_11_03_52_13\\e64_l128-128_ep10_sig_210  \n",
      "run_experiment()  when: 2026-01-11 03:55:33.913079 params: {'epochs': 10}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-11 03:55:42.791785\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 917us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_03_52_13\\e64_l128-128_ep10_sig_210\\normalized_training_df-e64_l128-128_ep10_sig_210.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_03_52_13\\e64_l128-128_ep10_sig_210\\normalized_training_df-e64_l128-128_ep10_sig_210.xlsx\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_03_52_13\\e64_l128-128_ep10_sig_210\\predictions-e64_l128-128_ep10_sig_210.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_03_52_13\\e64_l128-128_ep10_sig_210\\predictions-e64_l128-128_ep10_sig_210.xlsx\n",
      "[save_model] starting artifact save → exp/keras/keras-1/2026_01_11_03_52_13\\e64_l128-128_ep10_sig_210\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_03_52_13\\e64_l128-128_ep10_sig_210\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_03_52_13\\e64_l128-128_ep10_sig_210\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → exp/keras/keras-1/2026_01_11_03_52_13\\e64_l128-128_ep10_sig_210\\model\n",
      "Saved experiment → exp/keras/keras-1/2026_01_11_03_52_13\\e64_l128-128_ep10_sig_210\n",
      "Running Exp 5/21...\n",
      "Creating dir: exp/keras/keras-1/2026_01_11_03_52_13\\e32_l128-128_ep10_sig_203\n",
      "run_experiment()  exp_dir: exp/keras/keras-1/2026_01_11_03_52_13\\e32_l128-128_ep10_sig_203  \n",
      "run_experiment()  when: 2026-01-11 03:56:31.883455 params: {'epochs': 10}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-11 03:56:40.482466\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 676us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_03_52_13\\e32_l128-128_ep10_sig_203\\normalized_training_df-e32_l128-128_ep10_sig_203.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_03_52_13\\e32_l128-128_ep10_sig_203\\normalized_training_df-e32_l128-128_ep10_sig_203.xlsx\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_03_52_13\\e32_l128-128_ep10_sig_203\\predictions-e32_l128-128_ep10_sig_203.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_03_52_13\\e32_l128-128_ep10_sig_203\\predictions-e32_l128-128_ep10_sig_203.xlsx\n",
      "[save_model] starting artifact save → exp/keras/keras-1/2026_01_11_03_52_13\\e32_l128-128_ep10_sig_203\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_03_52_13\\e32_l128-128_ep10_sig_203\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_03_52_13\\e32_l128-128_ep10_sig_203\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → exp/keras/keras-1/2026_01_11_03_52_13\\e32_l128-128_ep10_sig_203\\model\n",
      "Saved experiment → exp/keras/keras-1/2026_01_11_03_52_13\\e32_l128-128_ep10_sig_203\n",
      "Running Exp 6/21...\n",
      "Creating dir: exp/keras/keras-1/2026_01_11_03_52_13\\e16_l128-128_ep10_sig_175\n",
      "run_experiment()  exp_dir: exp/keras/keras-1/2026_01_11_03_52_13\\e16_l128-128_ep10_sig_175  \n",
      "run_experiment()  when: 2026-01-11 03:57:31.075988 params: {'epochs': 10}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-11 03:57:42.611129\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 795us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_03_52_13\\e16_l128-128_ep10_sig_175\\normalized_training_df-e16_l128-128_ep10_sig_175.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_03_52_13\\e16_l128-128_ep10_sig_175\\normalized_training_df-e16_l128-128_ep10_sig_175.xlsx\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_03_52_13\\e16_l128-128_ep10_sig_175\\predictions-e16_l128-128_ep10_sig_175.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_03_52_13\\e16_l128-128_ep10_sig_175\\predictions-e16_l128-128_ep10_sig_175.xlsx\n",
      "[save_model] starting artifact save → exp/keras/keras-1/2026_01_11_03_52_13\\e16_l128-128_ep10_sig_175\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_03_52_13\\e16_l128-128_ep10_sig_175\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_03_52_13\\e16_l128-128_ep10_sig_175\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → exp/keras/keras-1/2026_01_11_03_52_13\\e16_l128-128_ep10_sig_175\\model\n",
      "Saved experiment → exp/keras/keras-1/2026_01_11_03_52_13\\e16_l128-128_ep10_sig_175\n",
      "Running Exp 7/21...\n",
      "Creating dir: exp/keras/keras-1/2026_01_11_03_52_13\\e12_l128-128_ep10_sig_941\n",
      "run_experiment()  exp_dir: exp/keras/keras-1/2026_01_11_03_52_13\\e12_l128-128_ep10_sig_941  \n",
      "run_experiment()  when: 2026-01-11 03:58:31.408466 params: {'epochs': 10}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-11 03:58:42.218398\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_03_52_13\\e12_l128-128_ep10_sig_941\\normalized_training_df-e12_l128-128_ep10_sig_941.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_03_52_13\\e12_l128-128_ep10_sig_941\\normalized_training_df-e12_l128-128_ep10_sig_941.xlsx\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_03_52_13\\e12_l128-128_ep10_sig_941\\predictions-e12_l128-128_ep10_sig_941.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_03_52_13\\e12_l128-128_ep10_sig_941\\predictions-e12_l128-128_ep10_sig_941.xlsx\n",
      "[save_model] starting artifact save → exp/keras/keras-1/2026_01_11_03_52_13\\e12_l128-128_ep10_sig_941\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_03_52_13\\e12_l128-128_ep10_sig_941\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_03_52_13\\e12_l128-128_ep10_sig_941\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → exp/keras/keras-1/2026_01_11_03_52_13\\e12_l128-128_ep10_sig_941\\model\n",
      "Saved experiment → exp/keras/keras-1/2026_01_11_03_52_13\\e12_l128-128_ep10_sig_941\n",
      "Running Exp 8/21...\n",
      "Creating dir: exp/keras/keras-1/2026_01_11_03_52_13\\e1024_l128-128_ep10_lin_167\n",
      "run_experiment()  exp_dir: exp/keras/keras-1/2026_01_11_03_52_13\\e1024_l128-128_ep10_lin_167  \n",
      "run_experiment()  when: 2026-01-11 03:59:35.728307 params: {'epochs': 10}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-11 04:00:11.248390\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 0s/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_03_52_13\\e1024_l128-128_ep10_lin_167\\normalized_training_df-e1024_l128-128_ep10_lin_167.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_03_52_13\\e1024_l128-128_ep10_lin_167\\normalized_training_df-e1024_l128-128_ep10_lin_167.xlsx\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_03_52_13\\e1024_l128-128_ep10_lin_167\\predictions-e1024_l128-128_ep10_lin_167.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_03_52_13\\e1024_l128-128_ep10_lin_167\\predictions-e1024_l128-128_ep10_lin_167.xlsx\n",
      "[save_model] starting artifact save → exp/keras/keras-1/2026_01_11_03_52_13\\e1024_l128-128_ep10_lin_167\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_03_52_13\\e1024_l128-128_ep10_lin_167\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_03_52_13\\e1024_l128-128_ep10_lin_167\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → exp/keras/keras-1/2026_01_11_03_52_13\\e1024_l128-128_ep10_lin_167\\model\n",
      "Saved experiment → exp/keras/keras-1/2026_01_11_03_52_13\\e1024_l128-128_ep10_lin_167\n",
      "Running Exp 9/21...\n",
      "Creating dir: exp/keras/keras-1/2026_01_11_03_52_13\\e256_l128-128_ep10_lin_205\n",
      "run_experiment()  exp_dir: exp/keras/keras-1/2026_01_11_03_52_13\\e256_l128-128_ep10_lin_205  \n",
      "run_experiment()  when: 2026-01-11 04:00:59.893003 params: {'epochs': 10}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-11 04:01:10.828169\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_03_52_13\\e256_l128-128_ep10_lin_205\\normalized_training_df-e256_l128-128_ep10_lin_205.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_03_52_13\\e256_l128-128_ep10_lin_205\\normalized_training_df-e256_l128-128_ep10_lin_205.xlsx\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_03_52_13\\e256_l128-128_ep10_lin_205\\predictions-e256_l128-128_ep10_lin_205.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_03_52_13\\e256_l128-128_ep10_lin_205\\predictions-e256_l128-128_ep10_lin_205.xlsx\n",
      "[save_model] starting artifact save → exp/keras/keras-1/2026_01_11_03_52_13\\e256_l128-128_ep10_lin_205\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_03_52_13\\e256_l128-128_ep10_lin_205\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_03_52_13\\e256_l128-128_ep10_lin_205\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → exp/keras/keras-1/2026_01_11_03_52_13\\e256_l128-128_ep10_lin_205\\model\n",
      "Saved experiment → exp/keras/keras-1/2026_01_11_03_52_13\\e256_l128-128_ep10_lin_205\n",
      "Running Exp 10/21...\n",
      "Creating dir: exp/keras/keras-1/2026_01_11_03_52_13\\e128_l128-128_ep10_lin_803\n",
      "run_experiment()  exp_dir: exp/keras/keras-1/2026_01_11_03_52_13\\e128_l128-128_ep10_lin_803  \n",
      "run_experiment()  when: 2026-01-11 04:01:59.350386 params: {'epochs': 10}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-11 04:02:09.119838\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_03_52_13\\e128_l128-128_ep10_lin_803\\normalized_training_df-e128_l128-128_ep10_lin_803.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_03_52_13\\e128_l128-128_ep10_lin_803\\normalized_training_df-e128_l128-128_ep10_lin_803.xlsx\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_03_52_13\\e128_l128-128_ep10_lin_803\\predictions-e128_l128-128_ep10_lin_803.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_03_52_13\\e128_l128-128_ep10_lin_803\\predictions-e128_l128-128_ep10_lin_803.xlsx\n",
      "[save_model] starting artifact save → exp/keras/keras-1/2026_01_11_03_52_13\\e128_l128-128_ep10_lin_803\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_03_52_13\\e128_l128-128_ep10_lin_803\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_03_52_13\\e128_l128-128_ep10_lin_803\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → exp/keras/keras-1/2026_01_11_03_52_13\\e128_l128-128_ep10_lin_803\\model\n",
      "Saved experiment → exp/keras/keras-1/2026_01_11_03_52_13\\e128_l128-128_ep10_lin_803\n",
      "Running Exp 11/21...\n",
      "Creating dir: exp/keras/keras-1/2026_01_11_03_52_13\\e64_l128-128_ep10_lin_193\n",
      "run_experiment()  exp_dir: exp/keras/keras-1/2026_01_11_03_52_13\\e64_l128-128_ep10_lin_193  \n",
      "run_experiment()  when: 2026-01-11 04:02:58.008402 params: {'epochs': 10}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-11 04:03:06.568218\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 0s/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_03_52_13\\e64_l128-128_ep10_lin_193\\normalized_training_df-e64_l128-128_ep10_lin_193.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_03_52_13\\e64_l128-128_ep10_lin_193\\normalized_training_df-e64_l128-128_ep10_lin_193.xlsx\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_03_52_13\\e64_l128-128_ep10_lin_193\\predictions-e64_l128-128_ep10_lin_193.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_03_52_13\\e64_l128-128_ep10_lin_193\\predictions-e64_l128-128_ep10_lin_193.xlsx\n",
      "[save_model] starting artifact save → exp/keras/keras-1/2026_01_11_03_52_13\\e64_l128-128_ep10_lin_193\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_03_52_13\\e64_l128-128_ep10_lin_193\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_03_52_13\\e64_l128-128_ep10_lin_193\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → exp/keras/keras-1/2026_01_11_03_52_13\\e64_l128-128_ep10_lin_193\\model\n",
      "Saved experiment → exp/keras/keras-1/2026_01_11_03_52_13\\e64_l128-128_ep10_lin_193\n",
      "Running Exp 12/21...\n",
      "Creating dir: exp/keras/keras-1/2026_01_11_03_52_13\\e32_l128-128_ep10_lin_735\n",
      "run_experiment()  exp_dir: exp/keras/keras-1/2026_01_11_03_52_13\\e32_l128-128_ep10_lin_735  \n",
      "run_experiment()  when: 2026-01-11 04:03:55.319025 params: {'epochs': 10}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-11 04:04:03.607897\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 404us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_03_52_13\\e32_l128-128_ep10_lin_735\\normalized_training_df-e32_l128-128_ep10_lin_735.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_03_52_13\\e32_l128-128_ep10_lin_735\\normalized_training_df-e32_l128-128_ep10_lin_735.xlsx\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_03_52_13\\e32_l128-128_ep10_lin_735\\predictions-e32_l128-128_ep10_lin_735.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_03_52_13\\e32_l128-128_ep10_lin_735\\predictions-e32_l128-128_ep10_lin_735.xlsx\n",
      "[save_model] starting artifact save → exp/keras/keras-1/2026_01_11_03_52_13\\e32_l128-128_ep10_lin_735\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_03_52_13\\e32_l128-128_ep10_lin_735\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_03_52_13\\e32_l128-128_ep10_lin_735\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → exp/keras/keras-1/2026_01_11_03_52_13\\e32_l128-128_ep10_lin_735\\model\n",
      "Saved experiment → exp/keras/keras-1/2026_01_11_03_52_13\\e32_l128-128_ep10_lin_735\n",
      "Running Exp 13/21...\n",
      "Creating dir: exp/keras/keras-1/2026_01_11_03_52_13\\e16_l128-128_ep10_lin_142\n",
      "run_experiment()  exp_dir: exp/keras/keras-1/2026_01_11_03_52_13\\e16_l128-128_ep10_lin_142  \n",
      "run_experiment()  when: 2026-01-11 04:04:52.618040 params: {'epochs': 10}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-11 04:05:00.678057\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 0s/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_03_52_13\\e16_l128-128_ep10_lin_142\\normalized_training_df-e16_l128-128_ep10_lin_142.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_03_52_13\\e16_l128-128_ep10_lin_142\\normalized_training_df-e16_l128-128_ep10_lin_142.xlsx\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_03_52_13\\e16_l128-128_ep10_lin_142\\predictions-e16_l128-128_ep10_lin_142.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_03_52_13\\e16_l128-128_ep10_lin_142\\predictions-e16_l128-128_ep10_lin_142.xlsx\n",
      "[save_model] starting artifact save → exp/keras/keras-1/2026_01_11_03_52_13\\e16_l128-128_ep10_lin_142\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_03_52_13\\e16_l128-128_ep10_lin_142\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_03_52_13\\e16_l128-128_ep10_lin_142\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → exp/keras/keras-1/2026_01_11_03_52_13\\e16_l128-128_ep10_lin_142\\model\n",
      "Saved experiment → exp/keras/keras-1/2026_01_11_03_52_13\\e16_l128-128_ep10_lin_142\n",
      "Running Exp 14/21...\n",
      "Creating dir: exp/keras/keras-1/2026_01_11_03_52_13\\e12_l128-128_ep10_lin_427\n",
      "run_experiment()  exp_dir: exp/keras/keras-1/2026_01_11_03_52_13\\e12_l128-128_ep10_lin_427  \n",
      "run_experiment()  when: 2026-01-11 04:05:49.185406 params: {'epochs': 10}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-11 04:05:58.237992\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 0s/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_03_52_13\\e12_l128-128_ep10_lin_427\\normalized_training_df-e12_l128-128_ep10_lin_427.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_03_52_13\\e12_l128-128_ep10_lin_427\\normalized_training_df-e12_l128-128_ep10_lin_427.xlsx\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_03_52_13\\e12_l128-128_ep10_lin_427\\predictions-e12_l128-128_ep10_lin_427.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_03_52_13\\e12_l128-128_ep10_lin_427\\predictions-e12_l128-128_ep10_lin_427.xlsx\n",
      "[save_model] starting artifact save → exp/keras/keras-1/2026_01_11_03_52_13\\e12_l128-128_ep10_lin_427\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_03_52_13\\e12_l128-128_ep10_lin_427\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_03_52_13\\e12_l128-128_ep10_lin_427\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → exp/keras/keras-1/2026_01_11_03_52_13\\e12_l128-128_ep10_lin_427\\model\n",
      "Saved experiment → exp/keras/keras-1/2026_01_11_03_52_13\\e12_l128-128_ep10_lin_427\n",
      "Running Exp 15/21...\n",
      "Creating dir: exp/keras/keras-1/2026_01_11_03_52_13\\e1024_l128-128_ep10_tan_188\n",
      "run_experiment()  exp_dir: exp/keras/keras-1/2026_01_11_03_52_13\\e1024_l128-128_ep10_tan_188  \n",
      "run_experiment()  when: 2026-01-11 04:06:46.818118 params: {'epochs': 10}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-11 04:07:22.658139\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 0s/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_03_52_13\\e1024_l128-128_ep10_tan_188\\normalized_training_df-e1024_l128-128_ep10_tan_188.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_03_52_13\\e1024_l128-128_ep10_tan_188\\normalized_training_df-e1024_l128-128_ep10_tan_188.xlsx\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_03_52_13\\e1024_l128-128_ep10_tan_188\\predictions-e1024_l128-128_ep10_tan_188.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_03_52_13\\e1024_l128-128_ep10_tan_188\\predictions-e1024_l128-128_ep10_tan_188.xlsx\n",
      "[save_model] starting artifact save → exp/keras/keras-1/2026_01_11_03_52_13\\e1024_l128-128_ep10_tan_188\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_03_52_13\\e1024_l128-128_ep10_tan_188\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_03_52_13\\e1024_l128-128_ep10_tan_188\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → exp/keras/keras-1/2026_01_11_03_52_13\\e1024_l128-128_ep10_tan_188\\model\n",
      "Saved experiment → exp/keras/keras-1/2026_01_11_03_52_13\\e1024_l128-128_ep10_tan_188\n",
      "Running Exp 16/21...\n",
      "Creating dir: exp/keras/keras-1/2026_01_11_03_52_13\\e256_l128-128_ep10_tan_824\n",
      "run_experiment()  exp_dir: exp/keras/keras-1/2026_01_11_03_52_13\\e256_l128-128_ep10_tan_824  \n",
      "run_experiment()  when: 2026-01-11 04:08:11.357698 params: {'epochs': 10}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-11 04:08:21.709448\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 0s/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_03_52_13\\e256_l128-128_ep10_tan_824\\normalized_training_df-e256_l128-128_ep10_tan_824.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_03_52_13\\e256_l128-128_ep10_tan_824\\normalized_training_df-e256_l128-128_ep10_tan_824.xlsx\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_03_52_13\\e256_l128-128_ep10_tan_824\\predictions-e256_l128-128_ep10_tan_824.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_03_52_13\\e256_l128-128_ep10_tan_824\\predictions-e256_l128-128_ep10_tan_824.xlsx\n",
      "[save_model] starting artifact save → exp/keras/keras-1/2026_01_11_03_52_13\\e256_l128-128_ep10_tan_824\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_03_52_13\\e256_l128-128_ep10_tan_824\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_03_52_13\\e256_l128-128_ep10_tan_824\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → exp/keras/keras-1/2026_01_11_03_52_13\\e256_l128-128_ep10_tan_824\\model\n",
      "Saved experiment → exp/keras/keras-1/2026_01_11_03_52_13\\e256_l128-128_ep10_tan_824\n",
      "Running Exp 17/21...\n",
      "Creating dir: exp/keras/keras-1/2026_01_11_03_52_13\\e128_l128-128_ep10_tan_103\n",
      "run_experiment()  exp_dir: exp/keras/keras-1/2026_01_11_03_52_13\\e128_l128-128_ep10_tan_103  \n",
      "run_experiment()  when: 2026-01-11 04:09:10.447828 params: {'epochs': 10}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-11 04:09:19.667529\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 800us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_03_52_13\\e128_l128-128_ep10_tan_103\\normalized_training_df-e128_l128-128_ep10_tan_103.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_03_52_13\\e128_l128-128_ep10_tan_103\\normalized_training_df-e128_l128-128_ep10_tan_103.xlsx\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_03_52_13\\e128_l128-128_ep10_tan_103\\predictions-e128_l128-128_ep10_tan_103.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_03_52_13\\e128_l128-128_ep10_tan_103\\predictions-e128_l128-128_ep10_tan_103.xlsx\n",
      "[save_model] starting artifact save → exp/keras/keras-1/2026_01_11_03_52_13\\e128_l128-128_ep10_tan_103\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_03_52_13\\e128_l128-128_ep10_tan_103\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_03_52_13\\e128_l128-128_ep10_tan_103\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → exp/keras/keras-1/2026_01_11_03_52_13\\e128_l128-128_ep10_tan_103\\model\n",
      "Saved experiment → exp/keras/keras-1/2026_01_11_03_52_13\\e128_l128-128_ep10_tan_103\n",
      "Running Exp 18/21...\n",
      "Creating dir: exp/keras/keras-1/2026_01_11_03_52_13\\e64_l128-128_ep10_tan_154\n",
      "run_experiment()  exp_dir: exp/keras/keras-1/2026_01_11_03_52_13\\e64_l128-128_ep10_tan_154  \n",
      "run_experiment()  when: 2026-01-11 04:10:07.669865 params: {'epochs': 10}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-11 04:10:16.019322\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 0s/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_03_52_13\\e64_l128-128_ep10_tan_154\\normalized_training_df-e64_l128-128_ep10_tan_154.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_03_52_13\\e64_l128-128_ep10_tan_154\\normalized_training_df-e64_l128-128_ep10_tan_154.xlsx\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_03_52_13\\e64_l128-128_ep10_tan_154\\predictions-e64_l128-128_ep10_tan_154.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_03_52_13\\e64_l128-128_ep10_tan_154\\predictions-e64_l128-128_ep10_tan_154.xlsx\n",
      "[save_model] starting artifact save → exp/keras/keras-1/2026_01_11_03_52_13\\e64_l128-128_ep10_tan_154\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_03_52_13\\e64_l128-128_ep10_tan_154\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_03_52_13\\e64_l128-128_ep10_tan_154\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → exp/keras/keras-1/2026_01_11_03_52_13\\e64_l128-128_ep10_tan_154\\model\n",
      "Saved experiment → exp/keras/keras-1/2026_01_11_03_52_13\\e64_l128-128_ep10_tan_154\n",
      "Running Exp 19/21...\n",
      "Creating dir: exp/keras/keras-1/2026_01_11_03_52_13\\e32_l128-128_ep10_tan_340\n",
      "run_experiment()  exp_dir: exp/keras/keras-1/2026_01_11_03_52_13\\e32_l128-128_ep10_tan_340  \n",
      "run_experiment()  when: 2026-01-11 04:11:04.147772 params: {'epochs': 10}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-11 04:11:12.157816\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_03_52_13\\e32_l128-128_ep10_tan_340\\normalized_training_df-e32_l128-128_ep10_tan_340.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_03_52_13\\e32_l128-128_ep10_tan_340\\normalized_training_df-e32_l128-128_ep10_tan_340.xlsx\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_03_52_13\\e32_l128-128_ep10_tan_340\\predictions-e32_l128-128_ep10_tan_340.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_03_52_13\\e32_l128-128_ep10_tan_340\\predictions-e32_l128-128_ep10_tan_340.xlsx\n",
      "[save_model] starting artifact save → exp/keras/keras-1/2026_01_11_03_52_13\\e32_l128-128_ep10_tan_340\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_03_52_13\\e32_l128-128_ep10_tan_340\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_03_52_13\\e32_l128-128_ep10_tan_340\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → exp/keras/keras-1/2026_01_11_03_52_13\\e32_l128-128_ep10_tan_340\\model\n",
      "Saved experiment → exp/keras/keras-1/2026_01_11_03_52_13\\e32_l128-128_ep10_tan_340\n",
      "Running Exp 20/21...\n",
      "Creating dir: exp/keras/keras-1/2026_01_11_03_52_13\\e16_l128-128_ep10_tan_593\n",
      "run_experiment()  exp_dir: exp/keras/keras-1/2026_01_11_03_52_13\\e16_l128-128_ep10_tan_593  \n",
      "run_experiment()  when: 2026-01-11 04:12:00.257550 params: {'epochs': 10}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-11 04:12:08.452764\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 402us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_03_52_13\\e16_l128-128_ep10_tan_593\\normalized_training_df-e16_l128-128_ep10_tan_593.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_03_52_13\\e16_l128-128_ep10_tan_593\\normalized_training_df-e16_l128-128_ep10_tan_593.xlsx\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_03_52_13\\e16_l128-128_ep10_tan_593\\predictions-e16_l128-128_ep10_tan_593.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_03_52_13\\e16_l128-128_ep10_tan_593\\predictions-e16_l128-128_ep10_tan_593.xlsx\n",
      "[save_model] starting artifact save → exp/keras/keras-1/2026_01_11_03_52_13\\e16_l128-128_ep10_tan_593\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_03_52_13\\e16_l128-128_ep10_tan_593\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_03_52_13\\e16_l128-128_ep10_tan_593\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → exp/keras/keras-1/2026_01_11_03_52_13\\e16_l128-128_ep10_tan_593\\model\n",
      "Saved experiment → exp/keras/keras-1/2026_01_11_03_52_13\\e16_l128-128_ep10_tan_593\n",
      "Running Exp 21/21...\n",
      "Creating dir: exp/keras/keras-1/2026_01_11_03_52_13\\e12_l128-128_ep10_tan_640\n",
      "run_experiment()  exp_dir: exp/keras/keras-1/2026_01_11_03_52_13\\e12_l128-128_ep10_tan_640  \n",
      "run_experiment()  when: 2026-01-11 04:12:56.277748 params: {'epochs': 10}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-11 04:13:04.307234\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 803us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_03_52_13\\e12_l128-128_ep10_tan_640\\normalized_training_df-e12_l128-128_ep10_tan_640.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_03_52_13\\e12_l128-128_ep10_tan_640\\normalized_training_df-e12_l128-128_ep10_tan_640.xlsx\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_03_52_13\\e12_l128-128_ep10_tan_640\\predictions-e12_l128-128_ep10_tan_640.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_03_52_13\\e12_l128-128_ep10_tan_640\\predictions-e12_l128-128_ep10_tan_640.xlsx\n",
      "[save_model] starting artifact save → exp/keras/keras-1/2026_01_11_03_52_13\\e12_l128-128_ep10_tan_640\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_03_52_13\\e12_l128-128_ep10_tan_640\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_03_52_13\\e12_l128-128_ep10_tan_640\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → exp/keras/keras-1/2026_01_11_03_52_13\\e12_l128-128_ep10_tan_640\\model\n",
      "Saved experiment → exp/keras/keras-1/2026_01_11_03_52_13\\e12_l128-128_ep10_tan_640\n"
     ]
    }
   ],
   "source": [
    "###########################################################\n",
    "\n",
    "modelParamsList = []\n",
    "layers = [\n",
    "    { \"units\": 128, \"activation\": \"relu\" },\n",
    "    { \"units\": 128, \"activation\": \"relu\" },\n",
    "    \n",
    "]\n",
    "output_activations = [\"sigmoid\", \"linear\", \"tanh\"]\n",
    "embDims = [1024,256,128,64,32,16,12]\n",
    "metrics = [\"Accuracy\", \"MAE\", \"MSE\", \"MAPE\", \"MSLE\", \"Precision\", \"Recall\", \"AUC\",  \"BinaryCrossentropy\", \"RootMeanSquaredError\"]\n",
    "\n",
    "for act in output_activations:\n",
    "    for dim in embDims:\n",
    "        modelParamsList.append({\n",
    "            \"trainParams\": { \"epochs\": 10 },\n",
    "            \"buildParams\": {\n",
    "                \"embedding_dim\": dim,\n",
    "                \"layers\": layers,\n",
    "                \"output_activation\": act,\n",
    "                \"optimizer\": \"adam\",\n",
    "                \"learning_rate\": 0.01,\n",
    "                \"loss\": \"binary_crossentropy\" if act == \"sigmoid\" else \"mse\",\n",
    "                \"metrics\": metrics\n",
    "            }\n",
    "        })\n",
    "\n",
    "ts = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "run_all_experiments( groceryML.training_df, modelParamsList, f\"exp/keras/keras-1/{ts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e99ad85b-4ce7-4439-8e92-6c895f3be8b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_all_experiments() when: 2026-01-11 04:13:53.027456  output_dir: exp/keras/keras-1/2026_01_11_04_13_53\n",
      "Running Exp 1/21...\n",
      "Creating dir: exp/keras/keras-1/2026_01_11_04_13_53\\e1024_l128-128_ep20_sig_633\n",
      "run_experiment()  exp_dir: exp/keras/keras-1/2026_01_11_04_13_53\\e1024_l128-128_ep20_sig_633  \n",
      "run_experiment()  when: 2026-01-11 04:13:53.027456 params: {'epochs': 20}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-11 04:15:01.907603\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_13_53\\e1024_l128-128_ep20_sig_633\\normalized_training_df-e1024_l128-128_ep20_sig_633.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_13_53\\e1024_l128-128_ep20_sig_633\\normalized_training_df-e1024_l128-128_ep20_sig_633.xlsx\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_13_53\\e1024_l128-128_ep20_sig_633\\predictions-e1024_l128-128_ep20_sig_633.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_13_53\\e1024_l128-128_ep20_sig_633\\predictions-e1024_l128-128_ep20_sig_633.xlsx\n",
      "[save_model] starting artifact save → exp/keras/keras-1/2026_01_11_04_13_53\\e1024_l128-128_ep20_sig_633\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_13_53\\e1024_l128-128_ep20_sig_633\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_13_53\\e1024_l128-128_ep20_sig_633\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → exp/keras/keras-1/2026_01_11_04_13_53\\e1024_l128-128_ep20_sig_633\\model\n",
      "Saved experiment → exp/keras/keras-1/2026_01_11_04_13_53\\e1024_l128-128_ep20_sig_633\n",
      "Running Exp 2/21...\n",
      "Creating dir: exp/keras/keras-1/2026_01_11_04_13_53\\e256_l128-128_ep20_sig_155\n",
      "run_experiment()  exp_dir: exp/keras/keras-1/2026_01_11_04_13_53\\e256_l128-128_ep20_sig_155  \n",
      "run_experiment()  when: 2026-01-11 04:15:51.067354 params: {'epochs': 20}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-11 04:16:11.487059\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 0s/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_13_53\\e256_l128-128_ep20_sig_155\\normalized_training_df-e256_l128-128_ep20_sig_155.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_13_53\\e256_l128-128_ep20_sig_155\\normalized_training_df-e256_l128-128_ep20_sig_155.xlsx\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_13_53\\e256_l128-128_ep20_sig_155\\predictions-e256_l128-128_ep20_sig_155.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_13_53\\e256_l128-128_ep20_sig_155\\predictions-e256_l128-128_ep20_sig_155.xlsx\n",
      "[save_model] starting artifact save → exp/keras/keras-1/2026_01_11_04_13_53\\e256_l128-128_ep20_sig_155\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_13_53\\e256_l128-128_ep20_sig_155\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_13_53\\e256_l128-128_ep20_sig_155\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → exp/keras/keras-1/2026_01_11_04_13_53\\e256_l128-128_ep20_sig_155\\model\n",
      "Saved experiment → exp/keras/keras-1/2026_01_11_04_13_53\\e256_l128-128_ep20_sig_155\n",
      "Running Exp 3/21...\n",
      "Creating dir: exp/keras/keras-1/2026_01_11_04_13_53\\e128_l128-128_ep20_sig_197\n",
      "run_experiment()  exp_dir: exp/keras/keras-1/2026_01_11_04_13_53\\e128_l128-128_ep20_sig_197  \n",
      "run_experiment()  when: 2026-01-11 04:16:59.857068 params: {'epochs': 20}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-11 04:17:17.447014\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 403us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_13_53\\e128_l128-128_ep20_sig_197\\normalized_training_df-e128_l128-128_ep20_sig_197.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_13_53\\e128_l128-128_ep20_sig_197\\normalized_training_df-e128_l128-128_ep20_sig_197.xlsx\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_13_53\\e128_l128-128_ep20_sig_197\\predictions-e128_l128-128_ep20_sig_197.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_13_53\\e128_l128-128_ep20_sig_197\\predictions-e128_l128-128_ep20_sig_197.xlsx\n",
      "[save_model] starting artifact save → exp/keras/keras-1/2026_01_11_04_13_53\\e128_l128-128_ep20_sig_197\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_13_53\\e128_l128-128_ep20_sig_197\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_13_53\\e128_l128-128_ep20_sig_197\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → exp/keras/keras-1/2026_01_11_04_13_53\\e128_l128-128_ep20_sig_197\\model\n",
      "Saved experiment → exp/keras/keras-1/2026_01_11_04_13_53\\e128_l128-128_ep20_sig_197\n",
      "Running Exp 4/21...\n",
      "Creating dir: exp/keras/keras-1/2026_01_11_04_13_53\\e64_l128-128_ep20_sig_616\n",
      "run_experiment()  exp_dir: exp/keras/keras-1/2026_01_11_04_13_53\\e64_l128-128_ep20_sig_616  \n",
      "run_experiment()  when: 2026-01-11 04:18:10.268566 params: {'epochs': 20}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-11 04:18:28.129315\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 800us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_13_53\\e64_l128-128_ep20_sig_616\\normalized_training_df-e64_l128-128_ep20_sig_616.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_13_53\\e64_l128-128_ep20_sig_616\\normalized_training_df-e64_l128-128_ep20_sig_616.xlsx\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_13_53\\e64_l128-128_ep20_sig_616\\predictions-e64_l128-128_ep20_sig_616.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_13_53\\e64_l128-128_ep20_sig_616\\predictions-e64_l128-128_ep20_sig_616.xlsx\n",
      "[save_model] starting artifact save → exp/keras/keras-1/2026_01_11_04_13_53\\e64_l128-128_ep20_sig_616\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_13_53\\e64_l128-128_ep20_sig_616\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_13_53\\e64_l128-128_ep20_sig_616\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → exp/keras/keras-1/2026_01_11_04_13_53\\e64_l128-128_ep20_sig_616\\model\n",
      "Saved experiment → exp/keras/keras-1/2026_01_11_04_13_53\\e64_l128-128_ep20_sig_616\n",
      "Running Exp 5/21...\n",
      "Creating dir: exp/keras/keras-1/2026_01_11_04_13_53\\e32_l128-128_ep20_sig_124\n",
      "run_experiment()  exp_dir: exp/keras/keras-1/2026_01_11_04_13_53\\e32_l128-128_ep20_sig_124  \n",
      "run_experiment()  when: 2026-01-11 04:19:21.539774 params: {'epochs': 20}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-11 04:19:38.348376\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 800us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_13_53\\e32_l128-128_ep20_sig_124\\normalized_training_df-e32_l128-128_ep20_sig_124.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_13_53\\e32_l128-128_ep20_sig_124\\normalized_training_df-e32_l128-128_ep20_sig_124.xlsx\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_13_53\\e32_l128-128_ep20_sig_124\\predictions-e32_l128-128_ep20_sig_124.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_13_53\\e32_l128-128_ep20_sig_124\\predictions-e32_l128-128_ep20_sig_124.xlsx\n",
      "[save_model] starting artifact save → exp/keras/keras-1/2026_01_11_04_13_53\\e32_l128-128_ep20_sig_124\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_13_53\\e32_l128-128_ep20_sig_124\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_13_53\\e32_l128-128_ep20_sig_124\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → exp/keras/keras-1/2026_01_11_04_13_53\\e32_l128-128_ep20_sig_124\\model\n",
      "Saved experiment → exp/keras/keras-1/2026_01_11_04_13_53\\e32_l128-128_ep20_sig_124\n",
      "Running Exp 6/21...\n",
      "Creating dir: exp/keras/keras-1/2026_01_11_04_13_53\\e16_l128-128_ep20_sig_160\n",
      "run_experiment()  exp_dir: exp/keras/keras-1/2026_01_11_04_13_53\\e16_l128-128_ep20_sig_160  \n",
      "run_experiment()  when: 2026-01-11 04:20:32.070590 params: {'epochs': 20}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-11 04:20:48.660046\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 800us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_13_53\\e16_l128-128_ep20_sig_160\\normalized_training_df-e16_l128-128_ep20_sig_160.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_13_53\\e16_l128-128_ep20_sig_160\\normalized_training_df-e16_l128-128_ep20_sig_160.xlsx\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_13_53\\e16_l128-128_ep20_sig_160\\predictions-e16_l128-128_ep20_sig_160.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_13_53\\e16_l128-128_ep20_sig_160\\predictions-e16_l128-128_ep20_sig_160.xlsx\n",
      "[save_model] starting artifact save → exp/keras/keras-1/2026_01_11_04_13_53\\e16_l128-128_ep20_sig_160\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_13_53\\e16_l128-128_ep20_sig_160\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_13_53\\e16_l128-128_ep20_sig_160\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → exp/keras/keras-1/2026_01_11_04_13_53\\e16_l128-128_ep20_sig_160\\model\n",
      "Saved experiment → exp/keras/keras-1/2026_01_11_04_13_53\\e16_l128-128_ep20_sig_160\n",
      "Running Exp 7/21...\n",
      "Creating dir: exp/keras/keras-1/2026_01_11_04_13_53\\e12_l128-128_ep20_sig_192\n",
      "run_experiment()  exp_dir: exp/keras/keras-1/2026_01_11_04_13_53\\e12_l128-128_ep20_sig_192  \n",
      "run_experiment()  when: 2026-01-11 04:21:43.001836 params: {'epochs': 20}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-11 04:21:59.538605\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 800us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_13_53\\e12_l128-128_ep20_sig_192\\normalized_training_df-e12_l128-128_ep20_sig_192.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_13_53\\e12_l128-128_ep20_sig_192\\normalized_training_df-e12_l128-128_ep20_sig_192.xlsx\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_13_53\\e12_l128-128_ep20_sig_192\\predictions-e12_l128-128_ep20_sig_192.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_13_53\\e12_l128-128_ep20_sig_192\\predictions-e12_l128-128_ep20_sig_192.xlsx\n",
      "[save_model] starting artifact save → exp/keras/keras-1/2026_01_11_04_13_53\\e12_l128-128_ep20_sig_192\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_13_53\\e12_l128-128_ep20_sig_192\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_13_53\\e12_l128-128_ep20_sig_192\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → exp/keras/keras-1/2026_01_11_04_13_53\\e12_l128-128_ep20_sig_192\\model\n",
      "Saved experiment → exp/keras/keras-1/2026_01_11_04_13_53\\e12_l128-128_ep20_sig_192\n",
      "Running Exp 8/21...\n",
      "Creating dir: exp/keras/keras-1/2026_01_11_04_13_53\\e1024_l128-128_ep20_lin_656\n",
      "run_experiment()  exp_dir: exp/keras/keras-1/2026_01_11_04_13_53\\e1024_l128-128_ep20_lin_656  \n",
      "run_experiment()  when: 2026-01-11 04:22:52.285612 params: {'epochs': 20}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-11 04:24:30.701945\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_13_53\\e1024_l128-128_ep20_lin_656\\normalized_training_df-e1024_l128-128_ep20_lin_656.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_13_53\\e1024_l128-128_ep20_lin_656\\normalized_training_df-e1024_l128-128_ep20_lin_656.xlsx\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_13_53\\e1024_l128-128_ep20_lin_656\\predictions-e1024_l128-128_ep20_lin_656.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_13_53\\e1024_l128-128_ep20_lin_656\\predictions-e1024_l128-128_ep20_lin_656.xlsx\n",
      "[save_model] starting artifact save → exp/keras/keras-1/2026_01_11_04_13_53\\e1024_l128-128_ep20_lin_656\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_13_53\\e1024_l128-128_ep20_lin_656\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_13_53\\e1024_l128-128_ep20_lin_656\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → exp/keras/keras-1/2026_01_11_04_13_53\\e1024_l128-128_ep20_lin_656\\model\n",
      "Saved experiment → exp/keras/keras-1/2026_01_11_04_13_53\\e1024_l128-128_ep20_lin_656\n",
      "Running Exp 9/21...\n",
      "Creating dir: exp/keras/keras-1/2026_01_11_04_13_53\\e256_l128-128_ep20_lin_770\n",
      "run_experiment()  exp_dir: exp/keras/keras-1/2026_01_11_04_13_53\\e256_l128-128_ep20_lin_770  \n",
      "run_experiment()  when: 2026-01-11 04:25:25.335306 params: {'epochs': 20}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-11 04:25:49.491939\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 800us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_13_53\\e256_l128-128_ep20_lin_770\\normalized_training_df-e256_l128-128_ep20_lin_770.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_13_53\\e256_l128-128_ep20_lin_770\\normalized_training_df-e256_l128-128_ep20_lin_770.xlsx\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_13_53\\e256_l128-128_ep20_lin_770\\predictions-e256_l128-128_ep20_lin_770.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_13_53\\e256_l128-128_ep20_lin_770\\predictions-e256_l128-128_ep20_lin_770.xlsx\n",
      "[save_model] starting artifact save → exp/keras/keras-1/2026_01_11_04_13_53\\e256_l128-128_ep20_lin_770\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_13_53\\e256_l128-128_ep20_lin_770\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_13_53\\e256_l128-128_ep20_lin_770\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → exp/keras/keras-1/2026_01_11_04_13_53\\e256_l128-128_ep20_lin_770\\model\n",
      "Saved experiment → exp/keras/keras-1/2026_01_11_04_13_53\\e256_l128-128_ep20_lin_770\n",
      "Running Exp 10/21...\n",
      "Creating dir: exp/keras/keras-1/2026_01_11_04_13_53\\e128_l128-128_ep20_lin_207\n",
      "run_experiment()  exp_dir: exp/keras/keras-1/2026_01_11_04_13_53\\e128_l128-128_ep20_lin_207  \n",
      "run_experiment()  when: 2026-01-11 04:26:43.898975 params: {'epochs': 20}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-11 04:27:03.866983\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 800us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_13_53\\e128_l128-128_ep20_lin_207\\normalized_training_df-e128_l128-128_ep20_lin_207.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_13_53\\e128_l128-128_ep20_lin_207\\normalized_training_df-e128_l128-128_ep20_lin_207.xlsx\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_13_53\\e128_l128-128_ep20_lin_207\\predictions-e128_l128-128_ep20_lin_207.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_13_53\\e128_l128-128_ep20_lin_207\\predictions-e128_l128-128_ep20_lin_207.xlsx\n",
      "[save_model] starting artifact save → exp/keras/keras-1/2026_01_11_04_13_53\\e128_l128-128_ep20_lin_207\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_13_53\\e128_l128-128_ep20_lin_207\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_13_53\\e128_l128-128_ep20_lin_207\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → exp/keras/keras-1/2026_01_11_04_13_53\\e128_l128-128_ep20_lin_207\\model\n",
      "Saved experiment → exp/keras/keras-1/2026_01_11_04_13_53\\e128_l128-128_ep20_lin_207\n",
      "Running Exp 11/21...\n",
      "Creating dir: exp/keras/keras-1/2026_01_11_04_13_53\\e64_l128-128_ep20_lin_218\n",
      "run_experiment()  exp_dir: exp/keras/keras-1/2026_01_11_04_13_53\\e64_l128-128_ep20_lin_218  \n",
      "run_experiment()  when: 2026-01-11 04:27:56.947854 params: {'epochs': 20}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-11 04:28:14.926098\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_13_53\\e64_l128-128_ep20_lin_218\\normalized_training_df-e64_l128-128_ep20_lin_218.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_13_53\\e64_l128-128_ep20_lin_218\\normalized_training_df-e64_l128-128_ep20_lin_218.xlsx\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_13_53\\e64_l128-128_ep20_lin_218\\predictions-e64_l128-128_ep20_lin_218.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_13_53\\e64_l128-128_ep20_lin_218\\predictions-e64_l128-128_ep20_lin_218.xlsx\n",
      "[save_model] starting artifact save → exp/keras/keras-1/2026_01_11_04_13_53\\e64_l128-128_ep20_lin_218\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_13_53\\e64_l128-128_ep20_lin_218\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_13_53\\e64_l128-128_ep20_lin_218\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → exp/keras/keras-1/2026_01_11_04_13_53\\e64_l128-128_ep20_lin_218\\model\n",
      "Saved experiment → exp/keras/keras-1/2026_01_11_04_13_53\\e64_l128-128_ep20_lin_218\n",
      "Running Exp 12/21...\n",
      "Creating dir: exp/keras/keras-1/2026_01_11_04_13_53\\e32_l128-128_ep20_lin_987\n",
      "run_experiment()  exp_dir: exp/keras/keras-1/2026_01_11_04_13_53\\e32_l128-128_ep20_lin_987  \n",
      "run_experiment()  when: 2026-01-11 04:29:08.428414 params: {'epochs': 20}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-11 04:29:25.173885\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 800us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_13_53\\e32_l128-128_ep20_lin_987\\normalized_training_df-e32_l128-128_ep20_lin_987.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_13_53\\e32_l128-128_ep20_lin_987\\normalized_training_df-e32_l128-128_ep20_lin_987.xlsx\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_13_53\\e32_l128-128_ep20_lin_987\\predictions-e32_l128-128_ep20_lin_987.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_13_53\\e32_l128-128_ep20_lin_987\\predictions-e32_l128-128_ep20_lin_987.xlsx\n",
      "[save_model] starting artifact save → exp/keras/keras-1/2026_01_11_04_13_53\\e32_l128-128_ep20_lin_987\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_13_53\\e32_l128-128_ep20_lin_987\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_13_53\\e32_l128-128_ep20_lin_987\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → exp/keras/keras-1/2026_01_11_04_13_53\\e32_l128-128_ep20_lin_987\\model\n",
      "Saved experiment → exp/keras/keras-1/2026_01_11_04_13_53\\e32_l128-128_ep20_lin_987\n",
      "Running Exp 13/21...\n",
      "Creating dir: exp/keras/keras-1/2026_01_11_04_13_53\\e16_l128-128_ep20_lin_939\n",
      "run_experiment()  exp_dir: exp/keras/keras-1/2026_01_11_04_13_53\\e16_l128-128_ep20_lin_939  \n",
      "run_experiment()  when: 2026-01-11 04:30:19.408227 params: {'epochs': 20}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-11 04:30:35.869913\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 600us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_13_53\\e16_l128-128_ep20_lin_939\\normalized_training_df-e16_l128-128_ep20_lin_939.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_13_53\\e16_l128-128_ep20_lin_939\\normalized_training_df-e16_l128-128_ep20_lin_939.xlsx\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_13_53\\e16_l128-128_ep20_lin_939\\predictions-e16_l128-128_ep20_lin_939.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_13_53\\e16_l128-128_ep20_lin_939\\predictions-e16_l128-128_ep20_lin_939.xlsx\n",
      "[save_model] starting artifact save → exp/keras/keras-1/2026_01_11_04_13_53\\e16_l128-128_ep20_lin_939\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_13_53\\e16_l128-128_ep20_lin_939\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_13_53\\e16_l128-128_ep20_lin_939\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → exp/keras/keras-1/2026_01_11_04_13_53\\e16_l128-128_ep20_lin_939\\model\n",
      "Saved experiment → exp/keras/keras-1/2026_01_11_04_13_53\\e16_l128-128_ep20_lin_939\n",
      "Running Exp 14/21...\n",
      "Creating dir: exp/keras/keras-1/2026_01_11_04_13_53\\e12_l128-128_ep20_lin_111\n",
      "run_experiment()  exp_dir: exp/keras/keras-1/2026_01_11_04_13_53\\e12_l128-128_ep20_lin_111  \n",
      "run_experiment()  when: 2026-01-11 04:31:29.484246 params: {'epochs': 20}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-11 04:31:45.902654\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_13_53\\e12_l128-128_ep20_lin_111\\normalized_training_df-e12_l128-128_ep20_lin_111.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_13_53\\e12_l128-128_ep20_lin_111\\normalized_training_df-e12_l128-128_ep20_lin_111.xlsx\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_13_53\\e12_l128-128_ep20_lin_111\\predictions-e12_l128-128_ep20_lin_111.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_13_53\\e12_l128-128_ep20_lin_111\\predictions-e12_l128-128_ep20_lin_111.xlsx\n",
      "[save_model] starting artifact save → exp/keras/keras-1/2026_01_11_04_13_53\\e12_l128-128_ep20_lin_111\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_13_53\\e12_l128-128_ep20_lin_111\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_13_53\\e12_l128-128_ep20_lin_111\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → exp/keras/keras-1/2026_01_11_04_13_53\\e12_l128-128_ep20_lin_111\\model\n",
      "Saved experiment → exp/keras/keras-1/2026_01_11_04_13_53\\e12_l128-128_ep20_lin_111\n",
      "Running Exp 15/21...\n",
      "Creating dir: exp/keras/keras-1/2026_01_11_04_13_53\\e1024_l128-128_ep20_tan_162\n",
      "run_experiment()  exp_dir: exp/keras/keras-1/2026_01_11_04_13_53\\e1024_l128-128_ep20_tan_162  \n",
      "run_experiment()  when: 2026-01-11 04:32:40.706355 params: {'epochs': 20}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-11 04:34:20.222351\n",
      "_build_combined_df()\n",
      "_build_sources()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n",
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_13_53\\e1024_l128-128_ep20_tan_162\\normalized_training_df-e1024_l128-128_ep20_tan_162.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_13_53\\e1024_l128-128_ep20_tan_162\\normalized_training_df-e1024_l128-128_ep20_tan_162.xlsx\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_13_53\\e1024_l128-128_ep20_tan_162\\predictions-e1024_l128-128_ep20_tan_162.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_13_53\\e1024_l128-128_ep20_tan_162\\predictions-e1024_l128-128_ep20_tan_162.xlsx\n",
      "[save_model] starting artifact save → exp/keras/keras-1/2026_01_11_04_13_53\\e1024_l128-128_ep20_tan_162\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_13_53\\e1024_l128-128_ep20_tan_162\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_13_53\\e1024_l128-128_ep20_tan_162\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → exp/keras/keras-1/2026_01_11_04_13_53\\e1024_l128-128_ep20_tan_162\\model\n",
      "Saved experiment → exp/keras/keras-1/2026_01_11_04_13_53\\e1024_l128-128_ep20_tan_162\n",
      "Running Exp 16/21...\n",
      "Creating dir: exp/keras/keras-1/2026_01_11_04_13_53\\e256_l128-128_ep20_tan_202\n",
      "run_experiment()  exp_dir: exp/keras/keras-1/2026_01_11_04_13_53\\e256_l128-128_ep20_tan_202  \n",
      "run_experiment()  when: 2026-01-11 04:35:14.880371 params: {'epochs': 20}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-11 04:35:42.217147\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 800us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_13_53\\e256_l128-128_ep20_tan_202\\normalized_training_df-e256_l128-128_ep20_tan_202.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_13_53\\e256_l128-128_ep20_tan_202\\normalized_training_df-e256_l128-128_ep20_tan_202.xlsx\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_13_53\\e256_l128-128_ep20_tan_202\\predictions-e256_l128-128_ep20_tan_202.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_13_53\\e256_l128-128_ep20_tan_202\\predictions-e256_l128-128_ep20_tan_202.xlsx\n",
      "[save_model] starting artifact save → exp/keras/keras-1/2026_01_11_04_13_53\\e256_l128-128_ep20_tan_202\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_13_53\\e256_l128-128_ep20_tan_202\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_13_53\\e256_l128-128_ep20_tan_202\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → exp/keras/keras-1/2026_01_11_04_13_53\\e256_l128-128_ep20_tan_202\\model\n",
      "Saved experiment → exp/keras/keras-1/2026_01_11_04_13_53\\e256_l128-128_ep20_tan_202\n",
      "Running Exp 17/21...\n",
      "Creating dir: exp/keras/keras-1/2026_01_11_04_13_53\\e128_l128-128_ep20_tan_118\n",
      "run_experiment()  exp_dir: exp/keras/keras-1/2026_01_11_04_13_53\\e128_l128-128_ep20_tan_118  \n",
      "run_experiment()  when: 2026-01-11 04:36:35.515084 params: {'epochs': 20}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-11 04:36:55.647000\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 800us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_13_53\\e128_l128-128_ep20_tan_118\\normalized_training_df-e128_l128-128_ep20_tan_118.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_13_53\\e128_l128-128_ep20_tan_118\\normalized_training_df-e128_l128-128_ep20_tan_118.xlsx\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_13_53\\e128_l128-128_ep20_tan_118\\predictions-e128_l128-128_ep20_tan_118.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_13_53\\e128_l128-128_ep20_tan_118\\predictions-e128_l128-128_ep20_tan_118.xlsx\n",
      "[save_model] starting artifact save → exp/keras/keras-1/2026_01_11_04_13_53\\e128_l128-128_ep20_tan_118\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_13_53\\e128_l128-128_ep20_tan_118\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_13_53\\e128_l128-128_ep20_tan_118\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → exp/keras/keras-1/2026_01_11_04_13_53\\e128_l128-128_ep20_tan_118\\model\n",
      "Saved experiment → exp/keras/keras-1/2026_01_11_04_13_53\\e128_l128-128_ep20_tan_118\n",
      "Running Exp 18/21...\n",
      "Creating dir: exp/keras/keras-1/2026_01_11_04_13_53\\e64_l128-128_ep20_tan_105\n",
      "run_experiment()  exp_dir: exp/keras/keras-1/2026_01_11_04_13_53\\e64_l128-128_ep20_tan_105  \n",
      "run_experiment()  when: 2026-01-11 04:37:49.458524 params: {'epochs': 20}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-11 04:38:07.556564\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 800us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_13_53\\e64_l128-128_ep20_tan_105\\normalized_training_df-e64_l128-128_ep20_tan_105.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_13_53\\e64_l128-128_ep20_tan_105\\normalized_training_df-e64_l128-128_ep20_tan_105.xlsx\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_13_53\\e64_l128-128_ep20_tan_105\\predictions-e64_l128-128_ep20_tan_105.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_13_53\\e64_l128-128_ep20_tan_105\\predictions-e64_l128-128_ep20_tan_105.xlsx\n",
      "[save_model] starting artifact save → exp/keras/keras-1/2026_01_11_04_13_53\\e64_l128-128_ep20_tan_105\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_13_53\\e64_l128-128_ep20_tan_105\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_13_53\\e64_l128-128_ep20_tan_105\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → exp/keras/keras-1/2026_01_11_04_13_53\\e64_l128-128_ep20_tan_105\\model\n",
      "Saved experiment → exp/keras/keras-1/2026_01_11_04_13_53\\e64_l128-128_ep20_tan_105\n",
      "Running Exp 19/21...\n",
      "Creating dir: exp/keras/keras-1/2026_01_11_04_13_53\\e32_l128-128_ep20_tan_260\n",
      "run_experiment()  exp_dir: exp/keras/keras-1/2026_01_11_04_13_53\\e32_l128-128_ep20_tan_260  \n",
      "run_experiment()  when: 2026-01-11 04:39:01.114070 params: {'epochs': 20}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-11 04:39:18.359041\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 800us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_13_53\\e32_l128-128_ep20_tan_260\\normalized_training_df-e32_l128-128_ep20_tan_260.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_13_53\\e32_l128-128_ep20_tan_260\\normalized_training_df-e32_l128-128_ep20_tan_260.xlsx\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_13_53\\e32_l128-128_ep20_tan_260\\predictions-e32_l128-128_ep20_tan_260.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_13_53\\e32_l128-128_ep20_tan_260\\predictions-e32_l128-128_ep20_tan_260.xlsx\n",
      "[save_model] starting artifact save → exp/keras/keras-1/2026_01_11_04_13_53\\e32_l128-128_ep20_tan_260\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_13_53\\e32_l128-128_ep20_tan_260\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_13_53\\e32_l128-128_ep20_tan_260\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → exp/keras/keras-1/2026_01_11_04_13_53\\e32_l128-128_ep20_tan_260\\model\n",
      "Saved experiment → exp/keras/keras-1/2026_01_11_04_13_53\\e32_l128-128_ep20_tan_260\n",
      "Running Exp 20/21...\n",
      "Creating dir: exp/keras/keras-1/2026_01_11_04_13_53\\e16_l128-128_ep20_tan_211\n",
      "run_experiment()  exp_dir: exp/keras/keras-1/2026_01_11_04_13_53\\e16_l128-128_ep20_tan_211  \n",
      "run_experiment()  when: 2026-01-11 04:40:11.917009 params: {'epochs': 20}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-11 04:40:28.716665\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 800us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_13_53\\e16_l128-128_ep20_tan_211\\normalized_training_df-e16_l128-128_ep20_tan_211.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_13_53\\e16_l128-128_ep20_tan_211\\normalized_training_df-e16_l128-128_ep20_tan_211.xlsx\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_13_53\\e16_l128-128_ep20_tan_211\\predictions-e16_l128-128_ep20_tan_211.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_13_53\\e16_l128-128_ep20_tan_211\\predictions-e16_l128-128_ep20_tan_211.xlsx\n",
      "[save_model] starting artifact save → exp/keras/keras-1/2026_01_11_04_13_53\\e16_l128-128_ep20_tan_211\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_13_53\\e16_l128-128_ep20_tan_211\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_13_53\\e16_l128-128_ep20_tan_211\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → exp/keras/keras-1/2026_01_11_04_13_53\\e16_l128-128_ep20_tan_211\\model\n",
      "Saved experiment → exp/keras/keras-1/2026_01_11_04_13_53\\e16_l128-128_ep20_tan_211\n",
      "Running Exp 21/21...\n",
      "Creating dir: exp/keras/keras-1/2026_01_11_04_13_53\\e12_l128-128_ep20_tan_169\n",
      "run_experiment()  exp_dir: exp/keras/keras-1/2026_01_11_04_13_53\\e12_l128-128_ep20_tan_169  \n",
      "run_experiment()  when: 2026-01-11 04:41:22.733756 params: {'epochs': 20}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-11 04:41:39.214520\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 600us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_13_53\\e12_l128-128_ep20_tan_169\\normalized_training_df-e12_l128-128_ep20_tan_169.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_13_53\\e12_l128-128_ep20_tan_169\\normalized_training_df-e12_l128-128_ep20_tan_169.xlsx\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_13_53\\e12_l128-128_ep20_tan_169\\predictions-e12_l128-128_ep20_tan_169.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_13_53\\e12_l128-128_ep20_tan_169\\predictions-e12_l128-128_ep20_tan_169.xlsx\n",
      "[save_model] starting artifact save → exp/keras/keras-1/2026_01_11_04_13_53\\e12_l128-128_ep20_tan_169\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_13_53\\e12_l128-128_ep20_tan_169\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_13_53\\e12_l128-128_ep20_tan_169\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → exp/keras/keras-1/2026_01_11_04_13_53\\e12_l128-128_ep20_tan_169\\model\n",
      "Saved experiment → exp/keras/keras-1/2026_01_11_04_13_53\\e12_l128-128_ep20_tan_169\n"
     ]
    }
   ],
   "source": [
    "###########################################################\n",
    "\n",
    "modelParamsList = []\n",
    "layers = [\n",
    "    { \"units\": 128, \"activation\": \"relu\" },\n",
    "    { \"units\": 128, \"activation\": \"relu\" },\n",
    "    \n",
    "]\n",
    "output_activations = [\"sigmoid\", \"linear\", \"tanh\"]\n",
    "embDims = [1024,256,128,64,32,16,12]\n",
    "metrics = [\"Accuracy\", \"MAE\", \"MSE\", \"MAPE\", \"MSLE\", \"Precision\", \"Recall\", \"AUC\",  \"BinaryCrossentropy\", \"RootMeanSquaredError\"]\n",
    "\n",
    "for act in output_activations:\n",
    "    for dim in embDims:\n",
    "        modelParamsList.append({\n",
    "            \"trainParams\": { \"epochs\": 20 },\n",
    "            \"buildParams\": {\n",
    "                \"embedding_dim\": dim,\n",
    "                \"layers\": layers,\n",
    "                \"output_activation\": act,\n",
    "                \"optimizer\": \"adam\",\n",
    "                \"learning_rate\": 0.001,\n",
    "                \"loss\": \"binary_crossentropy\" if act == \"sigmoid\" else \"mse\",\n",
    "                \"metrics\": metrics\n",
    "            }\n",
    "        })\n",
    "\n",
    "ts = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "run_all_experiments( groceryML.training_df, modelParamsList, f\"exp/keras/keras-1/{ts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3beb0526-61bf-42da-8853-99b8af8f1f05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_all_experiments() when: 2026-01-11 04:42:34.490071  output_dir: exp/keras/keras-1/2026_01_11_04_42_34\n",
      "Running Exp 1/21...\n",
      "Creating dir: exp/keras/keras-1/2026_01_11_04_42_34\\e1024_l128-128_ep30_sig_113\n",
      "run_experiment()  exp_dir: exp/keras/keras-1/2026_01_11_04_42_34\\e1024_l128-128_ep30_sig_113  \n",
      "run_experiment()  when: 2026-01-11 04:42:34.492072 params: {'epochs': 30}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-11 04:45:02.410511\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_42_34\\e1024_l128-128_ep30_sig_113\\normalized_training_df-e1024_l128-128_ep30_sig_113.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_42_34\\e1024_l128-128_ep30_sig_113\\normalized_training_df-e1024_l128-128_ep30_sig_113.xlsx\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_42_34\\e1024_l128-128_ep30_sig_113\\predictions-e1024_l128-128_ep30_sig_113.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_42_34\\e1024_l128-128_ep30_sig_113\\predictions-e1024_l128-128_ep30_sig_113.xlsx\n",
      "[save_model] starting artifact save → exp/keras/keras-1/2026_01_11_04_42_34\\e1024_l128-128_ep30_sig_113\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_42_34\\e1024_l128-128_ep30_sig_113\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_42_34\\e1024_l128-128_ep30_sig_113\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → exp/keras/keras-1/2026_01_11_04_42_34\\e1024_l128-128_ep30_sig_113\\model\n",
      "Saved experiment → exp/keras/keras-1/2026_01_11_04_42_34\\e1024_l128-128_ep30_sig_113\n",
      "Running Exp 2/21...\n",
      "Creating dir: exp/keras/keras-1/2026_01_11_04_42_34\\e256_l128-128_ep30_sig_159\n",
      "run_experiment()  exp_dir: exp/keras/keras-1/2026_01_11_04_42_34\\e256_l128-128_ep30_sig_159  \n",
      "run_experiment()  when: 2026-01-11 04:45:56.691902 params: {'epochs': 30}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-11 04:46:41.040368\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_42_34\\e256_l128-128_ep30_sig_159\\normalized_training_df-e256_l128-128_ep30_sig_159.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_42_34\\e256_l128-128_ep30_sig_159\\normalized_training_df-e256_l128-128_ep30_sig_159.xlsx\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_42_34\\e256_l128-128_ep30_sig_159\\predictions-e256_l128-128_ep30_sig_159.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_42_34\\e256_l128-128_ep30_sig_159\\predictions-e256_l128-128_ep30_sig_159.xlsx\n",
      "[save_model] starting artifact save → exp/keras/keras-1/2026_01_11_04_42_34\\e256_l128-128_ep30_sig_159\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_42_34\\e256_l128-128_ep30_sig_159\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_42_34\\e256_l128-128_ep30_sig_159\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → exp/keras/keras-1/2026_01_11_04_42_34\\e256_l128-128_ep30_sig_159\\model\n",
      "Saved experiment → exp/keras/keras-1/2026_01_11_04_42_34\\e256_l128-128_ep30_sig_159\n",
      "Running Exp 3/21...\n",
      "Creating dir: exp/keras/keras-1/2026_01_11_04_42_34\\e128_l128-128_ep30_sig_137\n",
      "run_experiment()  exp_dir: exp/keras/keras-1/2026_01_11_04_42_34\\e128_l128-128_ep30_sig_137  \n",
      "run_experiment()  when: 2026-01-11 04:47:36.060725 params: {'epochs': 30}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-11 04:48:10.306543\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1000us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_42_34\\e128_l128-128_ep30_sig_137\\normalized_training_df-e128_l128-128_ep30_sig_137.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_42_34\\e128_l128-128_ep30_sig_137\\normalized_training_df-e128_l128-128_ep30_sig_137.xlsx\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_42_34\\e128_l128-128_ep30_sig_137\\predictions-e128_l128-128_ep30_sig_137.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_42_34\\e128_l128-128_ep30_sig_137\\predictions-e128_l128-128_ep30_sig_137.xlsx\n",
      "[save_model] starting artifact save → exp/keras/keras-1/2026_01_11_04_42_34\\e128_l128-128_ep30_sig_137\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_42_34\\e128_l128-128_ep30_sig_137\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_42_34\\e128_l128-128_ep30_sig_137\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → exp/keras/keras-1/2026_01_11_04_42_34\\e128_l128-128_ep30_sig_137\\model\n",
      "Saved experiment → exp/keras/keras-1/2026_01_11_04_42_34\\e128_l128-128_ep30_sig_137\n",
      "Running Exp 4/21...\n",
      "Creating dir: exp/keras/keras-1/2026_01_11_04_42_34\\e64_l128-128_ep30_sig_123\n",
      "run_experiment()  exp_dir: exp/keras/keras-1/2026_01_11_04_42_34\\e64_l128-128_ep30_sig_123  \n",
      "run_experiment()  when: 2026-01-11 04:49:04.535280 params: {'epochs': 30}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-11 04:49:36.486372\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 800us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_42_34\\e64_l128-128_ep30_sig_123\\normalized_training_df-e64_l128-128_ep30_sig_123.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_42_34\\e64_l128-128_ep30_sig_123\\normalized_training_df-e64_l128-128_ep30_sig_123.xlsx\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_42_34\\e64_l128-128_ep30_sig_123\\predictions-e64_l128-128_ep30_sig_123.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_42_34\\e64_l128-128_ep30_sig_123\\predictions-e64_l128-128_ep30_sig_123.xlsx\n",
      "[save_model] starting artifact save → exp/keras/keras-1/2026_01_11_04_42_34\\e64_l128-128_ep30_sig_123\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_42_34\\e64_l128-128_ep30_sig_123\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_42_34\\e64_l128-128_ep30_sig_123\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → exp/keras/keras-1/2026_01_11_04_42_34\\e64_l128-128_ep30_sig_123\\model\n",
      "Saved experiment → exp/keras/keras-1/2026_01_11_04_42_34\\e64_l128-128_ep30_sig_123\n",
      "Running Exp 5/21...\n",
      "Creating dir: exp/keras/keras-1/2026_01_11_04_42_34\\e32_l128-128_ep30_sig_403\n",
      "run_experiment()  exp_dir: exp/keras/keras-1/2026_01_11_04_42_34\\e32_l128-128_ep30_sig_403  \n",
      "run_experiment()  when: 2026-01-11 04:50:31.174798 params: {'epochs': 30}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-11 04:50:59.361784\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_42_34\\e32_l128-128_ep30_sig_403\\normalized_training_df-e32_l128-128_ep30_sig_403.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_42_34\\e32_l128-128_ep30_sig_403\\normalized_training_df-e32_l128-128_ep30_sig_403.xlsx\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_42_34\\e32_l128-128_ep30_sig_403\\predictions-e32_l128-128_ep30_sig_403.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_42_34\\e32_l128-128_ep30_sig_403\\predictions-e32_l128-128_ep30_sig_403.xlsx\n",
      "[save_model] starting artifact save → exp/keras/keras-1/2026_01_11_04_42_34\\e32_l128-128_ep30_sig_403\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_42_34\\e32_l128-128_ep30_sig_403\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_42_34\\e32_l128-128_ep30_sig_403\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → exp/keras/keras-1/2026_01_11_04_42_34\\e32_l128-128_ep30_sig_403\\model\n",
      "Saved experiment → exp/keras/keras-1/2026_01_11_04_42_34\\e32_l128-128_ep30_sig_403\n",
      "Running Exp 6/21...\n",
      "Creating dir: exp/keras/keras-1/2026_01_11_04_42_34\\e16_l128-128_ep30_sig_331\n",
      "run_experiment()  exp_dir: exp/keras/keras-1/2026_01_11_04_42_34\\e16_l128-128_ep30_sig_331  \n",
      "run_experiment()  when: 2026-01-11 04:51:50.143711 params: {'epochs': 30}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-11 04:52:15.025042\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 673us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_42_34\\e16_l128-128_ep30_sig_331\\normalized_training_df-e16_l128-128_ep30_sig_331.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_42_34\\e16_l128-128_ep30_sig_331\\normalized_training_df-e16_l128-128_ep30_sig_331.xlsx\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_42_34\\e16_l128-128_ep30_sig_331\\predictions-e16_l128-128_ep30_sig_331.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_42_34\\e16_l128-128_ep30_sig_331\\predictions-e16_l128-128_ep30_sig_331.xlsx\n",
      "[save_model] starting artifact save → exp/keras/keras-1/2026_01_11_04_42_34\\e16_l128-128_ep30_sig_331\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_42_34\\e16_l128-128_ep30_sig_331\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_42_34\\e16_l128-128_ep30_sig_331\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → exp/keras/keras-1/2026_01_11_04_42_34\\e16_l128-128_ep30_sig_331\\model\n",
      "Saved experiment → exp/keras/keras-1/2026_01_11_04_42_34\\e16_l128-128_ep30_sig_331\n",
      "Running Exp 7/21...\n",
      "Creating dir: exp/keras/keras-1/2026_01_11_04_42_34\\e12_l128-128_ep30_sig_874\n",
      "run_experiment()  exp_dir: exp/keras/keras-1/2026_01_11_04_42_34\\e12_l128-128_ep30_sig_874  \n",
      "run_experiment()  when: 2026-01-11 04:53:04.379092 params: {'epochs': 30}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-11 04:53:29.157867\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 920us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_42_34\\e12_l128-128_ep30_sig_874\\normalized_training_df-e12_l128-128_ep30_sig_874.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_42_34\\e12_l128-128_ep30_sig_874\\normalized_training_df-e12_l128-128_ep30_sig_874.xlsx\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_42_34\\e12_l128-128_ep30_sig_874\\predictions-e12_l128-128_ep30_sig_874.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_42_34\\e12_l128-128_ep30_sig_874\\predictions-e12_l128-128_ep30_sig_874.xlsx\n",
      "[save_model] starting artifact save → exp/keras/keras-1/2026_01_11_04_42_34\\e12_l128-128_ep30_sig_874\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_42_34\\e12_l128-128_ep30_sig_874\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_42_34\\e12_l128-128_ep30_sig_874\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → exp/keras/keras-1/2026_01_11_04_42_34\\e12_l128-128_ep30_sig_874\\model\n",
      "Saved experiment → exp/keras/keras-1/2026_01_11_04_42_34\\e12_l128-128_ep30_sig_874\n",
      "Running Exp 8/21...\n",
      "Creating dir: exp/keras/keras-1/2026_01_11_04_42_34\\e1024_l128-128_ep30_lin_149\n",
      "run_experiment()  exp_dir: exp/keras/keras-1/2026_01_11_04_42_34\\e1024_l128-128_ep30_lin_149  \n",
      "run_experiment()  when: 2026-01-11 04:54:19.064638 params: {'epochs': 30}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-11 04:56:19.814710\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_42_34\\e1024_l128-128_ep30_lin_149\\normalized_training_df-e1024_l128-128_ep30_lin_149.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_42_34\\e1024_l128-128_ep30_lin_149\\normalized_training_df-e1024_l128-128_ep30_lin_149.xlsx\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_42_34\\e1024_l128-128_ep30_lin_149\\predictions-e1024_l128-128_ep30_lin_149.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_42_34\\e1024_l128-128_ep30_lin_149\\predictions-e1024_l128-128_ep30_lin_149.xlsx\n",
      "[save_model] starting artifact save → exp/keras/keras-1/2026_01_11_04_42_34\\e1024_l128-128_ep30_lin_149\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_42_34\\e1024_l128-128_ep30_lin_149\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_42_34\\e1024_l128-128_ep30_lin_149\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → exp/keras/keras-1/2026_01_11_04_42_34\\e1024_l128-128_ep30_lin_149\\model\n",
      "Saved experiment → exp/keras/keras-1/2026_01_11_04_42_34\\e1024_l128-128_ep30_lin_149\n",
      "Running Exp 9/21...\n",
      "Creating dir: exp/keras/keras-1/2026_01_11_04_42_34\\e256_l128-128_ep30_lin_393\n",
      "run_experiment()  exp_dir: exp/keras/keras-1/2026_01_11_04_42_34\\e256_l128-128_ep30_lin_393  \n",
      "run_experiment()  when: 2026-01-11 04:57:12.171653 params: {'epochs': 30}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-11 04:57:56.714550\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_42_34\\e256_l128-128_ep30_lin_393\\normalized_training_df-e256_l128-128_ep30_lin_393.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_42_34\\e256_l128-128_ep30_lin_393\\normalized_training_df-e256_l128-128_ep30_lin_393.xlsx\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_42_34\\e256_l128-128_ep30_lin_393\\predictions-e256_l128-128_ep30_lin_393.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_42_34\\e256_l128-128_ep30_lin_393\\predictions-e256_l128-128_ep30_lin_393.xlsx\n",
      "[save_model] starting artifact save → exp/keras/keras-1/2026_01_11_04_42_34\\e256_l128-128_ep30_lin_393\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_42_34\\e256_l128-128_ep30_lin_393\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_42_34\\e256_l128-128_ep30_lin_393\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → exp/keras/keras-1/2026_01_11_04_42_34\\e256_l128-128_ep30_lin_393\\model\n",
      "Saved experiment → exp/keras/keras-1/2026_01_11_04_42_34\\e256_l128-128_ep30_lin_393\n",
      "Running Exp 10/21...\n",
      "Creating dir: exp/keras/keras-1/2026_01_11_04_42_34\\e128_l128-128_ep30_lin_558\n",
      "run_experiment()  exp_dir: exp/keras/keras-1/2026_01_11_04_42_34\\e128_l128-128_ep30_lin_558  \n",
      "run_experiment()  when: 2026-01-11 04:58:47.024238 params: {'epochs': 30}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-11 04:59:18.174341\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 866us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_42_34\\e128_l128-128_ep30_lin_558\\normalized_training_df-e128_l128-128_ep30_lin_558.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_42_34\\e128_l128-128_ep30_lin_558\\normalized_training_df-e128_l128-128_ep30_lin_558.xlsx\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_42_34\\e128_l128-128_ep30_lin_558\\predictions-e128_l128-128_ep30_lin_558.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_42_34\\e128_l128-128_ep30_lin_558\\predictions-e128_l128-128_ep30_lin_558.xlsx\n",
      "[save_model] starting artifact save → exp/keras/keras-1/2026_01_11_04_42_34\\e128_l128-128_ep30_lin_558\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_42_34\\e128_l128-128_ep30_lin_558\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_42_34\\e128_l128-128_ep30_lin_558\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → exp/keras/keras-1/2026_01_11_04_42_34\\e128_l128-128_ep30_lin_558\\model\n",
      "Saved experiment → exp/keras/keras-1/2026_01_11_04_42_34\\e128_l128-128_ep30_lin_558\n",
      "Running Exp 11/21...\n",
      "Creating dir: exp/keras/keras-1/2026_01_11_04_42_34\\e64_l128-128_ep30_lin_287\n",
      "run_experiment()  exp_dir: exp/keras/keras-1/2026_01_11_04_42_34\\e64_l128-128_ep30_lin_287  \n",
      "run_experiment()  when: 2026-01-11 05:00:09.124495 params: {'epochs': 30}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-11 05:00:36.843318\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 202us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_42_34\\e64_l128-128_ep30_lin_287\\normalized_training_df-e64_l128-128_ep30_lin_287.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_42_34\\e64_l128-128_ep30_lin_287\\normalized_training_df-e64_l128-128_ep30_lin_287.xlsx\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_42_34\\e64_l128-128_ep30_lin_287\\predictions-e64_l128-128_ep30_lin_287.xlsx\n",
      "   XLSX Done: exp/keras/keras-1/2026_01_11_04_42_34\\e64_l128-128_ep30_lin_287\\predictions-e64_l128-128_ep30_lin_287.xlsx\n",
      "[save_model] starting artifact save → exp/keras/keras-1/2026_01_11_04_42_34\\e64_l128-128_ep30_lin_287\n",
      "[save_model] writing training_df snapshot (parquet, pre-normalized)\n",
      "[save_model] writing training history json\n",
      "[save_model] saving model directory files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_42_34\\e64_l128-128_ep30_lin_287\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp/keras/keras-1/2026_01_11_04_42_34\\e64_l128-128_ep30_lin_287\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_model] saving model weights (separate file)\n",
      "[save_model] all artifacts saved successfully → exp/keras/keras-1/2026_01_11_04_42_34\\e64_l128-128_ep30_lin_287\\model\n",
      "Saved experiment → exp/keras/keras-1/2026_01_11_04_42_34\\e64_l128-128_ep30_lin_287\n",
      "Running Exp 12/21...\n",
      "Creating dir: exp/keras/keras-1/2026_01_11_04_42_34\\e32_l128-128_ep30_lin_175\n",
      "run_experiment()  exp_dir: exp/keras/keras-1/2026_01_11_04_42_34\\e32_l128-128_ep30_lin_175  \n",
      "run_experiment()  when: 2026-01-11 05:01:26.759970 params: {'epochs': 30}  \n",
      "normalize_features()\n",
      "train_model()\n",
      "build_prediction_input() prediction_date=2026-01-11 05:01:54.494298\n",
      "_build_combined_df()\n",
      "_build_sources()\n",
      "creating target col: didBuy_target\n",
      "insert_negative_samples()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\source\\repos\\grocery-ml\\grocery_ml_core.py:276: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  additional_rcpts_df[\"date\"] = pd.to_datetime(additional_rcpts_df[\"date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_expected_gap_ewma()\n",
      "create_item_supply_level_feat()\n",
      "add_item_total_purchase_count_feat()\n",
      "build_trip_interveral_feautres()\n",
      "drop_rare_purchases()\n",
      "validate_no_empty_columns()\n",
      "self._build_combined_df() done\n",
      "create_item_supply_level_feat()\n",
      "normalize_features()\n",
      "build_prediction_input() is done\n",
      "Running Model.Predict()\n",
      "6/6 [==============================] - 0s 802us/step\n",
      "Exporting extra_dataframes:\n",
      "grocery_ml_tensorflow.export_dataframes_to_excel()\n",
      "Writing XLSX: exp/keras/keras-1/2026_01_11_04_42_34\\e32_l128-128_ep30_lin_175\\normalized_training_df-e32_l128-128_ep30_lin_175.xlsx\n"
     ]
    }
   ],
   "source": [
    "###########################################################\n",
    "\n",
    "modelParamsList = []\n",
    "layers = [\n",
    "    { \"units\": 128, \"activation\": \"relu\" },\n",
    "    { \"units\": 128, \"activation\": \"relu\" },\n",
    "    \n",
    "]\n",
    "output_activations = [\"sigmoid\", \"linear\", \"tanh\"]\n",
    "embDims = [1024,256,128,64,32,16,12]\n",
    "metrics = [\"Accuracy\", \"MAE\", \"MSE\", \"MAPE\", \"MSLE\", \"Precision\", \"Recall\", \"AUC\",  \"BinaryCrossentropy\", \"RootMeanSquaredError\"]\n",
    "\n",
    "for act in output_activations:\n",
    "    for dim in embDims:\n",
    "        modelParamsList.append({\n",
    "            \"trainParams\": { \"epochs\": 30 },\n",
    "            \"buildParams\": {\n",
    "                \"embedding_dim\": dim,\n",
    "                \"layers\": layers,\n",
    "                \"output_activation\": act,\n",
    "                \"optimizer\": \"adam\",\n",
    "                \"learning_rate\": 0.0001,\n",
    "                \"loss\": \"binary_crossentropy\" if act == \"sigmoid\" else \"mse\",\n",
    "                \"metrics\": metrics\n",
    "            }\n",
    "        })\n",
    "\n",
    "ts = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "run_all_experiments( groceryML.training_df, modelParamsList, f\"exp/keras/keras-1/{ts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cdaf35-960d-48b7-a20f-96c9b2bf25bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###########################################################\n",
    "\n",
    "modelParamsList = []\n",
    "layers = [\n",
    "    { \"units\": 128, \"activation\": \"relu\" },\n",
    "    { \"units\": 128, \"activation\": \"relu\" },    \n",
    "    { \"units\": 128, \"activation\": \"relu\" },\n",
    "    { \"units\": 128, \"activation\": \"relu\" },\n",
    "    { \"units\": 128, \"activation\": \"relu\" },\n",
    "    \n",
    "    \n",
    "]\n",
    "output_activations = [\"sigmoid\", \"linear\", \"tanh\"]\n",
    "embDims = [1024,256,128,64,32,16,12]\n",
    "metrics = [\"Accuracy\", \"MAE\", \"MSE\", \"MAPE\", \"MSLE\", \"Precision\", \"Recall\", \"AUC\",  \"BinaryCrossentropy\", \"RootMeanSquaredError\"]\n",
    "\n",
    "for act in output_activations:\n",
    "    for dim in embDims:\n",
    "        modelParamsList.append({\n",
    "            \"trainParams\": { \"epochs\": 10 },\n",
    "            \"buildParams\": {\n",
    "                \"embedding_dim\": dim,\n",
    "                \"layers\": layers,\n",
    "                \"output_activation\": act,\n",
    "                \"optimizer\": \"adam\",\n",
    "                \"learning_rate\": 0.01,\n",
    "                \"loss\": \"binary_crossentropy\" if act == \"sigmoid\" else \"mse\",\n",
    "                \"metrics\": metrics\n",
    "            }\n",
    "        })\n",
    "\n",
    "ts = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "run_all_experiments( groceryML.training_df, modelParamsList, f\"exp/keras/keras-1/{ts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fc0f3f-6abf-4593-9eb4-12dbd7e97818",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###########################################################\n",
    "\n",
    "modelParamsList = []\n",
    "layers = [\n",
    "    { \"units\": 128, \"activation\": \"relu\" },\n",
    "    { \"units\": 128, \"activation\": \"relu\" },    \n",
    "    { \"units\": 128, \"activation\": \"relu\" },\n",
    "    { \"units\": 128, \"activation\": \"relu\" },\n",
    "    { \"units\": 128, \"activation\": \"relu\" },\n",
    "    \n",
    "    \n",
    "]\n",
    "output_activations = [\"sigmoid\", \"linear\", \"tanh\"]\n",
    "embDims = [1024,256,128,64,32,16,12]\n",
    "metrics = [\"Accuracy\", \"MAE\", \"MSE\", \"MAPE\", \"MSLE\", \"Precision\", \"Recall\", \"AUC\",  \"BinaryCrossentropy\", \"RootMeanSquaredError\"]\n",
    "\n",
    "for act in output_activations:\n",
    "    for dim in embDims:\n",
    "        modelParamsList.append({\n",
    "            \"trainParams\": { \"epochs\": 10 },\n",
    "            \"buildParams\": {\n",
    "                \"embedding_dim\": dim,\n",
    "                \"layers\": layers,\n",
    "                \"output_activation\": act,\n",
    "                \"optimizer\": \"adam\",\n",
    "                \"learning_rate\": 0.001,\n",
    "                \"loss\": \"binary_crossentropy\" if act == \"sigmoid\" else \"mse\",\n",
    "                \"metrics\": metrics\n",
    "            }\n",
    "        })\n",
    "\n",
    "ts = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "run_all_experiments( groceryML.training_df, modelParamsList, f\"exp/keras/keras-1/{ts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b667118-e53a-4605-aa00-5f3e9b578fdf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###########################################################\n",
    "\n",
    "modelParamsList = []\n",
    "layers = [\n",
    "    { \"units\": 128, \"activation\": \"relu\" },\n",
    "    { \"units\": 128, \"activation\": \"relu\" },    \n",
    "    { \"units\": 128, \"activation\": \"relu\" },\n",
    "    { \"units\": 128, \"activation\": \"relu\" },\n",
    "    { \"units\": 128, \"activation\": \"relu\" },\n",
    "    \n",
    "    \n",
    "]\n",
    "output_activations = [\"sigmoid\", \"linear\", \"tanh\"]\n",
    "embDims = [1024,256,128,64,32,16,12]\n",
    "metrics = [\"Accuracy\", \"MAE\", \"MSE\", \"MAPE\", \"MSLE\", \"Precision\", \"Recall\", \"AUC\",  \"BinaryCrossentropy\", \"RootMeanSquaredError\"]\n",
    "\n",
    "for act in output_activations:\n",
    "    for dim in embDims:\n",
    "        modelParamsList.append({\n",
    "            \"trainParams\": { \"epochs\": 20 },\n",
    "            \"buildParams\": {\n",
    "                \"embedding_dim\": dim,\n",
    "                \"layers\": layers,\n",
    "                \"output_activation\": act,\n",
    "                \"optimizer\": \"adam\",\n",
    "                \"learning_rate\": 0.0001,\n",
    "                \"loss\": \"binary_crossentropy\" if act == \"sigmoid\" else \"mse\",\n",
    "                \"metrics\": metrics\n",
    "            }\n",
    "        })\n",
    "\n",
    "ts = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "run_all_experiments( groceryML.training_df, modelParamsList, f\"exp/keras/keras-1/{ts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5404e4-f977-40ab-8250-f34c86c037ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
